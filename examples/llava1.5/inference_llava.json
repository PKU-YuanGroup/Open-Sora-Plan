{
  "model_id": "llava",
  "text_decoder": {
      "num_layers": 32,
      "hidden_size": 4096,
      "num_attention_heads": 32,
      "num_query_groups": 32,
      "ffn_hidden_size": 11008,
      "add_bias_linear": false,
      "bias_activation_fusion": false,
      "gated_linear_unit": true,
      "apply_query_key_layer_scaling":false,
      "layernorm_zero_centered_gamma": false,
      "bias_dropout_fusion":false,
      "apply_rope_fusion": false,
      "attention_softmax_in_fp32": true,
      "attention_dropout": 0.0,
      "hidden_dropout": 0.0,
      "fp16": true,
      "params_dtype": "fp16",
      "deallocate_pipeline_outputs": true,
      "persist_layer_norm": true,
      "activation_func": "silu",
      "normalization": "RMSNorm",
      "language_vocab_size": 32000,
      "language_max_sequence_length": 4096,
      "lm_position_embedding_type": "rope",
      "is_encoder_decoder":false,
      "freeze": true,
      "ckpt_path": "/<your_vicuna_weights_path>/converted_vicuna.pt"
  },
  "image_encoder": {
      "vision_encoder": {
          "model_id": "clip",
          "num_layers": 24,
          "hidden_size": 1024,
          "num_attention_heads": 16,
          "num_query_groups": 16,
          "ffn_hidden_size": 4096,
          "post_layer_norm": false,
          "add_bias_linear": true,
          "add_qkv_bias": true,
          "hidden_dropout": 0.0,
          "attention_dropout": 0.0,
          "fp16": true,
          "params_dtype": "fp16",
          "gated_linear_unit": false,
          "kv_channels": 64,
          "layernorm_zero_centered_gamma": false,
          "bias_activation_fusion": false,
          "bias_dropout_fusion": false,
          "attention_softmax_in_fp32": true,
          "normalization": "LayerNorm",
          "apply_rope_fusion": false,
          "activation_func": "quick_gelu",
          "device": "npu",
          "add_class_token": true,
          "class_token_len": 1,
          "patch_size": 14,
          "image_size": 336,
          "freeze": true,
          "ckpt_path": "/<your_clip_weights_path>/converted_clip.pt"
      },
      "vision_projector": {
          "model_id": "mlp",
          "num_attention_heads": 1,
          "num_layers": 2,
          "gated_linear_unit": false,
          "bias_activation_fusion": false,
          "add_bias_linear": true,
          "input_size": 1024,
          "hidden_size": 4096,
          "ffn_hidden_size": 4096,
          "bf16": true,
          "params_dtype": "fp16",
          "activation_func": "gelu",
          "freeze": true,
          "ckpt_path": "/<your_mlp_weights_path>/mlp.pt"
      }
  },
  "text_encoder": null,
  "video_encoder": null,


  "dtype":"fp16",
  "device":"npu",
  "tokenizer":{
      "hub_backend": "hf",
      "autotokenizer_name": "AutoTokenizer",
      "from_pretrained": "llava_weights/vicuna-7b-v1.5",
      "local_files_only": false
  },
  "generation_config":{
      "bos_token_id": 1,
      "eos_token_id": 2,
      "max_length": 4096,
      "pad_token_id": 0,
      "temperature":0.2,
      "max_new_tokens":512,
      "output_attentions":false,
      "output_hidden_states":false,
      "use_cache":false,
      "decoder_start_token_id":null,
      "min_new_tokens":null,
      "min_length":0,
      "constraints":null,
      "num_beams":1,
      "do_sample":true,
      "force_words_ids":null,
      "top_k":50,
      "top_p":1.0,
      "prompt_lookup_num_tokens":null,
      "guidance_scale":null,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "diversity_penalty": 0.0,
      "early_stopping": false,
      "encoder_no_repeat_ngram_size": 0,
      "encoder_repetition_penalty": 1.0,
      "epsilon_cutoff": 0.0,
      "eta_cutoff": 0.0,
      "exponential_decay_length_penalty": null,
      "forced_bos_token_id": null,
      "forced_decoder_ids": null,
      "forced_eos_token_id": null,
      "length_penalty": 1.0,
      "low_memory": null,
      "max_time": null,
      "no_repeat_ngram_size": 0,
      "num_assistant_tokens": 5,
      "num_assistant_tokens_schedule": "heuristic",
      "num_beam_groups": 1,
      "num_return_sequences": 1,
      "output_scores": false,
      "penalty_alpha": null,
      "remove_invalid_values": false,
      "renormalize_logits": false,
      "repetition_penalty": 1.0,
      "return_dict_in_generate": false,
      "sequence_bias": null,
      "suppress_tokens": null,
      "typical_p": 1.0,
      "transformers_version": "4.31.0"
    },
    "image_processer_path": "clip-vit-large-patch14-336",
    "image_path":"examples/llava1.5/view.jpg",
    "prompts":"你好，描述一下这个图片"
  }