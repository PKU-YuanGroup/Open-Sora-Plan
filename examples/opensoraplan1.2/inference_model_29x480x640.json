{
    "ae": {
        "model_id": "casualvae",
        "from_pretrained": "./weights/vae/casualvae_statedict.pt",
        "dtype": "fp32",
        "output_dtype": "fp16",
        "decoder_spatial_upsample": [
            "",
            "SpatialUpsample2x",
            "Spatial2xTime2x3DUpsample",
            "Spatial2xTime2x3DUpsample"
        ],
        "decoder_temporal_upsample": [
            "",
            "",
            "",
            ""
        ],
        "encoder_conv_in": "Conv2d",
        "encoder_resnet_blocks": [
            "ResnetBlock2D",
            "ResnetBlock2D",
            "ResnetBlock3D",
            "ResnetBlock3D"
        ],
        "encoder_spatial_downsample": [
            "Downsample",
            "Spatial2xTime2x3DDownsample",
            "Spatial2xTime2x3DDownsample",
            ""
        ],
        "encoder_temporal_downsample": [
            "",
            "",
            "",
            ""
        ],
        "use_tiling": true,
        "tile_overlap_factor": 0.125,
        "vae_scale_factor":[4,8,8],
        "tile_sample_min_size":512,
        "tile_latent_min_size":64,
        "tile_sample_min_size_t":29,
        "tile_latent_min_size_t":8
    },
    "text_encoder": {
        "hub_backend": "hf",
        "model_id": "MT5",
        "from_pretrained": "./weights/google/mt5-xxl",
        "local_files_only": false,
        "low_cpu_mem_usage": true,
        "dtype": "fp16"
    },
    "tokenizer":{
        "hub_backend": "hf",
        "autotokenizer_name": "AutoTokenizer",
        "from_pretrained": "./opensoraplanv12/weights/mt5",
        "local_files_only": false
    },
    "predictor": {
        "dtype": "fp16",
        "model_id": "videodit",
        "num_layers" : 32,
        "num_heads": 24,
        "head_dim":96,
        "in_channels":4,
        "out_channels":4,
        "dropout":0.0,
        "cross_attention_dim":2304,
        "attention_bias":true,
        "input_size":[8, 60, 80],
        "patch_size":[1, 2, 2],
        "activation_fn":"gelu-approximate",
        "num_embeds_ada_norm":1000,
        "norm_type":"ada_norm_single",
        "norm_elementwise_affine":false,
        "norm_eps":1e-06,
        "caption_channels":4096,
        "interpolation_scale":[1.0, 1.0, 1.0],
        "use_rope":true,
        "from_pretrained": "./weights/29x480p/videodit_statedict.pth"
    },
    "diffusion": {
        "model_id": "PNDM",
        "num_inference_steps":50,
        "guidance_scale":5.0,
        "device":"npu"

    },
    "pipeline_config": {
        "use_attention_mask": true,
        "input_size": [29, 480, 640]
    },
    "micro_batch_size": 1,
    "frame_interval":1,
    "model_max_length": 512,
    "save_path":"./opensora_samples/samples/",
    "fps":24,
    "prompt":"examples/opensora1.0/samples_prompts.txt",
    "pipeline_class": "OpenSoraPlanPipeline",
    "device":"npu",
    "dtype": "fp16"
}

