[2024-09-18 09:19:28,881] torch.distributed.run: [WARNING] 
[2024-09-18 09:19:28,881] torch.distributed.run: [WARNING] *****************************************
[2024-09-18 09:19:28,881] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-09-18 09:19:28,881] torch.distributed.run: [WARNING] *****************************************
[2024-09-18 09:19:34,850] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:171: RuntimeWarning: torch.jit.script will be disabled by transfer_to_npu, which currently does not support it.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:209: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
[2024-09-18 09:19:34,948] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:171: RuntimeWarning: torch.jit.script will be disabled by transfer_to_npu, which currently does not support it.
  warnings.warn(msg, RuntimeWarning)
[2024-09-18 09:19:35,006] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
[2024-09-18 09:19:35,008] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:171: RuntimeWarning: torch.jit.script will be disabled by transfer_to_npu, which currently does not support it.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:171: RuntimeWarning: torch.jit.script will be disabled by transfer_to_npu, which currently does not support it.
  warnings.warn(msg, RuntimeWarning)
[2024-09-18 09:19:35,129] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:171: RuntimeWarning: torch.jit.script will be disabled by transfer_to_npu, which currently does not support it.
  warnings.warn(msg, RuntimeWarning)
[2024-09-18 09:19:35,232] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
[2024-09-18 09:19:35,273] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:171: RuntimeWarning: torch.jit.script will be disabled by transfer_to_npu, which currently does not support it.
  warnings.warn(msg, RuntimeWarning)
[2024-09-18 09:19:35,300] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:171: RuntimeWarning: torch.jit.script will be disabled by transfer_to_npu, which currently does not support it.
  warnings.warn(msg, RuntimeWarning)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:171: RuntimeWarning: torch.jit.script will be disabled by transfer_to_npu, which currently does not support it.
  warnings.warn(msg, RuntimeWarning)
skip replace _has_inf_or_nan
skip replace _has_inf_or_nan
skip replace _DeepSpeedEngine__check_params
skip replace __init__
skip replace _change_recovery_script_permissions
skip replace _DeepSpeedEngine__check_params
skip replace _copy_recovery_script
skip replace __init__
skip replace _get_expert_ckpt_name
skip replace _change_recovery_script_permissions
skip replace is_iterable_style_dataset
skip replace is_map_style_dataset
skip replace load_moe_state_dict
skip replace _copy_recovery_script
skip replace _get_expert_ckpt_name
skip replace is_iterable_style_dataset
skip replace is_map_style_dataset
skip replace load_moe_state_dict
skip replace _has_inf_or_nan
skip replace _DeepSpeedEngine__check_params
skip replace __init__
skip replace _change_recovery_script_permissions
skip replace _copy_recovery_script
skip replace _get_expert_ckpt_name
skip replace is_iterable_style_dataset
skip replace is_map_style_dataset
skip replace load_moe_state_dict
pid 411's current affinity list: 0-191
pid 411's new affinity list: 24-47
skip replace _has_inf_or_nan
skip replace _DeepSpeedEngine__check_params
skip replace __init__
skip replace _change_recovery_script_permissions
skip replace _copy_recovery_script
skip replace _get_expert_ckpt_name
skip replace is_iterable_style_dataset
skip replace is_map_style_dataset
skip replace load_moe_state_dict
The npu_config.on_npu is True
pid 412's current affinity list: 0-191
pid 412's new affinity list: 48-71
pid 415's current affinity list: 0-191
pid 415's new affinity list: 120-143
pid 410's current affinity list: 0-191
pid 410's new affinity list: 0-23
skip replace _has_inf_or_nan
skip replace _has_inf_or_nan
skip replace _DeepSpeedEngine__check_params
skip replace __init__
skip replace _change_recovery_script_permissions
skip replace _copy_recovery_script
skip replace _get_expert_ckpt_name
skip replace is_iterable_style_dataset
skip replace is_map_style_dataset
skip replace load_moe_state_dict
skip replace _DeepSpeedEngine__check_params
skip replace __init__
skip replace _change_recovery_script_permissions
skip replace _copy_recovery_script
skip replace _get_expert_ckpt_name
skip replace is_iterable_style_dataset
skip replace is_map_style_dataset
skip replace load_moe_state_dict
skip replace _has_inf_or_nan
skip replace _DeepSpeedEngine__check_params
skip replace __init__
skip replace _change_recovery_script_permissions
skip replace _copy_recovery_script
skip replace _get_expert_ckpt_name
skip replace is_iterable_style_dataset
skip replace is_map_style_dataset
skip replace load_moe_state_dict
skip replace _has_inf_or_nan
skip replace _DeepSpeedEngine__check_params
skip replace __init__
skip replace _change_recovery_script_permissions
skip replace _copy_recovery_script
skip replace _get_expert_ckpt_name
skip replace is_iterable_style_dataset
skip replace is_map_style_dataset
skip replace load_moe_state_dict
pid 413's current affinity list: 0-191
pid 413's new affinity list: 72-95
pid 414's current affinity list: 0-191
pid 414's new affinity list: 96-119
pid 417's current affinity list: 0-191
pid 417's new affinity list: 168-191
pid 416's current affinity list: 0-191
pid 416's new affinity list: 144-167
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/lightning_fabric/__init__.py:41: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/lightning_fabric/__init__.py:41: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/lightning_fabric/__init__.py:41: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/lightning_fabric/__init__.py:41: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/lightning_fabric/__init__.py:41: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/lightning_fabric/__init__.py:41: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/lightning_fabric/__init__.py:41: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/pytorch_lightning/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/pytorch_lightning/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/pytorch_lightning/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/pytorch_lightning/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/lightning_fabric/__init__.py:41: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/pytorch_lightning/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/pytorch_lightning/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/pytorch_lightning/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:20: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 0.29. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModelOutput`, instead.
  deprecate("Transformer2DModelOutput", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:20: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 0.29. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModelOutput`, instead.
  deprecate("Transformer2DModelOutput", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:20: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 0.29. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModelOutput`, instead.
  deprecate("Transformer2DModelOutput", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:20: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 0.29. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModelOutput`, instead.
  deprecate("Transformer2DModelOutput", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:25: FutureWarning: `Transformer2DModel` is deprecated and will be removed in version 0.29. Importing `Transformer2DModel` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModel`, instead.
  deprecate("Transformer2DModel", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:20: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 0.29. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModelOutput`, instead.
  deprecate("Transformer2DModelOutput", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:25: FutureWarning: `Transformer2DModel` is deprecated and will be removed in version 0.29. Importing `Transformer2DModel` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModel`, instead.
  deprecate("Transformer2DModel", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:20: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 0.29. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModelOutput`, instead.
  deprecate("Transformer2DModelOutput", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:25: FutureWarning: `Transformer2DModel` is deprecated and will be removed in version 0.29. Importing `Transformer2DModel` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModel`, instead.
  deprecate("Transformer2DModel", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:25: FutureWarning: `Transformer2DModel` is deprecated and will be removed in version 0.29. Importing `Transformer2DModel` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModel`, instead.
  deprecate("Transformer2DModel", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:25: FutureWarning: `Transformer2DModel` is deprecated and will be removed in version 0.29. Importing `Transformer2DModel` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModel`, instead.
  deprecate("Transformer2DModel", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:25: FutureWarning: `Transformer2DModel` is deprecated and will be removed in version 0.29. Importing `Transformer2DModel` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModel`, instead.
  deprecate("Transformer2DModel", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:20: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 0.29. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModelOutput`, instead.
  deprecate("Transformer2DModelOutput", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:25: FutureWarning: `Transformer2DModel` is deprecated and will be removed in version 0.29. Importing `Transformer2DModel` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModel`, instead.
  deprecate("Transformer2DModel", "0.29", deprecation_message)
[RANK-6]: Namespace(dataset='inpaint', data='scripts/train_data/video_data_debug.txt', sample_rate=1, train_fps=16, drop_short_ratio=0.0, speed_factor=1.0, num_frames=93, max_height=320, max_width=320, use_img_from_vid=False, use_image_num=0, model_max_length=512, cfg=0.1, dataloader_num_workers=0, train_batch_size=1, group_data=True, hw_stride=32, skip_low_resolution=True, force_resolution=False, trained_data_global_step=0, use_decord=True, model='OpenSoraInpaint-L/122', enable_8bit_t5=False, tile_overlap_factor=0.125, enable_tiling=False, compress_kv=False, attention_mode='xformers', use_rope=True, compress_kv_factor=1, interpolation_scale_h=1.0, interpolation_scale_w=1.0, interpolation_scale_t=1.0, downsampler=None, ae='WFVAEModel_D8_4x8x8', ae_path='/home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL', text_encoder_name='google/mt5-xxl', cache_dir='../../cache_dir/', pretrained=None, enable_stable_fp32=False, sparse1d=True, sparse2d=False, sparse_n=4, tile_sample_min_size=512, tile_sample_min_size_t=33, adapt_vae=False, use_motion=True, gradient_checkpointing=True, snr_gamma=None, use_ema=True, ema_decay=0.9999, ema_start_step=0, noise_offset=0.0, prediction_type='v_prediction', rescale_betas_zero_snr=True, num_sampling_steps=50, guidance_scale=2.5, enable_tracker=False, seed=1234, output_dir='/home/save_dir/runs/allinpaint_stage1', checkpoints_total_limit=None, checkpointing_steps=1000, resume_from_checkpoint='/home/save_dir/runs/allinpaint_stage1/checkpoint-13000', logging_dir='logs', report_to='wandb', num_train_epochs=100, max_train_steps=1000000, gradient_accumulation_steps=1, optimizer='adamW', learning_rate=1e-05, scale_lr=False, lr_warmup_steps=0, use_8bit_adam=False, adam_beta1=0.9, adam_beta2=0.999, prodigy_decouple=True, adam_weight_decay=0.01, adam_weight_decay_text_encoder=None, adam_epsilon=1e-08, prodigy_use_bias_correction=True, prodigy_safeguard_warmup=True, max_grad_norm=1.0, prodigy_beta3=None, lr_scheduler='constant', allow_tf32=True, mixed_precision='bf16', local_rank=-1, sp_size=1, train_sp_batch_size=1, t2v_ratio=0.0, i2v_ratio=0.0, transition_ratio=0.0, v2v_ratio=0.0, clear_video_ratio=0.0, Semantic_ratio=0.2, bbox_ratio=0.2, background_ratio=0.2, fixed_ratio=0.1, Semantic_expansion_ratio=0.1, fixed_bg_ratio=0.1, min_clear_ratio=0.25, default_text_ratio=0.0, pretrained_transformer_model_path='/home/image_data/captions/vpre_latest_134k/model_ema', yolomodel_pathorname='/home/image_data/hxy/Open-Sora-Plan/opensora/dataset/yolov9c-seg.pt', max_sequence_length=512)
[RANK-2]: Namespace(dataset='inpaint', data='scripts/train_data/video_data_debug.txt', sample_rate=1, train_fps=16, drop_short_ratio=0.0, speed_factor=1.0, num_frames=93, max_height=320, max_width=320, use_img_from_vid=False, use_image_num=0, model_max_length=512, cfg=0.1, dataloader_num_workers=0, train_batch_size=1, group_data=True, hw_stride=32, skip_low_resolution=True, force_resolution=False, trained_data_global_step=0, use_decord=True, model='OpenSoraInpaint-L/122', enable_8bit_t5=False, tile_overlap_factor=0.125, enable_tiling=False, compress_kv=False, attention_mode='xformers', use_rope=True, compress_kv_factor=1, interpolation_scale_h=1.0, interpolation_scale_w=1.0, interpolation_scale_t=1.0, downsampler=None, ae='WFVAEModel_D8_4x8x8', ae_path='/home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL', text_encoder_name='google/mt5-xxl', cache_dir='../../cache_dir/', pretrained=None, enable_stable_fp32=False, sparse1d=True, sparse2d=False, sparse_n=4, tile_sample_min_size=512, tile_sample_min_size_t=33, adapt_vae=False, use_motion=True, gradient_checkpointing=True, snr_gamma=None, use_ema=True, ema_decay=0.9999, ema_start_step=0, noise_offset=0.0, prediction_type='v_prediction', rescale_betas_zero_snr=True, num_sampling_steps=50, guidance_scale=2.5, enable_tracker=False, seed=1234, output_dir='/home/save_dir/runs/allinpaint_stage1', checkpoints_total_limit=None, checkpointing_steps=1000, resume_from_checkpoint='/home/save_dir/runs/allinpaint_stage1/checkpoint-13000', logging_dir='logs', report_to='wandb', num_train_epochs=100, max_train_steps=1000000, gradient_accumulation_steps=1, optimizer='adamW', learning_rate=1e-05, scale_lr=False, lr_warmup_steps=0, use_8bit_adam=False, adam_beta1=0.9, adam_beta2=0.999, prodigy_decouple=True, adam_weight_decay=0.01, adam_weight_decay_text_encoder=None, adam_epsilon=1e-08, prodigy_use_bias_correction=True, prodigy_safeguard_warmup=True, max_grad_norm=1.0, prodigy_beta3=None, lr_scheduler='constant', allow_tf32=True, mixed_precision='bf16', local_rank=-1, sp_size=1, train_sp_batch_size=1, t2v_ratio=0.0, i2v_ratio=0.0, transition_ratio=0.0, v2v_ratio=0.0, clear_video_ratio=0.0, Semantic_ratio=0.2, bbox_ratio=0.2, background_ratio=0.2, fixed_ratio=0.1, Semantic_expansion_ratio=0.1, fixed_bg_ratio=0.1, min_clear_ratio=0.25, default_text_ratio=0.0, pretrained_transformer_model_path='/home/image_data/captions/vpre_latest_134k/model_ema', yolomodel_pathorname='/home/image_data/hxy/Open-Sora-Plan/opensora/dataset/yolov9c-seg.pt', max_sequence_length=512)
[RANK-0]: Namespace(dataset='inpaint', data='scripts/train_data/video_data_debug.txt', sample_rate=1, train_fps=16, drop_short_ratio=0.0, speed_factor=1.0, num_frames=93, max_height=320, max_width=320, use_img_from_vid=False, use_image_num=0, model_max_length=512, cfg=0.1, dataloader_num_workers=0, train_batch_size=1, group_data=True, hw_stride=32, skip_low_resolution=True, force_resolution=False, trained_data_global_step=0, use_decord=True, model='OpenSoraInpaint-L/122', enable_8bit_t5=False, tile_overlap_factor=0.125, enable_tiling=False, compress_kv=False, attention_mode='xformers', use_rope=True, compress_kv_factor=1, interpolation_scale_h=1.0, interpolation_scale_w=1.0, interpolation_scale_t=1.0, downsampler=None, ae='WFVAEModel_D8_4x8x8', ae_path='/home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL', text_encoder_name='google/mt5-xxl', cache_dir='../../cache_dir/', pretrained=None, enable_stable_fp32=False, sparse1d=True, sparse2d=False, sparse_n=4, tile_sample_min_size=512, tile_sample_min_size_t=33, adapt_vae=False, use_motion=True, gradient_checkpointing=True, snr_gamma=None, use_ema=True, ema_decay=0.9999, ema_start_step=0, noise_offset=0.0, prediction_type='v_prediction', rescale_betas_zero_snr=True, num_sampling_steps=50, guidance_scale=2.5, enable_tracker=False, seed=1234, output_dir='/home/save_dir/runs/allinpaint_stage1', checkpoints_total_limit=None, checkpointing_steps=1000, resume_from_checkpoint='/home/save_dir/runs/allinpaint_stage1/checkpoint-13000', logging_dir='logs', report_to='wandb', num_train_epochs=100, max_train_steps=1000000, gradient_accumulation_steps=1, optimizer='adamW', learning_rate=1e-05, scale_lr=False, lr_warmup_steps=0, use_8bit_adam=False, adam_beta1=0.9, adam_beta2=0.999, prodigy_decouple=True, adam_weight_decay=0.01, adam_weight_decay_text_encoder=None, adam_epsilon=1e-08, prodigy_use_bias_correction=True, prodigy_safeguard_warmup=True, max_grad_norm=1.0, prodigy_beta3=None, lr_scheduler='constant', allow_tf32=True, mixed_precision='bf16', local_rank=-1, sp_size=1, train_sp_batch_size=1, t2v_ratio=0.0, i2v_ratio=0.0, transition_ratio=0.0, v2v_ratio=0.0, clear_video_ratio=0.0, Semantic_ratio=0.2, bbox_ratio=0.2, background_ratio=0.2, fixed_ratio=0.1, Semantic_expansion_ratio=0.1, fixed_bg_ratio=0.1, min_clear_ratio=0.25, default_text_ratio=0.0, pretrained_transformer_model_path='/home/image_data/captions/vpre_latest_134k/model_ema', yolomodel_pathorname='/home/image_data/hxy/Open-Sora-Plan/opensora/dataset/yolov9c-seg.pt', max_sequence_length=512)
[RANK-3]: Namespace(dataset='inpaint', data='scripts/train_data/video_data_debug.txt', sample_rate=1, train_fps=16, drop_short_ratio=0.0, speed_factor=1.0, num_frames=93, max_height=320, max_width=320, use_img_from_vid=False, use_image_num=0, model_max_length=512, cfg=0.1, dataloader_num_workers=0, train_batch_size=1, group_data=True, hw_stride=32, skip_low_resolution=True, force_resolution=False, trained_data_global_step=0, use_decord=True, model='OpenSoraInpaint-L/122', enable_8bit_t5=False, tile_overlap_factor=0.125, enable_tiling=False, compress_kv=False, attention_mode='xformers', use_rope=True, compress_kv_factor=1, interpolation_scale_h=1.0, interpolation_scale_w=1.0, interpolation_scale_t=1.0, downsampler=None, ae='WFVAEModel_D8_4x8x8', ae_path='/home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL', text_encoder_name='google/mt5-xxl', cache_dir='../../cache_dir/', pretrained=None, enable_stable_fp32=False, sparse1d=True, sparse2d=False, sparse_n=4, tile_sample_min_size=512, tile_sample_min_size_t=33, adapt_vae=False, use_motion=True, gradient_checkpointing=True, snr_gamma=None, use_ema=True, ema_decay=0.9999, ema_start_step=0, noise_offset=0.0, prediction_type='v_prediction', rescale_betas_zero_snr=True, num_sampling_steps=50, guidance_scale=2.5, enable_tracker=False, seed=1234, output_dir='/home/save_dir/runs/allinpaint_stage1', checkpoints_total_limit=None, checkpointing_steps=1000, resume_from_checkpoint='/home/save_dir/runs/allinpaint_stage1/checkpoint-13000', logging_dir='logs', report_to='wandb', num_train_epochs=100, max_train_steps=1000000, gradient_accumulation_steps=1, optimizer='adamW', learning_rate=1e-05, scale_lr=False, lr_warmup_steps=0, use_8bit_adam=False, adam_beta1=0.9, adam_beta2=0.999, prodigy_decouple=True, adam_weight_decay=0.01, adam_weight_decay_text_encoder=None, adam_epsilon=1e-08, prodigy_use_bias_correction=True, prodigy_safeguard_warmup=True, max_grad_norm=1.0, prodigy_beta3=None, lr_scheduler='constant', allow_tf32=True, mixed_precision='bf16', local_rank=-1, sp_size=1, train_sp_batch_size=1, t2v_ratio=0.0, i2v_ratio=0.0, transition_ratio=0.0, v2v_ratio=0.0, clear_video_ratio=0.0, Semantic_ratio=0.2, bbox_ratio=0.2, background_ratio=0.2, fixed_ratio=0.1, Semantic_expansion_ratio=0.1, fixed_bg_ratio=0.1, min_clear_ratio=0.25, default_text_ratio=0.0, pretrained_transformer_model_path='/home/image_data/captions/vpre_latest_134k/model_ema', yolomodel_pathorname='/home/image_data/hxy/Open-Sora-Plan/opensora/dataset/yolov9c-seg.pt', max_sequence_length=512)
[RANK-1]: Namespace(dataset='inpaint', data='scripts/train_data/video_data_debug.txt', sample_rate=1, train_fps=16, drop_short_ratio=0.0, speed_factor=1.0, num_frames=93, max_height=320, max_width=320, use_img_from_vid=False, use_image_num=0, model_max_length=512, cfg=0.1, dataloader_num_workers=0, train_batch_size=1, group_data=True, hw_stride=32, skip_low_resolution=True, force_resolution=False, trained_data_global_step=0, use_decord=True, model='OpenSoraInpaint-L/122', enable_8bit_t5=False, tile_overlap_factor=0.125, enable_tiling=False, compress_kv=False, attention_mode='xformers', use_rope=True, compress_kv_factor=1, interpolation_scale_h=1.0, interpolation_scale_w=1.0, interpolation_scale_t=1.0, downsampler=None, ae='WFVAEModel_D8_4x8x8', ae_path='/home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL', text_encoder_name='google/mt5-xxl', cache_dir='../../cache_dir/', pretrained=None, enable_stable_fp32=False, sparse1d=True, sparse2d=False, sparse_n=4, tile_sample_min_size=512, tile_sample_min_size_t=33, adapt_vae=False, use_motion=True, gradient_checkpointing=True, snr_gamma=None, use_ema=True, ema_decay=0.9999, ema_start_step=0, noise_offset=0.0, prediction_type='v_prediction', rescale_betas_zero_snr=True, num_sampling_steps=50, guidance_scale=2.5, enable_tracker=False, seed=1234, output_dir='/home/save_dir/runs/allinpaint_stage1', checkpoints_total_limit=None, checkpointing_steps=1000, resume_from_checkpoint='/home/save_dir/runs/allinpaint_stage1/checkpoint-13000', logging_dir='logs', report_to='wandb', num_train_epochs=100, max_train_steps=1000000, gradient_accumulation_steps=1, optimizer='adamW', learning_rate=1e-05, scale_lr=False, lr_warmup_steps=0, use_8bit_adam=False, adam_beta1=0.9, adam_beta2=0.999, prodigy_decouple=True, adam_weight_decay=0.01, adam_weight_decay_text_encoder=None, adam_epsilon=1e-08, prodigy_use_bias_correction=True, prodigy_safeguard_warmup=True, max_grad_norm=1.0, prodigy_beta3=None, lr_scheduler='constant', allow_tf32=True, mixed_precision='bf16', local_rank=-1, sp_size=1, train_sp_batch_size=1, t2v_ratio=0.0, i2v_ratio=0.0, transition_ratio=0.0, v2v_ratio=0.0, clear_video_ratio=0.0, Semantic_ratio=0.2, bbox_ratio=0.2, background_ratio=0.2, fixed_ratio=0.1, Semantic_expansion_ratio=0.1, fixed_bg_ratio=0.1, min_clear_ratio=0.25, default_text_ratio=0.0, pretrained_transformer_model_path='/home/image_data/captions/vpre_latest_134k/model_ema', yolomodel_pathorname='/home/image_data/hxy/Open-Sora-Plan/opensora/dataset/yolov9c-seg.pt', max_sequence_length=512)
[RANK-5]: Namespace(dataset='inpaint', data='scripts/train_data/video_data_debug.txt', sample_rate=1, train_fps=16, drop_short_ratio=0.0, speed_factor=1.0, num_frames=93, max_height=320, max_width=320, use_img_from_vid=False, use_image_num=0, model_max_length=512, cfg=0.1, dataloader_num_workers=0, train_batch_size=1, group_data=True, hw_stride=32, skip_low_resolution=True, force_resolution=False, trained_data_global_step=0, use_decord=True, model='OpenSoraInpaint-L/122', enable_8bit_t5=False, tile_overlap_factor=0.125, enable_tiling=False, compress_kv=False, attention_mode='xformers', use_rope=True, compress_kv_factor=1, interpolation_scale_h=1.0, interpolation_scale_w=1.0, interpolation_scale_t=1.0, downsampler=None, ae='WFVAEModel_D8_4x8x8', ae_path='/home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL', text_encoder_name='google/mt5-xxl', cache_dir='../../cache_dir/', pretrained=None, enable_stable_fp32=False, sparse1d=True, sparse2d=False, sparse_n=4, tile_sample_min_size=512, tile_sample_min_size_t=33, adapt_vae=False, use_motion=True, gradient_checkpointing=True, snr_gamma=None, use_ema=True, ema_decay=0.9999, ema_start_step=0, noise_offset=0.0, prediction_type='v_prediction', rescale_betas_zero_snr=True, num_sampling_steps=50, guidance_scale=2.5, enable_tracker=False, seed=1234, output_dir='/home/save_dir/runs/allinpaint_stage1', checkpoints_total_limit=None, checkpointing_steps=1000, resume_from_checkpoint='/home/save_dir/runs/allinpaint_stage1/checkpoint-13000', logging_dir='logs', report_to='wandb', num_train_epochs=100, max_train_steps=1000000, gradient_accumulation_steps=1, optimizer='adamW', learning_rate=1e-05, scale_lr=False, lr_warmup_steps=0, use_8bit_adam=False, adam_beta1=0.9, adam_beta2=0.999, prodigy_decouple=True, adam_weight_decay=0.01, adam_weight_decay_text_encoder=None, adam_epsilon=1e-08, prodigy_use_bias_correction=True, prodigy_safeguard_warmup=True, max_grad_norm=1.0, prodigy_beta3=None, lr_scheduler='constant', allow_tf32=True, mixed_precision='bf16', local_rank=-1, sp_size=1, train_sp_batch_size=1, t2v_ratio=0.0, i2v_ratio=0.0, transition_ratio=0.0, v2v_ratio=0.0, clear_video_ratio=0.0, Semantic_ratio=0.2, bbox_ratio=0.2, background_ratio=0.2, fixed_ratio=0.1, Semantic_expansion_ratio=0.1, fixed_bg_ratio=0.1, min_clear_ratio=0.25, default_text_ratio=0.0, pretrained_transformer_model_path='/home/image_data/captions/vpre_latest_134k/model_ema', yolomodel_pathorname='/home/image_data/hxy/Open-Sora-Plan/opensora/dataset/yolov9c-seg.pt', max_sequence_length=512)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/deepspeed/comm/comm.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  utils.logger.warn("HCCL backend in DeepSpeed not yet implemented")
[2024-09-18 09:19:49,537] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2024-09-18 09:19:49,537] [INFO] [comm.py:637:init_distributed] cdb=None
[RANK-4]: Namespace(dataset='inpaint', data='scripts/train_data/video_data_debug.txt', sample_rate=1, train_fps=16, drop_short_ratio=0.0, speed_factor=1.0, num_frames=93, max_height=320, max_width=320, use_img_from_vid=False, use_image_num=0, model_max_length=512, cfg=0.1, dataloader_num_workers=0, train_batch_size=1, group_data=True, hw_stride=32, skip_low_resolution=True, force_resolution=False, trained_data_global_step=0, use_decord=True, model='OpenSoraInpaint-L/122', enable_8bit_t5=False, tile_overlap_factor=0.125, enable_tiling=False, compress_kv=False, attention_mode='xformers', use_rope=True, compress_kv_factor=1, interpolation_scale_h=1.0, interpolation_scale_w=1.0, interpolation_scale_t=1.0, downsampler=None, ae='WFVAEModel_D8_4x8x8', ae_path='/home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL', text_encoder_name='google/mt5-xxl', cache_dir='../../cache_dir/', pretrained=None, enable_stable_fp32=False, sparse1d=True, sparse2d=False, sparse_n=4, tile_sample_min_size=512, tile_sample_min_size_t=33, adapt_vae=False, use_motion=True, gradient_checkpointing=True, snr_gamma=None, use_ema=True, ema_decay=0.9999, ema_start_step=0, noise_offset=0.0, prediction_type='v_prediction', rescale_betas_zero_snr=True, num_sampling_steps=50, guidance_scale=2.5, enable_tracker=False, seed=1234, output_dir='/home/save_dir/runs/allinpaint_stage1', checkpoints_total_limit=None, checkpointing_steps=1000, resume_from_checkpoint='/home/save_dir/runs/allinpaint_stage1/checkpoint-13000', logging_dir='logs', report_to='wandb', num_train_epochs=100, max_train_steps=1000000, gradient_accumulation_steps=1, optimizer='adamW', learning_rate=1e-05, scale_lr=False, lr_warmup_steps=0, use_8bit_adam=False, adam_beta1=0.9, adam_beta2=0.999, prodigy_decouple=True, adam_weight_decay=0.01, adam_weight_decay_text_encoder=None, adam_epsilon=1e-08, prodigy_use_bias_correction=True, prodigy_safeguard_warmup=True, max_grad_norm=1.0, prodigy_beta3=None, lr_scheduler='constant', allow_tf32=True, mixed_precision='bf16', local_rank=-1, sp_size=1, train_sp_batch_size=1, t2v_ratio=0.0, i2v_ratio=0.0, transition_ratio=0.0, v2v_ratio=0.0, clear_video_ratio=0.0, Semantic_ratio=0.2, bbox_ratio=0.2, background_ratio=0.2, fixed_ratio=0.1, Semantic_expansion_ratio=0.1, fixed_bg_ratio=0.1, min_clear_ratio=0.25, default_text_ratio=0.0, pretrained_transformer_model_path='/home/image_data/captions/vpre_latest_134k/model_ema', yolomodel_pathorname='/home/image_data/hxy/Open-Sora-Plan/opensora/dataset/yolov9c-seg.pt', max_sequence_length=512)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/deepspeed/comm/comm.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  utils.logger.warn("HCCL backend in DeepSpeed not yet implemented")
[2024-09-18 09:19:49,539] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/deepspeed/comm/comm.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  utils.logger.warn("HCCL backend in DeepSpeed not yet implemented")
[2024-09-18 09:19:49,539] [INFO] [comm.py:637:init_distributed] cdb=None
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/deepspeed/comm/comm.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  utils.logger.warn("HCCL backend in DeepSpeed not yet implemented")
[2024-09-18 09:19:49,539] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2024-09-18 09:19:49,540] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-09-18 09:19:49,540] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend hccl
[2024-09-18 09:19:49,540] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2024-09-18 09:19:49,540] [INFO] [comm.py:637:init_distributed] cdb=None
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/deepspeed/comm/comm.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  utils.logger.warn("HCCL backend in DeepSpeed not yet implemented")
[2024-09-18 09:19:49,541] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2024-09-18 09:19:49,542] [INFO] [comm.py:637:init_distributed] cdb=None
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/deepspeed/comm/comm.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  utils.logger.warn("HCCL backend in DeepSpeed not yet implemented")
[2024-09-18 09:19:49,542] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2024-09-18 09:19:49,543] [INFO] [comm.py:637:init_distributed] cdb=None
09/18/2024 09:19:49 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: hccl
Num processes: 8
Process index: 6
Local process index: 6
Device: npu:6

Mixed precision type: bf16
ds_config: {'fp16': {'enabled': False, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': True}, 'communication_data_type': 'fp32', 'gradient_clipping': 1.0, 'train_micro_batch_size_per_gpu': 'auto', 'train_batch_size': 'auto', 'gradient_accumulation_steps': 'auto', 'zero_optimization': {'stage': 2, 'overlap_comm': True, 'allgather_bucket_size': 536870912, 'contiguous_gradients': True, 'reduce_bucket_size': 536870912}, 'steps_per_print': inf}

/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/configuration_utils.py:244: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.load_config(...) followed by <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
Detected kernel version 4.19.90, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
09/18/2024 09:19:49 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: hccl
Num processes: 8
Process index: 2
Local process index: 2
Device: npu:2

Mixed precision type: bf16
ds_config: {'fp16': {'enabled': False, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': True}, 'communication_data_type': 'fp32', 'gradient_clipping': 1.0, 'train_micro_batch_size_per_gpu': 'auto', 'train_batch_size': 'auto', 'gradient_accumulation_steps': 'auto', 'zero_optimization': {'stage': 2, 'overlap_comm': True, 'allgather_bucket_size': 536870912, 'contiguous_gradients': True, 'reduce_bucket_size': 536870912}, 'steps_per_print': inf}

09/18/2024 09:19:49 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: hccl
Num processes: 8
Process index: 0
Local process index: 0
Device: npu:0

Mixed precision type: bf16
ds_config: {'fp16': {'enabled': False, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': True}, 'communication_data_type': 'fp32', 'gradient_clipping': 1.0, 'train_micro_batch_size_per_gpu': 'auto', 'train_batch_size': 'auto', 'gradient_accumulation_steps': 'auto', 'zero_optimization': {'stage': 2, 'overlap_comm': True, 'allgather_bucket_size': 536870912, 'contiguous_gradients': True, 'reduce_bucket_size': 536870912}, 'steps_per_print': inf}

09/18/2024 09:19:49 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: hccl
Num processes: 8
Process index: 3
Local process index: 3
Device: npu:3

Mixed precision type: bf16
ds_config: {'fp16': {'enabled': False, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': True}, 'communication_data_type': 'fp32', 'gradient_clipping': 1.0, 'train_micro_batch_size_per_gpu': 'auto', 'train_batch_size': 'auto', 'gradient_accumulation_steps': 'auto', 'zero_optimization': {'stage': 2, 'overlap_comm': True, 'allgather_bucket_size': 536870912, 'contiguous_gradients': True, 'reduce_bucket_size': 536870912}, 'steps_per_print': inf}

/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/deepspeed/comm/comm.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  utils.logger.warn("HCCL backend in DeepSpeed not yet implemented")
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/configuration_utils.py:244: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.load_config(...) followed by <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
[2024-09-18 09:19:49,550] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2024-09-18 09:19:49,550] [INFO] [comm.py:637:init_distributed] cdb=None
09/18/2024 09:19:49 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: hccl
Num processes: 8
Process index: 1
Local process index: 1
Device: npu:1

Mixed precision type: bf16
ds_config: {'fp16': {'enabled': False, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': True}, 'communication_data_type': 'fp32', 'gradient_clipping': 1.0, 'train_micro_batch_size_per_gpu': 'auto', 'train_batch_size': 'auto', 'gradient_accumulation_steps': 'auto', 'zero_optimization': {'stage': 2, 'overlap_comm': True, 'allgather_bucket_size': 536870912, 'contiguous_gradients': True, 'reduce_bucket_size': 536870912}, 'steps_per_print': inf}

/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/configuration_utils.py:244: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.load_config(...) followed by <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/configuration_utils.py:244: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.load_config(...) followed by <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/configuration_utils.py:244: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.load_config(...) followed by <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
09/18/2024 09:19:49 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: hccl
Num processes: 8
Process index: 5
Local process index: 5
Device: npu:5

Mixed precision type: bf16
ds_config: {'fp16': {'enabled': False, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': True}, 'communication_data_type': 'fp32', 'gradient_clipping': 1.0, 'train_micro_batch_size_per_gpu': 'auto', 'train_batch_size': 'auto', 'gradient_accumulation_steps': 'auto', 'zero_optimization': {'stage': 2, 'overlap_comm': True, 'allgather_bucket_size': 536870912, 'contiguous_gradients': True, 'reduce_bucket_size': 536870912}, 'steps_per_print': inf}

/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/configuration_utils.py:244: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.load_config(...) followed by <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
09/18/2024 09:19:49 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: hccl
Num processes: 8
Process index: 4
Local process index: 4
Device: npu:4

Mixed precision type: bf16
ds_config: {'fp16': {'enabled': False, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': True}, 'communication_data_type': 'fp32', 'gradient_clipping': 1.0, 'train_micro_batch_size_per_gpu': 'auto', 'train_batch_size': 'auto', 'gradient_accumulation_steps': 'auto', 'zero_optimization': {'stage': 2, 'overlap_comm': True, 'allgather_bucket_size': 536870912, 'contiguous_gradients': True, 'reduce_bucket_size': 536870912}, 'steps_per_print': inf}

/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/configuration_utils.py:244: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.load_config(...) followed by <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/pytorch_lightning/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:20: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 0.29. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModelOutput`, instead.
  deprecate("Transformer2DModelOutput", "0.29", deprecation_message)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/models/transformer_2d.py:25: FutureWarning: `Transformer2DModel` is deprecated and will be removed in version 0.29. Importing `Transformer2DModel` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.transformers.transformer_2d import Transformer2DModel`, instead.
  deprecate("Transformer2DModel", "0.29", deprecation_message)
[RANK-7]: Namespace(dataset='inpaint', data='scripts/train_data/video_data_debug.txt', sample_rate=1, train_fps=16, drop_short_ratio=0.0, speed_factor=1.0, num_frames=93, max_height=320, max_width=320, use_img_from_vid=False, use_image_num=0, model_max_length=512, cfg=0.1, dataloader_num_workers=0, train_batch_size=1, group_data=True, hw_stride=32, skip_low_resolution=True, force_resolution=False, trained_data_global_step=0, use_decord=True, model='OpenSoraInpaint-L/122', enable_8bit_t5=False, tile_overlap_factor=0.125, enable_tiling=False, compress_kv=False, attention_mode='xformers', use_rope=True, compress_kv_factor=1, interpolation_scale_h=1.0, interpolation_scale_w=1.0, interpolation_scale_t=1.0, downsampler=None, ae='WFVAEModel_D8_4x8x8', ae_path='/home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL', text_encoder_name='google/mt5-xxl', cache_dir='../../cache_dir/', pretrained=None, enable_stable_fp32=False, sparse1d=True, sparse2d=False, sparse_n=4, tile_sample_min_size=512, tile_sample_min_size_t=33, adapt_vae=False, use_motion=True, gradient_checkpointing=True, snr_gamma=None, use_ema=True, ema_decay=0.9999, ema_start_step=0, noise_offset=0.0, prediction_type='v_prediction', rescale_betas_zero_snr=True, num_sampling_steps=50, guidance_scale=2.5, enable_tracker=False, seed=1234, output_dir='/home/save_dir/runs/allinpaint_stage1', checkpoints_total_limit=None, checkpointing_steps=1000, resume_from_checkpoint='/home/save_dir/runs/allinpaint_stage1/checkpoint-13000', logging_dir='logs', report_to='wandb', num_train_epochs=100, max_train_steps=1000000, gradient_accumulation_steps=1, optimizer='adamW', learning_rate=1e-05, scale_lr=False, lr_warmup_steps=0, use_8bit_adam=False, adam_beta1=0.9, adam_beta2=0.999, prodigy_decouple=True, adam_weight_decay=0.01, adam_weight_decay_text_encoder=None, adam_epsilon=1e-08, prodigy_use_bias_correction=True, prodigy_safeguard_warmup=True, max_grad_norm=1.0, prodigy_beta3=None, lr_scheduler='constant', allow_tf32=True, mixed_precision='bf16', local_rank=-1, sp_size=1, train_sp_batch_size=1, t2v_ratio=0.0, i2v_ratio=0.0, transition_ratio=0.0, v2v_ratio=0.0, clear_video_ratio=0.0, Semantic_ratio=0.2, bbox_ratio=0.2, background_ratio=0.2, fixed_ratio=0.1, Semantic_expansion_ratio=0.1, fixed_bg_ratio=0.1, min_clear_ratio=0.25, default_text_ratio=0.0, pretrained_transformer_model_path='/home/image_data/captions/vpre_latest_134k/model_ema', yolomodel_pathorname='/home/image_data/hxy/Open-Sora-Plan/opensora/dataset/yolov9c-seg.pt', max_sequence_length=512)
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/deepspeed/comm/comm.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  utils.logger.warn("HCCL backend in DeepSpeed not yet implemented")
[2024-09-18 09:19:50,682] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2024-09-18 09:19:50,682] [INFO] [comm.py:637:init_distributed] cdb=None
09/18/2024 09:19:50 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: hccl
Num processes: 8
Process index: 7
Local process index: 7
Device: npu:7

Mixed precision type: bf16
ds_config: {'fp16': {'enabled': False, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': True}, 'communication_data_type': 'fp32', 'gradient_clipping': 1.0, 'train_micro_batch_size_per_gpu': 'auto', 'train_batch_size': 'auto', 'gradient_accumulation_steps': 'auto', 'zero_optimization': {'stage': 2, 'overlap_comm': True, 'allgather_bucket_size': 536870912, 'contiguous_gradients': True, 'reduce_bucket_size': 536870912}, 'steps_per_print': inf}

/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/diffusers/configuration_utils.py:244: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.load_config(...) followed by <class 'opensora.models.causalvideovae.model.vae.modeling_wfvae.WFVAEModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)
init from /home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL/wfvae.ckpt
Load from ema model!
init from /home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL/wfvae.ckpt
Load from ema model!
init from /home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL/wfvae.ckpt
Load from ema model!
init from /home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL/wfvae.ckpt
Load from ema model!
init from /home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL/wfvae.ckpt
Load from ema model!
['encoder.wavelet_tranform_3d.h_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_conv.conv.weight', 'encoder.wavelet_tranform_3d.h_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_v_conv.conv.weight', 'encoder.wavelet_tranform_2d.aa', 'encoder.wavelet_tranform_2d.ad', 'encoder.wavelet_tranform_2d.da', 'encoder.wavelet_tranform_2d.dd', 'decoder.inverse_wavelet_tranform_3d.h', 'decoder.inverse_wavelet_tranform_3d.g', 'decoder.inverse_wavelet_tranform_3d.hh', 'decoder.inverse_wavelet_tranform_3d.gh', 'decoder.inverse_wavelet_tranform_3d.h_v', 'decoder.inverse_wavelet_tranform_3d.g_v', 'decoder.inverse_wavelet_tranform_3d.hh_v', 'decoder.inverse_wavelet_tranform_3d.gh_v', 'decoder.inverse_wavelet_tranform_2d.aa', 'decoder.inverse_wavelet_tranform_2d.ad', 'decoder.inverse_wavelet_tranform_2d.da', 'decoder.inverse_wavelet_tranform_2d.dd'] []
['encoder.wavelet_tranform_3d.h_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_conv.conv.weight', 'encoder.wavelet_tranform_3d.h_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_v_conv.conv.weight', 'encoder.wavelet_tranform_2d.aa', 'encoder.wavelet_tranform_2d.ad', 'encoder.wavelet_tranform_2d.da', 'encoder.wavelet_tranform_2d.dd', 'decoder.inverse_wavelet_tranform_3d.h', 'decoder.inverse_wavelet_tranform_3d.g', 'decoder.inverse_wavelet_tranform_3d.hh', 'decoder.inverse_wavelet_tranform_3d.gh', 'decoder.inverse_wavelet_tranform_3d.h_v', 'decoder.inverse_wavelet_tranform_3d.g_v', 'decoder.inverse_wavelet_tranform_3d.hh_v', 'decoder.inverse_wavelet_tranform_3d.gh_v', 'decoder.inverse_wavelet_tranform_2d.aa', 'decoder.inverse_wavelet_tranform_2d.ad', 'decoder.inverse_wavelet_tranform_2d.da', 'decoder.inverse_wavelet_tranform_2d.dd'] []
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
init from /home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL/wfvae.ckpt
Load from ema model!
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
init from /home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL/wfvae.ckpt
Load from ema model!
['encoder.wavelet_tranform_3d.h_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_conv.conv.weight', 'encoder.wavelet_tranform_3d.h_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_v_conv.conv.weight', 'encoder.wavelet_tranform_2d.aa', 'encoder.wavelet_tranform_2d.ad', 'encoder.wavelet_tranform_2d.da', 'encoder.wavelet_tranform_2d.dd', 'decoder.inverse_wavelet_tranform_3d.h', 'decoder.inverse_wavelet_tranform_3d.g', 'decoder.inverse_wavelet_tranform_3d.hh', 'decoder.inverse_wavelet_tranform_3d.gh', 'decoder.inverse_wavelet_tranform_3d.h_v', 'decoder.inverse_wavelet_tranform_3d.g_v', 'decoder.inverse_wavelet_tranform_3d.hh_v', 'decoder.inverse_wavelet_tranform_3d.gh_v', 'decoder.inverse_wavelet_tranform_2d.aa', 'decoder.inverse_wavelet_tranform_2d.ad', 'decoder.inverse_wavelet_tranform_2d.da', 'decoder.inverse_wavelet_tranform_2d.dd'] []
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
['encoder.wavelet_tranform_3d.h_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_conv.conv.weight', 'encoder.wavelet_tranform_3d.h_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_v_conv.conv.weight', 'encoder.wavelet_tranform_2d.aa', 'encoder.wavelet_tranform_2d.ad', 'encoder.wavelet_tranform_2d.da', 'encoder.wavelet_tranform_2d.dd', 'decoder.inverse_wavelet_tranform_3d.h', 'decoder.inverse_wavelet_tranform_3d.g', 'decoder.inverse_wavelet_tranform_3d.hh', 'decoder.inverse_wavelet_tranform_3d.gh', 'decoder.inverse_wavelet_tranform_3d.h_v', 'decoder.inverse_wavelet_tranform_3d.g_v', 'decoder.inverse_wavelet_tranform_3d.hh_v', 'decoder.inverse_wavelet_tranform_3d.gh_v', 'decoder.inverse_wavelet_tranform_2d.aa', 'decoder.inverse_wavelet_tranform_2d.ad', 'decoder.inverse_wavelet_tranform_2d.da', 'decoder.inverse_wavelet_tranform_2d.dd'] []
['encoder.wavelet_tranform_3d.h_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_conv.conv.weight', 'encoder.wavelet_tranform_3d.h_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_v_conv.conv.weight', 'encoder.wavelet_tranform_2d.aa', 'encoder.wavelet_tranform_2d.ad', 'encoder.wavelet_tranform_2d.da', 'encoder.wavelet_tranform_2d.dd', 'decoder.inverse_wavelet_tranform_3d.h', 'decoder.inverse_wavelet_tranform_3d.g', 'decoder.inverse_wavelet_tranform_3d.hh', 'decoder.inverse_wavelet_tranform_3d.gh', 'decoder.inverse_wavelet_tranform_3d.h_v', 'decoder.inverse_wavelet_tranform_3d.g_v', 'decoder.inverse_wavelet_tranform_3d.hh_v', 'decoder.inverse_wavelet_tranform_3d.gh_v', 'decoder.inverse_wavelet_tranform_2d.aa', 'decoder.inverse_wavelet_tranform_2d.ad', 'decoder.inverse_wavelet_tranform_2d.da', 'decoder.inverse_wavelet_tranform_2d.dd'] []
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
['encoder.wavelet_tranform_3d.h_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_conv.conv.weight', 'encoder.wavelet_tranform_3d.h_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_v_conv.conv.weight', 'encoder.wavelet_tranform_2d.aa', 'encoder.wavelet_tranform_2d.ad', 'encoder.wavelet_tranform_2d.da', 'encoder.wavelet_tranform_2d.dd', 'decoder.inverse_wavelet_tranform_3d.h', 'decoder.inverse_wavelet_tranform_3d.g', 'decoder.inverse_wavelet_tranform_3d.hh', 'decoder.inverse_wavelet_tranform_3d.gh', 'decoder.inverse_wavelet_tranform_3d.h_v', 'decoder.inverse_wavelet_tranform_3d.g_v', 'decoder.inverse_wavelet_tranform_3d.hh_v', 'decoder.inverse_wavelet_tranform_3d.gh_v', 'decoder.inverse_wavelet_tranform_2d.aa', 'decoder.inverse_wavelet_tranform_2d.ad', 'decoder.inverse_wavelet_tranform_2d.da', 'decoder.inverse_wavelet_tranform_2d.dd'] []
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
['encoder.wavelet_tranform_3d.h_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_conv.conv.weight', 'encoder.wavelet_tranform_3d.h_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_v_conv.conv.weight', 'encoder.wavelet_tranform_2d.aa', 'encoder.wavelet_tranform_2d.ad', 'encoder.wavelet_tranform_2d.da', 'encoder.wavelet_tranform_2d.dd', 'decoder.inverse_wavelet_tranform_3d.h', 'decoder.inverse_wavelet_tranform_3d.g', 'decoder.inverse_wavelet_tranform_3d.hh', 'decoder.inverse_wavelet_tranform_3d.gh', 'decoder.inverse_wavelet_tranform_3d.h_v', 'decoder.inverse_wavelet_tranform_3d.g_v', 'decoder.inverse_wavelet_tranform_3d.hh_v', 'decoder.inverse_wavelet_tranform_3d.gh_v', 'decoder.inverse_wavelet_tranform_2d.aa', 'decoder.inverse_wavelet_tranform_2d.ad', 'decoder.inverse_wavelet_tranform_2d.da', 'decoder.inverse_wavelet_tranform_2d.dd'] []
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
init from /home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL/wfvae.ckpt
Load from ema model!
['encoder.wavelet_tranform_3d.h_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_conv.conv.weight', 'encoder.wavelet_tranform_3d.h_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.g_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.hh_v_conv.conv.weight', 'encoder.wavelet_tranform_3d.gh_v_conv.conv.weight', 'encoder.wavelet_tranform_2d.aa', 'encoder.wavelet_tranform_2d.ad', 'encoder.wavelet_tranform_2d.da', 'encoder.wavelet_tranform_2d.dd', 'decoder.inverse_wavelet_tranform_3d.h', 'decoder.inverse_wavelet_tranform_3d.g', 'decoder.inverse_wavelet_tranform_3d.hh', 'decoder.inverse_wavelet_tranform_3d.gh', 'decoder.inverse_wavelet_tranform_3d.h_v', 'decoder.inverse_wavelet_tranform_3d.g_v', 'decoder.inverse_wavelet_tranform_3d.hh_v', 'decoder.inverse_wavelet_tranform_3d.gh_v', 'decoder.inverse_wavelet_tranform_2d.aa', 'decoder.inverse_wavelet_tranform_2d.ad', 'decoder.inverse_wavelet_tranform_2d.da', 'decoder.inverse_wavelet_tranform_2d.dd'] []
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading OpenSoraInpaint pretrained weights...
Loading pretrained model from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors...
Loading OpenSoraInpaint pretrained weights...
Loading pretrained model from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors...
missing_keys 4 ['pos_embed_mask.0.proj.weight', 'pos_embed_mask.0.proj.bias', 'pos_embed_mask.1.weight', 'pos_embed_masked_hidden_states.1.weight'], unexpected_keys 0
Successfully load 695/699 keys from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors!
missing_keys 4 ['pos_embed_mask.0.proj.weight', 'pos_embed_mask.0.proj.bias', 'pos_embed_mask.1.weight', 'pos_embed_masked_hidden_states.1.weight'], unexpected_keys 0
Successfully load 695/699 keys from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors!
Loading OpenSoraInpaint pretrained weights...
Loading pretrained model from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors...
Loading OpenSoraInpaint pretrained weights...
Loading pretrained model from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors...
missing_keys 4 ['pos_embed_mask.0.proj.weight', 'pos_embed_mask.0.proj.bias', 'pos_embed_mask.1.weight', 'pos_embed_masked_hidden_states.1.weight'], unexpected_keys 0
Successfully load 695/699 keys from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors!
Loading OpenSoraInpaint pretrained weights...
Loading pretrained model from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors...
Loading OpenSoraInpaint pretrained weights...
Loading pretrained model from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors...
Loading OpenSoraInpaint pretrained weights...
Loading pretrained model from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors...
Loading OpenSoraInpaint pretrained weights...
Loading pretrained model from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors...
missing_keys 4 ['pos_embed_mask.0.proj.weight', 'pos_embed_mask.0.proj.bias', 'pos_embed_mask.1.weight', 'pos_embed_masked_hidden_states.1.weight'], unexpected_keys 0
Successfully load 695/699 keys from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors!
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
  0%|          | 0/1 [00:00<?, ?it/s]/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
  0%|          | 0/1 [00:00<?, ?it/s]missing_keys 4 ['pos_embed_mask.0.proj.weight', 'pos_embed_mask.0.proj.bias', 'pos_embed_mask.1.weight', 'pos_embed_masked_hidden_states.1.weight'], unexpected_keys 0
Successfully load 695/699 keys from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors!
missing_keys 4 ['pos_embed_mask.0.proj.weight', 'pos_embed_mask.0.proj.bias', 'pos_embed_mask.1.weight', 'pos_embed_masked_hidden_states.1.weight'], unexpected_keys 0
Successfully load 695/699 keys from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors!

  0%|          | 0/478625 [00:00<?, ?it/s][A
  1%|          | 3297/478625 [00:00<00:14, 32965.08it/s][A
  1%|▏         | 6594/478625 [00:00<00:14, 32227.87it/s][A
  2%|▏         | 9965/478625 [00:00<00:14, 32893.89it/s][A
  3%|▎         | 13331/478625 [00:00<00:14, 33192.92it/s][A09/18/2024 09:21:50 - INFO - __main__ - optimizer: AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: False
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0.01
)

  3%|▎         | 16652/478625 [00:00<00:14, 32314.62it/s][A
  4%|▍         | 20016/478625 [00:00<00:14, 32753.36it/s][A
  5%|▍         | 23296/478625 [00:00<00:14, 32072.75it/s][A
  6%|▌         | 26656/478625 [00:00<00:13, 32543.95it/s][A
  6%|▋         | 30015/478625 [00:00<00:13, 32864.76it/s][A
  7%|▋         | 33305/478625 [00:01<00:13, 32308.03it/s][A
  8%|▊         | 36657/478625 [00:01<00:13, 32670.60it/s][AYou are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565

  8%|▊         | 39928/478625 [00:01<00:13, 32029.45it/s][A
  9%|▉         | 43269/478625 [00:01<00:13, 32434.58it/s][Amissing_keys 4 ['pos_embed_mask.0.proj.weight', 'pos_embed_mask.0.proj.bias', 'pos_embed_mask.1.weight', 'pos_embed_masked_hidden_states.1.weight'], unexpected_keys 0
Successfully load 695/699 keys from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors!

  0%|          | 0/478625 [00:00<?, ?it/s][A
 10%|▉         | 46615/478625 [00:01<00:13, 32736.24it/s][Amissing_keys 4 ['pos_embed_mask.0.proj.weight', 'pos_embed_mask.0.proj.bias', 'pos_embed_mask.1.weight', 'pos_embed_masked_hidden_states.1.weight'], unexpected_keys 0

  1%|          | 3242/478625 [00:00<00:14, 32415.39it/s][ASuccessfully load 695/699 keys from /home/image_data/captions/vpre_latest_134k/model_ema/diffusion_pytorch_model.safetensors!

 10%|█         | 49892/478625 [00:01<00:13, 32138.22it/s][A
  1%|▏         | 6484/478625 [00:00<00:14, 32001.52it/s][A
 11%|█         | 53250/478625 [00:01<00:13, 32559.45it/s][A
  2%|▏         | 9825/478625 [00:00<00:14, 32637.24it/s][A
 12%|█▏        | 56605/478625 [00:01<00:12, 32851.23it/s][A
  3%|▎         | 13159/478625 [00:00<00:14, 32911.98it/s][A
 13%|█▎        | 59894/478625 [00:01<00:12, 32253.01it/s][A
  3%|▎         | 16451/478625 [00:00<00:14, 32094.54it/s][A
 13%|█▎        | 63198/478625 [00:01<00:12, 32482.61it/s][A
  4%|▍         | 19778/478625 [00:00<00:14, 32486.25it/s][A
 14%|█▍        | 66450/478625 [00:02<00:12, 32050.66it/s][A
  5%|▍         | 23030/478625 [00:00<00:14, 31845.24it/s][A
 15%|█▍        | 69815/478625 [00:02<00:12, 32518.56it/s][A
  6%|▌         | 26356/478625 [00:00<00:14, 32283.23it/s][A
 15%|█▌        | 73137/478625 [00:02<00:12, 32725.11it/s][A
  6%|▌         | 29681/478625 [00:00<00:13, 32579.67it/s][A
 16%|█▌        | 76412/478625 [00:02<00:12, 32211.11it/s][A
  7%|▋         | 32942/478625 [00:01<00:13, 31951.33it/s][A
 17%|█▋        | 79760/478625 [00:02<00:12, 32583.64it/s][A
  8%|▊         | 36277/478625 [00:01<00:13, 32339.05it/s][A
 17%|█▋        | 83022/478625 [00:02<00:12, 32098.99it/s][A
  8%|▊         | 39602/478625 [00:01<00:13, 32610.44it/s][A
 18%|█▊        | 86235/478625 [00:02<00:12, 31944.62it/s][A
  9%|▉         | 42866/478625 [00:01<00:13, 32018.18it/s][A
 19%|█▊        | 89611/478625 [00:02<00:11, 32477.31it/s][A
 10%|▉         | 46133/478625 [00:01<00:13, 32208.98it/s][A
 19%|█▉        | 92862/478625 [00:02<00:12, 31911.15it/s][A
 10%|█         | 49357/478625 [00:01<00:13, 31570.68it/s][A
 20%|██        | 96207/478625 [00:02<00:11, 32360.37it/s][A
 11%|█         | 52652/478625 [00:01<00:13, 31973.27it/s][A
 21%|██        | 99447/478625 [00:03<00:11, 31960.59it/s][A
 12%|█▏        | 55972/478625 [00:01<00:13, 32289.94it/s][A
 21%|██▏       | 102762/478625 [00:03<00:11, 32308.65it/s][A
 12%|█▏        | 59205/478625 [00:01<00:13, 31785.21it/s][A
 22%|██▏       | 106090/478625 [00:03<00:11, 32594.41it/s][A
 13%|█▎        | 62518/478625 [00:01<00:12, 32179.67it/s][A
 23%|██▎       | 109352/478625 [00:03<00:11, 32115.41it/s][A
 14%|█▎        | 65740/478625 [00:02<00:13, 31697.48it/s][A
 24%|██▎       | 112567/478625 [00:03<00:11, 31992.93it/s][A
 14%|█▍        | 68966/478625 [00:02<00:12, 31861.22it/s][A
 24%|██▍       | 115769/478625 [00:03<00:11, 31615.90it/s][A
 15%|█▌        | 72218/478625 [00:02<00:12, 32055.32it/s][A
 25%|██▍       | 119113/478625 [00:03<00:11, 32150.70it/s][A
 16%|█▌        | 75426/478625 [00:02<00:12, 31160.66it/s][A
 26%|██▌       | 122458/478625 [00:03<00:10, 32534.27it/s][A
 16%|█▋        | 78549/478625 [00:02<00:12, 30823.73it/s][A
 26%|██▋       | 125714/478625 [00:03<00:11, 32019.19it/s][A
 17%|█▋        | 81879/478625 [00:02<00:12, 31544.96it/s][A
 27%|██▋       | 129056/478625 [00:03<00:10, 32430.07it/s][A
 18%|█▊        | 85039/478625 [00:02<00:12, 31142.54it/s][A
 28%|██▊       | 132434/478625 [00:04<00:10, 32827.19it/s][A
 18%|█▊        | 88350/478625 [00:02<00:12, 31717.70it/s][A
 28%|██▊       | 135720/478625 [00:04<00:10, 31803.13it/s][A
 19%|█▉        | 91526/478625 [00:02<00:12, 31173.46it/s][A
 29%|██▉       | 139057/478625 [00:04<00:10, 32257.06it/s][A
 20%|█▉        | 94801/478625 [00:02<00:12, 31634.71it/s][A
 30%|██▉       | 142290/478625 [00:04<00:10, 31913.48it/s][A
 21%|██        | 98145/478625 [00:03<00:11, 32165.67it/s][A
 30%|███       | 145603/478625 [00:04<00:10, 32268.07it/s][A
 21%|██        | 101366/478625 [00:03<00:11, 31535.09it/s][A
 31%|███       | 148961/478625 [00:04<00:10, 32653.69it/s][A
 22%|██▏       | 104539/478625 [00:03<00:11, 31588.91it/s][A
 32%|███▏      | 152230/478625 [00:04<00:10, 32179.16it/s][A
 23%|██▎       | 107702/478625 [00:03<00:11, 30991.31it/s][A
 33%|███▎      | 155580/478625 [00:04<00:09, 32566.52it/s][A
 23%|██▎       | 111006/478625 [00:03<00:11, 31589.99it/s][A
 33%|███▎      | 158840/478625 [00:04<00:09, 32055.00it/s][A
 24%|██▍       | 114297/478625 [00:03<00:11, 31978.19it/s][A
 34%|███▍      | 162050/478625 [00:05<00:09, 31871.63it/s][A
 25%|██▍       | 117499/478625 [00:03<00:11, 31387.67it/s][A
 35%|███▍      | 165409/478625 [00:05<00:09, 32375.03it/s][A
 25%|██▌       | 120643/478625 [00:03<00:11, 31284.55it/s][A
 35%|███▌      | 168650/478625 [00:05<00:09, 31894.89it/s][A
 26%|██▌       | 123861/478625 [00:03<00:11, 31545.84it/s][A
 36%|███▌      | 171997/478625 [00:05<00:09, 32355.77it/s][A
 27%|██▋       | 127019/478625 [00:03<00:11, 31012.76it/s][A
 37%|███▋      | 175236/478625 [00:05<00:09, 31842.38it/s][A
 27%|██▋       | 130313/478625 [00:04<00:11, 31575.45it/s][A
 37%|███▋      | 178581/478625 [00:05<00:09, 32313.28it/s][A
 28%|██▊       | 133474/478625 [00:04<00:11, 31346.83it/s][A
 38%|███▊      | 181877/478625 [00:05<00:09, 32471.10it/s][A
 29%|██▊       | 136757/478625 [00:04<00:10, 31782.45it/s][A
 39%|███▊      | 185127/478625 [00:05<00:09, 31521.19it/s][A
 29%|██▉       | 140069/478625 [00:04<00:10, 32178.02it/s][A
 39%|███▉      | 188463/478625 [00:05<00:09, 32056.32it/s][A
 30%|██▉       | 143289/478625 [00:04<00:10, 31509.97it/s][A
 40%|████      | 191708/478625 [00:05<00:09, 31720.56it/s][A
 31%|███       | 146578/478625 [00:04<00:10, 31914.48it/s][A
 41%|████      | 195071/478625 [00:06<00:08, 32278.79it/s][A
 31%|███▏      | 149774/478625 [00:04<00:10, 31542.39it/s][A
 41%|████▏     | 198420/478625 [00:06<00:08, 32633.75it/s][A
 32%|███▏      | 153036/478625 [00:04<00:10, 31858.75it/s][A
 42%|████▏     | 201688/478625 [00:06<00:08, 31989.90it/s][A
 33%|███▎      | 156328/478625 [00:04<00:10, 32169.45it/s][A
 43%|████▎     | 204988/478625 [00:06<00:08, 32282.98it/s][A
 33%|███▎      | 159548/478625 [00:05<00:10, 31619.17it/s][A
 44%|████▎     | 208347/478625 [00:06<00:08, 32666.72it/s][A
 34%|███▍      | 162801/478625 [00:05<00:09, 31886.72it/s][A
 44%|████▍     | 211618/478625 [00:06<00:08, 31654.53it/s][A
 35%|███▍      | 166011/478625 [00:05<00:09, 31946.94it/s][A
 45%|████▍     | 214961/478625 [00:06<00:08, 32168.65it/s][A
 35%|███▌      | 169208/478625 [00:05<00:09, 31401.70it/s][A
 46%|████▌     | 218186/478625 [00:06<00:08, 31853.57it/s][A
 36%|███▌      | 172513/478625 [00:05<00:09, 31886.09it/s][A
 46%|████▋     | 221535/478625 [00:06<00:07, 32331.10it/s][A
 37%|███▋      | 175705/478625 [00:05<00:09, 31168.17it/s][A/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

 47%|████▋     | 224900/478625 [00:06<00:07, 32716.22it/s][A
 37%|███▋      | 179000/478625 [00:05<00:09, 31687.05it/s][A
 48%|████▊     | 228176/478625 [00:07<00:07, 32156.88it/s][A
 38%|███▊      | 182174/478625 [00:05<00:09, 31685.28it/s][A
 48%|████▊     | 231435/478625 [00:07<00:07, 32281.18it/s][A
 39%|███▊      | 185346/478625 [00:05<00:09, 31291.95it/s][A
 49%|████▉     | 234667/478625 [00:07<00:07, 31849.71it/s][A
 39%|███▉      | 188660/478625 [00:05<00:09, 31834.92it/s][A
 50%|████▉     | 237862/478625 [00:07<00:07, 31876.80it/s][A
 40%|████      | 191847/478625 [00:06<00:09, 30996.10it/s][A
 50%|█████     | 241213/478625 [00:07<00:07, 32356.57it/s][A
 41%|████      | 195096/478625 [00:06<00:09, 31431.09it/s][A
 51%|█████     | 244451/478625 [00:07<00:07, 31940.87it/s][A
 41%|████▏     | 198372/478625 [00:06<00:08, 31819.35it/s][A
 52%|█████▏    | 247799/478625 [00:07<00:07, 32394.26it/s][A
 42%|████▏     | 201559/478625 [00:06<00:08, 30921.71it/s][A
 52%|█████▏    | 251041/478625 [00:07<00:07, 31898.86it/s][A
 43%|████▎     | 204659/478625 [00:06<00:08, 30922.94it/s][A
 53%|█████▎    | 254381/478625 [00:07<00:06, 32339.95it/s][A
 43%|████▎     | 207941/478625 [00:06<00:08, 31477.86it/s][A
 54%|█████▍    | 257716/478625 [00:07<00:06, 32637.94it/s][A
 44%|████▍     | 211094/478625 [00:06<00:08, 31216.69it/s][A
 55%|█████▍    | 260983/478625 [00:08<00:06, 31368.43it/s][A
 45%|████▍     | 214305/478625 [00:06<00:08, 31478.92it/s][A
 55%|█████▌    | 264314/478625 [00:08<00:06, 31927.83it/s][A
 45%|████▌     | 217456/478625 [00:06<00:08, 31043.91it/s][A
 56%|█████▌    | 267670/478625 [00:08<00:06, 32403.74it/s][A
 46%|████▌     | 220754/478625 [00:06<00:08, 31611.15it/s][A
 57%|█████▋    | 270919/478625 [00:08<00:06, 31895.20it/s][A
 47%|████▋     | 223951/478625 [00:07<00:08, 31715.92it/s][A
 57%|█████▋    | 274256/478625 [00:08<00:06, 32324.88it/s][A
 47%|████▋     | 227125/478625 [00:07<00:08, 31267.55it/s][A
 58%|█████▊    | 277495/478625 [00:08<00:06, 31851.73it/s][A
 48%|████▊     | 230255/478625 [00:07<00:07, 31249.76it/s][A  0%|          | 0/1 [00:00<?, ?it/s]09/18/2024 09:21:59 - INFO - opensora.dataset.t2v_datasets - Building /home/image_data/captions/TV01_clips_final_478625_llavanext_217405_aes478625.json...

 59%|█████▊    | 280827/478625 [00:08<00:06, 32280.03it/s][A
 49%|████▉     | 233446/478625 [00:07<00:07, 31443.10it/s][A
 59%|█████▉    | 284178/478625 [00:08<00:05, 32640.81it/s][A
 49%|████▉     | 236592/478625 [00:07<00:07, 31134.63it/s][A
 60%|██████    | 287446/478625 [00:08<00:06, 31543.43it/s][A
 50%|█████     | 239871/478625 [00:07<00:07, 31623.74it/s][A
 61%|██████    | 290797/478625 [00:09<00:05, 32111.67it/s][A
 51%|█████     | 243036/478625 [00:07<00:07, 31051.11it/s][A
 61%|██████▏   | 294017/478625 [00:09<00:05, 31531.88it/s][A
 51%|█████▏    | 246228/478625 [00:07<00:07, 31303.06it/s][A
 62%|██████▏   | 297378/478625 [00:09<00:05, 32135.27it/s][A
 52%|█████▏    | 249503/478625 [00:07<00:07, 31729.58it/s][A
 63%|██████▎   | 300751/478625 [00:09<00:05, 32566.44it/s][A
 53%|█████▎    | 252679/478625 [00:07<00:07, 30944.63it/s][A
 64%|██████▎   | 304014/478625 [00:09<00:05, 32136.06it/s][A
 53%|█████▎    | 255973/478625 [00:08<00:07, 31525.22it/s][A
 64%|██████▍   | 307349/478625 [00:09<00:05, 32491.86it/s][A
 54%|█████▍    | 259131/478625 [00:08<00:07, 31214.74it/s][A
 65%|██████▍   | 310603/478625 [00:09<00:05, 32026.74it/s][A
 55%|█████▍    | 262257/478625 [00:08<00:07, 30665.74it/s][A
 66%|██████▌   | 313810/478625 [00:09<00:05, 31961.58it/s][A
 55%|█████▌    | 265549/478625 [00:08<00:06, 31323.44it/s][A
 66%|██████▋   | 317149/478625 [00:09<00:04, 32382.09it/s][A
 56%|█████▌    | 268686/478625 [00:08<00:06, 30613.65it/s][A
 67%|██████▋   | 320390/478625 [00:09<00:04, 31959.77it/s][A
 57%|█████▋    | 271946/478625 [00:08<00:06, 31189.88it/s][A
 68%|██████▊   | 323741/478625 [00:10<00:04, 32413.50it/s][A
 58%|█████▊    | 275248/478625 [00:08<00:06, 31726.16it/s][A
 68%|██████▊   | 326985/478625 [00:10<00:04, 31880.71it/s][A
 58%|█████▊    | 278426/478625 [00:08<00:06, 30654.94it/s][A
 69%|██████▉   | 330262/478625 [00:10<00:04, 32140.55it/s][A
 59%|█████▉    | 281718/478625 [00:08<00:06, 31308.76it/s][A
 70%|██████▉   | 333606/478625 [00:10<00:04, 32522.30it/s][A
 60%|█████▉    | 284859/478625 [00:09<00:06, 30544.57it/s][A
 70%|███████   | 336861/478625 [00:10<00:04, 31472.19it/s][A
 60%|██████    | 288137/478625 [00:09<00:06, 31189.40it/s][A
 71%|███████   | 340211/478625 [00:10<00:04, 32061.00it/s][A
 61%|██████    | 291391/478625 [00:09<00:05, 31582.67it/s][A
 72%|███████▏  | 343562/478625 [00:10<00:04, 32485.83it/s][A
 62%|██████▏   | 294557/478625 [00:09<00:05, 30729.15it/s][A
 72%|███████▏  | 346817/478625 [00:10<00:04, 31977.00it/s][A
 62%|██████▏   | 297848/478625 [00:09<00:05, 31361.47it/s][A
 73%|███████▎  | 350161/478625 [00:10<00:03, 32402.98it/s][A
 63%|██████▎   | 300993/478625 [00:09<00:05, 31376.60it/s][A
 74%|███████▍  | 353407/478625 [00:10<00:03, 31943.61it/s][A
 64%|██████▎   | 304137/478625 [00:09<00:05, 31070.91it/s][A
 75%|███████▍  | 356752/478625 [00:11<00:03, 32383.35it/s][A
 64%|██████▍   | 307286/478625 [00:09<00:05, 31193.31it/s][A
 75%|███████▌  | 360095/478625 [00:11<00:03, 32691.27it/s][A
 65%|██████▍   | 310409/478625 [00:09<00:05, 30994.36it/s][A
 76%|███████▌  | 363368/478625 [00:11<00:03, 31606.18it/s][A
 66%|██████▌   | 313675/478625 [00:09<00:05, 31485.71it/s][A
 77%|███████▋  | 366695/478625 [00:11<00:03, 32088.52it/s][A
 66%|██████▌   | 316957/478625 [00:10<00:05, 31878.96it/s][A
 77%|███████▋  | 369912/478625 [00:11<00:03, 31460.33it/s][A
 67%|██████▋   | 320147/478625 [00:10<00:05, 31043.94it/s][A
 78%|███████▊  | 373270/478625 [00:11<00:03, 32076.73it/s][A
 68%|██████▊   | 323309/478625 [00:10<00:04, 31210.95it/s][A
 79%|███████▊  | 376631/478625 [00:11<00:03, 32525.33it/s][A
 68%|██████▊   | 326435/478625 [00:10<00:04, 31199.16it/s][A
 79%|███████▉  | 379890/478625 [00:11<00:03, 32017.36it/s][A
 69%|██████▉   | 329558/478625 [00:10<00:04, 30601.69it/s][A
 80%|████████  | 383238/478625 [00:11<00:02, 32444.04it/s][A
 69%|██████▉   | 332639/478625 [00:10<00:04, 30659.97it/s][A
 81%|████████  | 386487/478625 [00:12<00:02, 31536.50it/s][A
 70%|███████   | 335708/478625 [00:10<00:04, 30209.12it/s][A
 81%|████████▏ | 389828/478625 [00:12<00:02, 32079.97it/s][A
 71%|███████   | 338817/478625 [00:10<00:04, 30465.98it/s][A
 82%|████████▏ | 393194/478625 [00:12<00:02, 32541.46it/s][A
 71%|███████▏  | 342011/478625 [00:10<00:04, 30901.01it/s][A
 83%|████████▎ | 396455/478625 [00:12<00:02, 32010.26it/s][A
 72%|███████▏  | 345104/478625 [00:10<00:04, 30659.12it/s][A
 84%|████████▎ | 399831/478625 [00:12<00:02, 32521.58it/s][A
 73%|███████▎  | 348410/478625 [00:11<00:04, 31369.02it/s][A
 84%|████████▍ | 403089/478625 [00:12<00:02, 32066.34it/s][A
 73%|███████▎  | 351723/478625 [00:11<00:03, 31890.47it/s][A
 85%|████████▍ | 406434/478625 [00:12<00:02, 32469.45it/s][A
 74%|███████▍  | 354915/478625 [00:11<00:03, 31353.59it/s][A
 86%|████████▌ | 409790/478625 [00:12<00:02, 32791.05it/s][A
 75%|███████▍  | 358201/478625 [00:11<00:03, 31797.39it/s][A
 86%|████████▋ | 413073/478625 [00:12<00:02, 31693.39it/s][A
 76%|███████▌  | 361384/478625 [00:11<00:03, 31412.41it/s][A
 87%|████████▋ | 416320/478625 [00:12<00:01, 31917.65it/s][A
 76%|███████▌  | 364671/478625 [00:11<00:03, 31840.12it/s][A
 88%|████████▊ | 419589/478625 [00:13<00:01, 31669.49it/s][A
 77%|███████▋  | 367894/478625 [00:11<00:03, 31954.66it/s][A
 88%|████████▊ | 422936/478625 [00:13<00:01, 32194.52it/s][A
 78%|███████▊  | 371092/478625 [00:11<00:03, 30700.23it/s][A
 89%|████████▉ | 426275/478625 [00:13<00:01, 32544.24it/s][A
 78%|███████▊  | 374174/478625 [00:11<00:03, 30482.52it/s][A
 90%|████████▉ | 429534/478625 [00:13<00:01, 32034.98it/s][A
 79%|███████▉  | 377230/478625 [00:11<00:03, 30486.80it/s][A
 90%|█████████ | 432893/478625 [00:13<00:01, 32490.72it/s][A
 79%|███████▉  | 380284/478625 [00:12<00:03, 30304.33it/s][A
 91%|█████████ | 436250/478625 [00:13<00:01, 32808.81it/s][A
 80%|████████  | 383605/478625 [00:12<00:03, 31158.50it/s][A
 92%|█████████▏| 439535/478625 [00:13<00:01, 31708.19it/s][A
 81%|████████  | 386726/478625 [00:12<00:02, 30686.61it/s][A
 93%|█████████▎| 442881/478625 [00:13<00:01, 32216.66it/s][A
 81%|████████▏ | 389853/478625 [00:12<00:02, 30854.68it/s][A
 93%|█████████▎| 446111/478625 [00:13<00:01, 31836.10it/s][A
 82%|████████▏ | 393135/478625 [00:12<00:02, 31432.92it/s][A
 94%|█████████▍| 449461/478625 [00:13<00:00, 32321.36it/s][A
 83%|████████▎ | 396282/478625 [00:12<00:02, 30768.70it/s][A
 95%|█████████▍| 452798/478625 [00:14<00:00, 32628.47it/s][A
 83%|████████▎ | 399527/478625 [00:12<00:02, 31261.17it/s][A
 95%|█████████▌| 456066/478625 [00:14<00:00, 32120.56it/s][A
 84%|████████▍ | 402711/478625 [00:12<00:02, 31430.12it/s][A
 96%|█████████▌| 459418/478625 [00:14<00:00, 32529.72it/s][A
 85%|████████▍ | 405858/478625 [00:12<00:02, 31006.97it/s][A
 97%|█████████▋| 462675/478625 [00:14<00:00, 31549.41it/s][A
 85%|████████▌ | 408962/478625 [00:13<00:02, 30956.26it/s][A
 97%|█████████▋| 465985/478625 [00:14<00:00, 31998.13it/s][A
 86%|████████▌ | 412060/478625 [00:13<00:02, 30467.84it/s][A
 98%|█████████▊| 469213/478625 [00:14<00:00, 32077.74it/s][A
 87%|████████▋ | 415218/478625 [00:13<00:02, 30792.23it/s][A
 99%|█████████▊| 472426/478625 [00:14<00:00, 31672.69it/s][A
 87%|████████▋ | 418478/478625 [00:13<00:01, 31324.04it/s][A
 99%|█████████▉| 475804/478625 [00:14<00:00, 32289.67it/s][A
 88%|████████▊ | 421613/478625 [00:13<00:01, 31063.68it/s][A100%|██████████| 478625/478625 [00:14<00:00, 32209.49it/s]
100%|██████████| 1/1 [00:21<00:00, 21.25s/it]100%|██████████| 1/1 [00:21<00:00, 21.25s/it]

 89%|████████▊ | 424722/478625 [00:13<00:01, 31012.43it/s][A
 89%|████████▉ | 427993/478625 [00:13<00:01, 31515.50it/s][A
 90%|█████████ | 431147/478625 [00:13<00:01, 31103.81it/s][A
 91%|█████████ | 434260/478625 [00:13<00:01, 30986.05it/s][A
 91%|█████████▏| 437360/478625 [00:13<00:01, 30616.80it/s][A/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

 92%|█████████▏| 440648/478625 [00:14<00:01, 31282.88it/s][A
  0%|          | 0/478625 [00:00<?, ?it/s][A
 93%|█████████▎| 443870/478625 [00:14<00:01, 31557.51it/s][Atime 21.929378032684326

  1%|          | 3171/478625 [00:00<00:15, 31615.36it/s][An_elements: 474899
data length: 474899

 93%|█████████▎| 447028/478625 [00:14<00:01, 31219.23it/s][A
  1%|▏         | 6333/478625 [00:00<00:15, 30991.04it/s][A
 94%|█████████▍| 450152/478625 [00:14<00:00, 31091.51it/s][A
  2%|▏         | 9624/478625 [00:00<00:14, 31855.15it/s][A
 95%|█████████▍| 453387/478625 [00:14<00:00, 30930.23it/s][A
  3%|▎         | 12958/478625 [00:00<00:14, 32435.59it/s][A
 95%|█████████▌| 456652/478625 [00:14<00:00, 31435.02it/s][A
  3%|▎         | 16203/478625 [00:00<00:14, 31692.30it/s][A
 96%|█████████▌| 459928/478625 [00:14<00:00, 31824.25it/s][A
  4%|▍         | 19505/478625 [00:00<00:14, 32133.41it/s][A
 97%|█████████▋| 463113/478625 [00:14<00:00, 30891.58it/s][A
  5%|▍         | 22831/478625 [00:00<00:14, 32494.94it/s][A
 97%|█████████▋| 466377/478625 [00:14<00:00, 31399.31it/s][A
  5%|▌         | 26084/478625 [00:00<00:14, 31839.65it/s][A
 98%|█████████▊| 469523/478625 [00:14<00:00, 31159.09it/s][A
  6%|▌         | 29378/478625 [00:00<00:13, 32173.60it/s][A
 99%|█████████▉| 472644/478625 [00:15<00:00, 30825.48it/s][A
  7%|▋         | 32599/478625 [00:01<00:14, 31626.46it/s][A
 99%|█████████▉| 475730/478625 [00:15<00:00, 30736.41it/s][A
  7%|▋         | 35877/478625 [00:01<00:13, 31970.25it/s][A100%|██████████| 478625/478625 [00:15<00:00, 31385.08it/s]
100%|██████████| 1/1 [00:21<00:00, 21.55s/it]100%|██████████| 1/1 [00:21<00:00, 21.55s/it]

  8%|▊         | 39145/478625 [00:01<00:13, 32181.88it/s][A
  9%|▉         | 42366/478625 [00:01<00:13, 31509.97it/s][A
 10%|▉         | 45647/478625 [00:01<00:13, 31891.06it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
 10%|█         | 48840/478625 [00:01<00:13, 31424.56it/s][A
 11%|█         | 52107/478625 [00:01<00:13, 31790.13it/s][A
 12%|█▏        | 55386/478625 [00:01<00:13, 32083.05it/s][A
 12%|█▏        | 58598/478625 [00:01<00:13, 31543.61it/s][Atime 22.218870162963867
n_elements: 474899
data length: 474899

 13%|█▎        | 61896/478625 [00:01<00:13, 31965.54it/s][A
 14%|█▎        | 65096/478625 [00:02<00:13, 31356.22it/s][A
 14%|█▍        | 68399/478625 [00:02<00:12, 31845.66it/s][A
 15%|█▍        | 71664/478625 [00:02<00:12, 32081.48it/s][A
 16%|█▌        | 74876/478625 [00:02<00:12, 31468.39it/s][A
 16%|█▋        | 78151/478625 [00:02<00:12, 31842.51it/s][A
 17%|█▋        | 81379/478625 [00:02<00:12, 31970.93it/s][A
 18%|█▊        | 84579/478625 [00:02<00:12, 31284.52it/s][A
 18%|█▊        | 87846/478625 [00:02<00:12, 31689.79it/s][A
 19%|█▉        | 91020/478625 [00:02<00:12, 31147.71it/s][A
 20%|█▉        | 94283/478625 [00:02<00:12, 31579.98it/s][A
 20%|██        | 97556/478625 [00:03<00:11, 31918.48it/s][A
 21%|██        | 100752/478625 [00:03<00:12, 31397.47it/s][A
 22%|██▏       | 103984/478625 [00:03<00:11, 31668.07it/s][A
 22%|██▏       | 107277/478625 [00:03<00:11, 32040.93it/s][A/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

 23%|██▎       | 110484/478625 [00:03<00:11, 31415.75it/s][A
 24%|██▍       | 113737/478625 [00:03<00:11, 31742.01it/s][A
 24%|██▍       | 116915/478625 [00:03<00:11, 31248.38it/s][A
 25%|██▌       | 120187/478625 [00:03<00:11, 31678.84it/s][A
 26%|██▌       | 123474/478625 [00:03<00:11, 32028.94it/s][A
 26%|██▋       | 126680/478625 [00:03<00:11, 31468.80it/s][A
 27%|██▋       | 129938/478625 [00:04<00:10, 31792.35it/s][A
 28%|██▊       | 133121/478625 [00:04<00:11, 31386.19it/s][A
 28%|██▊       | 136401/478625 [00:04<00:10, 31799.84it/s][A
 29%|██▉       | 139684/478625 [00:04<00:10, 32102.39it/s][A
 30%|██▉       | 142897/478625 [00:04<00:10, 31512.07it/s][A
 31%|███       | 146157/478625 [00:04<00:10, 31829.46it/s][A
 31%|███       | 149462/478625 [00:04<00:10, 32188.15it/s][A
 32%|███▏      | 152684/478625 [00:04<00:10, 31557.11it/s][A
 33%|███▎      | 155946/478625 [00:04<00:10, 31868.08it/s][A
 33%|███▎      | 159137/478625 [00:05<00:10, 31401.30it/s][A
 34%|███▍      | 162385/478625 [00:05<00:09, 31715.37it/s][A
 35%|███▍      | 165678/478625 [00:05<00:09, 32072.78it/s][A
 35%|███▌      | 168888/478625 [00:05<00:09, 31543.05it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
 36%|███▌      | 172166/478625 [00:05<00:09, 31906.11it/s][A
 37%|███▋      | 175360/478625 [00:05<00:09, 31395.83it/s][A
 37%|███▋      | 178652/478625 [00:05<00:09, 31841.33it/s][A
 38%|███▊      | 181877/478625 [00:05<00:09, 31936.75it/s][A
 39%|███▊      | 185074/478625 [00:05<00:09, 31403.45it/s][A
 39%|███▉      | 188356/478625 [00:05<00:09, 31818.64it/s][A
 40%|████      | 191669/478625 [00:06<00:09, 31380.99it/s][A
 41%|████      | 194952/478625 [00:06<00:08, 31800.72it/s][A
 41%|████▏     | 198224/478625 [00:06<00:08, 32068.57it/s][A
 42%|████▏     | 201435/478625 [00:06<00:08, 31480.01it/s][A
 43%|████▎     | 204647/478625 [00:06<00:08, 31667.10it/s][A
 43%|████▎     | 207920/478625 [00:06<00:08, 31977.89it/s][A
 44%|████▍     | 211121/478625 [00:06<00:08, 31400.46it/s][A/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

 45%|████▍     | 214408/478625 [00:06<00:08, 31831.17it/s][A
 45%|████▌     | 217595/478625 [00:06<00:08, 31369.28it/s][A
 46%|████▌     | 220890/478625 [00:06<00:08, 31831.42it/s][A
 47%|████▋     | 224187/478625 [00:07<00:07, 32167.20it/s][A
 48%|████▊     | 227407/478625 [00:07<00:07, 31636.68it/s][A
 48%|████▊     | 230575/478625 [00:07<00:07, 31335.99it/s][A
 49%|████▉     | 233865/478625 [00:07<00:07, 30988.59it/s][A
 50%|████▉     | 237160/478625 [00:07<00:07, 31555.99it/s][A
 50%|█████     | 240440/478625 [00:07<00:07, 31919.84it/s][A
 51%|█████     | 243636/478625 [00:07<00:07, 31379.51it/s][A
 52%|█████▏    | 246916/478625 [00:07<00:07, 31794.23it/s][A
 52%|█████▏    | 250187/478625 [00:07<00:07, 32061.73it/s][A
 53%|█████▎    | 253397/478625 [00:07<00:07, 31504.84it/s][A
 54%|█████▎    | 256684/478625 [00:08<00:06, 31904.95it/s][A
 54%|█████▍    | 259878/478625 [00:08<00:07, 31155.52it/s][A
 55%|█████▍    | 263171/478625 [00:08<00:06, 31672.91it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
 56%|█████▌    | 266453/478625 [00:08<00:06, 32008.04it/s][A
  0%|          | 0/478625 [00:00<?, ?it/s][A
 56%|█████▋    | 269659/478625 [00:08<00:06, 31423.59it/s][A
  1%|          | 2954/478625 [00:00<00:16, 29509.77it/s][A
 57%|█████▋    | 272807/478625 [00:08<00:06, 31334.86it/s][A
  1%|▏         | 5990/478625 [00:00<00:15, 29922.76it/s][A
 58%|█████▊    | 276079/478625 [00:08<00:06, 31007.84it/s][A
  2%|▏         | 9133/478625 [00:00<00:15, 30605.01it/s][A
 58%|█████▊    | 279376/478625 [00:08<00:06, 31576.76it/s][A
  3%|▎         | 12222/478625 [00:00<00:15, 30714.28it/s][A
 59%|█████▉    | 282656/478625 [00:08<00:06, 31934.07it/s][A
  3%|▎         | 15294/478625 [00:00<00:15, 29731.65it/s][A
 60%|█████▉    | 285853/478625 [00:09<00:06, 31452.20it/s][A
  4%|▍         | 18452/478625 [00:00<00:15, 30345.88it/s][A
 60%|██████    | 289110/478625 [00:09<00:05, 31777.78it/s][A
  5%|▍         | 21544/478625 [00:00<00:14, 30530.07it/s][A
 61%|██████    | 292327/478625 [00:09<00:05, 31893.12it/s][A
  5%|▌         | 24601/478625 [00:00<00:15, 29215.03it/s][A
 62%|██████▏   | 295519/478625 [00:09<00:05, 31414.22it/s][A
  6%|▌         | 27692/478625 [00:00<00:15, 29724.43it/s][A
 62%|██████▏   | 298814/478625 [00:09<00:05, 31865.74it/s][A
  6%|▋         | 30793/478625 [00:01<00:14, 30108.59it/s][A
 63%|██████▎   | 302004/478625 [00:09<00:05, 31387.84it/s][A
  7%|▋         | 33813/478625 [00:01<00:15, 29539.62it/s][A
 64%|██████▍   | 305282/478625 [00:09<00:05, 31795.67it/s][A
  8%|▊         | 36902/478625 [00:01<00:14, 29937.29it/s][A
 64%|██████▍   | 308551/478625 [00:09<00:05, 32058.22it/s][A
  8%|▊         | 39902/478625 [00:01<00:14, 29337.58it/s][A/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

 65%|██████▌   | 311760/478625 [00:09<00:05, 31543.49it/s][A
  9%|▉         | 42915/478625 [00:01<00:14, 29569.32it/s][A
 66%|██████▌   | 314918/478625 [00:09<00:05, 31408.19it/s][A/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(

 10%|▉         | 45994/478625 [00:01<00:14, 29926.55it/s][A
 66%|██████▋   | 318209/478625 [00:10<00:05, 31849.85it/s][A
 10%|█         | 48991/478625 [00:01<00:14, 29410.02it/s][A
 67%|██████▋   | 321397/478625 [00:10<00:05, 31301.66it/s][A
 11%|█         | 52087/478625 [00:01<00:14, 29865.22it/s][A
 68%|██████▊   | 324688/478625 [00:10<00:04, 31772.65it/s][A
 12%|█▏        | 55178/478625 [00:01<00:14, 30172.61it/s][A
 69%|██████▊   | 327869/478625 [00:10<00:04, 31010.35it/s][A
 12%|█▏        | 58199/478625 [00:01<00:14, 29311.61it/s][A
 69%|██████▉   | 331135/478625 [00:10<00:04, 31490.75it/s][A
 13%|█▎        | 61290/478625 [00:02<00:14, 29774.92it/s][A
 70%|██████▉   | 334436/478625 [00:10<00:04, 31935.65it/s][A
 13%|█▎        | 64379/478625 [00:02<00:13, 30101.72it/s][A
 71%|███████   | 337634/478625 [00:10<00:04, 31378.44it/s][A
 14%|█▍        | 67395/478625 [00:02<00:13, 29515.72it/s][A
 71%|███████   | 340923/478625 [00:10<00:04, 31820.82it/s][A
 15%|█▍        | 70479/478625 [00:02<00:13, 29903.14it/s][A
 72%|███████▏  | 344110/478625 [00:10<00:04, 31255.37it/s][A
 15%|█▌        | 73530/478625 [00:02<00:13, 29285.88it/s][A
 73%|███████▎  | 347372/478625 [00:10<00:04, 31652.27it/s][A
 16%|█▌        | 76465/478625 [00:02<00:13, 29241.35it/s][A
 73%|███████▎  | 350648/478625 [00:11<00:04, 31977.17it/s][A
 17%|█▋        | 79551/478625 [00:02<00:13, 29714.21it/s][A
 74%|███████▍  | 353850/478625 [00:11<00:03, 31442.09it/s][A
 17%|█▋        | 82527/478625 [00:02<00:13, 29296.47it/s][A
 75%|███████▍  | 356999/478625 [00:11<00:03, 31318.71it/s][A
 18%|█▊        | 85588/478625 [00:02<00:13, 29681.07it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
 75%|███████▌  | 360283/478625 [00:11<00:03, 31765.41it/s][A
 19%|█▊        | 88662/478625 [00:02<00:13, 29991.17it/s][A
 76%|███████▌  | 363463/478625 [00:11<00:03, 31259.11it/s][A  0%|          | 0/1 [00:00<?, ?it/s]
 19%|█▉        | 91664/478625 [00:03<00:13, 29299.42it/s][A
 77%|███████▋  | 366736/478625 [00:11<00:03, 31690.88it/s][A
 20%|█▉        | 94599/478625 [00:03<00:13, 29186.09it/s][A
 77%|███████▋  | 369909/478625 [00:11<00:03, 30968.53it/s][A
 20%|██        | 97644/478625 [00:03<00:12, 29555.53it/s][A
 78%|███████▊  | 373190/478625 [00:11<00:03, 31504.44it/s][A
 21%|██        | 100603/478625 [00:03<00:12, 29082.38it/s][A
 79%|███████▊  | 376487/478625 [00:11<00:03, 31934.36it/s][A
 22%|██▏       | 103651/478625 [00:03<00:12, 29489.85it/s][A
  0%|          | 0/478625 [00:00<?, ?it/s][A
 79%|███████▉  | 379685/478625 [00:11<00:03, 31371.51it/s][A
 22%|██▏       | 106688/478625 [00:03<00:12, 29747.78it/s][A
  1%|          | 3183/478625 [00:00<00:14, 31822.82it/s][A
 80%|████████  | 382980/478625 [00:12<00:03, 31824.46it/s][A
 23%|██▎       | 109666/478625 [00:03<00:12, 29195.45it/s][A
  1%|▏         | 6366/478625 [00:00<00:15, 30818.99it/s][A
 81%|████████  | 386167/478625 [00:12<00:02, 31359.06it/s][A
 24%|██▎       | 112720/478625 [00:03<00:12, 29588.21it/s][A
  2%|▏         | 9613/478625 [00:00<00:14, 31557.90it/s][A
 81%|████████▏ | 389443/478625 [00:12<00:02, 31768.20it/s][A
 24%|██▍       | 115683/478625 [00:03<00:12, 29399.87it/s][A
  3%|▎         | 12886/478625 [00:00<00:14, 32014.56it/s][A
 82%|████████▏ | 392749/478625 [00:12<00:02, 32147.76it/s][A
 25%|██▍       | 118626/478625 [00:04<00:12, 28849.33it/s][A
  3%|▎         | 16090/478625 [00:00<00:14, 31213.41it/s][A
 83%|████████▎ | 395967/478625 [00:12<00:02, 31400.61it/s][A
 25%|██▌       | 121685/478625 [00:04<00:12, 29356.61it/s][A
  4%|▍         | 19348/478625 [00:00<00:14, 31666.30it/s][A
 83%|████████▎ | 399113/478625 [00:12<00:02, 31333.80it/s][A
 26%|██▌       | 124625/478625 [00:04<00:12, 28919.03it/s][A
  5%|▍         | 22579/478625 [00:00<00:14, 31872.74it/s][A
 84%|████████▍ | 402402/478625 [00:12<00:02, 31789.65it/s][A
 27%|██▋       | 127662/478625 [00:04<00:11, 29342.45it/s][A
  5%|▌         | 25770/478625 [00:00<00:14, 31211.62it/s][A
 85%|████████▍ | 405585/478625 [00:12<00:02, 31256.33it/s][A
 27%|██▋       | 130727/478625 [00:04<00:11, 29726.72it/s][A
  6%|▌         | 29014/478625 [00:00<00:14, 31586.77it/s][A
 85%|████████▌ | 408883/478625 [00:12<00:02, 31761.62it/s][A
 28%|██▊       | 133703/478625 [00:04<00:12, 28708.27it/s][A
  7%|▋         | 32177/478625 [00:01<00:14, 31040.18it/s][A
 86%|████████▌ | 412063/478625 [00:13<00:02, 31136.58it/s][A
 29%|██▊       | 136767/478625 [00:04<00:11, 29267.52it/s][A
  7%|▋         | 35445/478625 [00:01<00:14, 31529.59it/s][A
 87%|████████▋ | 415261/478625 [00:13<00:02, 31382.19it/s][A
 29%|██▉       | 139806/478625 [00:04<00:11, 29594.57it/s][A
  8%|▊         | 38684/478625 [00:01<00:13, 31786.02it/s][A
 87%|████████▋ | 418543/478625 [00:13<00:01, 31805.40it/s][A
 30%|██▉       | 142772/478625 [00:04<00:11, 29047.60it/s][A
  9%|▊         | 41866/478625 [00:01<00:14, 31128.84it/s][A
 88%|████████▊ | 421727/478625 [00:13<00:01, 31289.40it/s][A
 30%|███       | 145820/478625 [00:04<00:11, 29464.89it/s][A
  9%|▉         | 45113/478625 [00:01<00:13, 31522.14it/s][A
 89%|████████▉ | 425032/478625 [00:13<00:01, 31805.35it/s][A
 31%|███       | 148865/478625 [00:05<00:11, 29751.90it/s][A
 10%|█         | 48270/478625 [00:01<00:13, 31046.80it/s][A
 89%|████████▉ | 428217/478625 [00:13<00:01, 31326.37it/s][A
 32%|███▏      | 151845/478625 [00:05<00:11, 29187.05it/s][A
 11%|█         | 51518/478625 [00:01<00:13, 31466.64it/s][A
 90%|█████████ | 431509/478625 [00:13<00:01, 31793.53it/s][A
 32%|███▏      | 154769/478625 [00:05<00:11, 29126.45it/s][A
 11%|█▏        | 54767/478625 [00:01<00:13, 31766.86it/s][A
 91%|█████████ | 434820/478625 [00:13<00:01, 32179.75it/s][A
 33%|███▎      | 157833/478625 [00:05<00:10, 29569.82it/s][A
 12%|█▏        | 57947/478625 [00:01<00:13, 31211.69it/s][A
 92%|█████████▏| 438041/478625 [00:13<00:01, 31094.08it/s][A
 34%|███▎      | 160794/478625 [00:05<00:10, 28987.57it/s][A
 13%|█▎        | 61207/478625 [00:01<00:13, 31619.78it/s][A
 92%|█████████▏| 441336/478625 [00:13<00:01, 31632.28it/s][A
 34%|███▍      | 163820/478625 [00:05<00:10, 29357.55it/s][A
 13%|█▎        | 64461/478625 [00:02<00:12, 31889.65it/s][A
 93%|█████████▎| 444621/478625 [00:14<00:01, 31989.11it/s][A
 35%|███▍      | 166760/478625 [00:05<00:10, 28918.01it/s][A
 14%|█▍        | 67653/478625 [00:02<00:13, 31313.84it/s][A
 94%|█████████▎| 447827/478625 [00:14<00:00, 31479.47it/s][A
 35%|███▌      | 169807/478625 [00:05<00:10, 29372.71it/s][A
 15%|█▍        | 70890/478625 [00:02<00:12, 31614.05it/s][A
 94%|█████████▍| 451102/478625 [00:14<00:00, 31849.35it/s][A
 36%|███▌      | 172748/478625 [00:05<00:10, 29180.43it/s][A
 15%|█▌        | 74055/478625 [00:02<00:12, 31148.54it/s][A
 95%|█████████▍| 454292/478625 [00:14<00:00, 31338.20it/s][A
 37%|███▋      | 175669/478625 [00:05<00:10, 28783.39it/s][A
 16%|█▌        | 77286/478625 [00:02<00:12, 31486.54it/s][A
 96%|█████████▌| 457574/478625 [00:14<00:00, 31770.57it/s][A
 37%|███▋      | 178744/478625 [00:06<00:10, 29358.86it/s][A
 17%|█▋        | 80530/478625 [00:02<00:12, 31767.37it/s][A
 96%|█████████▋| 460870/478625 [00:14<00:00, 32118.79it/s][A
 38%|███▊      | 181821/478625 [00:06<00:09, 29738.30it/s][A
 17%|█▋        | 83710/478625 [00:02<00:12, 31228.74it/s][A
 97%|█████████▋| 464086/478625 [00:14<00:00, 31382.04it/s][A
 39%|███▊      | 184798/478625 [00:06<00:10, 29191.29it/s][A
 18%|█▊        | 86944/478625 [00:02<00:12, 31554.84it/s][A
 98%|█████████▊| 467286/478625 [00:14<00:00, 31561.36it/s][A
 39%|███▉      | 187901/478625 [00:06<00:09, 29729.15it/s][A
 19%|█▉        | 90188/478625 [00:02<00:12, 31816.17it/s][A
 98%|█████████▊| 470447/478625 [00:14<00:00, 31166.85it/s][A
 40%|███▉      | 191008/478625 [00:06<00:09, 30124.15it/s][A
 20%|█▉        | 93373/478625 [00:02<00:12, 31198.01it/s][A
 99%|█████████▉| 473729/478625 [00:14<00:00, 31651.10it/s][A
  0%|          | 0/478625 [00:00<?, ?it/s][A
 41%|████      | 194024/478625 [00:06<00:09, 29080.65it/s][A
 20%|██        | 96633/478625 [00:03<00:12, 31607.21it/s][A
100%|█████████▉| 477039/478625 [00:15<00:00, 32077.55it/s][A
  1%|          | 3144/478625 [00:00<00:15, 31428.79it/s][A
 41%|████      | 197124/478625 [00:06<00:09, 29636.46it/s][A100%|██████████| 478625/478625 [00:15<00:00, 31649.66it/s]
100%|██████████| 1/1 [00:21<00:00, 21.88s/it]100%|██████████| 1/1 [00:21<00:00, 21.88s/it]

 21%|██        | 99798/478625 [00:03<00:12, 31136.75it/s][A
  1%|▏         | 6287/478625 [00:00<00:15, 30423.81it/s][A
 42%|████▏     | 200097/478625 [00:06<00:09, 29193.37it/s][A
 22%|██▏       | 103044/478625 [00:03<00:11, 31522.83it/s][A09/18/2024 09:22:21 - INFO - opensora.dataset.t2v_datasets - no_cap: 0, too_long: 3711, too_short: 2, no_resolution: 0, resolution_mismatch: 0, Counter(sample_size): Counter({'93x160x320': 84930, '29x160x320': 73201, '45x160x320': 68295, '61x160x320': 44578, '77x160x320': 38630, '93x128x320': 17805, '29x128x320': 16948, '93x224x320': 16403, '93x192x320': 15259, '45x128x320': 14788, '61x128x320': 9795, '29x224x320': 8615, '29x192x320': 8528, '45x224x320': 8477, '45x192x320': 8309, '77x128x320': 7730, '61x224x320': 6211, '61x192x320': 5983, '77x224x320': 5788, '77x192x320': 5268, '93x256x320': 3164, '45x256x320': 1510, '29x256x320': 1480, '61x256x320': 1152, '77x256x320': 1090, '93x96x320': 282, '45x96x320': 200, '29x96x320': 169, '61x96x320': 163, '77x96x320': 148}), cnt_movie: 0, cnt_img: 0, before filter: 478625, after filter: 474899

  2%|▏         | 9503/478625 [00:00<00:15, 31198.01it/s][A
 42%|████▏     | 203191/478625 [00:06<00:09, 29702.70it/s][A
 22%|██▏       | 106279/478625 [00:03<00:11, 31766.29it/s][A
  3%|▎         | 12706/478625 [00:00<00:14, 31520.18it/s][A
 43%|████▎     | 206246/478625 [00:06<00:09, 29950.18it/s][A
 23%|██▎       | 109459/478625 [00:03<00:11, 31199.65it/s][A
  3%|▎         | 15860/478625 [00:00<00:15, 30716.94it/s][A
 44%|████▎     | 209246/478625 [00:07<00:09, 29288.31it/s][A
 24%|██▎       | 112726/478625 [00:03<00:11, 31629.47it/s][A09/18/2024 09:22:21 - INFO - opensora.dataset.t2v_datasets - before filter: 478625, after filter: 474899 | motion_score: 474899, cnt_no_motion: 13 | 192077 > 0.95, 0.7 > 65730 Mean: 0.8593367888417824, Var: 0.03075349223473551, Std: 0.17536673639757203, Min: -0.0717548280954361, Max: 1.0

  4%|▍         | 19042/478625 [00:00<00:14, 31080.49it/s][A
 44%|████▍     | 212181/478625 [00:07<00:09, 29284.33it/s][A
 24%|██▍       | 115893/478625 [00:03<00:11, 30976.15it/s][A
  5%|▍         | 22229/478625 [00:00<00:14, 31334.40it/s][A
 45%|████▍     | 215256/478625 [00:07<00:08, 29713.69it/s][A
 25%|██▍       | 119140/478625 [00:03<00:11, 31411.89it/s][A
  5%|▌         | 25366/478625 [00:00<00:15, 30166.47it/s][A
 46%|████▌     | 218231/478625 [00:07<00:08, 29118.31it/s][A09/18/2024 09:22:21 - INFO - opensora.dataset.t2v_datasets - before filter: 478625, after filter: 474899 | aesthetic_score: 478625, cnt_no_aesthetic: 0 | 14374 > 5.75, 4.5 > 113830 Mean: 4.846693657797633, Var: 0.24147353645946146, Std: 0.4913995690468821, Min: 2.685077953338623, Max: 6.742257436116536

 26%|██▌       | 122381/478625 [00:03<00:11, 31704.62it/s][Atime 22.639402389526367
n_elements: 474899
data length: 474899

  6%|▌         | 28545/478625 [00:00<00:14, 30654.10it/s][A
 46%|████▌     | 221296/478625 [00:07<00:08, 29565.21it/s][A
 26%|██▌       | 125556/478625 [00:03<00:11, 31125.87it/s][A
  7%|▋         | 31619/478625 [00:01<00:14, 30297.23it/s][A
 47%|████▋     | 224403/478625 [00:07<00:08, 30007.92it/s][A
 27%|██▋       | 128786/478625 [00:04<00:11, 31469.69it/s][A
  7%|▋         | 34812/478625 [00:01<00:14, 30781.63it/s][A
 48%|████▊     | 227408/478625 [00:07<00:08, 29465.39it/s][A
 28%|██▊       | 132040/478625 [00:04<00:10, 31782.03it/s][A
  8%|▊         | 37986/478625 [00:01<00:14, 31065.31it/s][A
 48%|████▊     | 230359/478625 [00:07<00:08, 28991.45it/s][A
 28%|██▊       | 135222/478625 [00:04<00:10, 31275.44it/s][A
  9%|▊         | 41097/478625 [00:01<00:14, 30545.13it/s][A
 49%|████▊     | 233262/478625 [00:07<00:08, 28624.22it/s][A
 29%|██▉       | 138461/478625 [00:04<00:10, 31601.77it/s][A
  9%|▉         | 44260/478625 [00:01<00:14, 30864.40it/s][A
 49%|████▉     | 236128/478625 [00:08<00:08, 27273.30it/s][A
 30%|██▉       | 141625/478625 [00:04<00:10, 31120.55it/s][A
 10%|▉         | 47457/478625 [00:01<00:13, 31191.24it/s][A
 50%|████▉     | 239022/478625 [00:08<00:08, 27745.24it/s][A
 30%|███       | 144824/478625 [00:04<00:10, 31374.95it/s][A
 11%|█         | 50580/478625 [00:01<00:14, 30554.51it/s][A
 51%|█████     | 241930/478625 [00:08<00:08, 28129.57it/s][A
 31%|███       | 148080/478625 [00:04<00:10, 31721.92it/s][A09/18/2024 09:22:22 - INFO - __main__ - after train_dataloader
09/18/2024 09:22:22 - INFO - __main__ - before accelerator.prepare
[2024-09-18 09:22:22,652] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown

 11%|█         | 53788/478625 [00:01<00:13, 31001.98it/s][A
 51%|█████     | 244753/478625 [00:08<00:08, 28029.90it/s][A
 32%|███▏      | 151255/478625 [00:04<00:10, 31121.61it/s][A
 12%|█▏        | 56893/478625 [00:01<00:13, 30474.98it/s][A
 52%|█████▏    | 247842/478625 [00:08<00:07, 28868.58it/s][A
 32%|███▏      | 154504/478625 [00:04<00:10, 31522.07it/s][A
 13%|█▎        | 59945/478625 [00:01<00:13, 30464.58it/s][A
 52%|█████▏    | 250736/478625 [00:08<00:08, 28455.92it/s][A
 33%|███▎      | 157784/478625 [00:05<00:10, 31897.53it/s][A
 13%|█▎        | 63126/478625 [00:02<00:13, 30858.87it/s][A
 53%|█████▎    | 253672/478625 [00:08<00:07, 28719.07it/s][A
 34%|███▎      | 160977/478625 [00:05<00:10, 31265.84it/s][A
 14%|█▍        | 66215/478625 [00:02<00:13, 30441.86it/s][A
 54%|█████▎    | 256768/478625 [00:08<00:07, 29380.33it/s][A
 34%|███▍      | 164209/478625 [00:05<00:09, 31574.45it/s][A
 15%|█▍        | 69414/478625 [00:02<00:13, 30896.67it/s][A
 54%|█████▍    | 259711/478625 [00:08<00:07, 28800.83it/s][A
 35%|███▍      | 167371/478625 [00:05<00:10, 31088.04it/s][A
 15%|█▌        | 72600/478625 [00:02<00:13, 31179.23it/s][A
 55%|█████▍    | 262814/478625 [00:08<00:07, 29452.11it/s][A
 36%|███▌      | 170601/478625 [00:05<00:09, 31442.87it/s][A
 16%|█▌        | 75721/478625 [00:02<00:13, 30597.32it/s][A
 56%|█████▌    | 265970/478625 [00:09<00:07, 30072.57it/s][A
 36%|███▋      | 173865/478625 [00:05<00:09, 31793.92it/s][A
 16%|█▋        | 78866/478625 [00:02<00:12, 30845.65it/s][A
 56%|█████▌    | 268982/478625 [00:09<00:07, 29747.45it/s][A
 37%|███▋      | 177048/478625 [00:05<00:09, 31230.19it/s][A
 17%|█▋        | 81996/478625 [00:02<00:13, 30287.76it/s][A
 57%|█████▋    | 271969/478625 [00:09<00:06, 29783.06it/s][A
 38%|███▊      | 180306/478625 [00:05<00:09, 31625.75it/s][A
 18%|█▊        | 85169/478625 [00:02<00:12, 30707.49it/s][A
 57%|█████▋    | 275123/478625 [00:09<00:06, 30301.47it/s][A
 38%|███▊      | 183473/478625 [00:05<00:09, 30919.61it/s][A
 18%|█▊        | 88344/478625 [00:02<00:12, 31013.84it/s][A
 58%|█████▊    | 278156/478625 [00:09<00:06, 29884.81it/s][A
 39%|███▉      | 186748/478625 [00:05<00:09, 31412.20it/s][A
 19%|█▉        | 91449/478625 [00:02<00:12, 30424.59it/s][A
 59%|█████▉    | 281292/478625 [00:09<00:06, 30318.41it/s][A
 40%|███▉      | 190012/478625 [00:06<00:09, 31770.38it/s][A
  0%|          | 0/478625 [00:00<?, ?it/s][A
 20%|█▉        | 94617/478625 [00:03<00:12, 30790.76it/s][A
 59%|█████▉    | 284469/478625 [00:09<00:06, 30745.68it/s][A
 40%|████      | 193194/478625 [00:06<00:09, 31228.06it/s][A
  1%|          | 3192/478625 [00:00<00:14, 31912.35it/s][A
  0%|          | 0/478625 [00:00<?, ?it/s][A
 20%|██        | 97700/478625 [00:03<00:12, 30543.47it/s][A
 60%|██████    | 287546/478625 [00:09<00:06, 30235.59it/s][A
 41%|████      | 196440/478625 [00:06<00:08, 31589.16it/s][A
  1%|          | 3223/478625 [00:00<00:14, 32224.65it/s][A
  1%|▏         | 6384/478625 [00:00<00:15, 31181.22it/s][A
 21%|██        | 100758/478625 [00:03<00:12, 30138.27it/s][A
 61%|██████    | 290700/478625 [00:09<00:06, 30618.25it/s][A
 42%|████▏     | 199690/478625 [00:06<00:08, 31856.09it/s][A
  2%|▏         | 9612/478625 [00:00<00:14, 31674.40it/s][A
  1%|▏         | 6446/478625 [00:00<00:15, 30632.49it/s][A
 22%|██▏       | 103887/478625 [00:03<00:12, 30475.85it/s][A
 61%|██████▏   | 293765/478625 [00:09<00:06, 29447.78it/s][A
 42%|████▏     | 202879/478625 [00:06<00:08, 31294.35it/s][A
  3%|▎         | 12861/478625 [00:00<00:14, 31992.82it/s][A
  2%|▏         | 9759/478625 [00:00<00:14, 31737.16it/s][A
 22%|██▏       | 107080/478625 [00:03<00:12, 30902.93it/s][A
 62%|██████▏   | 296940/478625 [00:10<00:06, 30112.91it/s][A
 43%|████▎     | 206071/478625 [00:06<00:08, 31477.66it/s][A
  3%|▎         | 13084/478625 [00:00<00:14, 32322.42it/s][A
  3%|▎         | 16062/478625 [00:00<00:14, 31125.75it/s][A
 23%|██▎       | 110173/478625 [00:03<00:12, 30353.21it/s][A
 63%|██████▎   | 300095/478625 [00:10<00:05, 30532.46it/s][A
 44%|████▎     | 209222/478625 [00:06<00:08, 31040.33it/s][A
  4%|▍         | 19298/478625 [00:00<00:14, 31532.48it/s][A
  3%|▎         | 16321/478625 [00:00<00:14, 31765.21it/s][A
 24%|██▎       | 113360/478625 [00:03<00:11, 30798.11it/s][A
 63%|██████▎   | 303157/478625 [00:10<00:05, 30095.52it/s][A
 44%|████▍     | 212463/478625 [00:06<00:08, 31441.13it/s][A
  4%|▍         | 19632/478625 [00:00<00:14, 32212.64it/s][A
  5%|▍         | 22455/478625 [00:00<00:14, 30945.61it/s][A
 24%|██▍       | 116444/478625 [00:03<00:11, 30256.92it/s][A
 64%|██████▍   | 306313/478625 [00:10<00:05, 30478.04it/s][A
 45%|████▌     | 215718/478625 [00:06<00:08, 31766.90it/s][A
  5%|▌         | 25708/478625 [00:00<00:14, 31436.44it/s][A
  5%|▍         | 22894/478625 [00:00<00:14, 31659.67it/s][A
 25%|██▍       | 119631/478625 [00:03<00:11, 30728.92it/s][A
 65%|██████▍   | 309463/478625 [00:10<00:05, 30776.76it/s][A
 46%|████▌     | 218898/478625 [00:06<00:08, 31295.91it/s][A
  6%|▌         | 28940/478625 [00:00<00:14, 31705.66it/s][A
  5%|▌         | 26222/478625 [00:00<00:14, 32163.06it/s][A
 26%|██▌       | 122796/478625 [00:03<00:11, 30999.63it/s][A
 65%|██████▌   | 312545/478625 [00:10<00:05, 29838.99it/s][A
 46%|████▋     | 222148/478625 [00:07<00:08, 31649.71it/s][A
  6%|▌         | 29530/478625 [00:00<00:13, 32443.83it/s][A
  7%|▋         | 32114/478625 [00:01<00:14, 31133.61it/s][A
 26%|██▋       | 125900/478625 [00:04<00:11, 30453.26it/s][A
 66%|██████▌   | 315677/478625 [00:10<00:05, 30268.13it/s][A
 47%|████▋     | 225417/478625 [00:07<00:07, 31957.46it/s][A
  7%|▋         | 35347/478625 [00:01<00:14, 31489.88it/s][A
  7%|▋         | 32778/478625 [00:01<00:13, 31857.01it/s][A
 27%|██▋       | 129063/478625 [00:04<00:11, 30796.51it/s][A
 67%|██████▋   | 318711/478625 [00:10<00:05, 29948.89it/s][A
 48%|████▊     | 228615/478625 [00:07<00:08, 31053.44it/s][A
  8%|▊         | 38566/478625 [00:01<00:13, 31697.42it/s][A
  8%|▊         | 36115/478625 [00:01<00:13, 32309.83it/s][A
 28%|██▊       | 132246/478625 [00:04<00:11, 31101.65it/s][A
 67%|██████▋   | 321848/478625 [00:10<00:05, 30363.69it/s][A
 48%|████▊     | 231820/478625 [00:07<00:07, 31341.67it/s][A
  8%|▊         | 39408/478625 [00:01<00:13, 32494.48it/s][A
  9%|▊         | 41739/478625 [00:01<00:14, 30189.51it/s][A
 28%|██▊       | 135359/478625 [00:04<00:11, 30095.06it/s][A
 68%|██████▊   | 325020/478625 [00:10<00:04, 30762.87it/s][A
 49%|████▉     | 234960/478625 [00:07<00:07, 30956.28it/s][A
  9%|▉         | 42661/478625 [00:01<00:13, 31326.89it/s][A
  9%|▉         | 44946/478625 [00:01<00:14, 30732.50it/s][A
 29%|██▉       | 138510/478625 [00:04<00:11, 30505.32it/s][A
 69%|██████▊   | 328101/478625 [00:11<00:05, 29930.29it/s][A
 50%|████▉     | 238225/478625 [00:07<00:07, 31451.69it/s][A
 10%|▉         | 45975/478625 [00:01<00:13, 31855.55it/s][A
 10%|█         | 48033/478625 [00:01<00:14, 30457.14it/s][A
 30%|██▉       | 141568/478625 [00:04<00:11, 30045.04it/s][A
 69%|██████▉   | 331101/478625 [00:11<00:04, 29877.20it/s][A
 50%|█████     | 241490/478625 [00:07<00:07, 31803.06it/s][A
 11%|█         | 51236/478625 [00:01<00:13, 30915.25it/s][A
 10%|█         | 49170/478625 [00:01<00:13, 31477.70it/s][A
 30%|███       | 144696/478625 [00:04<00:10, 30404.47it/s][A
 70%|██████▉   | 334271/478625 [00:11<00:04, 30412.12it/s][A
 51%|█████     | 244674/478625 [00:07<00:07, 31216.90it/s][A
 11%|█▏        | 54476/478625 [00:01<00:13, 31349.71it/s][A
 11%|█         | 52471/478625 [00:01<00:13, 31926.85it/s][A
 31%|███       | 147900/478625 [00:04<00:10, 30883.79it/s][A
 70%|███████   | 337317/478625 [00:11<00:04, 29889.47it/s][A
 52%|█████▏    | 247915/478625 [00:07<00:07, 31565.74it/s][A
 12%|█▏        | 55799/478625 [00:01<00:13, 32325.25it/s][A
 12%|█▏        | 57618/478625 [00:01<00:13, 30822.44it/s][A
 32%|███▏      | 150993/478625 [00:04<00:10, 30281.89it/s][A
 71%|███████   | 340475/478625 [00:11<00:04, 30382.17it/s][A
 52%|█████▏    | 251076/478625 [00:07<00:07, 31024.09it/s][A
 13%|█▎        | 60863/478625 [00:01<00:13, 31300.09it/s][A
 12%|█▏        | 59037/478625 [00:01<00:13, 31788.06it/s][A
 32%|███▏      | 154179/478625 [00:05<00:10, 30743.35it/s][A
 72%|███████▏  | 343569/478625 [00:11<00:04, 29931.01it/s][A
 53%|█████▎    | 254326/478625 [00:08<00:07, 31453.97it/s][A
 13%|█▎        | 64074/478625 [00:02<00:13, 31538.83it/s][A
 13%|█▎        | 62377/478625 [00:01<00:12, 32260.10it/s][A
 33%|███▎      | 157367/478625 [00:05<00:10, 31076.34it/s][A
 72%|███████▏  | 346705/478625 [00:11<00:04, 30346.70it/s][A
 54%|█████▍    | 257571/478625 [00:08<00:06, 31746.72it/s][A
 14%|█▍        | 67232/478625 [00:02<00:13, 31016.84it/s][A
 14%|█▎        | 65608/478625 [00:02<00:13, 31502.18it/s][A
 34%|███▎      | 160479/478625 [00:05<00:10, 30481.58it/s][A
 73%|███████▎  | 349858/478625 [00:11<00:04, 30694.24it/s][A
 54%|█████▍    | 260749/478625 [00:08<00:07, 31002.07it/s][A
 15%|█▍        | 70478/478625 [00:02<00:12, 31439.87it/s][A
 14%|█▍        | 68948/478625 [00:02<00:12, 32053.09it/s][A
 34%|███▍      | 163630/478625 [00:05<00:10, 30780.83it/s][A
 74%|███████▎  | 352931/478625 [00:11<00:04, 29631.42it/s][A
 55%|█████▌    | 263855/478625 [00:08<00:06, 30990.10it/s][A
 15%|█▌        | 72248/478625 [00:02<00:12, 32329.84it/s][A
 15%|█▌        | 73626/478625 [00:02<00:13, 30941.55it/s][A
 35%|███▍      | 166712/478625 [00:05<00:10, 30322.01it/s][A
 74%|███████▍  | 356101/478625 [00:12<00:04, 30229.01it/s][A
 56%|█████▌    | 267095/478625 [00:08<00:06, 31403.37it/s][A
 16%|█▌        | 76855/478625 [00:02<00:12, 31337.05it/s][A
 16%|█▌        | 75486/478625 [00:02<00:12, 31866.84it/s][A
 35%|███▌      | 169859/478625 [00:05<00:10, 30657.74it/s][A
 75%|███████▌  | 359225/478625 [00:12<00:03, 30522.40it/s][A
 56%|█████▋    | 270239/478625 [00:08<00:06, 30845.78it/s][A
 17%|█▋        | 80048/478625 [00:02<00:12, 31509.94it/s][A
 16%|█▋        | 78809/478625 [00:02<00:12, 32266.04it/s][A
 36%|███▌      | 172929/478625 [00:05<00:10, 30439.52it/s][A
 76%|███████▌  | 362284/478625 [00:12<00:03, 30102.58it/s][A
 57%|█████▋    | 273472/478625 [00:08<00:06, 31280.63it/s][A
 17%|█▋        | 83202/478625 [00:02<00:12, 31046.80it/s][A
 17%|█▋        | 82040/478625 [00:02<00:12, 31598.31it/s][A
 37%|███▋      | 175976/478625 [00:05<00:10, 30047.87it/s][A
 76%|███████▋  | 365427/478625 [00:12<00:03, 30489.71it/s][A
 58%|█████▊    | 276604/478625 [00:08<00:06, 30892.78it/s][A
 18%|█▊        | 85360/478625 [00:02<00:12, 32064.94it/s][A
 18%|█▊        | 86310/478625 [00:02<00:12, 30433.41it/s][A
 37%|███▋      | 179147/478625 [00:05<00:09, 30534.85it/s][A
 77%|███████▋  | 368572/478625 [00:12<00:03, 30770.30it/s][A
 58%|█████▊    | 279840/478625 [00:08<00:06, 31323.79it/s][A
 19%|█▊        | 88670/478625 [00:02<00:12, 32366.40it/s][A
 19%|█▊        | 89569/478625 [00:02<00:12, 31061.04it/s][A
 38%|███▊      | 182282/478625 [00:05<00:09, 30774.00it/s][A
 59%|█████▉    | 283109/478625 [00:09<00:06, 31726.09it/s][A
 78%|███████▊  | 371653/478625 [00:12<00:03, 29512.00it/s][A
 19%|█▉        | 91911/478625 [00:02<00:12, 31756.42it/s][A
 19%|█▉        | 92680/478625 [00:02<00:12, 30522.11it/s][A
 39%|███▊      | 185362/478625 [00:06<00:09, 30265.64it/s][A
 78%|███████▊  | 374803/478625 [00:12<00:03, 30084.57it/s][A
 60%|█████▉    | 286285/478625 [00:09<00:06, 31196.71it/s][A
 20%|█▉        | 95219/478625 [00:02<00:11, 32143.44it/s][A
 20%|██        | 95901/478625 [00:03<00:12, 31012.41it/s][A
 39%|███▉      | 188556/478625 [00:06<00:09, 30757.96it/s][A
 79%|███████▉  | 377823/478625 [00:12<00:03, 29790.74it/s][A
 60%|██████    | 289524/478625 [00:09<00:05, 31546.32it/s][A
 21%|██        | 98507/478625 [00:03<00:11, 32359.99it/s][A
 21%|██        | 99007/478625 [00:03<00:12, 30611.47it/s][A
 40%|████      | 191682/478625 [00:06<00:09, 30328.89it/s][A
 80%|███████▉  | 380971/478625 [00:12<00:03, 30283.23it/s][A
 61%|██████    | 292730/478625 [00:09<00:05, 31697.77it/s][A

 21%|██▏       | 101747/478625 [00:03<00:11, 31751.62it/s][A 21%|██▏       | 102205/478625 [00:03<00:12, 31012.44it/s][A
 41%|████      | 194867/478625 [00:06<00:09, 30772.28it/s][A
 80%|████████  | 384140/478625 [00:12<00:03, 30697.03it/s][A
 62%|██████▏   | 295903/478625 [00:09<00:05, 31155.21it/s][A

 22%|██▏       | 105065/478625 [00:03<00:11, 32169.84it/s][A 22%|██▏       | 105401/478625 [00:03<00:11, 31290.17it/s][A
 41%|████▏     | 198035/478625 [00:06<00:09, 31037.03it/s][A
 81%|████████  | 387216/478625 [00:13<00:03, 30176.75it/s][A
 63%|██████▎   | 299187/478625 [00:09<00:05, 31650.22it/s][A
 23%|██▎       | 108533/478625 [00:03<00:11, 30859.11it/s][A
 23%|██▎       | 108286/478625 [00:03<00:11, 31695.46it/s][A
 42%|████▏     | 201142/478625 [00:06<00:09, 30456.21it/s][A
 82%|████████▏ | 390364/478625 [00:13<00:02, 30557.97it/s][A
 63%|██████▎   | 302356/478625 [00:09<00:05, 31157.12it/s][A
 23%|██▎       | 111750/478625 [00:03<00:11, 31242.62it/s][A
 23%|██▎       | 111602/478625 [00:03<00:11, 32125.02it/s][A
 43%|████▎     | 204313/478625 [00:06<00:08, 30821.61it/s][A
 82%|████████▏ | 393425/478625 [00:13<00:02, 30403.08it/s][A
 64%|██████▍   | 305476/478625 [00:09<00:05, 31140.04it/s][A
 24%|██▍       | 114962/478625 [00:03<00:11, 31500.95it/s][A
 24%|██▍       | 114884/478625 [00:03<00:11, 32327.62it/s][A
 43%|████▎     | 207437/478625 [00:06<00:08, 30942.40it/s][A
 65%|██████▍   | 308749/478625 [00:09<00:05, 31607.78it/s][A
 83%|████████▎ | 396469/478625 [00:13<00:02, 29905.98it/s][A
 25%|██▍       | 118120/478625 [00:03<00:11, 31781.02it/s][A
 25%|██▍       | 118115/478625 [00:03<00:11, 30864.69it/s][A
 44%|████▍     | 210534/478625 [00:06<00:08, 29918.28it/s][A
 83%|████████▎ | 399626/478625 [00:13<00:02, 30393.11it/s][A
 65%|██████▌   | 311913/478625 [00:09<00:05, 31269.70it/s][A
 25%|██▌       | 121435/478625 [00:03<00:11, 32181.26it/s][A
 25%|██▌       | 121325/478625 [00:03<00:11, 31227.17it/s][A
 45%|████▍     | 213701/478625 [00:06<00:08, 30424.95it/s][A
 66%|██████▌   | 315164/478625 [00:10<00:05, 31635.58it/s][A
 84%|████████▍ | 402669/478625 [00:13<00:02, 29960.94it/s][A
 26%|██▌       | 124657/478625 [00:03<00:11, 31734.19it/s][A
 26%|██▌       | 124452/478625 [00:04<00:11, 30758.95it/s][A
 45%|████▌     | 216894/478625 [00:07<00:08, 30863.40it/s][A
 85%|████████▍ | 405821/478625 [00:13<00:02, 30416.21it/s][A
 67%|██████▋   | 318330/478625 [00:10<00:05, 31234.72it/s][A
 27%|██▋       | 127931/478625 [00:03<00:10, 32028.93it/s][A
 27%|██▋       | 127658/478625 [00:04<00:11, 31138.07it/s][A
 46%|████▌     | 219987/478625 [00:07<00:08, 30406.85it/s][A
 85%|████████▌ | 408969/478625 [00:13<00:02, 30708.84it/s][A
 67%|██████▋   | 321617/478625 [00:10<00:04, 31716.63it/s][A
 27%|██▋       | 131244/478625 [00:04<00:10, 32352.70it/s][A
 27%|██▋       | 130776/478625 [00:04<00:11, 30736.29it/s][A
 47%|████▋     | 223182/478625 [00:07<00:08, 30858.81it/s][A
 68%|██████▊   | 324907/478625 [00:10<00:04, 32065.25it/s][A
 86%|████████▌ | 412043/478625 [00:13<00:02, 29674.86it/s][A
 28%|██▊       | 134482/478625 [00:04<00:10, 31792.56it/s][A
 28%|██▊       | 133853/478625 [00:04<00:11, 30440.85it/s][A
 47%|████▋     | 226273/478625 [00:07<00:08, 30407.96it/s][A
 69%|██████▊   | 328116/478625 [00:10<00:04, 31181.82it/s]
[A 87%|████████▋ | 415116/478625 [00:13<00:02, 29980.14it/s][A
 29%|██▉       | 137786/478625 [00:04<00:10, 32159.14it/s][A
 29%|██▊       | 137067/478625 [00:04<00:11, 30938.72it/s][A
 48%|████▊     | 229449/478625 [00:07<00:08, 30802.46it/s][A

 69%|██████▉   | 331372/478625 [00:10<00:04, 31583.08it/s][A 87%|████████▋ | 418260/478625 [00:14<00:01, 30406.98it/s][A
 29%|██▉       | 140293/478625 [00:04<00:10, 31327.09it/s][A
 29%|██▉       | 141053/478625 [00:04<00:10, 31658.13it/s][A
 49%|████▊     | 232534/478625 [00:07<00:07, 30812.59it/s][A
 70%|██████▉   | 334613/478625 [00:10<00:04, 31825.14it/s][A
 88%|████████▊ | 421307/478625 [00:14<00:01, 30047.83it/s][A
 30%|███       | 144321/478625 [00:04<00:10, 31956.03it/s][A
 30%|██▉       | 143429/478625 [00:04<00:10, 30704.80it/s][A
 49%|████▉     | 235618/478625 [00:07<00:08, 30345.60it/s][A
 89%|████████▊ | 424453/478625 [00:14<00:01, 30462.24it/s][A
 71%|███████   | 337800/478625 [00:10<00:04, 31129.55it/s][A
 31%|███       | 147655/478625 [00:04<00:10, 32361.55it/s][A
 31%|███       | 146621/478625 [00:04<00:10, 31061.21it/s][A
 50%|████▉     | 238800/478625 [00:07<00:07, 30754.01it/s][A
 89%|████████▉ | 427599/478625 [00:14<00:01, 30754.26it/s][A
 71%|███████▏  | 341055/478625 [00:10<00:04, 31542.42it/s][A
 32%|███▏      | 150895/478625 [00:04<00:10, 31734.25it/s][A
 31%|███▏      | 149731/478625 [00:04<00:10, 30605.26it/s][A
 51%|█████     | 241984/478625 [00:07<00:07, 31072.93it/s][A
 90%|████████▉ | 430678/478625 [00:14<00:01, 30257.15it/s][A
 72%|███████▏  | 344215/478625 [00:10<00:04, 31000.08it/s][A
 32%|███▏      | 154229/478625 [00:04<00:10, 32204.59it/s][A
 32%|███▏      | 152952/478625 [00:04<00:10, 31073.93it/s][A
 51%|█████     | 245094/478625 [00:08<00:07, 30103.59it/s][A
 91%|█████████ | 433708/478625 [00:14<00:01, 30011.78it/s][A
 73%|███████▎  | 347320/478625 [00:11<00:04, 30878.44it/s][A
 33%|███▎      | 157561/478625 [00:04<00:09, 32531.30it/s][A
 33%|███▎      | 156175/478625 [00:05<00:10, 31413.36it/s][A
 52%|█████▏    | 248262/478625 [00:08<00:07, 30561.73it/s][A
 73%|███████▎  | 350570/478625 [00:11<00:04, 31354.61it/s][A
 91%|█████████ | 436712/478625 [00:14<00:01, 29763.63it/s][A

 33%|███▎      | 159320/478625 [00:05<00:10, 30947.43it/s][A 34%|███▎      | 160818/478625 [00:05<00:09, 31894.28it/s][A
 53%|█████▎    | 251325/478625 [00:08<00:07, 30153.45it/s][A
 92%|█████████▏| 439866/478625 [00:14<00:01, 30285.42it/s][A
 74%|███████▍  | 353709/478625 [00:11<00:04, 30885.51it/s][A

 34%|███▍      | 162490/478625 [00:05<00:10, 31168.57it/s][A 34%|███▍      | 164105/478625 [00:05<00:09, 32177.72it/s][A
 53%|█████▎    | 254500/478625 [00:08<00:07, 30618.44it/s][A
 93%|█████████▎| 443013/478625 [00:14<00:01, 30634.78it/s][A
 75%|███████▍  | 356958/478625 [00:11<00:03, 31313.02it/s][A
 35%|███▍      | 167327/478625 [00:05<00:09, 31642.39it/s][A
 35%|███▍      | 165676/478625 [00:05<00:10, 30764.95it/s][A
 54%|█████▍    | 257666/478625 [00:08<00:07, 30924.06it/s][A

 75%|███████▌  | 360189/478625 [00:11<00:03, 31606.68it/s][A 93%|█████████▎| 446079/478625 [00:15<00:01, 30175.36it/s][A
 36%|███▌      | 170672/478625 [00:05<00:09, 32169.63it/s][A
 35%|███▌      | 168904/478625 [00:05<00:09, 31207.46it/s][A
 54%|█████▍    | 260763/478625 [00:08<00:07, 30216.16it/s][A
 94%|█████████▍| 449229/478625 [00:15<00:00, 30564.96it/s][A
 76%|███████▌  | 363353/478625 [00:11<00:03, 31093.07it/s][A
 36%|███▋      | 174036/478625 [00:05<00:09, 32602.98it/s][A
 36%|███▌      | 172028/478625 [00:05<00:09, 30897.83it/s][A
 55%|█████▌    | 263948/478625 [00:08<00:06, 30693.60it/s][A
 94%|█████████▍| 452289/478625 [00:15<00:00, 30349.30it/s][A
 77%|███████▋  | 366575/478625 [00:11<00:03, 31421.78it/s][A
 37%|███▋      | 177300/478625 [00:05<00:09, 32108.93it/s][A
 37%|███▋      | 175121/478625 [00:05<00:09, 30570.23it/s][A
 56%|█████▌    | 267114/478625 [00:08<00:06, 30976.49it/s][A
 95%|█████████▌| 455326/478625 [00:15<00:00, 29957.85it/s][A
 77%|███████▋  | 369721/478625 [00:11<00:03, 30699.27it/s][A
 38%|███▊      | 180633/478625 [00:05<00:09, 32466.35it/s][A
 37%|███▋      | 178349/478625 [00:05<00:09, 31069.98it/s][A
 56%|█████▋    | 270216/478625 [00:08<00:06, 30399.97it/s][A
 96%|█████████▌| 458473/478625 [00:15<00:00, 30398.48it/s][A
 78%|███████▊  | 373001/478625 [00:11<00:03, 31310.32it/s][A
 38%|███▊      | 181532/478625 [00:05<00:09, 31293.61it/s][A
 38%|███▊      | 183883/478625 [00:05<00:09, 31847.99it/s][A
 57%|█████▋    | 273385/478625 [00:08<00:06, 30777.07it/s][A
 96%|█████████▋| 461632/478625 [00:15<00:00, 30748.43it/s][A
 79%|███████▊  | 376256/478625 [00:11<00:03, 31674.13it/s][A
 39%|███▉      | 187254/478625 [00:05<00:08, 32392.11it/s][A
 39%|███▊      | 184664/478625 [00:05<00:09, 30680.92it/s][A
 58%|█████▊    | 276467/478625 [00:09<00:06, 30300.95it/s][A
 97%|█████████▋| 464709/478625 [00:15<00:00, 30128.08it/s][A
 79%|███████▉  | 379428/478625 [00:12<00:03, 31061.30it/s][A
 40%|███▉      | 190638/478625 [00:05<00:08, 32817.92it/s][A
 39%|███▉      | 187887/478625 [00:06<00:09, 31134.29it/s][A
 58%|█████▊    | 279636/478625 [00:09<00:06, 30707.03it/s][A
 98%|█████████▊| 467784/478625 [00:15<00:00, 30308.11it/s][A
 80%|███████▉  | 382690/478625 [00:12<00:03, 31516.01it/s][A
 41%|████      | 193924/478625 [00:06<00:08, 32259.03it/s][A
 40%|███▉      | 191004/478625 [00:06<00:09, 30752.28it/s][A
 59%|█████▉    | 282711/478625 [00:09<00:06, 30578.51it/s][A
 98%|█████████▊| 470818/478625 [00:15<00:00, 29951.00it/s][A
 81%|████████  | 385847/478625 [00:12<00:02, 30955.26it/s][A
 41%|████      | 197297/478625 [00:06<00:08, 32690.32it/s][A
 41%|████      | 194225/478625 [00:06<00:09, 31180.81it/s][A
 60%|█████▉    | 285772/478625 [00:09<00:06, 30180.40it/s][A
 99%|█████████▉| 473941/478625 [00:15<00:00, 30324.22it/s][A
 81%|████████▏ | 388948/478625 [00:12<00:02, 30904.84it/s][A
 41%|████      | 197428/478625 [00:06<00:08, 31428.64it/s][A
 42%|████▏     | 200570/478625 [00:06<00:08, 32086.18it/s][A
 60%|██████    | 288951/478625 [00:09<00:06, 30650.23it/s][A
100%|█████████▉| 477117/478625 [00:16<00:00, 30748.17it/s][A
 82%|████████▏ | 392178/478625 [00:12<00:02, 31315.01it/s][A

 43%|████▎     | 203913/478625 [00:06<00:08, 32477.33it/s][A 42%|████▏     | 200574/478625 [00:06<00:08, 30934.23it/s][A100%|██████████| 478625/478625 [00:16<00:00, 29765.27it/s]
100%|██████████| 1/1 [00:23<00:00, 23.03s/it]100%|██████████| 1/1 [00:23<00:00, 23.03s/it]

 61%|██████    | 292056/478625 [00:09<00:06, 30767.51it/s][A
 83%|████████▎ | 395313/478625 [00:12<00:02, 30861.55it/s][A

 43%|████▎     | 207221/478625 [00:06<00:08, 32654.02it/s][A 43%|████▎     | 203766/478625 [00:06<00:08, 31222.81it/s][A
 62%|██████▏   | 295135/478625 [00:09<00:06, 30287.56it/s][A
 83%|████████▎ | 398554/478625 [00:12<00:02, 31313.94it/s][A
 43%|████▎     | 206961/478625 [00:06<00:08, 31436.81it/s][A
 44%|████▍     | 210490/478625 [00:06<00:08, 32204.40it/s][A
 62%|██████▏   | 298347/478625 [00:09<00:05, 30826.89it/s][A
 84%|████████▍ | 401809/478625 [00:12<00:02, 31678.32it/s][A
 45%|████▍     | 213851/478625 [00:06<00:08, 32616.08it/s][A
 44%|████▍     | 210107/478625 [00:06<00:08, 30151.72it/s][A
 63%|██████▎   | 301433/478625 [00:09<00:05, 30338.97it/s][A
 85%|████████▍ | 404980/478625 [00:12<00:02, 31115.14it/s][A
 45%|████▍     | 213340/478625 [00:06<00:08, 30779.86it/s][A
 45%|████▌     | 217116/478625 [00:06<00:08, 31604.50it/s][A
 64%|██████▎   | 304610/478625 [00:09<00:05, 30756.63it/s][A
 85%|████████▌ | 408232/478625 [00:13<00:02, 31526.31it/s][A
 46%|████▌     | 220488/478625 [00:06<00:08, 32217.76it/s][A
 45%|████▌     | 216429/478625 [00:06<00:08, 30441.09it/s][A
 64%|██████▍   | 307783/478625 [00:10<00:05, 31043.18it/s][A
 86%|████████▌ | 411388/478625 [00:13<00:02, 30984.61it/s][A
 47%|████▋     | 223859/478625 [00:06<00:07, 32654.86it/s][A
 46%|████▌     | 219665/478625 [00:07<00:08, 31000.31it/s][A
 65%|██████▍   | 310890/478625 [00:10<00:05, 30529.93it/s][A
 87%|████████▋ | 414620/478625 [00:13<00:02, 31375.22it/s][A
 47%|████▋     | 222894/478625 [00:07<00:08, 31378.23it/s][A
 47%|████▋     | 227131/478625 [00:07<00:07, 32161.69it/s][A
 66%|██████▌   | 314080/478625 [00:10<00:05, 30932.69it/s][A
 87%|████████▋ | 417762/478625 [00:13<00:01, 31352.27it/s][A
 48%|████▊     | 230414/478625 [00:07<00:07, 32356.84it/s][A
 47%|████▋     | 226038/478625 [00:07<00:08, 30991.47it/s][A
 66%|██████▋   | 317255/478625 [00:10<00:05, 31173.37it/s][A
 88%|████████▊ | 420900/478625 [00:13<00:01, 30903.19it/s][A
 49%|████▉     | 233790/478625 [00:07<00:07, 32768.57it/s][A
 48%|████▊     | 229239/478625 [00:07<00:07, 31288.94it/s][A
 67%|██████▋   | 320375/478625 [00:10<00:05, 30137.93it/s][A
 89%|████████▊ | 424148/478625 [00:13<00:01, 31364.07it/s][A
 49%|████▊     | 232400/478625 [00:07<00:07, 31381.82it/s][A
 50%|████▉     | 237071/478625 [00:07<00:07, 32261.04it/s][A
 68%|██████▊   | 323547/478625 [00:10<00:05, 30595.20it/s][A
 89%|████████▉ | 427385/478625 [00:13<00:01, 31661.12it/s][A
 50%|█████     | 240301/478625 [00:07<00:07, 32164.14it/s][A
 49%|████▉     | 235541/478625 [00:07<00:07, 30894.19it/s][A
 68%|██████▊   | 326727/478625 [00:10<00:04, 30947.37it/s][A
 90%|████████▉ | 430554/478625 [00:13<00:01, 30660.23it/s][A
 50%|████▉     | 238766/478625 [00:07<00:07, 31292.51it/s][A
 51%|█████     | 243520/478625 [00:07<00:07, 31830.85it/s][A
 69%|██████▉   | 329828/478625 [00:10<00:04, 30199.53it/s][Atime 24.2894606590271

 91%|█████████ | 433801/478625 [00:13<00:01, 31185.84it/s][An_elements: 474899
data length: 474899

 52%|█████▏    | 246879/478625 [00:07<00:07, 32347.46it/s][A
 51%|█████     | 241899/478625 [00:07<00:07, 30809.89it/s][A
 70%|██████▉   | 333020/478625 [00:10<00:04, 30700.87it/s][A
 91%|█████████▏| 436927/478625 [00:13<00:01, 30809.05it/s][A
 52%|█████▏    | 250227/478625 [00:07<00:06, 32679.70it/s][A
 51%|█████     | 245120/478625 [00:07<00:07, 31219.50it/s][A
 70%|███████   | 336097/478625 [00:10<00:04, 30194.63it/s][A
 92%|█████████▏| 440177/478625 [00:14<00:01, 31303.83it/s][A
 52%|█████▏    | 248349/478625 [00:07<00:07, 31534.26it/s][A
 53%|█████▎    | 253498/478625 [00:07<00:06, 32208.07it/s][A
 71%|███████   | 339283/478625 [00:11<00:04, 30679.94it/s][A
 93%|█████████▎| 443452/478625 [00:14<00:01, 31727.37it/s][A
 54%|█████▎    | 256861/478625 [00:07<00:06, 32625.62it/s][A
 53%|█████▎    | 251506/478625 [00:08<00:07, 30948.19it/s][A
 72%|███████▏  | 342458/478625 [00:11<00:04, 30994.27it/s][A
 93%|█████████▎| 446629/478625 [00:14<00:01, 31153.75it/s][A
 53%|█████▎    | 254605/478625 [00:08<00:07, 30413.28it/s][A
 54%|█████▍    | 260127/478625 [00:08<00:06, 31357.73it/s][A
 72%|███████▏  | 345562/478625 [00:11<00:04, 30432.41it/s][A
 94%|█████████▍| 449860/478625 [00:14<00:00, 31490.93it/s][A
 54%|█████▍    | 257808/478625 [00:08<00:07, 30883.99it/s][A
 55%|█████▌    | 263483/478625 [00:08<00:06, 31991.66it/s][A
 73%|███████▎  | 348725/478625 [00:11<00:04, 30783.22it/s][A
 95%|█████████▍| 453100/478625 [00:14<00:00, 31758.18it/s][A
 56%|█████▌    | 266871/478625 [00:08<00:06, 32542.11it/s][A
 55%|█████▍    | 260901/478625 [00:08<00:07, 30288.84it/s][A
 74%|███████▎  | 351907/478625 [00:11<00:04, 31087.50it/s][A
 95%|█████████▌| 456279/478625 [00:14<00:00, 31174.42it/s][A
 55%|█████▌    | 264101/478625 [00:08<00:06, 30787.31it/s][A
 56%|█████▋    | 270134/478625 [00:08<00:06, 31910.58it/s][A
 74%|███████▍  | 355020/478625 [00:11<00:04, 30388.06it/s][A
 96%|█████████▌| 459536/478625 [00:14<00:00, 31582.45it/s][A
 57%|█████▋    | 273490/478625 [00:08<00:06, 32391.62it/s][A
 56%|█████▌    | 267185/478625 [00:08<00:06, 30445.49it/s][A
 75%|███████▍  | 358064/478625 [00:11<00:03, 30301.15it/s][A
 97%|█████████▋| 462698/478625 [00:14<00:00, 31054.53it/s][A
 56%|█████▋    | 270397/478625 [00:08<00:06, 30934.76it/s][A
 58%|█████▊    | 276736/478625 [00:08<00:06, 31998.95it/s][A
 75%|███████▌  | 361098/478625 [00:11<00:03, 29985.93it/s][A
 97%|█████████▋| 465912/478625 [00:14<00:00, 31370.35it/s][A
 57%|█████▋    | 273615/478625 [00:08<00:06, 31300.85it/s][A
 59%|█████▊    | 280080/478625 [00:08<00:06, 32418.69it/s][A
 76%|███████▌  | 364265/478625 [00:11<00:03, 30479.70it/s][A
 98%|█████████▊| 469053/478625 [00:14<00:00, 31346.60it/s][A
 58%|█████▊    | 276749/478625 [00:08<00:06, 30811.78it/s][A
 59%|█████▉    | 283327/478625 [00:08<00:06, 32268.03it/s][A
 77%|███████▋  | 367421/478625 [00:11<00:03, 30796.32it/s][A
 99%|█████████▊| 472191/478625 [00:15<00:00, 30424.74it/s][A
 58%|█████▊    | 279956/478625 [00:09<00:06, 31180.67it/s][A
 60%|█████▉    | 286557/478625 [00:08<00:06, 31935.83it/s][A
 77%|███████▋  | 370504/478625 [00:12<00:03, 30075.61it/s][A
 99%|█████████▉| 475433/478625 [00:15<00:00, 31004.94it/s][A
 59%|█████▉    | 283186/478625 [00:09<00:06, 31509.10it/s][A
 61%|██████    | 289908/478625 [00:09<00:05, 32396.48it/s][A
 78%|███████▊  | 373711/478625 [00:12<00:03, 30657.38it/s][A100%|██████████| 478625/478625 [00:15<00:00, 31353.14it/s]
100%|██████████| 1/1 [00:21<00:00, 21.92s/it]100%|██████████| 1/1 [00:21<00:00, 21.92s/it]

 60%|█████▉    | 286340/478625 [00:09<00:06, 31017.90it/s][A
 61%|██████    | 293151/478625 [00:09<00:05, 31802.51it/s][A
 79%|███████▊  | 376889/478625 [00:12<00:03, 30987.00it/s][A
 60%|██████    | 289515/478625 [00:09<00:06, 31232.09it/s][A
 62%|██████▏   | 296521/478625 [00:09<00:05, 32358.66it/s][A
 79%|███████▉  | 379992/478625 [00:12<00:03, 30499.79it/s][A
 63%|██████▎   | 299906/478625 [00:09<00:05, 32797.89it/s][A
 61%|██████    | 292641/478625 [00:09<00:06, 30554.89it/s][A
 80%|████████  | 383170/478625 [00:12<00:03, 30874.39it/s][A
 62%|██████▏   | 295817/478625 [00:09<00:05, 30871.78it/s][A
 63%|██████▎   | 303190/478625 [00:09<00:05, 31772.46it/s][A
 81%|████████  | 386261/478625 [00:12<00:03, 30109.45it/s][A
 62%|██████▏   | 299032/478625 [00:09<00:05, 31245.82it/s][A
 64%|██████▍   | 306539/478625 [00:09<00:05, 32269.40it/s][A
 81%|████████▏ | 389429/478625 [00:12<00:02, 30566.48it/s][A
 65%|██████▍   | 309883/478625 [00:09<00:05, 31923.10it/s][A
 63%|██████▎   | 302160/478625 [00:09<00:05, 29767.65it/s][A
 82%|████████▏ | 392638/478625 [00:12<00:02, 31011.35it/s][A
 65%|██████▌   | 313269/478625 [00:09<00:05, 32484.07it/s][A
 64%|██████▍   | 305362/478625 [00:09<00:05, 30411.63it/s][A
 83%|████████▎ | 395744/478625 [00:12<00:02, 29934.16it/s][Atime 22.66064691543579

 66%|██████▌   | 316628/478625 [00:09<00:04, 32806.86it/s][A
 64%|██████▍   | 308516/478625 [00:09<00:05, 30738.33it/s][An_elements: 474899
data length: 474899

 83%|████████▎ | 398938/478625 [00:13<00:02, 30512.24it/s][A
 65%|██████▌   | 311601/478625 [00:10<00:05, 30403.34it/s][A
 67%|██████▋   | 319914/478625 [00:09<00:04, 32240.08it/s][A
 84%|████████▍ | 402108/478625 [00:13<00:02, 30857.33it/s][A
 66%|██████▌   | 314811/478625 [00:10<00:05, 30870.58it/s][A
 68%|██████▊   | 323193/478625 [00:10<00:04, 32170.16it/s][A
 85%|████████▍ | 405201/478625 [00:13<00:02, 30425.41it/s][A
 68%|██████▊   | 326526/478625 [00:10<00:04, 32508.47it/s][A
 66%|██████▋   | 317905/478625 [00:10<00:05, 30499.50it/s][A
 85%|████████▌ | 408358/478625 [00:13<00:02, 30759.32it/s][A
 67%|██████▋   | 321127/478625 [00:10<00:05, 31003.33it/s][A
 69%|██████▉   | 329780/478625 [00:10<00:04, 31825.64it/s][A
 86%|████████▌ | 411439/478625 [00:13<00:02, 30308.81it/s][A
 68%|██████▊   | 324347/478625 [00:10<00:04, 31356.33it/s][A
 70%|██████▉   | 333143/478625 [00:10<00:04, 32351.17it/s][A
 87%|████████▋ | 414610/478625 [00:13<00:02, 30718.96it/s][A
 68%|██████▊   | 327487/478625 [00:10<00:04, 30733.02it/s][A
 70%|███████   | 336383/478625 [00:10<00:04, 31935.58it/s][A
 87%|████████▋ | 417686/478625 [00:13<00:01, 30697.60it/s][A
 69%|██████▉   | 330626/478625 [00:10<00:04, 30923.56it/s][A
 71%|███████   | 339742/478625 [00:10<00:04, 32417.94it/s][A
 88%|████████▊ | 420759/478625 [00:13<00:01, 30306.60it/s][A
 70%|██████▉   | 333832/478625 [00:10<00:04, 31258.41it/s][A
 72%|███████▏  | 343102/478625 [00:10<00:04, 32765.90it/s][A
 89%|████████▊ | 423937/478625 [00:13<00:01, 30740.13it/s][A
 70%|███████   | 336962/478625 [00:10<00:04, 30764.17it/s][A
 72%|███████▏  | 346382/478625 [00:10<00:04, 31717.69it/s][A
 89%|████████▉ | 427112/478625 [00:13<00:01, 31036.79it/s][A
 71%|███████   | 340195/478625 [00:10<00:04, 31223.66it/s][A
 73%|███████▎  | 349748/478625 [00:10<00:03, 32281.74it/s][A
 90%|████████▉ | 430218/478625 [00:14<00:01, 30019.53it/s][A
 72%|███████▏  | 343321/478625 [00:11<00:04, 30753.09it/s][A
 74%|███████▎  | 352984/478625 [00:10<00:03, 31860.93it/s][A
 91%|█████████ | 433408/478625 [00:14<00:01, 30566.64it/s][A
 72%|███████▏  | 346400/478625 [00:11<00:04, 30217.26it/s][A
 74%|███████▍  | 356345/478625 [00:11<00:03, 32371.07it/s][A
 91%|█████████ | 436472/478625 [00:14<00:01, 30156.83it/s][A
 73%|███████▎  | 349613/478625 [00:11<00:04, 30773.16it/s][A
 75%|███████▌  | 359718/478625 [00:11<00:03, 32768.81it/s][A
 92%|█████████▏| 439663/478625 [00:14<00:01, 30667.22it/s][A
 74%|███████▎  | 352695/478625 [00:11<00:04, 30380.89it/s][A
 76%|███████▌  | 363000/478625 [00:11<00:03, 32261.29it/s][A
 93%|█████████▎| 442848/478625 [00:14<00:01, 31012.97it/s][A
 74%|███████▍  | 355917/478625 [00:11<00:03, 30918.30it/s][A
 77%|███████▋  | 366231/478625 [00:11<00:03, 31958.88it/s][A
 93%|█████████▎| 445954/478625 [00:14<00:01, 30228.94it/s][A
 75%|███████▌  | 359111/478625 [00:11<00:03, 31218.42it/s][A
 77%|███████▋  | 369431/478625 [00:11<00:03, 31457.07it/s][A
 94%|█████████▍| 449122/478625 [00:14<00:00, 30649.99it/s][A
 76%|███████▌  | 362236/478625 [00:11<00:03, 30808.25it/s][A
 78%|███████▊  | 372795/478625 [00:11<00:03, 32093.46it/s][A
 94%|█████████▍| 452290/478625 [00:14<00:00, 30952.67it/s][A
 76%|███████▋  | 365467/478625 [00:11<00:03, 31248.08it/s][A
 79%|███████▊  | 376141/478625 [00:11<00:03, 32494.91it/s][A
 95%|█████████▌| 455390/478625 [00:14<00:00, 30434.39it/s][A
 77%|███████▋  | 368595/478625 [00:11<00:03, 30750.98it/s][A
 79%|███████▉  | 379394/478625 [00:11<00:03, 32033.68it/s][A
 96%|█████████▌| 458567/478625 [00:14<00:00, 30824.21it/s][A
 78%|███████▊  | 371730/478625 [00:11<00:03, 30923.99it/s][A
 80%|███████▉  | 382767/478625 [00:11<00:02, 32530.89it/s][A
 96%|█████████▋| 461758/478625 [00:15<00:00, 30384.75it/s][A
 78%|███████▊  | 374964/478625 [00:12<00:03, 31340.27it/s][A
 81%|████████  | 386024/478625 [00:12<00:02, 32073.34it/s][A
 97%|█████████▋| 464918/478625 [00:15<00:00, 30738.71it/s][A
 79%|███████▉  | 378101/478625 [00:12<00:03, 30818.69it/s][A
 81%|████████▏ | 389235/478625 [00:12<00:02, 32031.75it/s][A
 98%|█████████▊| 467997/478625 [00:15<00:00, 30264.80it/s][A
 80%|███████▉  | 381344/478625 [00:12<00:03, 31292.19it/s][A
 82%|████████▏ | 392606/478625 [00:12<00:02, 32525.77it/s][A
 98%|█████████▊| 471028/478625 [00:15<00:00, 29917.86it/s][A
 80%|████████  | 384569/478625 [00:12<00:02, 31574.10it/s][A
 83%|████████▎ | 395861/478625 [00:12<00:02, 32032.24it/s][A
 99%|█████████▉| 474211/478625 [00:15<00:00, 30475.80it/s][A
 81%|████████  | 387729/478625 [00:12<00:02, 31049.96it/s][A
 83%|████████▎ | 399219/478625 [00:12<00:02, 32486.95it/s][A
100%|█████████▉| 477364/478625 [00:15<00:00, 30785.53it/s][A100%|██████████| 478625/478625 [00:15<00:00, 30596.83it/s]
100%|██████████| 1/1 [00:22<00:00, 22.34s/it]100%|██████████| 1/1 [00:22<00:00, 22.34s/it]

 84%|████████▍ | 402608/478625 [00:12<00:02, 32901.76it/s][A
 82%|████████▏ | 390838/478625 [00:12<00:02, 30430.39it/s][A
 82%|████████▏ | 393886/478625 [00:12<00:02, 30191.35it/s][A
 85%|████████▍ | 405901/478625 [00:12<00:02, 32269.50it/s][A
 83%|████████▎ | 397085/478625 [00:12<00:02, 30715.79it/s][A
 85%|████████▌ | 409132/478625 [00:12<00:02, 32084.96it/s][A
 84%|████████▎ | 400322/478625 [00:12<00:02, 31202.43it/s][A
 86%|████████▌ | 412344/478625 [00:12<00:02, 31647.94it/s][A
 84%|████████▍ | 403446/478625 [00:13<00:02, 30768.68it/s][A
 87%|████████▋ | 415570/478625 [00:12<00:01, 31826.55it/s][A
 85%|████████▍ | 406677/478625 [00:13<00:02, 31220.60it/s][A
 88%|████████▊ | 418902/478625 [00:13<00:01, 32264.99it/s][A
 86%|████████▌ | 409895/478625 [00:13<00:02, 31502.54it/s][A
 88%|████████▊ | 422131/478625 [00:13<00:01, 31830.50it/s][Atime 23.071712017059326

 86%|████████▋ | 413048/478625 [00:13<00:02, 30850.91it/s][A
 89%|████████▉ | 425440/478625 [00:13<00:01, 32199.50it/s][An_elements: 474899
data length: 474899

 87%|████████▋ | 416160/478625 [00:13<00:02, 30927.62it/s][A
 90%|████████▉ | 428663/478625 [00:13<00:01, 31749.58it/s][A
 88%|████████▊ | 419256/478625 [00:13<00:01, 30608.09it/s][A
 90%|█████████ | 431841/478625 [00:13<00:01, 31716.49it/s][A
 88%|████████▊ | 422474/478625 [00:13<00:01, 31070.64it/s][A
 91%|█████████ | 435194/478625 [00:13<00:01, 32252.13it/s][A
 89%|████████▉ | 425688/478625 [00:13<00:01, 31386.44it/s][A
 92%|█████████▏| 438422/478625 [00:13<00:01, 31881.36it/s][A
 90%|████████▉ | 428829/478625 [00:13<00:01, 30890.06it/s][A
 92%|█████████▏| 441793/478625 [00:13<00:01, 32418.56it/s][A
 90%|█████████ | 432053/478625 [00:13<00:01, 31286.76it/s][A
 93%|█████████▎| 445038/478625 [00:13<00:01, 31919.52it/s][A
 91%|█████████ | 435185/478625 [00:14<00:01, 30712.28it/s][A
 94%|█████████▎| 448415/478625 [00:13<00:00, 32462.44it/s][A
 92%|█████████▏| 438260/478625 [00:14<00:01, 30424.87it/s][A
 94%|█████████▍| 451665/478625 [00:14<00:00, 32117.66it/s][A
 92%|█████████▏| 441491/478625 [00:14<00:01, 30974.49it/s][A
 95%|█████████▌| 454880/478625 [00:14<00:00, 31707.20it/s][A
 93%|█████████▎| 444592/478625 [00:14<00:01, 30581.99it/s][A
 96%|█████████▌| 458239/478625 [00:14<00:00, 32257.81it/s][A
 94%|█████████▎| 447823/478625 [00:14<00:00, 31088.93it/s][A
 96%|█████████▋| 461598/478625 [00:14<00:00, 32650.95it/s][A
 94%|█████████▍| 451037/478625 [00:14<00:00, 31397.42it/s][A
 97%|█████████▋| 464866/478625 [00:14<00:00, 31967.01it/s][A
 95%|█████████▍| 454180/478625 [00:14<00:00, 30820.03it/s][A
 98%|█████████▊| 468110/478625 [00:14<00:00, 32104.59it/s][A
 96%|█████████▌| 457412/478625 [00:14<00:00, 31258.01it/s][A
 98%|█████████▊| 471324/478625 [00:14<00:00, 31357.94it/s][A
 96%|█████████▌| 460632/478625 [00:14<00:00, 31534.86it/s][A
 99%|█████████▉| 474679/478625 [00:14<00:00, 31996.83it/s][A
 97%|█████████▋| 463789/478625 [00:14<00:00, 30880.16it/s][A
100%|█████████▉| 478030/478625 [00:14<00:00, 32440.21it/s][A100%|██████████| 478625/478625 [00:14<00:00, 32143.17it/s]
100%|██████████| 1/1 [00:21<00:00, 21.57s/it]100%|██████████| 1/1 [00:21<00:00, 21.57s/it]

 98%|█████████▊| 466891/478625 [00:15<00:00, 30919.89it/s][A
 98%|█████████▊| 469987/478625 [00:15<00:00, 30595.65it/s][A
 99%|█████████▉| 473188/478625 [00:15<00:00, 31009.62it/s][A
100%|█████████▉| 476426/478625 [00:15<00:00, 31414.81it/s][A100%|██████████| 478625/478625 [00:15<00:00, 30958.30it/s]
100%|██████████| 1/1 [00:22<00:00, 22.16s/it]100%|██████████| 1/1 [00:22<00:00, 22.16s/it]
time 22.229705810546875
n_elements: 474899
data length: 474899
time 22.814438343048096
n_elements: 474899
data length: 474899
[2024-09-18 09:22:58,771] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-09-18 09:22:58,780] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-09-18 09:22:58,780] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-09-18 09:22:58,932] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2024-09-18 09:22:58,932] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch_npu.utils._optim.partialclass.<locals>.NewCls'>
zp rank is 3, zp_size=8
[2024-09-18 09:22:58,932] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-09-18 09:22:58,932] [INFO] [stage_1_and_2.py:173:__init__] Reduce bucket size 536870912
zp rank is 6, zp_size=8
[2024-09-18 09:22:58,932] [INFO] [stage_1_and_2.py:174:__init__] Allgather bucket size 536870912
[2024-09-18 09:22:58,932] [INFO] [stage_1_and_2.py:175:__init__] CPU Offload: False
zp rank is 5, zp_size=8
[2024-09-18 09:22:58,932] [INFO] [stage_1_and_2.py:176:__init__] Round robin gradient partitioning: False
zp rank is 2, zp_size=8
zp rank is 0, zp_size=8
zp rank is 4, zp_size=8
zp rank is 1, zp_size=8
zp rank is 7, zp_size=8
[2024-09-18 09:23:05,463] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:06,091] [INFO] [utils.py:791:see_memory_usage] Before initializing optimizer states
[2024-09-18 09:23:06,093] [INFO] [utils.py:792:see_memory_usage] MA 17.78 GB         Max_MA 18.44 GB         CA 18.78 GB         Max_CA 19 GB 
[2024-09-18 09:23:06,093] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 235.17 GB, percent = 15.6%
[2024-09-18 09:23:06,325] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:08,504] [INFO] [utils.py:791:see_memory_usage] After initializing optimizer states
[2024-09-18 09:23:08,505] [INFO] [utils.py:792:see_memory_usage] MA 20.41 GB         Max_MA 24.35 GB         CA 25.36 GB         Max_CA 25 GB 
[2024-09-18 09:23:08,505] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 236.17 GB, percent = 15.6%
[2024-09-18 09:23:08,506] [INFO] [stage_1_and_2.py:552:__init__] optimizer state initialized
[2024-09-18 09:23:09,037] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:09,206] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:09,593] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:09,620] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:10,872] [INFO] [utils.py:791:see_memory_usage] After initializing ZeRO optimizer
[2024-09-18 09:23:10,873] [INFO] [utils.py:792:see_memory_usage] MA 20.41 GB         Max_MA 20.41 GB         CA 25.36 GB         Max_CA 25 GB 
[2024-09-18 09:23:10,873] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 227.46 GB, percent = 15.1%
[2024-09-18 09:23:10,882] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2024-09-18 09:23:10,882] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-09-18 09:23:10,882] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-09-18 09:23:10,882] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[(0.9, 0.999)]
[2024-09-18 09:23:10,885] [INFO] [config.py:984:print] DeepSpeedEngine configuration:
[2024-09-18 09:23:10,885] [INFO] [config.py:988:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-09-18 09:23:10,886] [INFO] [config.py:988:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-09-18 09:23:10,886] [INFO] [config.py:988:print]   amp_enabled .................. False
[2024-09-18 09:23:10,886] [INFO] [config.py:988:print]   amp_params ................... False
[2024-09-18 09:23:10,886] [INFO] [config.py:988:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-09-18 09:23:10,886] [INFO] [config.py:988:print]   bfloat16_enabled ............. True
[2024-09-18 09:23:10,886] [INFO] [config.py:988:print]   checkpoint_parallel_write_pipeline  False
[2024-09-18 09:23:10,886] [INFO] [config.py:988:print]   checkpoint_tag_validation_enabled  True
[2024-09-18 09:23:10,886] [INFO] [config.py:988:print]   checkpoint_tag_validation_fail  False
[2024-09-18 09:23:10,886] [INFO] [config.py:988:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0xffff089789d0>
[2024-09-18 09:23:10,886] [INFO] [config.py:988:print]   communication_data_type ...... torch.float32
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   curriculum_enabled_legacy .... False
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   curriculum_params_legacy ..... False
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   data_efficiency_enabled ...... False
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   dataloader_drop_last ......... False
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   disable_allgather ............ False
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   dump_state ................... False
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   dynamic_loss_scale_args ...... None
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   eigenvalue_enabled ........... False
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   eigenvalue_gas_boundary_resolution  1
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   eigenvalue_layer_num ......... 0
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   eigenvalue_max_iter .......... 100
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   eigenvalue_stability ......... 1e-06
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   eigenvalue_tol ............... 0.01
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   eigenvalue_verbose ........... False
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   elasticity_enabled ........... False
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-09-18 09:23:10,887] [INFO] [config.py:988:print]   fp16_auto_cast ............... None
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   fp16_enabled ................. False
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   fp16_master_weights_and_gradients  False
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   global_rank .................. 0
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   grad_accum_dtype ............. None
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   gradient_accumulation_steps .. 1
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   gradient_clipping ............ 1.0
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   gradient_predivide_factor .... 1.0
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   graph_harvesting ............. False
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   initial_dynamic_scale ........ 1
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   load_universal_checkpoint .... False
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   loss_scale ................... 1.0
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   memory_breakdown ............. False
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   mics_hierarchial_params_gather  False
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   mics_shard_size .............. -1
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-09-18 09:23:10,888] [INFO] [config.py:988:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   optimizer_legacy_fusion ...... False
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   optimizer_name ............... None
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   optimizer_params ............. None
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   pld_enabled .................. False
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   pld_params ................... False
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   prescale_gradients ........... False
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   scheduler_name ............... None
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   scheduler_params ............. None
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   seq_parallel_communication_data_type  torch.float32
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   sparse_attention ............. None
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   sparse_gradients_enabled ..... False
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   steps_per_print .............. inf
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   train_batch_size ............. 8
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   train_micro_batch_size_per_gpu  1
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   use_data_before_expert_parallel_  False
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   use_node_local_storage ....... False
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   wall_clock_breakdown ......... False
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   weight_quantization_config ... None
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   world_size ................... 8
[2024-09-18 09:23:10,889] [INFO] [config.py:988:print]   zero_allow_untested_optimizer  True
[2024-09-18 09:23:10,890] [INFO] [config.py:988:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=536870912 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=536870912 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-09-18 09:23:10,890] [INFO] [config.py:988:print]   zero_enabled ................. True
[2024-09-18 09:23:10,890] [INFO] [config.py:988:print]   zero_force_ds_cpu_optimizer .. True
[2024-09-18 09:23:10,890] [INFO] [config.py:988:print]   zero_optimization_stage ...... 2
[2024-09-18 09:23:10,890] [INFO] [config.py:974:print_user_config]   json = {
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "loss_scale_window": 1000, 
        "initial_scale_power": 16, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "bf16": {
        "enabled": true
    }, 
    "communication_data_type": "fp32", 
    "gradient_clipping": 1.0, 
    "train_micro_batch_size_per_gpu": 1, 
    "train_batch_size": 8, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 2, 
        "overlap_comm": true, 
        "allgather_bucket_size": 5.368709e+08, 
        "contiguous_gradients": true, 
        "reduce_bucket_size": 5.368709e+08
    }, 
    "steps_per_print": inf, 
    "zero_allow_untested_optimizer": true
}
09/18/2024 09:23:10 - INFO - __main__ - after accelerator.prepare
09/18/2024 09:23:12 - INFO - __main__ - init trackers...
[2024-09-18 09:23:12,725] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:13,099] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:13,334] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:13,413] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:13,766] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
[2024-09-18 09:23:14,287] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt...
[2024-09-18 09:23:16,262] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
[2024-09-18 09:23:16,262] [INFO] [engine.py:2998:_get_all_zero_checkpoint_state_dicts] successfully read 8 ZeRO state_dicts for rank 4
[2024-09-18 09:23:16,538] [INFO] [engine.py:2930:_load_zero_checkpoint] loading 8 zero partition checkpoints for rank 4
[2024-09-18 09:23:16,683] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt.
[2024-09-18 09:23:16,683] [INFO] [engine.py:2998:_get_all_zero_checkpoint_state_dicts] successfully read 8 ZeRO state_dicts for rank 5
[2024-09-18 09:23:16,975] [INFO] [engine.py:2930:_load_zero_checkpoint] loading 8 zero partition checkpoints for rank 5
[2024-09-18 09:23:18,768] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:18,919] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:18,942] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:18,943] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:19,722] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
wandb: Currently logged in as: pkuhxy (pkuhxy-Peking University). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /home/image_data/hxy/Open-Sora-Plan/wandb/run-20240918_092320-8wekatqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sponge-10
wandb: ⭐️ View project at https://wandb.ai/pkuhxy-Peking%20University/allinpaint_stage1
wandb: 🚀 View run at https://wandb.ai/pkuhxy-Peking%20University/allinpaint_stage1/runs/8wekatqc
09/18/2024 09:23:22 - INFO - __main__ - ***** Running training *****
09/18/2024 09:23:22 - INFO - __main__ -   Model = DeepSpeedEngine(
  (module): OpenSoraInpaint(
    (pos_embed): PatchEmbed2D(
      (proj): Conv2d(8, 2304, kernel_size=(2, 2), stride=(2, 2))
    )
    (transformer_blocks): ModuleList(
      (0-31): 32 x BasicTransformerBlock(
        (norm1): LayerNorm((2304,), eps=1e-06, elementwise_affine=False)
        (attn1): Attention(
          (to_q): Linear(in_features=2304, out_features=2304, bias=True)
          (to_k): Linear(in_features=2304, out_features=2304, bias=True)
          (to_v): Linear(in_features=2304, out_features=2304, bias=True)
          (to_out): ModuleList(
            (0): Linear(in_features=2304, out_features=2304, bias=True)
            (1): Dropout(p=0.0, inplace=False)
          )
        )
        (norm2): LayerNorm((2304,), eps=1e-06, elementwise_affine=False)
        (attn2): Attention(
          (to_q): Linear(in_features=2304, out_features=2304, bias=True)
          (to_k): Linear(in_features=2304, out_features=2304, bias=True)
          (to_v): Linear(in_features=2304, out_features=2304, bias=True)
          (to_out): ModuleList(
            (0): Linear(in_features=2304, out_features=2304, bias=True)
            (1): Dropout(p=0.0, inplace=False)
          )
        )
        (ff): FeedForward(
          (net): ModuleList(
            (0): GELU(
              (proj): Linear(in_features=2304, out_features=9216, bias=True)
            )
            (1): Dropout(p=0.0, inplace=False)
            (2): Linear(in_features=9216, out_features=2304, bias=True)
          )
        )
      )
    )
    (norm_out): LayerNorm((2304,), eps=1e-06, elementwise_affine=False)
    (proj_out): Linear(in_features=2304, out_features=32, bias=True)
    (adaln_single): AdaLayerNormSingle(
      (emb): PixArtAlphaCombinedTimestepSizeEmbeddings(
        (time_proj): Timesteps()
        (timestep_embedder): TimestepEmbedding(
          (linear_1): Linear(in_features=256, out_features=2304, bias=True)
          (act): SiLU()
          (linear_2): Linear(in_features=2304, out_features=2304, bias=True)
        )
      )
      (silu): SiLU()
      (linear): Linear(in_features=2304, out_features=13824, bias=True)
    )
    (caption_projection): PixArtAlphaTextProjection(
      (linear_1): Linear(in_features=4096, out_features=2304, bias=True)
      (act_1): GELU(approximate='tanh')
      (linear_2): Linear(in_features=2304, out_features=2304, bias=True)
    )
    (motion_projection): MotionAdaLayerNormSingle(
      (emb): MotionEmbeddings(
        (motion_proj): Timesteps()
        (motion_embedder): TimestepEmbedding(
          (linear_1): Linear(in_features=256, out_features=2304, bias=True)
          (act): SiLU()
          (linear_2): Linear(in_features=2304, out_features=2304, bias=True)
        )
      )
      (silu): SiLU()
      (linear): Linear(in_features=2304, out_features=13824, bias=True)
    )
    (pos_embed_mask): ModuleList(
      (0): PatchEmbed2D(
        (proj): Conv2d(4, 2304, kernel_size=(2, 2), stride=(2, 2))
      )
      (1): Linear(in_features=2304, out_features=2304, bias=False)
    )
    (pos_embed_masked_hidden_states): ModuleList(
      (0): PatchEmbed2D(
        (proj): Conv2d(8, 2304, kernel_size=(2, 2), stride=(2, 2))
      )
      (1): Linear(in_features=2304, out_features=2304, bias=False)
    )
  )
)
09/18/2024 09:23:22 - INFO - __main__ -   Num examples = 474899
09/18/2024 09:23:22 - INFO - __main__ -   Num Epochs = 17
09/18/2024 09:23:22 - INFO - __main__ -   Instantaneous batch size per device = 1
09/18/2024 09:23:22 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
09/18/2024 09:23:22 - INFO - __main__ -   Gradient Accumulation steps = 1
09/18/2024 09:23:22 - INFO - __main__ -   Total optimization steps = 1000000
09/18/2024 09:23:22 - INFO - __main__ -   Total optimization steps (num_update_steps_per_epoch) = 59362
09/18/2024 09:23:22 - INFO - __main__ -   Total trainable parameters = 2.8204808 B
Resuming from checkpoint checkpoint-13000
09/18/2024 09:23:22 - INFO - accelerate.accelerator - Loading states from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000
09/18/2024 09:23:22 - INFO - accelerate.accelerator - Loading DeepSpeed Model and Optimizer
[2024-09-18 09:23:22,967] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:23,746] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:24,841] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:24,864] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:25,360] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt...
[2024-09-18 09:23:25,430] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2024-09-18 09:23:26,500] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:27,025] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:27,749] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2024-09-18 09:23:27,749] [INFO] [engine.py:2998:_get_all_zero_checkpoint_state_dicts] successfully read 8 ZeRO state_dicts for rank 2
[2024-09-18 09:23:28,015] [INFO] [engine.py:2930:_load_zero_checkpoint] loading 8 zero partition checkpoints for rank 2
[2024-09-18 09:23:28,032] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt.
[2024-09-18 09:23:28,033] [INFO] [engine.py:2998:_get_all_zero_checkpoint_state_dicts] successfully read 8 ZeRO state_dicts for rank 7
[2024-09-18 09:23:29,237] [INFO] [engine.py:2930:_load_zero_checkpoint] loading 8 zero partition checkpoints for rank 7
[2024-09-18 09:23:29,345] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:29,346] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:29,627] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:29,629] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:31,125] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:33,822] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:34,833] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt...
[2024-09-18 09:23:34,908] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:34,937] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:35,246] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2024-09-18 09:23:35,274] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-18 09:23:36,809] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:36,810] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 09:23:37,179] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt.
[2024-09-18 09:23:37,179] [INFO] [engine.py:2998:_get_all_zero_checkpoint_state_dicts] successfully read 8 ZeRO state_dicts for rank 6
[2024-09-18 09:23:37,426] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2024-09-18 09:23:37,427] [INFO] [engine.py:2998:_get_all_zero_checkpoint_state_dicts] successfully read 8 ZeRO state_dicts for rank 3
[2024-09-18 09:23:37,464] [INFO] [engine.py:2930:_load_zero_checkpoint] loading 8 zero partition checkpoints for rank 6
[2024-09-18 09:23:37,622] [INFO] [engine.py:2930:_load_zero_checkpoint] loading 8 zero partition checkpoints for rank 3
[2024-09-18 09:23:37,652] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-18 09:23:37,653] [INFO] [engine.py:2998:_get_all_zero_checkpoint_state_dicts] successfully read 8 ZeRO state_dicts for rank 0
[2024-09-18 09:23:37,850] [INFO] [engine.py:2930:_load_zero_checkpoint] loading 8 zero partition checkpoints for rank 0
09/18/2024 09:23:37 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer loaded from input dir /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model
The config attributes {'decay': 0.9999, 'inv_gamma': 1.0, 'min_decay': 0.0, 'optimization_step': 13000, 'power': 0.6666666666666666, 'update_after_step': 0, 'use_ema_warmup': False} were passed to OpenSoraInpaint, but are not expected and will be ignored. Please verify your config.json configuration file.
[] -> [195210]
[] -> [195210]
[] -> [195210]
[] -> [195210]
[] -> [164918]
[2024-09-18 09:23:42,341] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 09:23:42,775] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[] -> [184079]
[] -> [164918]
[] -> [164918]
[] -> [184079]
[] -> [184079]
shuffled_megabatches 59363
have been trained idx: 0
after shuffled_megabatches 59363
[2024-09-18 09:23:45,062] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /home/save_dir/runs/allinpaint_stage1/checkpoint-13000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-09-18 09:23:45,062] [INFO] [engine.py:2998:_get_all_zero_checkpoint_state_dicts] successfully read 8 ZeRO state_dicts for rank 1
[2024-09-18 09:23:45,334] [INFO] [engine.py:2930:_load_zero_checkpoint] loading 8 zero partition checkpoints for rank 1
shuffled_megabatches 59363
have been trained idx: 0
after shuffled_megabatches 59363
[] -> [195210]
[] -> [195210]
[] -> [195210]
[] -> [195210]
[] -> [164918]
[] -> [164918]
[] -> [195210]
[] -> [164918]
[] -> [164918]
[] -> [195210]
shuffled_megabatches 59363
have been trained idx: 0
after shuffled_megabatches 59363
shuffled_megabatches 59363
have been trained idx: 0
after shuffled_megabatches 59363
--[] -> [195210]
[] -> [164918]
[] -> [195210]
[] -> [164918]
[] -> [184079]
09/18/2024 09:24:02 - INFO - accelerate.checkpointing - All model weights loaded successfully
09/18/2024 09:24:02 - INFO - accelerate.checkpointing - All optimizer states loaded successfully
09/18/2024 09:24:02 - INFO - accelerate.checkpointing - All scheduler states loaded successfully
09/18/2024 09:24:02 - INFO - accelerate.checkpointing - All dataloader sampler states loaded successfully
09/18/2024 09:24:02 - INFO - accelerate.checkpointing - All random states loaded successfully
09/18/2024 09:24:02 - INFO - accelerate.accelerator - Loading in 0 custom states
Steps:   1%|▏         | 13000/1000000 [00:00<?, ?it/s][] -> [164918]
[] -> [164918]
[] -> [164918]
[] -> [195210]
[] -> [164918]
shuffled_megabatches 59363
have been trained idx: 0
after shuffled_megabatches 59363
[] -> [184079]
[] -> [184079]
[] -> [184079]
[] -> [184079]
[] -> [184079]
shuffled_megabatches 59363
have been trained idx: 0
after shuffled_megabatches 59363
shuffled_megabatches 59363
have been trained idx: 0
after shuffled_megabatches 59363
\--\[] -> [184079]
[] -> [184079]
[] -> [184079]
[] -> [184079]
[] -> [184079]
-shuffled_megabatches 59363
have been trained idx: 0
after shuffled_megabatches 59363
|\-\-[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'torchvision::nms' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'torchvision::nms' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
|\/[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'torchvision::nms' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
-|\\/[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'torchvision::nms' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
||[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'torchvision::nms' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
\||[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'torchvision::nms' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
/[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'torchvision::nms' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
/|//[W VariableFallbackKernel.cpp:51] Warning: CAUTION: The operator 'torchvision::nms' is not currently supported on the NPU backend and will fall back to run on the CPU. This may have performance implications. (function npu_cpu_fallback)
//-------Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.Warning: Device do not support double dtype now, dtype cast repalce with float.

Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Steps:   1%|▏         | 13001/1000000 [01:08<18666:08:11, 68.08s/it][RANK-0]: Step: [13001], local_loss=0.6912007927894592, train_loss=0.12457204610109329, time_cost=19.01971125602722
Steps:   1%|▏         | 13001/1000000 [01:08<18666:08:11, 68.08s/it, lr=1e-5, step_loss=0.691]Steps:   1%|▏         | 13002/1000000 [01:21<9797:18:55, 35.73s/it, lr=1e-5, step_loss=0.691] [RANK-0]: Step: [13002], local_loss=0.05346745625138283, train_loss=0.15149728953838348, time_cost=3.7545714378356934
Steps:   1%|▏         | 13002/1000000 [01:21<9797:18:55, 35.73s/it, lr=1e-5, step_loss=0.0535]Steps:   1%|▏         | 13003/1000000 [01:27<6056:04:01, 22.09s/it, lr=1e-5, step_loss=0.0535][RANK-0]: Step: [13003], local_loss=0.05149325728416443, train_loss=0.05202096700668335, time_cost=1.3344981670379639
Steps:   1%|▏         | 13003/1000000 [01:27<6056:04:01, 22.09s/it, lr=1e-5, step_loss=0.0515]Steps:   1%|▏         | 13004/1000000 [01:39<4968:33:34, 18.12s/it, lr=1e-5, step_loss=0.0515][RANK-0]: Step: [13004], local_loss=0.09427880495786667, train_loss=0.2024877518415451, time_cost=4.650153875350952
Steps:   1%|▏         | 13004/1000000 [01:39<4968:33:34, 18.12s/it, lr=1e-5, step_loss=0.0943]Steps:   1%|▏         | 13005/1000000 [01:47<4016:39:12, 14.65s/it, lr=1e-5, step_loss=0.0943][RANK-0]: Step: [13005], local_loss=0.09295719861984253, train_loss=0.07010133564472198, time_cost=2.67057728767395
Steps:   1%|▏         | 13005/1000000 [01:47<4016:39:12, 14.65s/it, lr=1e-5, step_loss=0.093] Steps:   1%|▏         | 13006/1000000 [02:00<3857:48:01, 14.07s/it, lr=1e-5, step_loss=0.093][RANK-0]: Step: [13006], local_loss=0.25009989738464355, train_loss=0.08790505677461624, time_cost=3.0588011741638184
Steps:   1%|▏         | 13006/1000000 [02:00<3857:48:01, 14.07s/it, lr=1e-5, step_loss=0.25] Steps:   1%|▏         | 13007/1000000 [02:12<3631:26:20, 13.25s/it, lr=1e-5, step_loss=0.25][RANK-0]: Step: [13007], local_loss=0.017799871042370796, train_loss=0.04780075326561928, time_cost=4.980525732040405
Steps:   1%|▏         | 13007/1000000 [02:12<3631:26:20, 13.25s/it, lr=1e-5, step_loss=0.0178]Steps:   1%|▏         | 13008/1000000 [02:25<3614:36:52, 13.18s/it, lr=1e-5, step_loss=0.0178][RANK-0]: Step: [13008], local_loss=0.019148966297507286, train_loss=0.13378217816352844, time_cost=3.6623857021331787
Steps:   1%|▏         | 13008/1000000 [02:25<3614:36:52, 13.18s/it, lr=1e-5, step_loss=0.0191]Steps:   1%|▏         | 13009/1000000 [02:35<3384:15:27, 12.34s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [13009], local_loss=0.05808651074767113, train_loss=0.07216843962669373, time_cost=4.509132146835327
Steps:   1%|▏         | 13009/1000000 [02:35<3384:15:27, 12.34s/it, lr=1e-5, step_loss=0.0581]Steps:   1%|▏         | 13010/1000000 [02:42<2957:24:19, 10.79s/it, lr=1e-5, step_loss=0.0581][RANK-0]: Step: [13010], local_loss=0.08228850364685059, train_loss=0.14680400490760803, time_cost=5.417214870452881
Steps:   1%|▏         | 13010/1000000 [02:42<2957:24:19, 10.79s/it, lr=1e-5, step_loss=0.0823]Steps:   1%|▏         | 13011/1000000 [02:57<3261:44:27, 11.90s/it, lr=1e-5, step_loss=0.0823][RANK-0]: Step: [13011], local_loss=0.07371076941490173, train_loss=0.11238759011030197, time_cost=10.597983837127686
Steps:   1%|▏         | 13011/1000000 [02:57<3261:44:27, 11.90s/it, lr=1e-5, step_loss=0.0737]Steps:   1%|▏         | 13012/1000000 [03:02<2716:23:18,  9.91s/it, lr=1e-5, step_loss=0.0737][RANK-0]: Step: [13012], local_loss=0.07446154952049255, train_loss=0.10717670619487762, time_cost=4.037163734436035
Steps:   1%|▏         | 13012/1000000 [03:02<2716:23:18,  9.91s/it, lr=1e-5, step_loss=0.0745]Steps:   1%|▏         | 13013/1000000 [03:14<2876:15:11, 10.49s/it, lr=1e-5, step_loss=0.0745][RANK-0]: Step: [13013], local_loss=0.07520817965269089, train_loss=0.09095172584056854, time_cost=6.417724847793579
Steps:   1%|▏         | 13013/1000000 [03:14<2876:15:11, 10.49s/it, lr=1e-5, step_loss=0.0752]Steps:   1%|▏         | 13014/1000000 [03:25<2921:26:02, 10.66s/it, lr=1e-5, step_loss=0.0752][RANK-0]: Step: [13014], local_loss=0.09652598202228546, train_loss=0.04960218444466591, time_cost=1.1971819400787354
Steps:   1%|▏         | 13014/1000000 [03:25<2921:26:02, 10.66s/it, lr=1e-5, step_loss=0.0965]Steps:   1%|▏         | 13015/1000000 [03:30<2424:49:38,  8.84s/it, lr=1e-5, step_loss=0.0965][RANK-0]: Step: [13015], local_loss=0.04726234823465347, train_loss=0.06895175576210022, time_cost=1.2257764339447021
Steps:   1%|▏         | 13015/1000000 [03:30<2424:49:38,  8.84s/it, lr=1e-5, step_loss=0.0473]Steps:   1%|▏         | 13016/1000000 [03:38<2348:13:01,  8.57s/it, lr=1e-5, step_loss=0.0473][RANK-0]: Step: [13016], local_loss=0.05506616458296776, train_loss=0.3400516211986542, time_cost=6.736793279647827
Steps:   1%|▏         | 13016/1000000 [03:38<2348:13:01,  8.57s/it, lr=1e-5, step_loss=0.0551]Steps:   1%|▏         | 13017/1000000 [03:53<2948:58:34, 10.76s/it, lr=1e-5, step_loss=0.0551][RANK-0]: Step: [13017], local_loss=0.05423709377646446, train_loss=0.06873168051242828, time_cost=7.181159257888794
Steps:   1%|▏         | 13017/1000000 [03:53<2948:58:34, 10.76s/it, lr=1e-5, step_loss=0.0542]Steps:   1%|▏         | 13018/1000000 [04:01<2684:23:15,  9.79s/it, lr=1e-5, step_loss=0.0542][RANK-0]: Step: [13018], local_loss=0.040669962763786316, train_loss=0.040384046733379364, time_cost=2.5510759353637695
Steps:   1%|▏         | 13018/1000000 [04:01<2684:23:15,  9.79s/it, lr=1e-5, step_loss=0.0407]Steps:   1%|▏         | 13019/1000000 [04:10<2608:07:55,  9.51s/it, lr=1e-5, step_loss=0.0407][RANK-0]: Step: [13019], local_loss=0.05926625803112984, train_loss=0.11356660723686218, time_cost=3.3819761276245117
Steps:   1%|▏         | 13019/1000000 [04:10<2608:07:55,  9.51s/it, lr=1e-5, step_loss=0.0593]Steps:   1%|▏         | 13020/1000000 [04:20<2673:09:02,  9.75s/it, lr=1e-5, step_loss=0.0593][RANK-0]: Step: [13020], local_loss=0.09075923264026642, train_loss=0.07698927819728851, time_cost=2.5750885009765625
Steps:   1%|▏         | 13020/1000000 [04:20<2673:09:02,  9.75s/it, lr=1e-5, step_loss=0.0908]Steps:   1%|▏         | 13021/1000000 [04:28<2513:54:26,  9.17s/it, lr=1e-5, step_loss=0.0908][RANK-0]: Step: [13021], local_loss=0.04174676910042763, train_loss=0.05156717076897621, time_cost=1.179793357849121
Steps:   1%|▏         | 13021/1000000 [04:28<2513:54:26,  9.17s/it, lr=1e-5, step_loss=0.0417]Steps:   1%|▏         | 13022/1000000 [04:43<3007:14:17, 10.97s/it, lr=1e-5, step_loss=0.0417][RANK-0]: Step: [13022], local_loss=0.8709360957145691, train_loss=0.15748746693134308, time_cost=7.2980382442474365
Steps:   1%|▏         | 13022/1000000 [04:43<3007:14:17, 10.97s/it, lr=1e-5, step_loss=0.871] -\\Steps:   1%|▏         | 13023/1000000 [04:58<3332:11:53, 12.15s/it, lr=1e-5, step_loss=0.871][RANK-0]: Step: [13023], local_loss=0.06282350420951843, train_loss=0.04616738110780716, time_cost=1.1814916133880615
Steps:   1%|▏         | 13023/1000000 [04:58<3332:11:53, 12.15s/it, lr=1e-5, step_loss=0.0628]Steps:   1%|▏         | 13024/1000000 [05:15<3685:12:27, 13.44s/it, lr=1e-5, step_loss=0.0628][RANK-0]: Step: [13024], local_loss=0.049919042736291885, train_loss=0.05239512026309967, time_cost=1.166670799255371
Steps:   1%|▏         | 13024/1000000 [05:15<3685:12:27, 13.44s/it, lr=1e-5, step_loss=0.0499]Steps:   1%|▏         | 13025/1000000 [05:27<3574:47:06, 13.04s/it, lr=1e-5, step_loss=0.0499][RANK-0]: Step: [13025], local_loss=0.03861309587955475, train_loss=0.03512583300471306, time_cost=1.349654197692871
Steps:   1%|▏         | 13025/1000000 [05:27<3574:47:06, 13.04s/it, lr=1e-5, step_loss=0.0386]Steps:   1%|▏         | 13026/1000000 [05:33<2998:16:11, 10.94s/it, lr=1e-5, step_loss=0.0386][RANK-0]: Step: [13026], local_loss=0.15979133546352386, train_loss=0.1384120136499405, time_cost=4.767601490020752
Steps:   1%|▏         | 13026/1000000 [05:33<2998:16:11, 10.94s/it, lr=1e-5, step_loss=0.16]  Steps:   1%|▏         | 13027/1000000 [05:41<2783:19:10, 10.15s/it, lr=1e-5, step_loss=0.16][RANK-0]: Step: [13027], local_loss=0.09809400141239166, train_loss=0.06433211266994476, time_cost=2.022052526473999
Steps:   1%|▏         | 13027/1000000 [05:41<2783:19:10, 10.15s/it, lr=1e-5, step_loss=0.0981]Steps:   1%|▏         | 13028/1000000 [05:56<3198:43:07, 11.67s/it, lr=1e-5, step_loss=0.0981][RANK-0]: Step: [13028], local_loss=0.2219545543193817, train_loss=0.06990769505500793, time_cost=5.798627853393555
Steps:   1%|▏         | 13028/1000000 [05:56<3198:43:07, 11.67s/it, lr=1e-5, step_loss=0.222] Steps:   1%|▏         | 13029/1000000 [06:11<3491:42:00, 12.74s/it, lr=1e-5, step_loss=0.222][RANK-0]: Step: [13029], local_loss=0.03141722083091736, train_loss=0.05907723680138588, time_cost=5.804453611373901
Steps:   1%|▏         | 13029/1000000 [06:11<3491:42:00, 12.74s/it, lr=1e-5, step_loss=0.0314]Steps:   1%|▏         | 13030/1000000 [06:20<3172:55:28, 11.57s/it, lr=1e-5, step_loss=0.0314][RANK-0]: Step: [13030], local_loss=0.03849932178854942, train_loss=0.06205734238028526, time_cost=6.8168840408325195
Steps:   1%|▏         | 13030/1000000 [06:20<3172:55:28, 11.57s/it, lr=1e-5, step_loss=0.0385]Steps:   1%|▏         | 13031/1000000 [06:29<2935:16:08, 10.71s/it, lr=1e-5, step_loss=0.0385][RANK-0]: Step: [13031], local_loss=0.039324142038822174, train_loss=0.05625995993614197, time_cost=1.6398472785949707
Steps:   1%|▏         | 13031/1000000 [06:29<2935:16:08, 10.71s/it, lr=1e-5, step_loss=0.0393]Steps:   1%|▏         | 13032/1000000 [06:38<2823:04:25, 10.30s/it, lr=1e-5, step_loss=0.0393][RANK-0]: Step: [13032], local_loss=0.11689900606870651, train_loss=0.09351343661546707, time_cost=1.6884443759918213
Steps:   1%|▏         | 13032/1000000 [06:38<2823:04:25, 10.30s/it, lr=1e-5, step_loss=0.117] Steps:   1%|▏         | 13033/1000000 [06:49<2862:35:14, 10.44s/it, lr=1e-5, step_loss=0.117][RANK-0]: Step: [13033], local_loss=0.025134621188044548, train_loss=0.03481939807534218, time_cost=1.7861218452453613
Steps:   1%|▏         | 13033/1000000 [06:49<2862:35:14, 10.44s/it, lr=1e-5, step_loss=0.0251]Steps:   1%|▏         | 13034/1000000 [07:03<3122:23:17, 11.39s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [13034], local_loss=0.061988476663827896, train_loss=0.0456680990755558, time_cost=3.758488893508911
Steps:   1%|▏         | 13034/1000000 [07:03<3122:23:17, 11.39s/it, lr=1e-5, step_loss=0.062] Steps:   1%|▏         | 13035/1000000 [07:08<2610:01:06,  9.52s/it, lr=1e-5, step_loss=0.062][RANK-0]: Step: [13035], local_loss=0.031341444700956345, train_loss=0.03647599741816521, time_cost=2.0890414714813232
Steps:   1%|▏         | 13035/1000000 [07:08<2610:01:06,  9.52s/it, lr=1e-5, step_loss=0.0313]Steps:   1%|▏         | 13036/1000000 [07:17<2554:00:26,  9.32s/it, lr=1e-5, step_loss=0.0313][RANK-0]: Step: [13036], local_loss=0.042183853685855865, train_loss=0.06822597980499268, time_cost=3.629178047180176
Steps:   1%|▏         | 13036/1000000 [07:17<2554:00:26,  9.32s/it, lr=1e-5, step_loss=0.0422]Steps:   1%|▏         | 13037/1000000 [07:22<2188:24:24,  7.98s/it, lr=1e-5, step_loss=0.0422][RANK-0]: Step: [13037], local_loss=0.06189291551709175, train_loss=0.05200623348355293, time_cost=1.892902135848999
Steps:   1%|▏         | 13037/1000000 [07:22<2188:24:24,  7.98s/it, lr=1e-5, step_loss=0.0619]Steps:   1%|▏         | 13038/1000000 [07:29<2149:23:35,  7.84s/it, lr=1e-5, step_loss=0.0619][RANK-0]: Step: [13038], local_loss=0.08573242276906967, train_loss=0.08797606825828552, time_cost=3.000669240951538
Steps:   1%|▏         | 13038/1000000 [07:29<2149:23:35,  7.84s/it, lr=1e-5, step_loss=0.0857]Steps:   1%|▏         | 13039/1000000 [07:36<2093:31:45,  7.64s/it, lr=1e-5, step_loss=0.0857][RANK-0]: Step: [13039], local_loss=0.07212965935468674, train_loss=0.12634927034378052, time_cost=1.7842943668365479
Steps:   1%|▏         | 13039/1000000 [07:36<2093:31:45,  7.64s/it, lr=1e-5, step_loss=0.0721]Steps:   1%|▏         | 13040/1000000 [07:49<2504:04:10,  9.13s/it, lr=1e-5, step_loss=0.0721][RANK-0]: Step: [13040], local_loss=0.05564303323626518, train_loss=0.08759918808937073, time_cost=1.8180129528045654
Steps:   1%|▏         | 13040/1000000 [07:49<2504:04:10,  9.13s/it, lr=1e-5, step_loss=0.0556]Steps:   1%|▏         | 13041/1000000 [07:54<2139:33:28,  7.80s/it, lr=1e-5, step_loss=0.0556][RANK-0]: Step: [13041], local_loss=0.03688441589474678, train_loss=0.04052276164293289, time_cost=1.7254462242126465
Steps:   1%|▏         | 13041/1000000 [07:54<2139:33:28,  7.80s/it, lr=1e-5, step_loss=0.0369]Steps:   1%|▏         | 13042/1000000 [07:58<1857:42:35,  6.78s/it, lr=1e-5, step_loss=0.0369][RANK-0]: Step: [13042], local_loss=0.09647025913000107, train_loss=0.0604621097445488, time_cost=1.1955194473266602
Steps:   1%|▏         | 13042/1000000 [07:58<1857:42:35,  6.78s/it, lr=1e-5, step_loss=0.0965]Steps:   1%|▏         | 13043/1000000 [08:04<1769:44:30,  6.46s/it, lr=1e-5, step_loss=0.0965][RANK-0]: Step: [13043], local_loss=0.030699556693434715, train_loss=0.06671479344367981, time_cost=2.955723762512207
Steps:   1%|▏         | 13043/1000000 [08:04<1769:44:30,  6.46s/it, lr=1e-5, step_loss=0.0307]Steps:   1%|▏         | 13044/1000000 [08:15<2210:01:17,  8.06s/it, lr=1e-5, step_loss=0.0307][RANK-0]: Step: [13044], local_loss=0.0862542912364006, train_loss=0.07042145729064941, time_cost=3.6811792850494385
Steps:   1%|▏         | 13044/1000000 [08:15<2210:01:17,  8.06s/it, lr=1e-5, step_loss=0.0863]Steps:   1%|▏         | 13045/1000000 [08:19<1876:51:41,  6.85s/it, lr=1e-5, step_loss=0.0863][RANK-0]: Step: [13045], local_loss=0.03839487209916115, train_loss=0.11812586337327957, time_cost=1.3724353313446045
Steps:   1%|▏         | 13045/1000000 [08:19<1876:51:41,  6.85s/it, lr=1e-5, step_loss=0.0384]Steps:   1%|▏         | 13046/1000000 [08:26<1858:02:22,  6.78s/it, lr=1e-5, step_loss=0.0384][RANK-0]: Step: [13046], local_loss=0.21678945422172546, train_loss=0.07650742679834366, time_cost=1.6032350063323975
Steps:   1%|▏         | 13046/1000000 [08:26<1858:02:22,  6.78s/it, lr=1e-5, step_loss=0.217] Steps:   1%|▏         | 13047/1000000 [08:31<1711:33:35,  6.24s/it, lr=1e-5, step_loss=0.217][RANK-0]: Step: [13047], local_loss=0.4205295443534851, train_loss=0.10969267040491104, time_cost=3.995391607284546
Steps:   1%|▏         | 13047/1000000 [08:31<1711:33:35,  6.24s/it, lr=1e-5, step_loss=0.421]Steps:   1%|▏         | 13048/1000000 [08:41<2049:46:18,  7.48s/it, lr=1e-5, step_loss=0.421][RANK-0]: Step: [13048], local_loss=0.06901390105485916, train_loss=0.12885023653507233, time_cost=2.125579595565796
Steps:   1%|▏         | 13048/1000000 [08:41<2049:46:18,  7.48s/it, lr=1e-5, step_loss=0.069]Steps:   1%|▏         | 13049/1000000 [08:54<2475:55:55,  9.03s/it, lr=1e-5, step_loss=0.069][RANK-0]: Step: [13049], local_loss=0.4977265000343323, train_loss=0.11252966523170471, time_cost=3.8791282176971436
Steps:   1%|▏         | 13049/1000000 [08:54<2475:55:55,  9.03s/it, lr=1e-5, step_loss=0.498]Steps:   1%|▏         | 13050/1000000 [09:11<3131:36:46, 11.42s/it, lr=1e-5, step_loss=0.498][RANK-0]: Step: [13050], local_loss=0.040667250752449036, train_loss=0.06971438229084015, time_cost=8.345251321792603
Steps:   1%|▏         | 13050/1000000 [09:11<3131:36:46, 11.42s/it, lr=1e-5, step_loss=0.0407]Steps:   1%|▏         | 13051/1000000 [09:23<3198:52:19, 11.67s/it, lr=1e-5, step_loss=0.0407][RANK-0]: Step: [13051], local_loss=0.11105022579431534, train_loss=0.08668375015258789, time_cost=2.6864776611328125
Steps:   1%|▏         | 13051/1000000 [09:23<3198:52:19, 11.67s/it, lr=1e-5, step_loss=0.111] Steps:   1%|▏         | 13052/1000000 [09:28<2587:28:30,  9.44s/it, lr=1e-5, step_loss=0.111][RANK-0]: Step: [13052], local_loss=0.04316336661577225, train_loss=0.045426253229379654, time_cost=3.1966445446014404
Steps:   1%|▏         | 13052/1000000 [09:28<2587:28:30,  9.44s/it, lr=1e-5, step_loss=0.0432]Steps:   1%|▏         | 13053/1000000 [09:37<2589:32:05,  9.45s/it, lr=1e-5, step_loss=0.0432][RANK-0]: Step: [13053], local_loss=0.08944638073444366, train_loss=0.1109633594751358, time_cost=1.5816352367401123
Steps:   1%|▏         | 13053/1000000 [09:37<2589:32:05,  9.45s/it, lr=1e-5, step_loss=0.0894]Steps:   1%|▏         | 13054/1000000 [09:42<2237:52:01,  8.16s/it, lr=1e-5, step_loss=0.0894][RANK-0]: Step: [13054], local_loss=0.0322047621011734, train_loss=0.04483100026845932, time_cost=2.3469419479370117
Steps:   1%|▏         | 13054/1000000 [09:42<2237:52:01,  8.16s/it, lr=1e-5, step_loss=0.0322]Steps:   1%|▏         | 13055/1000000 [09:50<2237:07:00,  8.16s/it, lr=1e-5, step_loss=0.0322][RANK-0]: Step: [13055], local_loss=0.04546746239066124, train_loss=0.08085073530673981, time_cost=1.1877892017364502
Steps:   1%|▏         | 13055/1000000 [09:50<2237:07:00,  8.16s/it, lr=1e-5, step_loss=0.0455]Steps:   1%|▏         | 13056/1000000 [10:03<2641:38:07,  9.64s/it, lr=1e-5, step_loss=0.0455][RANK-0]: Step: [13056], local_loss=0.030740784481167793, train_loss=0.051894668489694595, time_cost=1.177433729171753
Steps:   1%|▏         | 13056/1000000 [10:03<2641:38:07,  9.64s/it, lr=1e-5, step_loss=0.0307]Steps:   1%|▏         | 13057/1000000 [10:08<2263:39:22,  8.26s/it, lr=1e-5, step_loss=0.0307][RANK-0]: Step: [13057], local_loss=0.028211969882249832, train_loss=0.07409092783927917, time_cost=1.7246479988098145
Steps:   1%|▏         | 13057/1000000 [10:08<2263:39:22,  8.26s/it, lr=1e-5, step_loss=0.0282]Steps:   1%|▏         | 13058/1000000 [10:17<2254:55:22,  8.23s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [13058], local_loss=0.09834682941436768, train_loss=0.08208297938108444, time_cost=6.672968864440918
Steps:   1%|▏         | 13058/1000000 [10:17<2254:55:22,  8.23s/it, lr=1e-5, step_loss=0.0983]Steps:   1%|▏         | 13059/1000000 [10:26<2323:45:17,  8.48s/it, lr=1e-5, step_loss=0.0983][RANK-0]: Step: [13059], local_loss=0.07239135354757309, train_loss=0.06804746389389038, time_cost=1.1543831825256348
Steps:   1%|▏         | 13059/1000000 [10:26<2323:45:17,  8.48s/it, lr=1e-5, step_loss=0.0724]Steps:   1%|▏         | 13060/1000000 [10:30<1972:18:18,  7.19s/it, lr=1e-5, step_loss=0.0724][RANK-0]: Step: [13060], local_loss=0.031734079122543335, train_loss=0.04941225051879883, time_cost=1.232001781463623
Steps:   1%|▏         | 13060/1000000 [10:30<1972:18:18,  7.19s/it, lr=1e-5, step_loss=0.0317]Steps:   1%|▏         | 13061/1000000 [10:36<1917:09:08,  6.99s/it, lr=1e-5, step_loss=0.0317][RANK-0]: Step: [13061], local_loss=0.0321425125002861, train_loss=0.051371339708566666, time_cost=2.02801251411438
Steps:   1%|▏         | 13061/1000000 [10:36<1917:09:08,  6.99s/it, lr=1e-5, step_loss=0.0321]Steps:   1%|▏         | 13062/1000000 [10:47<2208:46:20,  8.06s/it, lr=1e-5, step_loss=0.0321][RANK-0]: Step: [13062], local_loss=0.0281971488147974, train_loss=0.03899931535124779, time_cost=1.2628154754638672
Steps:   1%|▏         | 13062/1000000 [10:47<2208:46:20,  8.06s/it, lr=1e-5, step_loss=0.0282]Steps:   1%|▏         | 13063/1000000 [10:51<1911:21:10,  6.97s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [13063], local_loss=0.034505829215049744, train_loss=0.036058228462934494, time_cost=2.996906280517578
Steps:   1%|▏         | 13063/1000000 [10:51<1911:21:10,  6.97s/it, lr=1e-5, step_loss=0.0345]Steps:   1%|▏         | 13064/1000000 [10:57<1803:41:50,  6.58s/it, lr=1e-5, step_loss=0.0345][RANK-0]: Step: [13064], local_loss=0.10796792805194855, train_loss=0.11528446525335312, time_cost=1.1932508945465088
Steps:   1%|▏         | 13064/1000000 [10:57<1803:41:50,  6.58s/it, lr=1e-5, step_loss=0.108] Steps:   1%|▏         | 13065/1000000 [11:09<2248:30:06,  8.20s/it, lr=1e-5, step_loss=0.108][RANK-0]: Step: [13065], local_loss=0.016511397436261177, train_loss=0.08320055902004242, time_cost=5.838212490081787
Steps:   1%|▏         | 13065/1000000 [11:09<2248:30:06,  8.20s/it, lr=1e-5, step_loss=0.0165]Steps:   1%|▏         | 13066/1000000 [11:18<2343:05:11,  8.55s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [13066], local_loss=0.053020454943180084, train_loss=0.09214553236961365, time_cost=3.3808982372283936
Steps:   1%|▏         | 13066/1000000 [11:18<2343:05:11,  8.55s/it, lr=1e-5, step_loss=0.053] Steps:   1%|▏         | 13067/1000000 [11:23<2055:27:28,  7.50s/it, lr=1e-5, step_loss=0.053][RANK-0]: Step: [13067], local_loss=0.021782565861940384, train_loss=0.19200366735458374, time_cost=2.2089591026306152
Steps:   1%|▏         | 13067/1000000 [11:23<2055:27:28,  7.50s/it, lr=1e-5, step_loss=0.0218]Steps:   1%|▏         | 13068/1000000 [11:29<1873:21:58,  6.83s/it, lr=1e-5, step_loss=0.0218][RANK-0]: Step: [13068], local_loss=0.053066276013851166, train_loss=0.06589754670858383, time_cost=2.5695953369140625
Steps:   1%|▏         | 13068/1000000 [11:29<1873:21:58,  6.83s/it, lr=1e-5, step_loss=0.0531]Steps:   1%|▏         | 13069/1000000 [11:36<1889:19:33,  6.89s/it, lr=1e-5, step_loss=0.0531][RANK-0]: Step: [13069], local_loss=12.626391410827637, train_loss=1.7698101997375488, time_cost=2.0311930179595947
Steps:   1%|▏         | 13069/1000000 [11:36<1889:19:33,  6.89s/it, lr=1e-5, step_loss=12.6]  Steps:   1%|▏         | 13070/1000000 [11:41<1779:30:41,  6.49s/it, lr=1e-5, step_loss=12.6][RANK-0]: Step: [13070], local_loss=0.1008138582110405, train_loss=0.1352553814649582, time_cost=3.000626802444458
Steps:   1%|▏         | 13070/1000000 [11:41<1779:30:41,  6.49s/it, lr=1e-5, step_loss=0.101]Steps:   1%|▏         | 13071/1000000 [11:49<1901:25:36,  6.94s/it, lr=1e-5, step_loss=0.101][RANK-0]: Step: [13071], local_loss=0.0929906815290451, train_loss=0.06481929123401642, time_cost=4.204439163208008
Steps:   1%|▏         | 13071/1000000 [11:49<1901:25:36,  6.94s/it, lr=1e-5, step_loss=0.093]Steps:   1%|▏         | 13072/1000000 [11:58<2045:10:05,  7.46s/it, lr=1e-5, step_loss=0.093][RANK-0]: Step: [13072], local_loss=0.041687414050102234, train_loss=0.042519938200712204, time_cost=2.517719030380249
Steps:   1%|▏         | 13072/1000000 [11:58<2045:10:05,  7.46s/it, lr=1e-5, step_loss=0.0417]Steps:   1%|▏         | 13073/1000000 [12:09<2312:53:23,  8.44s/it, lr=1e-5, step_loss=0.0417][RANK-0]: Step: [13073], local_loss=0.027906322851777077, train_loss=0.057496048510074615, time_cost=1.2641541957855225
Steps:   1%|▏         | 13073/1000000 [12:09<2312:53:23,  8.44s/it, lr=1e-5, step_loss=0.0279]Steps:   1%|▏         | 13074/1000000 [12:16<2234:38:38,  8.15s/it, lr=1e-5, step_loss=0.0279][RANK-0]: Step: [13074], local_loss=0.05297687649726868, train_loss=0.08475500345230103, time_cost=3.516213893890381
Steps:   1%|▏         | 13074/1000000 [12:16<2234:38:38,  8.15s/it, lr=1e-5, step_loss=0.053] Steps:   1%|▏         | 13075/1000000 [12:26<2374:51:10,  8.66s/it, lr=1e-5, step_loss=0.053][RANK-0]: Step: [13075], local_loss=0.017238549888134003, train_loss=0.12071967124938965, time_cost=1.200681447982788
Steps:   1%|▏         | 13075/1000000 [12:26<2374:51:10,  8.66s/it, lr=1e-5, step_loss=0.0172]Steps:   1%|▏         | 13076/1000000 [12:37<2553:27:00,  9.31s/it, lr=1e-5, step_loss=0.0172][RANK-0]: Step: [13076], local_loss=0.020224357023835182, train_loss=0.05678611993789673, time_cost=1.204789161682129
Steps:   1%|▏         | 13076/1000000 [12:37<2553:27:00,  9.31s/it, lr=1e-5, step_loss=0.0202]Steps:   1%|▏         | 13077/1000000 [12:45<2459:00:20,  8.97s/it, lr=1e-5, step_loss=0.0202][RANK-0]: Step: [13077], local_loss=0.036586444824934006, train_loss=0.04997251182794571, time_cost=1.7450807094573975
Steps:   1%|▏         | 13077/1000000 [12:45<2459:00:20,  8.97s/it, lr=1e-5, step_loss=0.0366]Steps:   1%|▏         | 13078/1000000 [12:50<2159:40:07,  7.88s/it, lr=1e-5, step_loss=0.0366][RANK-0]: Step: [13078], local_loss=0.028620729222893715, train_loss=0.060873307287693024, time_cost=4.1338512897491455
Steps:   1%|▏         | 13078/1000000 [12:50<2159:40:07,  7.88s/it, lr=1e-5, step_loss=0.0286]Steps:   1%|▏         | 13079/1000000 [12:57<2063:03:42,  7.53s/it, lr=1e-5, step_loss=0.0286][RANK-0]: Step: [13079], local_loss=0.06756910681724548, train_loss=0.16852787137031555, time_cost=2.517662286758423
Steps:   1%|▏         | 13079/1000000 [12:57<2063:03:42,  7.53s/it, lr=1e-5, step_loss=0.0676]Steps:   1%|▏         | 13080/1000000 [13:11<2613:46:07,  9.53s/it, lr=1e-5, step_loss=0.0676][RANK-0]: Step: [13080], local_loss=0.02846851386129856, train_loss=2.790355920791626, time_cost=1.2054784297943115
Steps:   1%|▏         | 13080/1000000 [13:11<2613:46:07,  9.53s/it, lr=1e-5, step_loss=0.0285]Steps:   1%|▏         | 13081/1000000 [13:24<2901:18:01, 10.58s/it, lr=1e-5, step_loss=0.0285][RANK-0]: Step: [13081], local_loss=0.03340919315814972, train_loss=0.14923742413520813, time_cost=11.22702407836914
Steps:   1%|▏         | 13081/1000000 [13:24<2901:18:01, 10.58s/it, lr=1e-5, step_loss=0.0334]Steps:   1%|▏         | 13082/1000000 [13:33<2765:50:47, 10.09s/it, lr=1e-5, step_loss=0.0334][RANK-0]: Step: [13082], local_loss=0.24614779651165009, train_loss=0.06319369375705719, time_cost=1.1739492416381836
Steps:   1%|▏         | 13082/1000000 [13:33<2765:50:47, 10.09s/it, lr=1e-5, step_loss=0.246] Steps:   1%|▏         | 13083/1000000 [13:42<2693:25:06,  9.82s/it, lr=1e-5, step_loss=0.246][RANK-0]: Step: [13083], local_loss=0.03692837059497833, train_loss=0.1230938583612442, time_cost=1.6080572605133057
Steps:   1%|▏         | 13083/1000000 [13:42<2693:25:06,  9.82s/it, lr=1e-5, step_loss=0.0369]Steps:   1%|▏         | 13084/1000000 [13:56<3025:51:56, 11.04s/it, lr=1e-5, step_loss=0.0369][RANK-0]: Step: [13084], local_loss=0.013816016726195812, train_loss=0.0423557385802269, time_cost=1.1852567195892334
Steps:   1%|▏         | 13084/1000000 [13:56<3025:51:56, 11.04s/it, lr=1e-5, step_loss=0.0138]Steps:   1%|▏         | 13085/1000000 [14:02<2607:01:28,  9.51s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [13085], local_loss=0.024363450706005096, train_loss=0.04568168520927429, time_cost=1.8156864643096924
Steps:   1%|▏         | 13085/1000000 [14:02<2607:01:28,  9.51s/it, lr=1e-5, step_loss=0.0244]Steps:   1%|▏         | 13086/1000000 [14:15<2884:56:23, 10.52s/it, lr=1e-5, step_loss=0.0244][RANK-0]: Step: [13086], local_loss=0.2272205352783203, train_loss=0.102378249168396, time_cost=3.174506187438965
Steps:   1%|▏         | 13086/1000000 [14:15<2884:56:23, 10.52s/it, lr=1e-5, step_loss=0.227] Steps:   1%|▏         | 13087/1000000 [14:22<2609:12:13,  9.52s/it, lr=1e-5, step_loss=0.227][RANK-0]: Step: [13087], local_loss=0.029507849365472794, train_loss=0.03481770306825638, time_cost=2.7101190090179443
Steps:   1%|▏         | 13087/1000000 [14:22<2609:12:13,  9.52s/it, lr=1e-5, step_loss=0.0295]Steps:   1%|▏         | 13088/1000000 [14:31<2562:04:07,  9.35s/it, lr=1e-5, step_loss=0.0295][RANK-0]: Step: [13088], local_loss=0.034952204674482346, train_loss=0.16942976415157318, time_cost=2.7203369140625
Steps:   1%|▏         | 13088/1000000 [14:31<2562:04:07,  9.35s/it, lr=1e-5, step_loss=0.035] Steps:   1%|▏         | 13089/1000000 [14:36<2202:10:44,  8.03s/it, lr=1e-5, step_loss=0.035][RANK-0]: Step: [13089], local_loss=0.05845103785395622, train_loss=0.07421861588954926, time_cost=1.1768662929534912
Steps:   1%|▏         | 13089/1000000 [14:36<2202:10:44,  8.03s/it, lr=1e-5, step_loss=0.0585]Steps:   1%|▏         | 13090/1000000 [14:43<2114:02:11,  7.71s/it, lr=1e-5, step_loss=0.0585][RANK-0]: Step: [13090], local_loss=0.044071584939956665, train_loss=0.042979493737220764, time_cost=2.6621956825256348
Steps:   1%|▏         | 13090/1000000 [14:43<2114:02:11,  7.71s/it, lr=1e-5, step_loss=0.0441]Steps:   1%|▏         | 13091/1000000 [14:50<2077:53:08,  7.58s/it, lr=1e-5, step_loss=0.0441][RANK-0]: Step: [13091], local_loss=0.03262651339173317, train_loss=0.04302695393562317, time_cost=2.614711046218872
Steps:   1%|▏         | 13091/1000000 [14:50<2077:53:08,  7.58s/it, lr=1e-5, step_loss=0.0326]Steps:   1%|▏         | 13092/1000000 [14:55<1849:47:50,  6.75s/it, lr=1e-5, step_loss=0.0326][RANK-0]: Step: [13092], local_loss=0.02401992492377758, train_loss=0.04160035401582718, time_cost=3.8219733238220215
Steps:   1%|▏         | 13092/1000000 [14:55<1849:47:50,  6.75s/it, lr=1e-5, step_loss=0.024] Steps:   1%|▏         | 13093/1000000 [15:02<1821:09:07,  6.64s/it, lr=1e-5, step_loss=0.024][RANK-0]: Step: [13093], local_loss=0.04525874927639961, train_loss=0.038348302245140076, time_cost=2.5620081424713135
Steps:   1%|▏         | 13093/1000000 [15:02<1821:09:07,  6.64s/it, lr=1e-5, step_loss=0.0453]Steps:   1%|▏         | 13094/1000000 [15:06<1635:55:49,  5.97s/it, lr=1e-5, step_loss=0.0453][RANK-0]: Step: [13094], local_loss=0.038956418633461, train_loss=0.08861736953258514, time_cost=1.7374298572540283
Steps:   1%|▏         | 13094/1000000 [15:06<1635:55:49,  5.97s/it, lr=1e-5, step_loss=0.039] Steps:   1%|▏         | 13095/1000000 [15:14<1788:16:12,  6.52s/it, lr=1e-5, step_loss=0.039][RANK-0]: Step: [13095], local_loss=0.03843923285603523, train_loss=0.06873827427625656, time_cost=1.6491179466247559
Steps:   1%|▏         | 13095/1000000 [15:14<1788:16:12,  6.52s/it, lr=1e-5, step_loss=0.0384]Steps:   1%|▏         | 13096/1000000 [15:28<2451:58:00,  8.94s/it, lr=1e-5, step_loss=0.0384][RANK-0]: Step: [13096], local_loss=0.04634671285748482, train_loss=0.03067866712808609, time_cost=6.420986652374268
Steps:   1%|▏         | 13096/1000000 [15:28<2451:58:00,  8.94s/it, lr=1e-5, step_loss=0.0463]Steps:   1%|▏         | 13097/1000000 [15:37<2385:00:39,  8.70s/it, lr=1e-5, step_loss=0.0463][RANK-0]: Step: [13097], local_loss=0.014897074550390244, train_loss=0.04523338004946709, time_cost=3.0526394844055176
Steps:   1%|▏         | 13097/1000000 [15:37<2385:00:39,  8.70s/it, lr=1e-5, step_loss=0.0149]Steps:   1%|▏         | 13098/1000000 [15:44<2302:14:56,  8.40s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [13098], local_loss=0.10048118233680725, train_loss=0.032033879309892654, time_cost=2.5276007652282715
Steps:   1%|▏         | 13098/1000000 [15:44<2302:14:56,  8.40s/it, lr=1e-5, step_loss=0.1]   Steps:   1%|▏         | 13099/1000000 [15:50<2086:43:36,  7.61s/it, lr=1e-5, step_loss=0.1][RANK-0]: Step: [13099], local_loss=0.03699418902397156, train_loss=0.052640125155448914, time_cost=1.249600887298584
Steps:   1%|▏         | 13099/1000000 [15:50<2086:43:36,  7.61s/it, lr=1e-5, step_loss=0.037]\|\\\\|\Steps:   1%|▏         | 13100/1000000 [15:56<1931:52:01,  7.05s/it, lr=1e-5, step_loss=0.037][RANK-0]: Step: [13100], local_loss=0.019349968060851097, train_loss=0.04692091420292854, time_cost=1.6953916549682617
Steps:   1%|▏         | 13100/1000000 [15:56<1931:52:01,  7.05s/it, lr=1e-5, step_loss=0.0193]Steps:   1%|▏         | 13101/1000000 [16:06<2184:32:49,  7.97s/it, lr=1e-5, step_loss=0.0193][RANK-0]: Step: [13101], local_loss=0.04074251651763916, train_loss=0.05827762931585312, time_cost=7.5485780239105225
Steps:   1%|▏         | 13101/1000000 [16:06<2184:32:49,  7.97s/it, lr=1e-5, step_loss=0.0407]Steps:   1%|▏         | 13102/1000000 [16:13<2133:29:56,  7.78s/it, lr=1e-5, step_loss=0.0407][RANK-0]: Step: [13102], local_loss=0.04693391174077988, train_loss=0.03496510162949562, time_cost=5.060737609863281
Steps:   1%|▏         | 13102/1000000 [16:13<2133:29:56,  7.78s/it, lr=1e-5, step_loss=0.0469]Steps:   1%|▏         | 13103/1000000 [16:23<2285:45:12,  8.34s/it, lr=1e-5, step_loss=0.0469][RANK-0]: Step: [13103], local_loss=0.09972681105136871, train_loss=0.04201456904411316, time_cost=1.3102316856384277
Steps:   1%|▏         | 13103/1000000 [16:23<2285:45:12,  8.34s/it, lr=1e-5, step_loss=0.0997]Steps:   1%|▏         | 13104/1000000 [16:33<2421:24:41,  8.83s/it, lr=1e-5, step_loss=0.0997][RANK-0]: Step: [13104], local_loss=0.3339431881904602, train_loss=0.09735651314258575, time_cost=1.6835877895355225
Steps:   1%|▏         | 13104/1000000 [16:33<2421:24:41,  8.83s/it, lr=1e-5, step_loss=0.334] Steps:   1%|▏         | 13105/1000000 [16:37<2054:12:00,  7.49s/it, lr=1e-5, step_loss=0.334][RANK-0]: Step: [13105], local_loss=1.0055567026138306, train_loss=0.18502509593963623, time_cost=1.3435649871826172
Steps:   1%|▏         | 13105/1000000 [16:37<2054:12:00,  7.49s/it, lr=1e-5, step_loss=1.01] Steps:   1%|▏         | 13106/1000000 [16:49<2401:03:00,  8.76s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [13106], local_loss=0.021855153143405914, train_loss=0.04572649300098419, time_cost=2.246246337890625
Steps:   1%|▏         | 13106/1000000 [16:49<2401:03:00,  8.76s/it, lr=1e-5, step_loss=0.0219]Steps:   1%|▏         | 13107/1000000 [17:03<2844:00:16, 10.37s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [13107], local_loss=0.057524994015693665, train_loss=0.15326879918575287, time_cost=3.1481869220733643
Steps:   1%|▏         | 13107/1000000 [17:03<2844:00:16, 10.37s/it, lr=1e-5, step_loss=0.0575]Steps:   1%|▏         | 13108/1000000 [17:19<3270:44:19, 11.93s/it, lr=1e-5, step_loss=0.0575][RANK-0]: Step: [13108], local_loss=0.03417633846402168, train_loss=0.025647010654211044, time_cost=5.079161882400513
Steps:   1%|▏         | 13108/1000000 [17:19<3270:44:19, 11.93s/it, lr=1e-5, step_loss=0.0342]Steps:   1%|▏         | 13109/1000000 [17:27<2934:53:59, 10.71s/it, lr=1e-5, step_loss=0.0342][RANK-0]: Step: [13109], local_loss=0.10346468538045883, train_loss=0.03790801763534546, time_cost=5.850907802581787
Steps:   1%|▏         | 13109/1000000 [17:27<2934:53:59, 10.71s/it, lr=1e-5, step_loss=0.103] Steps:   1%|▏         | 13110/1000000 [17:41<3226:55:07, 11.77s/it, lr=1e-5, step_loss=0.103][RANK-0]: Step: [13110], local_loss=0.041591577231884, train_loss=0.05055317282676697, time_cost=4.300922155380249
Steps:   1%|▏         | 13110/1000000 [17:41<3226:55:07, 11.77s/it, lr=1e-5, step_loss=0.0416]Steps:   1%|▏         | 13111/1000000 [17:49<2966:27:42, 10.82s/it, lr=1e-5, step_loss=0.0416][RANK-0]: Step: [13111], local_loss=0.19305622577667236, train_loss=0.15996259450912476, time_cost=7.175643444061279
Steps:   1%|▏         | 13111/1000000 [17:49<2966:27:42, 10.82s/it, lr=1e-5, step_loss=0.193] Steps:   1%|▏         | 13112/1000000 [18:04<3239:05:19, 11.82s/it, lr=1e-5, step_loss=0.193][RANK-0]: Step: [13112], local_loss=0.09676774591207504, train_loss=0.04465578496456146, time_cost=10.7322678565979
Steps:   1%|▏         | 13112/1000000 [18:04<3239:05:19, 11.82s/it, lr=1e-5, step_loss=0.0968]Steps:   1%|▏         | 13113/1000000 [18:13<3008:01:04, 10.97s/it, lr=1e-5, step_loss=0.0968][RANK-0]: Step: [13113], local_loss=0.08763279765844345, train_loss=0.12336064875125885, time_cost=1.3171472549438477
Steps:   1%|▏         | 13113/1000000 [18:13<3008:01:04, 10.97s/it, lr=1e-5, step_loss=0.0876]Steps:   1%|▏         | 13114/1000000 [18:22<2898:50:03, 10.57s/it, lr=1e-5, step_loss=0.0876][RANK-0]: Step: [13114], local_loss=0.18038348853588104, train_loss=0.10528422892093658, time_cost=1.6713910102844238
Steps:   1%|▏         | 13114/1000000 [18:22<2898:50:03, 10.57s/it, lr=1e-5, step_loss=0.18]  Steps:   1%|▏         | 13115/1000000 [18:29<2591:09:42,  9.45s/it, lr=1e-5, step_loss=0.18][RANK-0]: Step: [13115], local_loss=0.10920414328575134, train_loss=0.050302062183618546, time_cost=2.1505613327026367
Steps:   1%|▏         | 13115/1000000 [18:29<2591:09:42,  9.45s/it, lr=1e-5, step_loss=0.109]Steps:   1%|▏         | 13116/1000000 [18:35<2268:04:36,  8.27s/it, lr=1e-5, step_loss=0.109][RANK-0]: Step: [13116], local_loss=0.018159223720431328, train_loss=0.03283941373229027, time_cost=1.9134230613708496
Steps:   1%|▏         | 13116/1000000 [18:35<2268:04:36,  8.27s/it, lr=1e-5, step_loss=0.0182]Steps:   1%|▏         | 13117/1000000 [18:43<2302:57:18,  8.40s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [13117], local_loss=0.17999626696109772, train_loss=0.08191338181495667, time_cost=2.4765350818634033
Steps:   1%|▏         | 13117/1000000 [18:43<2302:57:18,  8.40s/it, lr=1e-5, step_loss=0.18]  Steps:   1%|▏         | 13118/1000000 [18:54<2492:20:24,  9.09s/it, lr=1e-5, step_loss=0.18][RANK-0]: Step: [13118], local_loss=0.061047062277793884, train_loss=0.06060813367366791, time_cost=1.5453870296478271
Steps:   1%|▏         | 13118/1000000 [18:54<2492:20:24,  9.09s/it, lr=1e-5, step_loss=0.061]Steps:   1%|▏         | 13119/1000000 [19:05<2646:29:09,  9.65s/it, lr=1e-5, step_loss=0.061][RANK-0]: Step: [13119], local_loss=0.02680654637515545, train_loss=0.05349159985780716, time_cost=2.311969757080078
Steps:   1%|▏         | 13119/1000000 [19:05<2646:29:09,  9.65s/it, lr=1e-5, step_loss=0.0268]Steps:   1%|▏         | 13120/1000000 [19:17<2807:56:56, 10.24s/it, lr=1e-5, step_loss=0.0268][RANK-0]: Step: [13120], local_loss=0.022763241082429886, train_loss=0.03609267622232437, time_cost=2.763843059539795
Steps:   1%|▏         | 13120/1000000 [19:17<2807:56:56, 10.24s/it, lr=1e-5, step_loss=0.0228]Steps:   1%|▏         | 13121/1000000 [19:22<2410:42:58,  8.79s/it, lr=1e-5, step_loss=0.0228][RANK-0]: Step: [13121], local_loss=0.019231528043746948, train_loss=0.03059130162000656, time_cost=2.4536657333374023
Steps:   1%|▏         | 13121/1000000 [19:22<2410:42:58,  8.79s/it, lr=1e-5, step_loss=0.0192]Steps:   1%|▏         | 13122/1000000 [19:26<2027:10:21,  7.39s/it, lr=1e-5, step_loss=0.0192][RANK-0]: Step: [13122], local_loss=0.03370708227157593, train_loss=16.550260543823242, time_cost=3.07731556892395
Steps:   1%|▏         | 13122/1000000 [19:26<2027:10:21,  7.39s/it, lr=1e-5, step_loss=0.0337]Steps:   1%|▏         | 13123/1000000 [19:35<2162:55:38,  7.89s/it, lr=1e-5, step_loss=0.0337][RANK-0]: Step: [13123], local_loss=0.06831838935613632, train_loss=0.06980307400226593, time_cost=1.2256388664245605
Steps:   1%|▏         | 13123/1000000 [19:35<2162:55:38,  7.89s/it, lr=1e-5, step_loss=0.0683]Steps:   1%|▏         | 13124/1000000 [19:41<2005:20:52,  7.32s/it, lr=1e-5, step_loss=0.0683][RANK-0]: Step: [13124], local_loss=0.04542916640639305, train_loss=0.1738218516111374, time_cost=2.5165488719940186
Steps:   1%|▏         | 13124/1000000 [19:41<2005:20:52,  7.32s/it, lr=1e-5, step_loss=0.0454]Steps:   1%|▏         | 13125/1000000 [19:57<2735:44:52,  9.98s/it, lr=1e-5, step_loss=0.0454][RANK-0]: Step: [13125], local_loss=312.01141357421875, train_loss=39.066001892089844, time_cost=6.094141483306885
Steps:   1%|▏         | 13125/1000000 [19:57<2735:44:52,  9.98s/it, lr=1e-5, step_loss=312]   Steps:   1%|▏         | 13126/1000000 [20:13<3181:58:32, 11.61s/it, lr=1e-5, step_loss=312][RANK-0]: Step: [13126], local_loss=0.01936848647892475, train_loss=0.05701569467782974, time_cost=6.352644681930542
Steps:   1%|▏         | 13126/1000000 [20:13<3181:58:32, 11.61s/it, lr=1e-5, step_loss=0.0194]Steps:   1%|▏         | 13127/1000000 [20:19<2733:23:59,  9.97s/it, lr=1e-5, step_loss=0.0194][RANK-0]: Step: [13127], local_loss=0.04245865345001221, train_loss=0.1919579952955246, time_cost=1.3725497722625732
Steps:   1%|▏         | 13127/1000000 [20:19<2733:23:59,  9.97s/it, lr=1e-5, step_loss=0.0425]Steps:   1%|▏         | 13128/1000000 [20:25<2398:15:01,  8.75s/it, lr=1e-5, step_loss=0.0425][RANK-0]: Step: [13128], local_loss=0.040106769651174545, train_loss=0.056483328342437744, time_cost=2.1607120037078857
Steps:   1%|▏         | 13128/1000000 [20:25<2398:15:01,  8.75s/it, lr=1e-5, step_loss=0.0401]Steps:   1%|▏         | 13129/1000000 [20:30<2139:40:26,  7.81s/it, lr=1e-5, step_loss=0.0401][RANK-0]: Step: [13129], local_loss=0.025106167420744896, train_loss=0.07494321465492249, time_cost=2.6307239532470703
Steps:   1%|▏         | 13129/1000000 [20:30<2139:40:26,  7.81s/it, lr=1e-5, step_loss=0.0251]Steps:   1%|▏         | 13130/1000000 [20:35<1871:49:53,  6.83s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [13130], local_loss=0.08088233321905136, train_loss=0.08678480237722397, time_cost=3.594440460205078
Steps:   1%|▏         | 13130/1000000 [20:35<1871:49:53,  6.83s/it, lr=1e-5, step_loss=0.0809]Steps:   1%|▏         | 13131/1000000 [20:45<2169:20:49,  7.91s/it, lr=1e-5, step_loss=0.0809][RANK-0]: Step: [13131], local_loss=0.12218077480792999, train_loss=0.12001074850559235, time_cost=3.886932611465454
Steps:   1%|▏         | 13131/1000000 [20:45<2169:20:49,  7.91s/it, lr=1e-5, step_loss=0.122] Steps:   1%|▏         | 13132/1000000 [20:50<1937:51:15,  7.07s/it, lr=1e-5, step_loss=0.122][RANK-0]: Step: [13132], local_loss=1.0068145990371704, train_loss=0.19208204746246338, time_cost=1.2345881462097168
Steps:   1%|▏         | 13132/1000000 [20:50<1937:51:15,  7.07s/it, lr=1e-5, step_loss=1.01] Steps:   1%|▏         | 13133/1000000 [20:58<1985:20:39,  7.24s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [13133], local_loss=0.026281308382749557, train_loss=0.06508874893188477, time_cost=5.409805774688721
Steps:   1%|▏         | 13133/1000000 [20:58<1985:20:39,  7.24s/it, lr=1e-5, step_loss=0.0263]Steps:   1%|▏         | 13134/1000000 [21:12<2558:27:55,  9.33s/it, lr=1e-5, step_loss=0.0263][RANK-0]: Step: [13134], local_loss=0.13868924975395203, train_loss=0.041370801627635956, time_cost=4.5665905475616455
Steps:   1%|▏         | 13134/1000000 [21:12<2558:27:55,  9.33s/it, lr=1e-5, step_loss=0.139] Steps:   1%|▏         | 13135/1000000 [21:23<2643:46:07,  9.64s/it, lr=1e-5, step_loss=0.139][RANK-0]: Step: [13135], local_loss=0.011522999033331871, train_loss=0.04047710821032524, time_cost=4.657576084136963
Steps:   1%|▏         | 13135/1000000 [21:23<2643:46:07,  9.64s/it, lr=1e-5, step_loss=0.0115]Steps:   1%|▏         | 13136/1000000 [21:28<2304:41:08,  8.41s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [13136], local_loss=0.028660595417022705, train_loss=0.037886470556259155, time_cost=4.084460973739624
Steps:   1%|▏         | 13136/1000000 [21:28<2304:41:08,  8.41s/it, lr=1e-5, step_loss=0.0287]Steps:   1%|▏         | 13137/1000000 [21:40<2559:12:52,  9.34s/it, lr=1e-5, step_loss=0.0287][RANK-0]: Step: [13137], local_loss=0.1074889600276947, train_loss=0.03941509500145912, time_cost=4.258029937744141
Steps:   1%|▏         | 13137/1000000 [21:40<2559:12:52,  9.34s/it, lr=1e-5, step_loss=0.107] Steps:   1%|▏         | 13138/1000000 [21:53<2871:12:44, 10.47s/it, lr=1e-5, step_loss=0.107][RANK-0]: Step: [13138], local_loss=0.038507185876369476, train_loss=0.061482373625040054, time_cost=2.1262359619140625
Steps:   1%|▏         | 13138/1000000 [21:53<2871:12:44, 10.47s/it, lr=1e-5, step_loss=0.0385]Steps:   1%|▏         | 13139/1000000 [22:03<2887:43:26, 10.53s/it, lr=1e-5, step_loss=0.0385][RANK-0]: Step: [13139], local_loss=0.01888616569340229, train_loss=0.03157810866832733, time_cost=4.634539604187012
Steps:   1%|▏         | 13139/1000000 [22:03<2887:43:26, 10.53s/it, lr=1e-5, step_loss=0.0189]Steps:   1%|▏         | 13140/1000000 [22:15<2951:18:24, 10.77s/it, lr=1e-5, step_loss=0.0189][RANK-0]: Step: [13140], local_loss=0.01614447869360447, train_loss=0.047176212072372437, time_cost=3.617816209793091
Steps:   1%|▏         | 13140/1000000 [22:15<2951:18:24, 10.77s/it, lr=1e-5, step_loss=0.0161]Steps:   1%|▏         | 13141/1000000 [22:19<2420:52:39,  8.83s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [13141], local_loss=0.018788618966937065, train_loss=0.021329745650291443, time_cost=1.873966932296753
Steps:   1%|▏         | 13141/1000000 [22:19<2420:52:39,  8.83s/it, lr=1e-5, step_loss=0.0188]Steps:   1%|▏         | 13142/1000000 [22:26<2267:48:18,  8.27s/it, lr=1e-5, step_loss=0.0188][RANK-0]: Step: [13142], local_loss=0.012427844107151031, train_loss=0.06315744668245316, time_cost=5.466761827468872
Steps:   1%|▏         | 13142/1000000 [22:26<2267:48:18,  8.27s/it, lr=1e-5, step_loss=0.0124]Steps:   1%|▏         | 13143/1000000 [22:31<1985:10:51,  7.24s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [13143], local_loss=0.1265893280506134, train_loss=0.05349583923816681, time_cost=1.8503401279449463
Steps:   1%|▏         | 13143/1000000 [22:31<1985:10:51,  7.24s/it, lr=1e-5, step_loss=0.127] Steps:   1%|▏         | 13144/1000000 [22:37<1871:54:57,  6.83s/it, lr=1e-5, step_loss=0.127][RANK-0]: Step: [13144], local_loss=0.045149900019168854, train_loss=0.06810595095157623, time_cost=1.7451469898223877
Steps:   1%|▏         | 13144/1000000 [22:37<1871:54:57,  6.83s/it, lr=1e-5, step_loss=0.0451]Steps:   1%|▏         | 13145/1000000 [22:42<1753:44:09,  6.40s/it, lr=1e-5, step_loss=0.0451][RANK-0]: Step: [13145], local_loss=0.031243067234754562, train_loss=0.0517609566450119, time_cost=1.4542531967163086
Steps:   1%|▏         | 13145/1000000 [22:42<1753:44:09,  6.40s/it, lr=1e-5, step_loss=0.0312]Steps:   1%|▏         | 13146/1000000 [22:53<2157:53:17,  7.87s/it, lr=1e-5, step_loss=0.0312][RANK-0]: Step: [13146], local_loss=0.05994883552193642, train_loss=0.023839913308620453, time_cost=1.8006527423858643
Steps:   1%|▏         | 13146/1000000 [22:53<2157:53:17,  7.87s/it, lr=1e-5, step_loss=0.0599]Steps:   1%|▏         | 13147/1000000 [22:59<1947:55:27,  7.11s/it, lr=1e-5, step_loss=0.0599][RANK-0]: Step: [13147], local_loss=0.03550783544778824, train_loss=0.08677570521831512, time_cost=1.2746918201446533
Steps:   1%|▏         | 13147/1000000 [22:59<1947:55:27,  7.11s/it, lr=1e-5, step_loss=0.0355]Steps:   1%|▏         | 13148/1000000 [23:06<1931:55:13,  7.05s/it, lr=1e-5, step_loss=0.0355][RANK-0]: Step: [13148], local_loss=0.012929833494126797, train_loss=0.03608351945877075, time_cost=2.3490285873413086
Steps:   1%|▏         | 13148/1000000 [23:06<1931:55:13,  7.05s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 13149/1000000 [23:15<2095:06:18,  7.64s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [13149], local_loss=0.05941811949014664, train_loss=0.04758409783244133, time_cost=1.9761345386505127
Steps:   1%|▏         | 13149/1000000 [23:15<2095:06:18,  7.64s/it, lr=1e-5, step_loss=0.0594]Steps:   1%|▏         | 13150/1000000 [23:24<2227:57:08,  8.13s/it, lr=1e-5, step_loss=0.0594][RANK-0]: Step: [13150], local_loss=0.013666301034390926, train_loss=0.062167271971702576, time_cost=1.8359179496765137
Steps:   1%|▏         | 13150/1000000 [23:24<2227:57:08,  8.13s/it, lr=1e-5, step_loss=0.0137]Steps:   1%|▏         | 13151/1000000 [23:31<2167:40:15,  7.91s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [13151], local_loss=0.024904116988182068, train_loss=0.05628638714551926, time_cost=2.111520290374756
Steps:   1%|▏         | 13151/1000000 [23:31<2167:40:15,  7.91s/it, lr=1e-5, step_loss=0.0249]Steps:   1%|▏         | 13152/1000000 [23:36<1914:58:45,  6.99s/it, lr=1e-5, step_loss=0.0249][RANK-0]: Step: [13152], local_loss=0.055536869913339615, train_loss=0.04820302128791809, time_cost=1.9099736213684082
Steps:   1%|▏         | 13152/1000000 [23:36<1914:58:45,  6.99s/it, lr=1e-5, step_loss=0.0555]Steps:   1%|▏         | 13153/1000000 [23:43<1896:26:18,  6.92s/it, lr=1e-5, step_loss=0.0555][RANK-0]: Step: [13153], local_loss=0.009403069503605366, train_loss=0.03509426489472389, time_cost=1.778031587600708
Steps:   1%|▏         | 13153/1000000 [23:43<1896:26:18,  6.92s/it, lr=1e-5, step_loss=0.0094]Steps:   1%|▏         | 13154/1000000 [23:52<2045:28:51,  7.46s/it, lr=1e-5, step_loss=0.0094][RANK-0]: Step: [13154], local_loss=0.04079338535666466, train_loss=0.06180643290281296, time_cost=1.2301602363586426
Steps:   1%|▏         | 13154/1000000 [23:52<2045:28:51,  7.46s/it, lr=1e-5, step_loss=0.0408]Steps:   1%|▏         | 13155/1000000 [24:04<2457:59:22,  8.97s/it, lr=1e-5, step_loss=0.0408][RANK-0]: Step: [13155], local_loss=0.021748840808868408, train_loss=0.035820141434669495, time_cost=5.1499598026275635
Steps:   1%|▏         | 13155/1000000 [24:04<2457:59:22,  8.97s/it, lr=1e-5, step_loss=0.0217]Steps:   1%|▏         | 13156/1000000 [24:18<2842:53:12, 10.37s/it, lr=1e-5, step_loss=0.0217][RANK-0]: Step: [13156], local_loss=0.013484518975019455, train_loss=0.10290974378585815, time_cost=9.99199652671814
Steps:   1%|▏         | 13156/1000000 [24:18<2842:53:12, 10.37s/it, lr=1e-5, step_loss=0.0135]Steps:   1%|▏         | 13157/1000000 [24:27<2784:23:08, 10.16s/it, lr=1e-5, step_loss=0.0135][RANK-0]: Step: [13157], local_loss=0.04063837230205536, train_loss=0.03617580235004425, time_cost=1.5251717567443848
Steps:   1%|▏         | 13157/1000000 [24:27<2784:23:08, 10.16s/it, lr=1e-5, step_loss=0.0406]Steps:   1%|▏         | 13158/1000000 [24:38<2814:49:47, 10.27s/it, lr=1e-5, step_loss=0.0406][RANK-0]: Step: [13158], local_loss=0.012009682133793831, train_loss=0.043030496686697006, time_cost=5.737839937210083
Steps:   1%|▏         | 13158/1000000 [24:38<2814:49:47, 10.27s/it, lr=1e-5, step_loss=0.012] Steps:   1%|▏         | 13159/1000000 [24:49<2870:52:16, 10.47s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [13159], local_loss=0.179998517036438, train_loss=0.08336964249610901, time_cost=3.203026294708252
Steps:   1%|▏         | 13159/1000000 [24:49<2870:52:16, 10.47s/it, lr=1e-5, step_loss=0.18] Steps:   1%|▏         | 13160/1000000 [24:56<2627:37:19,  9.59s/it, lr=1e-5, step_loss=0.18][RANK-0]: Step: [13160], local_loss=0.027663052082061768, train_loss=0.03352579474449158, time_cost=3.0615298748016357
Steps:   1%|▏         | 13160/1000000 [24:56<2627:37:19,  9.59s/it, lr=1e-5, step_loss=0.0277]Steps:   1%|▏         | 13161/1000000 [25:04<2470:00:05,  9.01s/it, lr=1e-5, step_loss=0.0277][RANK-0]: Step: [13161], local_loss=0.5575603246688843, train_loss=0.14774489402770996, time_cost=3.438587188720703
Steps:   1%|▏         | 13161/1000000 [25:04<2470:00:05,  9.01s/it, lr=1e-5, step_loss=0.558] Steps:   1%|▏         | 13162/1000000 [25:20<3026:56:34, 11.04s/it, lr=1e-5, step_loss=0.558][RANK-0]: Step: [13162], local_loss=0.05174930766224861, train_loss=0.04845255985856056, time_cost=13.240673065185547
Steps:   1%|▏         | 13162/1000000 [25:20<3026:56:34, 11.04s/it, lr=1e-5, step_loss=0.0517]Steps:   1%|▏         | 13163/1000000 [25:27<2703:45:33,  9.86s/it, lr=1e-5, step_loss=0.0517][RANK-0]: Step: [13163], local_loss=0.06260128319263458, train_loss=0.027198350057005882, time_cost=1.2182166576385498
Steps:   1%|▏         | 13163/1000000 [25:27<2703:45:33,  9.86s/it, lr=1e-5, step_loss=0.0626]Steps:   1%|▏         | 13164/1000000 [25:40<2934:38:28, 10.71s/it, lr=1e-5, step_loss=0.0626][RANK-0]: Step: [13164], local_loss=0.014770268462598324, train_loss=0.026304520666599274, time_cost=2.7253105640411377
Steps:   1%|▏         | 13164/1000000 [25:40<2934:38:28, 10.71s/it, lr=1e-5, step_loss=0.0148]Steps:   1%|▏         | 13165/1000000 [25:45<2524:15:55,  9.21s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [13165], local_loss=0.016317496076226234, train_loss=0.058757103979587555, time_cost=1.7391879558563232
Steps:   1%|▏         | 13165/1000000 [25:45<2524:15:55,  9.21s/it, lr=1e-5, step_loss=0.0163]Steps:   1%|▏         | 13166/1000000 [25:51<2208:04:33,  8.06s/it, lr=1e-5, step_loss=0.0163][RANK-0]: Step: [13166], local_loss=0.35062646865844727, train_loss=0.16899043321609497, time_cost=2.8104989528656006
Steps:   1%|▏         | 13166/1000000 [25:51<2208:04:33,  8.06s/it, lr=1e-5, step_loss=0.351] Steps:   1%|▏         | 13167/1000000 [26:00<2301:10:50,  8.39s/it, lr=1e-5, step_loss=0.351][RANK-0]: Step: [13167], local_loss=0.07780645787715912, train_loss=0.16930219531059265, time_cost=3.933316469192505
Steps:   1%|▏         | 13167/1000000 [26:00<2301:10:50,  8.39s/it, lr=1e-5, step_loss=0.0778]Steps:   1%|▏         | 13168/1000000 [26:05<2028:26:01,  7.40s/it, lr=1e-5, step_loss=0.0778][RANK-0]: Step: [13168], local_loss=0.02413816563785076, train_loss=0.16572228074073792, time_cost=1.8234851360321045
Steps:   1%|▏         | 13168/1000000 [26:05<2028:26:01,  7.40s/it, lr=1e-5, step_loss=0.0241]Steps:   1%|▏         | 13169/1000000 [26:12<2007:13:50,  7.32s/it, lr=1e-5, step_loss=0.0241][RANK-0]: Step: [13169], local_loss=0.04536370187997818, train_loss=0.0483078807592392, time_cost=2.708235502243042
Steps:   1%|▏         | 13169/1000000 [26:12<2007:13:50,  7.32s/it, lr=1e-5, step_loss=0.0454]Steps:   1%|▏         | 13170/1000000 [26:18<1859:03:22,  6.78s/it, lr=1e-5, step_loss=0.0454][RANK-0]: Step: [13170], local_loss=0.014442075043916702, train_loss=0.07222521305084229, time_cost=2.138774871826172
Steps:   1%|▏         | 13170/1000000 [26:18<1859:03:22,  6.78s/it, lr=1e-5, step_loss=0.0144]Steps:   1%|▏         | 13171/1000000 [26:23<1701:06:26,  6.21s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [13171], local_loss=0.035142526030540466, train_loss=0.05523782595992088, time_cost=1.9399337768554688
Steps:   1%|▏         | 13171/1000000 [26:23<1701:06:26,  6.21s/it, lr=1e-5, step_loss=0.0351]Steps:   1%|▏         | 13172/1000000 [26:27<1589:05:48,  5.80s/it, lr=1e-5, step_loss=0.0351][RANK-0]: Step: [13172], local_loss=0.08355949819087982, train_loss=0.08822311460971832, time_cost=1.6423592567443848
Steps:   1%|▏         | 13172/1000000 [26:27<1589:05:48,  5.80s/it, lr=1e-5, step_loss=0.0836]Steps:   1%|▏         | 13173/1000000 [26:32<1506:48:00,  5.50s/it, lr=1e-5, step_loss=0.0836][RANK-0]: Step: [13173], local_loss=0.026214230805635452, train_loss=0.026717063039541245, time_cost=1.773697853088379
Steps:   1%|▏         | 13173/1000000 [26:32<1506:48:00,  5.50s/it, lr=1e-5, step_loss=0.0262]Steps:   1%|▏         | 13174/1000000 [26:39<1626:00:43,  5.93s/it, lr=1e-5, step_loss=0.0262][RANK-0]: Step: [13174], local_loss=0.026615776121616364, train_loss=0.07085120677947998, time_cost=2.4955170154571533
Steps:   1%|▏         | 13174/1000000 [26:39<1626:00:43,  5.93s/it, lr=1e-5, step_loss=0.0266]Steps:   1%|▏         | 13175/1000000 [26:44<1547:05:13,  5.64s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [13175], local_loss=0.023811236023902893, train_loss=0.06780962646007538, time_cost=2.4630703926086426
Steps:   1%|▏         | 13175/1000000 [26:44<1547:05:13,  5.64s/it, lr=1e-5, step_loss=0.0238]Steps:   1%|▏         | 13176/1000000 [26:51<1664:45:33,  6.07s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [13176], local_loss=0.5746315717697144, train_loss=0.09480898827314377, time_cost=2.755544900894165
Steps:   1%|▏         | 13176/1000000 [26:51<1664:45:33,  6.07s/it, lr=1e-5, step_loss=0.575] Steps:   1%|▏         | 13177/1000000 [27:01<1978:20:14,  7.22s/it, lr=1e-5, step_loss=0.575][RANK-0]: Step: [13177], local_loss=0.02878577448427677, train_loss=0.06572560220956802, time_cost=3.0436317920684814
Steps:   1%|▏         | 13177/1000000 [27:01<1978:20:14,  7.22s/it, lr=1e-5, step_loss=0.0288]Steps:   1%|▏         | 13178/1000000 [27:12<2257:04:37,  8.23s/it, lr=1e-5, step_loss=0.0288][RANK-0]: Step: [13178], local_loss=0.0211885217577219, train_loss=0.047985292971134186, time_cost=4.271620273590088
Steps:   1%|▏         | 13178/1000000 [27:12<2257:04:37,  8.23s/it, lr=1e-5, step_loss=0.0212]Steps:   1%|▏         | 13179/1000000 [27:27<2798:47:29, 10.21s/it, lr=1e-5, step_loss=0.0212][RANK-0]: Step: [13179], local_loss=0.0381661057472229, train_loss=0.04049187898635864, time_cost=5.897655963897705
Steps:   1%|▏         | 13179/1000000 [27:27<2798:47:29, 10.21s/it, lr=1e-5, step_loss=0.0382]Steps:   1%|▏         | 13180/1000000 [27:39<2997:11:42, 10.93s/it, lr=1e-5, step_loss=0.0382][RANK-0]: Step: [13180], local_loss=0.012414146214723587, train_loss=0.04437246546149254, time_cost=3.7502779960632324
Steps:   1%|▏         | 13180/1000000 [27:39<2997:11:42, 10.93s/it, lr=1e-5, step_loss=0.0124]Steps:   1%|▏         | 13181/1000000 [27:52<3138:59:12, 11.45s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [13181], local_loss=0.014756560325622559, train_loss=0.07469622045755386, time_cost=3.6149184703826904
Steps:   1%|▏         | 13181/1000000 [27:52<3138:59:12, 11.45s/it, lr=1e-5, step_loss=0.0148]Steps:   1%|▏         | 13182/1000000 [28:00<2832:59:30, 10.34s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [13182], local_loss=0.0814359039068222, train_loss=0.05149794742465019, time_cost=2.059143543243408
Steps:   1%|▏         | 13182/1000000 [28:00<2832:59:30, 10.34s/it, lr=1e-5, step_loss=0.0814]Steps:   1%|▏         | 13183/1000000 [28:09<2778:27:12, 10.14s/it, lr=1e-5, step_loss=0.0814][RANK-0]: Step: [13183], local_loss=0.028783895075321198, train_loss=0.03758067637681961, time_cost=1.236525535583496
Steps:   1%|▏         | 13183/1000000 [28:09<2778:27:12, 10.14s/it, lr=1e-5, step_loss=0.0288]Steps:   1%|▏         | 13184/1000000 [28:18<2654:25:37,  9.68s/it, lr=1e-5, step_loss=0.0288][RANK-0]: Step: [13184], local_loss=0.08533217012882233, train_loss=0.10311339795589447, time_cost=2.45756459236145
Steps:   1%|▏         | 13184/1000000 [28:18<2654:25:37,  9.68s/it, lr=1e-5, step_loss=0.0853]Steps:   1%|▏         | 13185/1000000 [28:29<2768:16:40, 10.10s/it, lr=1e-5, step_loss=0.0853][RANK-0]: Step: [13185], local_loss=0.014653196558356285, train_loss=0.027267461642622948, time_cost=1.57425856590271
Steps:   1%|▏         | 13185/1000000 [28:29<2768:16:40, 10.10s/it, lr=1e-5, step_loss=0.0147]Steps:   1%|▏         | 13186/1000000 [28:38<2666:02:15,  9.73s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [13186], local_loss=0.06270230561494827, train_loss=0.044516000896692276, time_cost=4.802984237670898
Steps:   1%|▏         | 13186/1000000 [28:38<2666:02:15,  9.73s/it, lr=1e-5, step_loss=0.0627]Steps:   1%|▏         | 13187/1000000 [28:43<2297:19:47,  8.38s/it, lr=1e-5, step_loss=0.0627][RANK-0]: Step: [13187], local_loss=0.05779623985290527, train_loss=0.035368531942367554, time_cost=2.5114808082580566
Steps:   1%|▏         | 13187/1000000 [28:43<2297:19:47,  8.38s/it, lr=1e-5, step_loss=0.0578]Steps:   1%|▏         | 13188/1000000 [28:48<2054:48:49,  7.50s/it, lr=1e-5, step_loss=0.0578][RANK-0]: Step: [13188], local_loss=0.018115097656846046, train_loss=0.05278296768665314, time_cost=3.312152624130249
Steps:   1%|▏         | 13188/1000000 [28:48<2054:48:49,  7.50s/it, lr=1e-5, step_loss=0.0181]Steps:   1%|▏         | 13189/1000000 [28:58<2184:23:41,  7.97s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [13189], local_loss=0.020780378952622414, train_loss=0.17965993285179138, time_cost=1.3796124458312988
Steps:   1%|▏         | 13189/1000000 [28:58<2184:23:41,  7.97s/it, lr=1e-5, step_loss=0.0208]Steps:   1%|▏         | 13190/1000000 [29:03<2008:27:26,  7.33s/it, lr=1e-5, step_loss=0.0208][RANK-0]: Step: [13190], local_loss=0.04102002829313278, train_loss=0.04811627417802811, time_cost=1.4678480625152588
Steps:   1%|▏         | 13190/1000000 [29:03<2008:27:26,  7.33s/it, lr=1e-5, step_loss=0.041] Steps:   1%|▏         | 13191/1000000 [29:08<1780:37:29,  6.50s/it, lr=1e-5, step_loss=0.041][RANK-0]: Step: [13191], local_loss=1.0074646472930908, train_loss=0.16876699030399323, time_cost=1.5589632987976074
Steps:   1%|▏         | 13191/1000000 [29:08<1780:37:29,  6.50s/it, lr=1e-5, step_loss=1.01] Steps:   1%|▏         | 13192/1000000 [29:15<1817:17:53,  6.63s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [13192], local_loss=0.01777707040309906, train_loss=0.042525339871644974, time_cost=2.560573101043701
Steps:   1%|▏         | 13192/1000000 [29:15<1817:17:53,  6.63s/it, lr=1e-5, step_loss=0.0178]Steps:   1%|▏         | 13193/1000000 [29:24<1983:30:09,  7.24s/it, lr=1e-5, step_loss=0.0178][RANK-0]: Step: [13193], local_loss=0.1714099645614624, train_loss=0.07798004150390625, time_cost=3.142624616622925
Steps:   1%|▏         | 13193/1000000 [29:24<1983:30:09,  7.24s/it, lr=1e-5, step_loss=0.171] Steps:   1%|▏         | 13194/1000000 [29:32<2066:18:53,  7.54s/it, lr=1e-5, step_loss=0.171][RANK-0]: Step: [13194], local_loss=0.06351673603057861, train_loss=0.18569988012313843, time_cost=3.3390960693359375
Steps:   1%|▏         | 13194/1000000 [29:32<2066:18:53,  7.54s/it, lr=1e-5, step_loss=0.0635]Steps:   1%|▏         | 13195/1000000 [29:41<2226:03:20,  8.12s/it, lr=1e-5, step_loss=0.0635][RANK-0]: Step: [13195], local_loss=0.04240182787179947, train_loss=0.04030241817235947, time_cost=1.2375669479370117
Steps:   1%|▏         | 13195/1000000 [29:41<2226:03:20,  8.12s/it, lr=1e-5, step_loss=0.0424]Steps:   1%|▏         | 13196/1000000 [29:56<2743:48:53, 10.01s/it, lr=1e-5, step_loss=0.0424][RANK-0]: Step: [13196], local_loss=0.22454792261123657, train_loss=0.0648391842842102, time_cost=5.882969617843628
Steps:   1%|▏         | 13196/1000000 [29:56<2743:48:53, 10.01s/it, lr=1e-5, step_loss=0.225] Steps:   1%|▏         | 13197/1000000 [30:06<2769:33:11, 10.10s/it, lr=1e-5, step_loss=0.225][RANK-0]: Step: [13197], local_loss=0.0547226220369339, train_loss=0.044726498425006866, time_cost=4.697136878967285
Steps:   1%|▏         | 13197/1000000 [30:06<2769:33:11, 10.10s/it, lr=1e-5, step_loss=0.0547]Steps:   1%|▏         | 13198/1000000 [30:14<2607:03:40,  9.51s/it, lr=1e-5, step_loss=0.0547][RANK-0]: Step: [13198], local_loss=0.08305056393146515, train_loss=0.15255725383758545, time_cost=3.922651767730713
Steps:   1%|▏         | 13198/1000000 [30:14<2607:03:40,  9.51s/it, lr=1e-5, step_loss=0.0831]Steps:   1%|▏         | 13199/1000000 [30:20<2293:30:29,  8.37s/it, lr=1e-5, step_loss=0.0831][RANK-0]: Step: [13199], local_loss=0.06236198544502258, train_loss=0.03913804143667221, time_cost=2.3457438945770264
Steps:   1%|▏         | 13199/1000000 [30:20<2293:30:29,  8.37s/it, lr=1e-5, step_loss=0.0624]Steps:   1%|▏         | 13200/1000000 [30:26<2136:56:04,  7.80s/it, lr=1e-5, step_loss=0.0624][RANK-0]: Step: [13200], local_loss=0.0108203599229455, train_loss=0.08954431116580963, time_cost=2.2190535068511963
Steps:   1%|▏         | 13200/1000000 [30:26<2136:56:04,  7.80s/it, lr=1e-5, step_loss=0.0108]Steps:   1%|▏         | 13201/1000000 [30:39<2506:38:49,  9.14s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [13201], local_loss=0.33779412508010864, train_loss=0.07983358949422836, time_cost=3.076204538345337
Steps:   1%|▏         | 13201/1000000 [30:39<2506:38:49,  9.14s/it, lr=1e-5, step_loss=0.338] Steps:   1%|▏         | 13202/1000000 [30:51<2819:41:43, 10.29s/it, lr=1e-5, step_loss=0.338][RANK-0]: Step: [13202], local_loss=0.025400204584002495, train_loss=0.02904755435883999, time_cost=11.22696042060852
Steps:   1%|▏         | 13202/1000000 [30:51<2819:41:43, 10.29s/it, lr=1e-5, step_loss=0.0254]Steps:   1%|▏         | 13203/1000000 [31:06<3170:09:05, 11.57s/it, lr=1e-5, step_loss=0.0254][RANK-0]: Step: [13203], local_loss=0.021866198629140854, train_loss=0.034987498074769974, time_cost=5.48032808303833
Steps:   1%|▏         | 13203/1000000 [31:06<3170:09:05, 11.57s/it, lr=1e-5, step_loss=0.0219]Steps:   1%|▏         | 13204/1000000 [31:19<3288:50:51, 12.00s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [13204], local_loss=0.051197804510593414, train_loss=0.1069478690624237, time_cost=1.2041220664978027
Steps:   1%|▏         | 13204/1000000 [31:19<3288:50:51, 12.00s/it, lr=1e-5, step_loss=0.0512]Steps:   1%|▏         | 13205/1000000 [31:26<2899:42:57, 10.58s/it, lr=1e-5, step_loss=0.0512][RANK-0]: Step: [13205], local_loss=0.025320161134004593, train_loss=0.05392134189605713, time_cost=1.2643849849700928
Steps:   1%|▏         | 13205/1000000 [31:26<2899:42:57, 10.58s/it, lr=1e-5, step_loss=0.0253]Steps:   1%|▏         | 13206/1000000 [31:32<2515:01:13,  9.18s/it, lr=1e-5, step_loss=0.0253][RANK-0]: Step: [13206], local_loss=0.009441281668841839, train_loss=0.07628699392080307, time_cost=1.5151610374450684
Steps:   1%|▏         | 13206/1000000 [31:32<2515:01:13,  9.18s/it, lr=1e-5, step_loss=0.00944]Steps:   1%|▏         | 13207/1000000 [31:43<2637:57:20,  9.62s/it, lr=1e-5, step_loss=0.00944][RANK-0]: Step: [13207], local_loss=1.0126692056655884, train_loss=0.24244432151317596, time_cost=1.2501001358032227
Steps:   1%|▏         | 13207/1000000 [31:43<2637:57:20,  9.62s/it, lr=1e-5, step_loss=1.01]   Steps:   1%|▏         | 13208/1000000 [31:55<2849:37:52, 10.40s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [13208], local_loss=0.06026504561305046, train_loss=0.029073406010866165, time_cost=5.167768239974976
Steps:   1%|▏         | 13208/1000000 [31:55<2849:37:52, 10.40s/it, lr=1e-5, step_loss=0.0603]Steps:   1%|▏         | 13209/1000000 [32:00<2415:49:40,  8.81s/it, lr=1e-5, step_loss=0.0603][RANK-0]: Step: [13209], local_loss=0.029952233657240868, train_loss=0.04244694113731384, time_cost=1.2265324592590332
Steps:   1%|▏         | 13209/1000000 [32:00<2415:49:40,  8.81s/it, lr=1e-5, step_loss=0.03]  Steps:   1%|▏         | 13210/1000000 [32:17<3033:55:27, 11.07s/it, lr=1e-5, step_loss=0.03][RANK-0]: Step: [13210], local_loss=0.10210392624139786, train_loss=0.17225544154644012, time_cost=7.482334136962891
Steps:   1%|▏         | 13210/1000000 [32:17<3033:55:27, 11.07s/it, lr=1e-5, step_loss=0.102]Steps:   1%|▏         | 13211/1000000 [32:27<3019:23:11, 11.02s/it, lr=1e-5, step_loss=0.102][RANK-0]: Step: [13211], local_loss=0.11307652294635773, train_loss=0.041888732463121414, time_cost=3.252293109893799
Steps:   1%|▏         | 13211/1000000 [32:27<3019:23:11, 11.02s/it, lr=1e-5, step_loss=0.113]Steps:   1%|▏         | 13212/1000000 [32:38<3007:55:34, 10.97s/it, lr=1e-5, step_loss=0.113][RANK-0]: Step: [13212], local_loss=0.03579035401344299, train_loss=0.05269023776054382, time_cost=4.050771951675415
Steps:   1%|▏         | 13212/1000000 [32:38<3007:55:34, 10.97s/it, lr=1e-5, step_loss=0.0358]Steps:   1%|▏         | 13213/1000000 [32:50<3032:25:21, 11.06s/it, lr=1e-5, step_loss=0.0358][RANK-0]: Step: [13213], local_loss=0.0388774573802948, train_loss=0.039823777973651886, time_cost=1.2368927001953125
Steps:   1%|▏         | 13213/1000000 [32:50<3032:25:21, 11.06s/it, lr=1e-5, step_loss=0.0389]Steps:   1%|▏         | 13214/1000000 [32:55<2603:38:50,  9.50s/it, lr=1e-5, step_loss=0.0389][RANK-0]: Step: [13214], local_loss=0.022237857803702354, train_loss=0.042536478489637375, time_cost=1.5613021850585938
Steps:   1%|▏         | 13214/1000000 [32:55<2603:38:50,  9.50s/it, lr=1e-5, step_loss=0.0222]Steps:   1%|▏         | 13215/1000000 [33:06<2718:30:11,  9.92s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [13215], local_loss=0.052725207060575485, train_loss=0.11891829967498779, time_cost=3.307107925415039
Steps:   1%|▏         | 13215/1000000 [33:06<2718:30:11,  9.92s/it, lr=1e-5, step_loss=0.0527]Steps:   1%|▏         | 13216/1000000 [33:11<2269:12:03,  8.28s/it, lr=1e-5, step_loss=0.0527][RANK-0]: Step: [13216], local_loss=0.18011213839054108, train_loss=0.050204865634441376, time_cost=1.946136236190796
Steps:   1%|▏         | 13216/1000000 [33:11<2269:12:03,  8.28s/it, lr=1e-5, step_loss=0.18]  Steps:   1%|▏         | 13217/1000000 [33:18<2199:34:40,  8.02s/it, lr=1e-5, step_loss=0.18][RANK-0]: Step: [13217], local_loss=0.01586761884391308, train_loss=0.07587067782878876, time_cost=1.5612397193908691
Steps:   1%|▏         | 13217/1000000 [33:18<2199:34:40,  8.02s/it, lr=1e-5, step_loss=0.0159]Steps:   1%|▏         | 13218/1000000 [33:29<2412:17:54,  8.80s/it, lr=1e-5, step_loss=0.0159][RANK-0]: Step: [13218], local_loss=0.026785828173160553, train_loss=0.021971937268972397, time_cost=4.026827573776245
Steps:   1%|▏         | 13218/1000000 [33:29<2412:17:54,  8.80s/it, lr=1e-5, step_loss=0.0268]Steps:   1%|▏         | 13219/1000000 [33:42<2789:59:37, 10.18s/it, lr=1e-5, step_loss=0.0268][RANK-0]: Step: [13219], local_loss=0.023232780396938324, train_loss=0.027279717847704887, time_cost=4.56596565246582
Steps:   1%|▏         | 13219/1000000 [33:42<2789:59:37, 10.18s/it, lr=1e-5, step_loss=0.0232]Steps:   1%|▏         | 13220/1000000 [33:54<2886:19:23, 10.53s/it, lr=1e-5, step_loss=0.0232][RANK-0]: Step: [13220], local_loss=0.08396926522254944, train_loss=0.041984569281339645, time_cost=1.9785830974578857
Steps:   1%|▏         | 13220/1000000 [33:54<2886:19:23, 10.53s/it, lr=1e-5, step_loss=0.084] Steps:   1%|▏         | 13221/1000000 [34:02<2749:30:50, 10.03s/it, lr=1e-5, step_loss=0.084][RANK-0]: Step: [13221], local_loss=0.01659863442182541, train_loss=0.2789533734321594, time_cost=3.7492728233337402
Steps:   1%|▏         | 13221/1000000 [34:02<2749:30:50, 10.03s/it, lr=1e-5, step_loss=0.0166]Steps:   1%|▏         | 13222/1000000 [34:13<2805:32:45, 10.24s/it, lr=1e-5, step_loss=0.0166][RANK-0]: Step: [13222], local_loss=0.06205308809876442, train_loss=0.044160500168800354, time_cost=5.844446182250977
Steps:   1%|▏         | 13222/1000000 [34:13<2805:32:45, 10.24s/it, lr=1e-5, step_loss=0.0621]Steps:   1%|▏         | 13223/1000000 [34:19<2442:25:29,  8.91s/it, lr=1e-5, step_loss=0.0621][RANK-0]: Step: [13223], local_loss=0.022355198860168457, train_loss=0.1225549578666687, time_cost=3.1095025539398193
Steps:   1%|▏         | 13223/1000000 [34:19<2442:25:29,  8.91s/it, lr=1e-5, step_loss=0.0224]Steps:   1%|▏         | 13224/1000000 [34:35<2994:42:48, 10.93s/it, lr=1e-5, step_loss=0.0224][RANK-0]: Step: [13224], local_loss=0.03297046571969986, train_loss=12.8208646774292, time_cost=8.014299869537354
Steps:   1%|▏         | 13224/1000000 [34:35<2994:42:48, 10.93s/it, lr=1e-5, step_loss=0.033] Steps:   1%|▏         | 13225/1000000 [34:41<2643:27:16,  9.64s/it, lr=1e-5, step_loss=0.033][RANK-0]: Step: [13225], local_loss=0.039107177406549454, train_loss=0.030412090942263603, time_cost=2.2182440757751465
Steps:   1%|▏         | 13225/1000000 [34:41<2643:27:16,  9.64s/it, lr=1e-5, step_loss=0.0391]Steps:   1%|▏         | 13226/1000000 [34:46<2208:29:29,  8.06s/it, lr=1e-5, step_loss=0.0391][RANK-0]: Step: [13226], local_loss=0.02415456436574459, train_loss=0.10672350972890854, time_cost=1.3024578094482422
Steps:   1%|▏         | 13226/1000000 [34:46<2208:29:29,  8.06s/it, lr=1e-5, step_loss=0.0242]Steps:   1%|▏         | 13227/1000000 [34:56<2374:15:23,  8.66s/it, lr=1e-5, step_loss=0.0242][RANK-0]: Step: [13227], local_loss=0.04886593297123909, train_loss=0.04102000966668129, time_cost=5.149754762649536
Steps:   1%|▏         | 13227/1000000 [34:56<2374:15:23,  8.66s/it, lr=1e-5, step_loss=0.0489]/home/image_data/hxy/Open-Sora-Plan/opensora/utils/utils.py:369: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.
  caption = BeautifulSoup(caption, features='html.parser').text
Steps:   1%|▏         | 13228/1000000 [35:10<2879:07:04, 10.50s/it, lr=1e-5, step_loss=0.0489][RANK-0]: Step: [13228], local_loss=0.029158135876059532, train_loss=0.043564170598983765, time_cost=7.219979763031006
Steps:   1%|▏         | 13228/1000000 [35:10<2879:07:04, 10.50s/it, lr=1e-5, step_loss=0.0292]Steps:   1%|▏         | 13229/1000000 [35:24<3094:31:09, 11.29s/it, lr=1e-5, step_loss=0.0292][RANK-0]: Step: [13229], local_loss=0.012530694715678692, train_loss=0.07269572466611862, time_cost=1.20662260055542
Steps:   1%|▏         | 13229/1000000 [35:24<3094:31:09, 11.29s/it, lr=1e-5, step_loss=0.0125]Steps:   1%|▏         | 13230/1000000 [35:30<2655:25:37,  9.69s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [13230], local_loss=0.09910750389099121, train_loss=0.035583704710006714, time_cost=1.6438374519348145
Steps:   1%|▏         | 13230/1000000 [35:30<2655:25:37,  9.69s/it, lr=1e-5, step_loss=0.0991]Steps:   1%|▏         | 13231/1000000 [35:37<2490:51:41,  9.09s/it, lr=1e-5, step_loss=0.0991][RANK-0]: Step: [13231], local_loss=0.028180783614516258, train_loss=0.05604290962219238, time_cost=1.2158377170562744
Steps:   1%|▏         | 13231/1000000 [35:37<2490:51:41,  9.09s/it, lr=1e-5, step_loss=0.0282]Steps:   1%|▏         | 13232/1000000 [35:51<2837:25:13, 10.35s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [13232], local_loss=0.12223666906356812, train_loss=0.031778931617736816, time_cost=4.323913812637329
Steps:   1%|▏         | 13232/1000000 [35:51<2837:25:13, 10.35s/it, lr=1e-5, step_loss=0.122] Steps:   1%|▏         | 13233/1000000 [36:03<3036:24:55, 11.08s/it, lr=1e-5, step_loss=0.122][RANK-0]: Step: [13233], local_loss=0.04655452072620392, train_loss=0.060358963906764984, time_cost=3.3398211002349854
Steps:   1%|▏         | 13233/1000000 [36:03<3036:24:55, 11.08s/it, lr=1e-5, step_loss=0.0466]Steps:   1%|▏         | 13234/1000000 [36:10<2657:03:51,  9.69s/it, lr=1e-5, step_loss=0.0466][RANK-0]: Step: [13234], local_loss=0.1595897376537323, train_loss=0.0779021829366684, time_cost=4.944026470184326
Steps:   1%|▏         | 13234/1000000 [36:10<2657:03:51,  9.69s/it, lr=1e-5, step_loss=0.16]  Steps:   1%|▏         | 13235/1000000 [36:21<2811:58:28, 10.26s/it, lr=1e-5, step_loss=0.16][RANK-0]: Step: [13235], local_loss=0.07774230092763901, train_loss=0.08970507979393005, time_cost=3.870039939880371
Steps:   1%|▏         | 13235/1000000 [36:21<2811:58:28, 10.26s/it, lr=1e-5, step_loss=0.0777]Steps:   1%|▏         | 13236/1000000 [36:28<2475:28:05,  9.03s/it, lr=1e-5, step_loss=0.0777][RANK-0]: Step: [13236], local_loss=0.04048386588692665, train_loss=0.029368672519922256, time_cost=1.55411958694458
Steps:   1%|▏         | 13236/1000000 [36:28<2475:28:05,  9.03s/it, lr=1e-5, step_loss=0.0405]Steps:   1%|▏         | 13237/1000000 [36:34<2295:26:05,  8.37s/it, lr=1e-5, step_loss=0.0405][RANK-0]: Step: [13237], local_loss=0.06867463886737823, train_loss=0.07370585203170776, time_cost=1.916755199432373
Steps:   1%|▏         | 13237/1000000 [36:34<2295:26:05,  8.37s/it, lr=1e-5, step_loss=0.0687]Steps:   1%|▏         | 13238/1000000 [36:42<2198:22:42,  8.02s/it, lr=1e-5, step_loss=0.0687][RANK-0]: Step: [13238], local_loss=0.03526769578456879, train_loss=0.14609640836715698, time_cost=2.5113868713378906
Steps:   1%|▏         | 13238/1000000 [36:42<2198:22:42,  8.02s/it, lr=1e-5, step_loss=0.0353]Steps:   1%|▏         | 13239/1000000 [36:53<2501:01:45,  9.12s/it, lr=1e-5, step_loss=0.0353][RANK-0]: Step: [13239], local_loss=0.039242666214704514, train_loss=0.03837670385837555, time_cost=1.303511619567871
Steps:   1%|▏         | 13239/1000000 [36:53<2501:01:45,  9.12s/it, lr=1e-5, step_loss=0.0392]Steps:   1%|▏         | 13240/1000000 [36:58<2178:24:53,  7.95s/it, lr=1e-5, step_loss=0.0392][RANK-0]: Step: [13240], local_loss=0.023738034069538116, train_loss=0.030270591378211975, time_cost=2.472184181213379
Steps:   1%|▏         | 13240/1000000 [36:58<2178:24:53,  7.95s/it, lr=1e-5, step_loss=0.0237]Steps:   1%|▏         | 13241/1000000 [37:04<2020:50:16,  7.37s/it, lr=1e-5, step_loss=0.0237][RANK-0]: Step: [13241], local_loss=0.02118365466594696, train_loss=0.049884915351867676, time_cost=1.3674225807189941
Steps:   1%|▏         | 13241/1000000 [37:04<2020:50:16,  7.37s/it, lr=1e-5, step_loss=0.0212]Steps:   1%|▏         | 13242/1000000 [37:10<1895:41:00,  6.92s/it, lr=1e-5, step_loss=0.0212][RANK-0]: Step: [13242], local_loss=0.01706778258085251, train_loss=0.0384918674826622, time_cost=1.4158086776733398
Steps:   1%|▏         | 13242/1000000 [37:10<1895:41:00,  6.92s/it, lr=1e-5, step_loss=0.0171]Steps:   1%|▏         | 13243/1000000 [37:24<2437:49:15,  8.89s/it, lr=1e-5, step_loss=0.0171][RANK-0]: Step: [13243], local_loss=0.035617999732494354, train_loss=0.0522271990776062, time_cost=1.402034044265747
Steps:   1%|▏         | 13243/1000000 [37:24<2437:49:15,  8.89s/it, lr=1e-5, step_loss=0.0356]Steps:   1%|▏         | 13244/1000000 [37:35<2654:30:52,  9.68s/it, lr=1e-5, step_loss=0.0356][RANK-0]: Step: [13244], local_loss=0.03445132449269295, train_loss=0.06343646347522736, time_cost=1.4917008876800537
Steps:   1%|▏         | 13244/1000000 [37:35<2654:30:52,  9.68s/it, lr=1e-5, step_loss=0.0345]Steps:   1%|▏         | 13245/1000000 [37:45<2615:52:52,  9.54s/it, lr=1e-5, step_loss=0.0345][RANK-0]: Step: [13245], local_loss=0.017564380541443825, train_loss=0.026506688445806503, time_cost=2.272190809249878
Steps:   1%|▏         | 13245/1000000 [37:45<2615:52:52,  9.54s/it, lr=1e-5, step_loss=0.0176]Steps:   1%|▏         | 13246/1000000 [37:56<2755:10:59, 10.05s/it, lr=1e-5, step_loss=0.0176][RANK-0]: Step: [13246], local_loss=0.056560490280389786, train_loss=0.09615917503833771, time_cost=1.2406349182128906
Steps:   1%|▏         | 13246/1000000 [37:56<2755:10:59, 10.05s/it, lr=1e-5, step_loss=0.0566]Steps:   1%|▏         | 13247/1000000 [38:05<2685:47:57,  9.80s/it, lr=1e-5, step_loss=0.0566][RANK-0]: Step: [13247], local_loss=0.018830012530088425, train_loss=0.08555755019187927, time_cost=3.3143081665039062
Steps:   1%|▏         | 13247/1000000 [38:05<2685:47:57,  9.80s/it, lr=1e-5, step_loss=0.0188]Steps:   1%|▏         | 13248/1000000 [38:14<2641:11:12,  9.64s/it, lr=1e-5, step_loss=0.0188][RANK-0]: Step: [13248], local_loss=0.05266211926937103, train_loss=0.06670302152633667, time_cost=1.2920453548431396
Steps:   1%|▏         | 13248/1000000 [38:14<2641:11:12,  9.64s/it, lr=1e-5, step_loss=0.0527]Steps:   1%|▏         | 13249/1000000 [38:19<2232:59:51,  8.15s/it, lr=1e-5, step_loss=0.0527][RANK-0]: Step: [13249], local_loss=0.09989000111818314, train_loss=0.0841955840587616, time_cost=1.7803802490234375
Steps:   1%|▏         | 13249/1000000 [38:19<2232:59:51,  8.15s/it, lr=1e-5, step_loss=0.0999]Steps:   1%|▏         | 13250/1000000 [38:27<2228:44:24,  8.13s/it, lr=1e-5, step_loss=0.0999][RANK-0]: Step: [13250], local_loss=0.03720015287399292, train_loss=0.053516972810029984, time_cost=6.744050741195679
Steps:   1%|▏         | 13250/1000000 [38:27<2228:44:24,  8.13s/it, lr=1e-5, step_loss=0.0372]Steps:   1%|▏         | 13251/1000000 [38:32<1976:44:16,  7.21s/it, lr=1e-5, step_loss=0.0372][RANK-0]: Step: [13251], local_loss=0.07961182296276093, train_loss=0.053351230919361115, time_cost=2.384568452835083
Steps:   1%|▏         | 13251/1000000 [38:32<1976:44:16,  7.21s/it, lr=1e-5, step_loss=0.0796]Steps:   1%|▏         | 13252/1000000 [38:43<2252:12:12,  8.22s/it, lr=1e-5, step_loss=0.0796][RANK-0]: Step: [13252], local_loss=0.015796620398759842, train_loss=0.17418231070041656, time_cost=2.382411241531372
Steps:   1%|▏         | 13252/1000000 [38:43<2252:12:12,  8.22s/it, lr=1e-5, step_loss=0.0158]Steps:   1%|▏         | 13253/1000000 [38:52<2305:01:30,  8.41s/it, lr=1e-5, step_loss=0.0158][RANK-0]: Step: [13253], local_loss=0.07458055764436722, train_loss=0.07889203727245331, time_cost=1.7724196910858154
Steps:   1%|▏         | 13253/1000000 [38:52<2305:01:30,  8.41s/it, lr=1e-5, step_loss=0.0746]Steps:   1%|▏         | 13254/1000000 [38:56<1962:17:49,  7.16s/it, lr=1e-5, step_loss=0.0746][RANK-0]: Step: [13254], local_loss=0.025701012462377548, train_loss=0.07602238655090332, time_cost=1.8163414001464844
Steps:   1%|▏         | 13254/1000000 [38:56<1962:17:49,  7.16s/it, lr=1e-5, step_loss=0.0257]Steps:   1%|▏         | 13255/1000000 [39:12<2676:49:30,  9.77s/it, lr=1e-5, step_loss=0.0257][RANK-0]: Step: [13255], local_loss=0.027635402977466583, train_loss=0.058616966009140015, time_cost=7.431949615478516
Steps:   1%|▏         | 13255/1000000 [39:12<2676:49:30,  9.77s/it, lr=1e-5, step_loss=0.0276]Steps:   1%|▏         | 13256/1000000 [39:16<2230:01:00,  8.14s/it, lr=1e-5, step_loss=0.0276][RANK-0]: Step: [13256], local_loss=0.020394328981637955, train_loss=0.021112142130732536, time_cost=1.262434959411621
Steps:   1%|▏         | 13256/1000000 [39:16<2230:01:00,  8.14s/it, lr=1e-5, step_loss=0.0204]Steps:   1%|▏         | 13257/1000000 [39:21<1971:11:52,  7.19s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [13257], local_loss=0.012350838631391525, train_loss=0.039548859000205994, time_cost=2.54235577583313
Steps:   1%|▏         | 13257/1000000 [39:21<1971:11:52,  7.19s/it, lr=1e-5, step_loss=0.0124]Steps:   1%|▏         | 13258/1000000 [39:35<2496:27:31,  9.11s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [13258], local_loss=0.020094793289899826, train_loss=0.07480413466691971, time_cost=1.309025526046753
Steps:   1%|▏         | 13258/1000000 [39:35<2496:27:31,  9.11s/it, lr=1e-5, step_loss=0.0201]Steps:   1%|▏         | 13259/1000000 [39:42<2357:06:28,  8.60s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [13259], local_loss=0.02606811374425888, train_loss=0.027547543868422508, time_cost=1.2466356754302979
Steps:   1%|▏         | 13259/1000000 [39:42<2357:06:28,  8.60s/it, lr=1e-5, step_loss=0.0261]Steps:   1%|▏         | 13260/1000000 [39:48<2133:44:29,  7.78s/it, lr=1e-5, step_loss=0.0261][RANK-0]: Step: [13260], local_loss=0.05412370339035988, train_loss=0.08327548950910568, time_cost=1.4100117683410645
Steps:   1%|▏         | 13260/1000000 [39:48<2133:44:29,  7.78s/it, lr=1e-5, step_loss=0.0541]Steps:   1%|▏         | 13261/1000000 [39:55<2074:42:38,  7.57s/it, lr=1e-5, step_loss=0.0541][RANK-0]: Step: [13261], local_loss=0.21133683621883392, train_loss=0.1596008688211441, time_cost=2.9798543453216553
Steps:   1%|▏         | 13261/1000000 [39:55<2074:42:38,  7.57s/it, lr=1e-5, step_loss=0.211] Steps:   1%|▏         | 13262/1000000 [40:09<2640:59:46,  9.64s/it, lr=1e-5, step_loss=0.211][RANK-0]: Step: [13262], local_loss=0.017359454184770584, train_loss=0.03434324264526367, time_cost=6.912027359008789
Steps:   1%|▏         | 13262/1000000 [40:09<2640:59:46,  9.64s/it, lr=1e-5, step_loss=0.0174]Steps:   1%|▏         | 13263/1000000 [40:25<3155:03:49, 11.51s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [13263], local_loss=0.014002986252307892, train_loss=0.027342714369297028, time_cost=7.501801490783691
Steps:   1%|▏         | 13263/1000000 [40:25<3155:03:49, 11.51s/it, lr=1e-5, step_loss=0.014] Steps:   1%|▏         | 13264/1000000 [40:35<3010:08:52, 10.98s/it, lr=1e-5, step_loss=0.014][RANK-0]: Step: [13264], local_loss=0.02626928873360157, train_loss=0.05778592452406883, time_cost=1.9225330352783203
Steps:   1%|▏         | 13264/1000000 [40:35<3010:08:52, 10.98s/it, lr=1e-5, step_loss=0.0263]Steps:   1%|▏         | 13265/1000000 [40:46<2972:30:17, 10.84s/it, lr=1e-5, step_loss=0.0263][RANK-0]: Step: [13265], local_loss=0.025640571489930153, train_loss=0.02667124569416046, time_cost=1.2913858890533447
Steps:   1%|▏         | 13265/1000000 [40:46<2972:30:17, 10.84s/it, lr=1e-5, step_loss=0.0256]Steps:   1%|▏         | 13266/1000000 [40:51<2547:07:13,  9.29s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [13266], local_loss=0.016864506527781487, train_loss=0.11388338357210159, time_cost=3.244433879852295
Steps:   1%|▏         | 13266/1000000 [40:51<2547:07:13,  9.29s/it, lr=1e-5, step_loss=0.0169]Steps:   1%|▏         | 13267/1000000 [40:58<2366:47:19,  8.63s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [13267], local_loss=0.04119095206260681, train_loss=0.046285152435302734, time_cost=1.2298507690429688
Steps:   1%|▏         | 13267/1000000 [40:58<2366:47:19,  8.63s/it, lr=1e-5, step_loss=0.0412]Steps:   1%|▏         | 13268/1000000 [41:12<2767:51:23, 10.10s/it, lr=1e-5, step_loss=0.0412][RANK-0]: Step: [13268], local_loss=0.01919611170887947, train_loss=0.035679690539836884, time_cost=1.2211289405822754
Steps:   1%|▏         | 13268/1000000 [41:12<2767:51:23, 10.10s/it, lr=1e-5, step_loss=0.0192]Steps:   1%|▏         | 13269/1000000 [41:22<2774:59:08, 10.12s/it, lr=1e-5, step_loss=0.0192][RANK-0]: Step: [13269], local_loss=0.011227262206375599, train_loss=0.05267580598592758, time_cost=3.1360268592834473
Steps:   1%|▏         | 13269/1000000 [41:22<2774:59:08, 10.12s/it, lr=1e-5, step_loss=0.0112]Steps:   1%|▏         | 13270/1000000 [41:28<2396:19:30,  8.74s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [13270], local_loss=0.02328656241297722, train_loss=0.04988039284944534, time_cost=2.0436277389526367
Steps:   1%|▏         | 13270/1000000 [41:28<2396:19:30,  8.74s/it, lr=1e-5, step_loss=0.0233]Steps:   1%|▏         | 13271/1000000 [41:45<3111:35:21, 11.35s/it, lr=1e-5, step_loss=0.0233][RANK-0]: Step: [13271], local_loss=0.014960705302655697, train_loss=0.04837513715028763, time_cost=8.12609052658081
Steps:   1%|▏         | 13271/1000000 [41:45<3111:35:21, 11.35s/it, lr=1e-5, step_loss=0.015] Steps:   1%|▏         | 13272/1000000 [41:50<2601:40:01,  9.49s/it, lr=1e-5, step_loss=0.015][RANK-0]: Step: [13272], local_loss=0.01692132279276848, train_loss=0.03109065815806389, time_cost=1.401900291442871
Steps:   1%|▏         | 13272/1000000 [41:50<2601:40:01,  9.49s/it, lr=1e-5, step_loss=0.0169]Steps:   1%|▏         | 13273/1000000 [41:56<2271:15:26,  8.29s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [13273], local_loss=0.017250914126634598, train_loss=0.0342203751206398, time_cost=2.540235757827759
Steps:   1%|▏         | 13273/1000000 [41:56<2271:15:26,  8.29s/it, lr=1e-5, step_loss=0.0173]Steps:   1%|▏         | 13274/1000000 [42:10<2745:50:40, 10.02s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [13274], local_loss=0.017631491646170616, train_loss=0.052391327917575836, time_cost=1.3311412334442139
Steps:   1%|▏         | 13274/1000000 [42:10<2745:50:40, 10.02s/it, lr=1e-5, step_loss=0.0176]Steps:   1%|▏         | 13275/1000000 [42:26<3288:28:20, 12.00s/it, lr=1e-5, step_loss=0.0176][RANK-0]: Step: [13275], local_loss=0.015629563480615616, train_loss=0.18927693367004395, time_cost=8.730788469314575
Steps:   1%|▏         | 13275/1000000 [42:26<3288:28:20, 12.00s/it, lr=1e-5, step_loss=0.0156]Steps:   1%|▏         | 13276/1000000 [42:38<3304:47:01, 12.06s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [13276], local_loss=0.012111738324165344, train_loss=0.07306176424026489, time_cost=2.4006383419036865
Steps:   1%|▏         | 13276/1000000 [42:38<3304:47:01, 12.06s/it, lr=1e-5, step_loss=0.0121]Steps:   1%|▏         | 13277/1000000 [42:44<2797:50:13, 10.21s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [13277], local_loss=0.02809874340891838, train_loss=0.05806947126984596, time_cost=1.7300746440887451
Steps:   1%|▏         | 13277/1000000 [42:44<2797:50:13, 10.21s/it, lr=1e-5, step_loss=0.0281]Steps:   1%|▏         | 13278/1000000 [42:55<2828:11:13, 10.32s/it, lr=1e-5, step_loss=0.0281][RANK-0]: Step: [13278], local_loss=0.10846161097288132, train_loss=0.05084802582859993, time_cost=2.926593065261841
Steps:   1%|▏         | 13278/1000000 [42:55<2828:11:13, 10.32s/it, lr=1e-5, step_loss=0.108] Steps:   1%|▏         | 13279/1000000 [43:00<2395:23:06,  8.74s/it, lr=1e-5, step_loss=0.108][RANK-0]: Step: [13279], local_loss=0.04860755428671837, train_loss=0.08207790553569794, time_cost=1.291182518005371
Steps:   1%|▏         | 13279/1000000 [43:00<2395:23:06,  8.74s/it, lr=1e-5, step_loss=0.0486]Steps:   1%|▏         | 13280/1000000 [43:09<2404:56:30,  8.77s/it, lr=1e-5, step_loss=0.0486][RANK-0]: Step: [13280], local_loss=0.04584875330328941, train_loss=0.04918181896209717, time_cost=1.3648948669433594
Steps:   1%|▏         | 13280/1000000 [43:09<2404:56:30,  8.77s/it, lr=1e-5, step_loss=0.0458]Steps:   1%|▏         | 13281/1000000 [43:14<2125:05:53,  7.75s/it, lr=1e-5, step_loss=0.0458][RANK-0]: Step: [13281], local_loss=0.013278250582516193, train_loss=0.06731817126274109, time_cost=1.6505706310272217
Steps:   1%|▏         | 13281/1000000 [43:14<2125:05:53,  7.75s/it, lr=1e-5, step_loss=0.0133]Steps:   1%|▏         | 13282/1000000 [43:19<1911:32:59,  6.97s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [13282], local_loss=0.03920094668865204, train_loss=0.06761215627193451, time_cost=2.098390579223633
Steps:   1%|▏         | 13282/1000000 [43:19<1911:32:59,  6.97s/it, lr=1e-5, step_loss=0.0392]Steps:   1%|▏         | 13283/1000000 [43:27<1974:33:52,  7.20s/it, lr=1e-5, step_loss=0.0392][RANK-0]: Step: [13283], local_loss=0.019182443618774414, train_loss=0.06579490005970001, time_cost=4.646694898605347
Steps:   1%|▏         | 13283/1000000 [43:27<1974:33:52,  7.20s/it, lr=1e-5, step_loss=0.0192]Steps:   1%|▏         | 13284/1000000 [43:42<2625:44:02,  9.58s/it, lr=1e-5, step_loss=0.0192][RANK-0]: Step: [13284], local_loss=0.043693944811820984, train_loss=0.16536925733089447, time_cost=11.187982082366943
Steps:   1%|▏         | 13284/1000000 [43:42<2625:44:02,  9.58s/it, lr=1e-5, step_loss=0.0437]Steps:   1%|▏         | 13285/1000000 [43:50<2472:27:43,  9.02s/it, lr=1e-5, step_loss=0.0437][RANK-0]: Step: [13285], local_loss=0.06285645067691803, train_loss=0.03354477882385254, time_cost=3.6338367462158203
Steps:   1%|▏         | 13285/1000000 [43:50<2472:27:43,  9.02s/it, lr=1e-5, step_loss=0.0629]Steps:   1%|▏         | 13286/1000000 [43:56<2208:07:58,  8.06s/it, lr=1e-5, step_loss=0.0629][RANK-0]: Step: [13286], local_loss=0.027101946994662285, train_loss=0.04167298600077629, time_cost=4.673206329345703
Steps:   1%|▏         | 13286/1000000 [43:56<2208:07:58,  8.06s/it, lr=1e-5, step_loss=0.0271]Steps:   1%|▏         | 13287/1000000 [44:07<2476:07:04,  9.03s/it, lr=1e-5, step_loss=0.0271][RANK-0]: Step: [13287], local_loss=0.05175875872373581, train_loss=0.07403577119112015, time_cost=2.082552433013916
Steps:   1%|▏         | 13287/1000000 [44:07<2476:07:04,  9.03s/it, lr=1e-5, step_loss=0.0518]Steps:   1%|▏         | 13288/1000000 [44:12<2159:05:29,  7.88s/it, lr=1e-5, step_loss=0.0518][RANK-0]: Step: [13288], local_loss=0.010506227612495422, train_loss=0.023325607180595398, time_cost=2.1480839252471924
Steps:   1%|▏         | 13288/1000000 [44:12<2159:05:29,  7.88s/it, lr=1e-5, step_loss=0.0105]Steps:   1%|▏         | 13289/1000000 [44:20<2118:40:20,  7.73s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [13289], local_loss=0.01630805805325508, train_loss=0.1064055860042572, time_cost=1.2874903678894043
Steps:   1%|▏         | 13289/1000000 [44:20<2118:40:20,  7.73s/it, lr=1e-5, step_loss=0.0163]Steps:   1%|▏         | 13290/1000000 [44:33<2618:07:08,  9.55s/it, lr=1e-5, step_loss=0.0163][RANK-0]: Step: [13290], local_loss=0.05307132750749588, train_loss=0.020687682554125786, time_cost=1.232146978378296
Steps:   1%|▏         | 13290/1000000 [44:33<2618:07:08,  9.55s/it, lr=1e-5, step_loss=0.0531]Steps:   1%|▏         | 13291/1000000 [44:39<2251:27:25,  8.21s/it, lr=1e-5, step_loss=0.0531][RANK-0]: Step: [13291], local_loss=0.022184807807207108, train_loss=0.047195594757795334, time_cost=1.2565314769744873
Steps:   1%|▏         | 13291/1000000 [44:39<2251:27:25,  8.21s/it, lr=1e-5, step_loss=0.0222]Steps:   1%|▏         | 13292/1000000 [44:46<2176:48:26,  7.94s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [13292], local_loss=0.8545049428939819, train_loss=0.1453384906053543, time_cost=2.8409368991851807
Steps:   1%|▏         | 13292/1000000 [44:46<2176:48:26,  7.94s/it, lr=1e-5, step_loss=0.855] Steps:   1%|▏         | 13293/1000000 [44:57<2447:03:38,  8.93s/it, lr=1e-5, step_loss=0.855][RANK-0]: Step: [13293], local_loss=0.0399441123008728, train_loss=0.10846521705389023, time_cost=2.4090678691864014
Steps:   1%|▏         | 13293/1000000 [44:57<2447:03:38,  8.93s/it, lr=1e-5, step_loss=0.0399]Steps:   1%|▏         | 13294/1000000 [45:11<2833:36:56, 10.34s/it, lr=1e-5, step_loss=0.0399][RANK-0]: Step: [13294], local_loss=0.037796273827552795, train_loss=0.02963564731180668, time_cost=6.257978439331055
Steps:   1%|▏         | 13294/1000000 [45:11<2833:36:56, 10.34s/it, lr=1e-5, step_loss=0.0378]Steps:   1%|▏         | 13295/1000000 [45:15<2340:30:37,  8.54s/it, lr=1e-5, step_loss=0.0378][RANK-0]: Step: [13295], local_loss=0.015184439718723297, train_loss=0.03379826992750168, time_cost=1.7011020183563232
Steps:   1%|▏         | 13295/1000000 [45:15<2340:30:37,  8.54s/it, lr=1e-5, step_loss=0.0152]Steps:   1%|▏         | 13296/1000000 [45:26<2569:56:18,  9.38s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [13296], local_loss=0.49836429953575134, train_loss=0.1246710941195488, time_cost=3.3236849308013916
Steps:   1%|▏         | 13296/1000000 [45:26<2569:56:18,  9.38s/it, lr=1e-5, step_loss=0.498] Steps:   1%|▏         | 13297/1000000 [45:36<2627:00:11,  9.58s/it, lr=1e-5, step_loss=0.498][RANK-0]: Step: [13297], local_loss=0.10053510963916779, train_loss=0.06217005476355553, time_cost=4.1290624141693115
Steps:   1%|▏         | 13297/1000000 [45:36<2627:00:11,  9.58s/it, lr=1e-5, step_loss=0.101]Steps:   1%|▏         | 13298/1000000 [45:41<2216:03:35,  8.09s/it, lr=1e-5, step_loss=0.101][RANK-0]: Step: [13298], local_loss=0.03079104796051979, train_loss=0.027677038684487343, time_cost=1.5999464988708496
Steps:   1%|▏         | 13298/1000000 [45:41<2216:03:35,  8.09s/it, lr=1e-5, step_loss=0.0308]Steps:   1%|▏         | 13299/1000000 [45:49<2174:25:35,  7.93s/it, lr=1e-5, step_loss=0.0308][RANK-0]: Step: [13299], local_loss=0.020261496305465698, train_loss=0.12389448285102844, time_cost=1.4455230236053467
Steps:   1%|▏         | 13299/1000000 [45:49<2174:25:35,  7.93s/it, lr=1e-5, step_loss=0.0203]Steps:   1%|▏         | 13300/1000000 [45:59<2382:54:47,  8.69s/it, lr=1e-5, step_loss=0.0203][RANK-0]: Step: [13300], local_loss=0.020043572410941124, train_loss=0.023878712207078934, time_cost=1.8857581615447998
Steps:   1%|▏         | 13300/1000000 [45:59<2382:54:47,  8.69s/it, lr=1e-5, step_loss=0.02]  Steps:   1%|▏         | 13301/1000000 [46:10<2601:41:16,  9.49s/it, lr=1e-5, step_loss=0.02][RANK-0]: Step: [13301], local_loss=0.014194154180586338, train_loss=0.059609610587358475, time_cost=3.2576045989990234
Steps:   1%|▏         | 13301/1000000 [46:10<2601:41:16,  9.49s/it, lr=1e-5, step_loss=0.0142]Steps:   1%|▏         | 13302/1000000 [46:16<2256:59:26,  8.23s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [13302], local_loss=0.0134323975071311, train_loss=19.1467342376709, time_cost=2.338552474975586
Steps:   1%|▏         | 13302/1000000 [46:16<2256:59:26,  8.23s/it, lr=1e-5, step_loss=0.0134]Steps:   1%|▏         | 13303/1000000 [46:22<2099:56:34,  7.66s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [13303], local_loss=0.02480911836028099, train_loss=0.03662927821278572, time_cost=5.305424451828003
Steps:   1%|▏         | 13303/1000000 [46:22<2099:56:34,  7.66s/it, lr=1e-5, step_loss=0.0248]Steps:   1%|▏         | 13304/1000000 [46:27<1876:47:50,  6.85s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [13304], local_loss=0.08034798502922058, train_loss=0.03600595146417618, time_cost=1.650475025177002
Steps:   1%|▏         | 13304/1000000 [46:27<1876:47:50,  6.85s/it, lr=1e-5, step_loss=0.0803]Steps:   1%|▏         | 13305/1000000 [46:38<2224:46:47,  8.12s/it, lr=1e-5, step_loss=0.0803][RANK-0]: Step: [13305], local_loss=0.097853884100914, train_loss=0.1932350993156433, time_cost=1.2445790767669678
Steps:   1%|▏         | 13305/1000000 [46:38<2224:46:47,  8.12s/it, lr=1e-5, step_loss=0.0979]Steps:   1%|▏         | 13306/1000000 [46:43<1989:01:02,  7.26s/it, lr=1e-5, step_loss=0.0979][RANK-0]: Step: [13306], local_loss=0.07187826931476593, train_loss=0.06907309591770172, time_cost=2.2842419147491455
Steps:   1%|▏         | 13306/1000000 [46:43<1989:01:02,  7.26s/it, lr=1e-5, step_loss=0.0719]Steps:   1%|▏         | 13307/1000000 [46:54<2309:16:10,  8.43s/it, lr=1e-5, step_loss=0.0719][RANK-0]: Step: [13307], local_loss=281.74884033203125, train_loss=35.26844787597656, time_cost=1.2416374683380127
Steps:   1%|▏         | 13307/1000000 [46:54<2309:16:10,  8.43s/it, lr=1e-5, step_loss=282]   Steps:   1%|▏         | 13308/1000000 [47:07<2657:53:21,  9.70s/it, lr=1e-5, step_loss=282][RANK-0]: Step: [13308], local_loss=0.026358909904956818, train_loss=0.03124437853693962, time_cost=1.2247307300567627
Steps:   1%|▏         | 13308/1000000 [47:07<2657:53:21,  9.70s/it, lr=1e-5, step_loss=0.0264]Steps:   1%|▏         | 13309/1000000 [47:13<2335:07:26,  8.52s/it, lr=1e-5, step_loss=0.0264][RANK-0]: Step: [13309], local_loss=170.4026641845703, train_loss=21.327056884765625, time_cost=1.4817988872528076
Steps:   1%|▏         | 13309/1000000 [47:13<2335:07:26,  8.52s/it, lr=1e-5, step_loss=170]   Steps:   1%|▏         | 13310/1000000 [47:24<2572:51:10,  9.39s/it, lr=1e-5, step_loss=170][RANK-0]: Step: [13310], local_loss=0.04473113268613815, train_loss=0.04614754393696785, time_cost=7.6263861656188965
Steps:   1%|▏         | 13310/1000000 [47:24<2572:51:10,  9.39s/it, lr=1e-5, step_loss=0.0447]Steps:   1%|▏         | 13311/1000000 [47:33<2539:45:48,  9.27s/it, lr=1e-5, step_loss=0.0447][RANK-0]: Step: [13311], local_loss=0.03925153613090515, train_loss=0.03421158343553543, time_cost=1.801577091217041
Steps:   1%|▏         | 13311/1000000 [47:33<2539:45:48,  9.27s/it, lr=1e-5, step_loss=0.0393]Steps:   1%|▏         | 13312/1000000 [47:45<2715:54:34,  9.91s/it, lr=1e-5, step_loss=0.0393][RANK-0]: Step: [13312], local_loss=0.006488011684268713, train_loss=0.08091143518686295, time_cost=2.829402208328247
Steps:   1%|▏         | 13312/1000000 [47:45<2715:54:34,  9.91s/it, lr=1e-5, step_loss=0.00649]Steps:   1%|▏         | 13313/1000000 [47:50<2316:08:52,  8.45s/it, lr=1e-5, step_loss=0.00649][RANK-0]: Step: [13313], local_loss=0.005220478400588036, train_loss=0.0647137388586998, time_cost=2.2020199298858643
Steps:   1%|▏         | 13313/1000000 [47:50<2316:08:52,  8.45s/it, lr=1e-5, step_loss=0.00522]Steps:   1%|▏         | 13314/1000000 [47:54<1973:57:31,  7.20s/it, lr=1e-5, step_loss=0.00522][RANK-0]: Step: [13314], local_loss=0.015673378482460976, train_loss=0.04919004067778587, time_cost=1.5104775428771973
Steps:   1%|▏         | 13314/1000000 [47:54<1973:57:31,  7.20s/it, lr=1e-5, step_loss=0.0157] Steps:   1%|▏         | 13315/1000000 [48:08<2552:43:28,  9.31s/it, lr=1e-5, step_loss=0.0157][RANK-0]: Step: [13315], local_loss=0.027240900322794914, train_loss=0.03357582539319992, time_cost=5.846371650695801
Steps:   1%|▏         | 13315/1000000 [48:08<2552:43:28,  9.31s/it, lr=1e-5, step_loss=0.0272]Steps:   1%|▏         | 13316/1000000 [48:17<2535:20:00,  9.25s/it, lr=1e-5, step_loss=0.0272][RANK-0]: Step: [13316], local_loss=0.009674720466136932, train_loss=0.022135213017463684, time_cost=1.2201831340789795
Steps:   1%|▏         | 13316/1000000 [48:17<2535:20:00,  9.25s/it, lr=1e-5, step_loss=0.00967]Steps:   1%|▏         | 13317/1000000 [48:24<2341:43:02,  8.54s/it, lr=1e-5, step_loss=0.00967][RANK-0]: Step: [13317], local_loss=0.06236722320318222, train_loss=0.151855930685997, time_cost=1.2316319942474365
Steps:   1%|▏         | 13317/1000000 [48:24<2341:43:02,  8.54s/it, lr=1e-5, step_loss=0.0624] Steps:   1%|▏         | 13318/1000000 [48:33<2367:05:31,  8.64s/it, lr=1e-5, step_loss=0.0624][RANK-0]: Step: [13318], local_loss=0.009712663479149342, train_loss=0.05003098398447037, time_cost=2.5188722610473633
Steps:   1%|▏         | 13318/1000000 [48:33<2367:05:31,  8.64s/it, lr=1e-5, step_loss=0.00971]Steps:   1%|▏         | 13319/1000000 [48:44<2585:36:42,  9.43s/it, lr=1e-5, step_loss=0.00971][RANK-0]: Step: [13319], local_loss=0.028636811301112175, train_loss=0.10119649767875671, time_cost=3.1316163539886475
Steps:   1%|▏         | 13319/1000000 [48:44<2585:36:42,  9.43s/it, lr=1e-5, step_loss=0.0286] Steps:   1%|▏         | 13320/1000000 [48:53<2508:49:33,  9.15s/it, lr=1e-5, step_loss=0.0286][RANK-0]: Step: [13320], local_loss=0.6056174039840698, train_loss=0.11884045600891113, time_cost=2.69834041595459
Steps:   1%|▏         | 13320/1000000 [48:53<2508:49:33,  9.15s/it, lr=1e-5, step_loss=0.606] Steps:   1%|▏         | 13321/1000000 [49:04<2649:45:25,  9.67s/it, lr=1e-5, step_loss=0.606][RANK-0]: Step: [13321], local_loss=0.07807517796754837, train_loss=0.12563897669315338, time_cost=3.098313331604004
Steps:   1%|▏         | 13321/1000000 [49:04<2649:45:25,  9.67s/it, lr=1e-5, step_loss=0.0781]Steps:   1%|▏         | 13322/1000000 [49:15<2775:45:15, 10.13s/it, lr=1e-5, step_loss=0.0781][RANK-0]: Step: [13322], local_loss=0.011362706311047077, train_loss=0.0292237289249897, time_cost=3.5619497299194336
Steps:   1%|▏         | 13322/1000000 [49:15<2775:45:15, 10.13s/it, lr=1e-5, step_loss=0.0114]Steps:   1%|▏         | 13323/1000000 [49:24<2689:44:37,  9.81s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [13323], local_loss=0.0324849858880043, train_loss=0.04209686070680618, time_cost=3.035335063934326
Steps:   1%|▏         | 13323/1000000 [49:24<2689:44:37,  9.81s/it, lr=1e-5, step_loss=0.0325]Steps:   1%|▏         | 13324/1000000 [49:29<2328:08:54,  8.49s/it, lr=1e-5, step_loss=0.0325][RANK-0]: Step: [13324], local_loss=0.01688859611749649, train_loss=0.08274635672569275, time_cost=2.699368476867676
Steps:   1%|▏         | 13324/1000000 [49:29<2328:08:54,  8.49s/it, lr=1e-5, step_loss=0.0169]Steps:   1%|▏         | 13325/1000000 [49:40<2458:36:07,  8.97s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [13325], local_loss=0.026844438165426254, train_loss=0.09741184115409851, time_cost=2.0248188972473145
Steps:   1%|▏         | 13325/1000000 [49:40<2458:36:07,  8.97s/it, lr=1e-5, step_loss=0.0268]Steps:   1%|▏         | 13326/1000000 [49:45<2206:02:58,  8.05s/it, lr=1e-5, step_loss=0.0268][RANK-0]: Step: [13326], local_loss=0.04451395571231842, train_loss=0.031061800196766853, time_cost=4.305134057998657
Steps:   1%|▏         | 13326/1000000 [49:45<2206:02:58,  8.05s/it, lr=1e-5, step_loss=0.0445]Steps:   1%|▏         | 13327/1000000 [49:50<1945:37:56,  7.10s/it, lr=1e-5, step_loss=0.0445][RANK-0]: Step: [13327], local_loss=0.05411623790860176, train_loss=0.032151855528354645, time_cost=2.3139212131500244
Steps:   1%|▏         | 13327/1000000 [49:50<1945:37:56,  7.10s/it, lr=1e-5, step_loss=0.0541]Steps:   1%|▏         | 13328/1000000 [49:57<1944:15:35,  7.09s/it, lr=1e-5, step_loss=0.0541][RANK-0]: Step: [13328], local_loss=0.027308663353323936, train_loss=0.06240338459610939, time_cost=2.931884527206421
Steps:   1%|▏         | 13328/1000000 [49:57<1944:15:35,  7.09s/it, lr=1e-5, step_loss=0.0273]Steps:   1%|▏         | 13329/1000000 [50:05<1943:13:01,  7.09s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [13329], local_loss=0.01057969406247139, train_loss=0.09835398942232132, time_cost=2.8156468868255615
Steps:   1%|▏         | 13329/1000000 [50:05<1943:13:01,  7.09s/it, lr=1e-5, step_loss=0.0106]Steps:   1%|▏         | 13330/1000000 [50:20<2660:33:55,  9.71s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [13330], local_loss=0.032460883259773254, train_loss=0.030169906094670296, time_cost=6.8585309982299805
Steps:   1%|▏         | 13330/1000000 [50:20<2660:33:55,  9.71s/it, lr=1e-5, step_loss=0.0325]Steps:   1%|▏         | 13331/1000000 [50:34<2964:10:13, 10.82s/it, lr=1e-5, step_loss=0.0325][RANK-0]: Step: [13331], local_loss=0.03578707203269005, train_loss=0.04667501151561737, time_cost=4.151549577713013
Steps:   1%|▏         | 13331/1000000 [50:34<2964:10:13, 10.82s/it, lr=1e-5, step_loss=0.0358]Steps:   1%|▏         | 13332/1000000 [50:41<2712:41:37,  9.90s/it, lr=1e-5, step_loss=0.0358][RANK-0]: Step: [13332], local_loss=0.027314241975545883, train_loss=0.14391618967056274, time_cost=2.949911594390869
Steps:   1%|▏         | 13332/1000000 [50:41<2712:41:37,  9.90s/it, lr=1e-5, step_loss=0.0273]Steps:   1%|▏         | 13333/1000000 [50:47<2324:03:01,  8.48s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [13333], local_loss=0.24328850209712982, train_loss=0.07507207989692688, time_cost=1.4949922561645508
Steps:   1%|▏         | 13333/1000000 [50:47<2324:03:01,  8.48s/it, lr=1e-5, step_loss=0.243] Steps:   1%|▏         | 13334/1000000 [50:52<2036:59:11,  7.43s/it, lr=1e-5, step_loss=0.243][RANK-0]: Step: [13334], local_loss=0.060028694570064545, train_loss=0.05040821060538292, time_cost=1.228543758392334
Steps:   1%|▏         | 13334/1000000 [50:52<2036:59:11,  7.43s/it, lr=1e-5, step_loss=0.06] Steps:   1%|▏         | 13335/1000000 [51:00<2153:09:08,  7.86s/it, lr=1e-5, step_loss=0.06][RANK-0]: Step: [13335], local_loss=0.011626871302723885, train_loss=0.034397467970848083, time_cost=2.557065010070801
Steps:   1%|▏         | 13335/1000000 [51:00<2153:09:08,  7.86s/it, lr=1e-5, step_loss=0.0116]Steps:   1%|▏         | 13336/1000000 [51:15<2676:02:33,  9.76s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [13336], local_loss=0.026585901156067848, train_loss=0.04108984395861626, time_cost=3.6662821769714355
Steps:   1%|▏         | 13336/1000000 [51:15<2676:02:33,  9.76s/it, lr=1e-5, step_loss=0.0266]Steps:   1%|▏         | 13337/1000000 [51:22<2462:51:45,  8.99s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [13337], local_loss=0.09263008832931519, train_loss=0.04232759028673172, time_cost=2.712800979614258
Steps:   1%|▏         | 13337/1000000 [51:22<2462:51:45,  8.99s/it, lr=1e-5, step_loss=0.0926]Steps:   1%|▏         | 13338/1000000 [51:27<2142:26:02,  7.82s/it, lr=1e-5, step_loss=0.0926][RANK-0]: Step: [13338], local_loss=0.04826108738780022, train_loss=8.55874252319336, time_cost=1.4137234687805176
Steps:   1%|▏         | 13338/1000000 [51:27<2142:26:02,  7.82s/it, lr=1e-5, step_loss=0.0483]Steps:   1%|▏         | 13339/1000000 [51:32<1917:53:57,  7.00s/it, lr=1e-5, step_loss=0.0483][RANK-0]: Step: [13339], local_loss=0.10751545429229736, train_loss=0.0737651139497757, time_cost=2.2693984508514404
Steps:   1%|▏         | 13339/1000000 [51:32<1917:53:57,  7.00s/it, lr=1e-5, step_loss=0.108] Steps:   1%|▏         | 13340/1000000 [51:43<2212:38:05,  8.07s/it, lr=1e-5, step_loss=0.108][RANK-0]: Step: [13340], local_loss=0.1352383941411972, train_loss=0.06688454002141953, time_cost=3.5050406455993652
Steps:   1%|▏         | 13340/1000000 [51:43<2212:38:05,  8.07s/it, lr=1e-5, step_loss=0.135]Steps:   1%|▏         | 13341/1000000 [51:49<2045:43:13,  7.46s/it, lr=1e-5, step_loss=0.135][RANK-0]: Step: [13341], local_loss=0.04132281243801117, train_loss=0.025782369077205658, time_cost=1.5158288478851318
Steps:   1%|▏         | 13341/1000000 [51:49<2045:43:13,  7.46s/it, lr=1e-5, step_loss=0.0413]Steps:   1%|▏         | 13342/1000000 [52:01<2472:06:13,  9.02s/it, lr=1e-5, step_loss=0.0413][RANK-0]: Step: [13342], local_loss=0.04941233992576599, train_loss=0.0974804237484932, time_cost=5.681484699249268
Steps:   1%|▏         | 13342/1000000 [52:01<2472:06:13,  9.02s/it, lr=1e-5, step_loss=0.0494]Steps:   1%|▏         | 13343/1000000 [52:10<2460:41:56,  8.98s/it, lr=1e-5, step_loss=0.0494][RANK-0]: Step: [13343], local_loss=0.020147783681750298, train_loss=0.0780140832066536, time_cost=6.692410469055176
Steps:   1%|▏         | 13343/1000000 [52:10<2460:41:56,  8.98s/it, lr=1e-5, step_loss=0.0201]Steps:   1%|▏         | 13344/1000000 [52:20<2495:14:46,  9.10s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [13344], local_loss=0.049814071506261826, train_loss=0.04078809916973114, time_cost=1.2289834022521973
Steps:   1%|▏         | 13344/1000000 [52:20<2495:14:46,  9.10s/it, lr=1e-5, step_loss=0.0498]Steps:   1%|▏         | 13345/1000000 [52:27<2354:37:41,  8.59s/it, lr=1e-5, step_loss=0.0498][RANK-0]: Step: [13345], local_loss=244.424072265625, train_loss=30.588388442993164, time_cost=2.866863489151001
Steps:   1%|▏         | 13345/1000000 [52:27<2354:37:41,  8.59s/it, lr=1e-5, step_loss=244]   Steps:   1%|▏         | 13346/1000000 [52:37<2449:44:40,  8.94s/it, lr=1e-5, step_loss=244][RANK-0]: Step: [13346], local_loss=0.02008160389959812, train_loss=0.08608280122280121, time_cost=3.6839919090270996
Steps:   1%|▏         | 13346/1000000 [52:37<2449:44:40,  8.94s/it, lr=1e-5, step_loss=0.0201]Steps:   1%|▏         | 13347/1000000 [52:46<2461:40:49,  8.98s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [13347], local_loss=0.030062638223171234, train_loss=0.03009345941245556, time_cost=6.6511523723602295
Steps:   1%|▏         | 13347/1000000 [52:46<2461:40:49,  8.98s/it, lr=1e-5, step_loss=0.0301]Steps:   1%|▏         | 13348/1000000 [52:59<2802:36:17, 10.23s/it, lr=1e-5, step_loss=0.0301][RANK-0]: Step: [13348], local_loss=0.026722412556409836, train_loss=0.04343476891517639, time_cost=1.234490156173706
Steps:   1%|▏         | 13348/1000000 [52:59<2802:36:17, 10.23s/it, lr=1e-5, step_loss=0.0267]Steps:   1%|▏         | 13349/1000000 [53:12<3027:21:19, 11.05s/it, lr=1e-5, step_loss=0.0267][RANK-0]: Step: [13349], local_loss=0.05214068293571472, train_loss=0.09599217772483826, time_cost=4.44559645652771
Steps:   1%|▏         | 13349/1000000 [53:12<3027:21:19, 11.05s/it, lr=1e-5, step_loss=0.0521]Steps:   1%|▏         | 13350/1000000 [53:26<3304:23:53, 12.06s/it, lr=1e-5, step_loss=0.0521][RANK-0]: Step: [13350], local_loss=0.05278506129980087, train_loss=0.03069988451898098, time_cost=6.815937519073486
Steps:   1%|▏         | 13350/1000000 [53:26<3304:23:53, 12.06s/it, lr=1e-5, step_loss=0.0528]Steps:   1%|▏         | 13351/1000000 [53:32<2809:49:55, 10.25s/it, lr=1e-5, step_loss=0.0528][RANK-0]: Step: [13351], local_loss=0.06537193804979324, train_loss=0.04471161216497421, time_cost=1.9784374237060547
Steps:   1%|▏         | 13351/1000000 [53:32<2809:49:55, 10.25s/it, lr=1e-5, step_loss=0.0654]Steps:   1%|▏         | 13352/1000000 [53:42<2760:52:14, 10.07s/it, lr=1e-5, step_loss=0.0654][RANK-0]: Step: [13352], local_loss=0.006810406222939491, train_loss=0.015554985962808132, time_cost=1.8631060123443604
Steps:   1%|▏         | 13352/1000000 [53:42<2760:52:14, 10.07s/it, lr=1e-5, step_loss=0.00681]Steps:   1%|▏         | 13353/1000000 [53:48<2421:04:28,  8.83s/it, lr=1e-5, step_loss=0.00681][RANK-0]: Step: [13353], local_loss=0.06332708895206451, train_loss=24.08957290649414, time_cost=1.7219135761260986
Steps:   1%|▏         | 13353/1000000 [53:48<2421:04:28,  8.83s/it, lr=1e-5, step_loss=0.0633] Steps:   1%|▏         | 13354/1000000 [54:03<2958:40:51, 10.80s/it, lr=1e-5, step_loss=0.0633][RANK-0]: Step: [13354], local_loss=0.01434463169425726, train_loss=0.03998997062444687, time_cost=6.565210342407227
Steps:   1%|▏         | 13354/1000000 [54:03<2958:40:51, 10.80s/it, lr=1e-5, step_loss=0.0143]Steps:   1%|▏         | 13355/1000000 [54:15<3002:53:04, 10.96s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [13355], local_loss=0.4376968741416931, train_loss=0.0967601016163826, time_cost=4.714349985122681
Steps:   1%|▏         | 13355/1000000 [54:15<3002:53:04, 10.96s/it, lr=1e-5, step_loss=0.438] Steps:   1%|▏         | 13356/1000000 [54:22<2694:15:14,  9.83s/it, lr=1e-5, step_loss=0.438][RANK-0]: Step: [13356], local_loss=0.01468427013605833, train_loss=0.06606552004814148, time_cost=2.900102376937866
Steps:   1%|▏         | 13356/1000000 [54:22<2694:15:14,  9.83s/it, lr=1e-5, step_loss=0.0147]Steps:   1%|▏         | 13357/1000000 [54:37<3121:49:47, 11.39s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [13357], local_loss=0.014760911464691162, train_loss=0.02279829792678356, time_cost=7.745791912078857
Steps:   1%|▏         | 13357/1000000 [54:37<3121:49:47, 11.39s/it, lr=1e-5, step_loss=0.0148]Steps:   1%|▏         | 13358/1000000 [54:46<2936:57:44, 10.72s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [13358], local_loss=0.07612963765859604, train_loss=0.031725142151117325, time_cost=6.0366010665893555
Steps:   1%|▏         | 13358/1000000 [54:46<2936:57:44, 10.72s/it, lr=1e-5, step_loss=0.0761]Steps:   1%|▏         | 13359/1000000 [54:53<2587:02:06,  9.44s/it, lr=1e-5, step_loss=0.0761][RANK-0]: Step: [13359], local_loss=0.1462632268667221, train_loss=0.17476105690002441, time_cost=1.2337591648101807
Steps:   1%|▏         | 13359/1000000 [54:53<2587:02:06,  9.44s/it, lr=1e-5, step_loss=0.146] Steps:   1%|▏         | 13360/1000000 [55:08<3116:46:30, 11.37s/it, lr=1e-5, step_loss=0.146][RANK-0]: Step: [13360], local_loss=0.17708313465118408, train_loss=0.16356801986694336, time_cost=2.7185311317443848
Steps:   1%|▏         | 13360/1000000 [55:08<3116:46:30, 11.37s/it, lr=1e-5, step_loss=0.177]Steps:   1%|▏         | 13361/1000000 [55:13<2534:15:14,  9.25s/it, lr=1e-5, step_loss=0.177][RANK-0]: Step: [13361], local_loss=0.016999881714582443, train_loss=0.02666482701897621, time_cost=1.4073889255523682
Steps:   1%|▏         | 13361/1000000 [55:13<2534:15:14,  9.25s/it, lr=1e-5, step_loss=0.017]Steps:   1%|▏         | 13362/1000000 [55:20<2336:15:59,  8.52s/it, lr=1e-5, step_loss=0.017][RANK-0]: Step: [13362], local_loss=1.006155014038086, train_loss=0.16074970364570618, time_cost=2.568528413772583
Steps:   1%|▏         | 13362/1000000 [55:20<2336:15:59,  8.52s/it, lr=1e-5, step_loss=1.01] Steps:   1%|▏         | 13363/1000000 [55:27<2263:05:43,  8.26s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [13363], local_loss=0.024823637679219246, train_loss=0.051574524492025375, time_cost=1.2393913269042969
Steps:   1%|▏         | 13363/1000000 [55:27<2263:05:43,  8.26s/it, lr=1e-5, step_loss=0.0248]Steps:   1%|▏         | 13364/1000000 [55:38<2478:35:34,  9.04s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [13364], local_loss=0.018226753920316696, train_loss=0.03160303086042404, time_cost=3.0222010612487793
Steps:   1%|▏         | 13364/1000000 [55:38<2478:35:34,  9.04s/it, lr=1e-5, step_loss=0.0182]Steps:   1%|▏         | 13365/1000000 [55:43<2179:08:11,  7.95s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [13365], local_loss=0.010546551086008549, train_loss=0.03113425523042679, time_cost=1.3430333137512207
Steps:   1%|▏         | 13365/1000000 [55:43<2179:08:11,  7.95s/it, lr=1e-5, step_loss=0.0105]Steps:   1%|▏         | 13366/1000000 [55:48<1881:43:09,  6.87s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [13366], local_loss=0.013563291169703007, train_loss=0.14777985215187073, time_cost=1.2963736057281494
Steps:   1%|▏         | 13366/1000000 [55:48<1881:43:09,  6.87s/it, lr=1e-5, step_loss=0.0136]Steps:   1%|▏         | 13367/1000000 [55:55<1882:41:49,  6.87s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [13367], local_loss=0.07418973743915558, train_loss=0.04753166437149048, time_cost=2.1415505409240723
Steps:   1%|▏         | 13367/1000000 [55:55<1882:41:49,  6.87s/it, lr=1e-5, step_loss=0.0742]Steps:   1%|▏         | 13368/1000000 [56:10<2549:56:20,  9.30s/it, lr=1e-5, step_loss=0.0742][RANK-0]: Step: [13368], local_loss=0.03207717090845108, train_loss=0.028668474406003952, time_cost=5.076571941375732
Steps:   1%|▏         | 13368/1000000 [56:10<2549:56:20,  9.30s/it, lr=1e-5, step_loss=0.0321]Steps:   1%|▏         | 13369/1000000 [56:17<2389:11:40,  8.72s/it, lr=1e-5, step_loss=0.0321][RANK-0]: Step: [13369], local_loss=0.0369577556848526, train_loss=0.04006209969520569, time_cost=2.873807668685913
Steps:   1%|▏         | 13369/1000000 [56:17<2389:11:40,  8.72s/it, lr=1e-5, step_loss=0.037] Steps:   1%|▏         | 13370/1000000 [56:31<2806:57:54, 10.24s/it, lr=1e-5, step_loss=0.037][RANK-0]: Step: [13370], local_loss=0.01985526829957962, train_loss=1.1008286476135254, time_cost=6.33524751663208
Steps:   1%|▏         | 13370/1000000 [56:31<2806:57:54, 10.24s/it, lr=1e-5, step_loss=0.0199]Steps:   1%|▏         | 13371/1000000 [56:46<3245:32:48, 11.84s/it, lr=1e-5, step_loss=0.0199][RANK-0]: Step: [13371], local_loss=0.0050602080300450325, train_loss=0.06471315026283264, time_cost=11.311499118804932
Steps:   1%|▏         | 13371/1000000 [56:46<3245:32:48, 11.84s/it, lr=1e-5, step_loss=0.00506]Steps:   1%|▏         | 13372/1000000 [57:00<3383:54:07, 12.35s/it, lr=1e-5, step_loss=0.00506][RANK-0]: Step: [13372], local_loss=0.0350380577147007, train_loss=0.025568882003426552, time_cost=10.719223022460938
Steps:   1%|▏         | 13372/1000000 [57:00<3383:54:07, 12.35s/it, lr=1e-5, step_loss=0.035]  Steps:   1%|▏         | 13373/1000000 [57:14<3558:46:17, 12.99s/it, lr=1e-5, step_loss=0.035][RANK-0]: Step: [13373], local_loss=0.01822029799222946, train_loss=0.0225354116410017, time_cost=4.9205896854400635
Steps:   1%|▏         | 13373/1000000 [57:14<3558:46:17, 12.99s/it, lr=1e-5, step_loss=0.0182]Steps:   1%|▏         | 13374/1000000 [57:23<3220:37:00, 11.75s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [13374], local_loss=0.017108505591750145, train_loss=0.04516957700252533, time_cost=2.7040252685546875
Steps:   1%|▏         | 13374/1000000 [57:23<3220:37:00, 11.75s/it, lr=1e-5, step_loss=0.0171]Steps:   1%|▏         | 13375/1000000 [57:32<2994:20:29, 10.93s/it, lr=1e-5, step_loss=0.0171][RANK-0]: Step: [13375], local_loss=0.03642949461936951, train_loss=0.023724323138594627, time_cost=2.377298593521118
Steps:   1%|▏         | 13375/1000000 [57:32<2994:20:29, 10.93s/it, lr=1e-5, step_loss=0.0364]Steps:   1%|▏         | 13376/1000000 [57:38<2543:38:19,  9.28s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [13376], local_loss=0.05480866879224777, train_loss=0.11001627892255783, time_cost=1.69140625
Steps:   1%|▏         | 13376/1000000 [57:38<2543:38:19,  9.28s/it, lr=1e-5, step_loss=0.0548]Steps:   1%|▏         | 13377/1000000 [57:44<2288:05:42,  8.35s/it, lr=1e-5, step_loss=0.0548][RANK-0]: Step: [13377], local_loss=0.0655045285820961, train_loss=0.038618750870227814, time_cost=1.9694020748138428
Steps:   1%|▏         | 13377/1000000 [57:44<2288:05:42,  8.35s/it, lr=1e-5, step_loss=0.0655]Steps:   1%|▏         | 13378/1000000 [57:56<2573:50:44,  9.39s/it, lr=1e-5, step_loss=0.0655][RANK-0]: Step: [13378], local_loss=0.014439061284065247, train_loss=0.10573671013116837, time_cost=3.7614026069641113
Steps:   1%|▏         | 13378/1000000 [57:56<2573:50:44,  9.39s/it, lr=1e-5, step_loss=0.0144]Steps:   1%|▏         | 13379/1000000 [58:09<2868:22:02, 10.47s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [13379], local_loss=0.13863369822502136, train_loss=18.48619842529297, time_cost=7.390361785888672
Steps:   1%|▏         | 13379/1000000 [58:09<2868:22:02, 10.47s/it, lr=1e-5, step_loss=0.139] Steps:   1%|▏         | 13380/1000000 [58:16<2608:19:24,  9.52s/it, lr=1e-5, step_loss=0.139][RANK-0]: Step: [13380], local_loss=0.013151640072464943, train_loss=0.024674540385603905, time_cost=3.335901975631714
Steps:   1%|▏         | 13380/1000000 [58:16<2608:19:24,  9.52s/it, lr=1e-5, step_loss=0.0132]Steps:   1%|▏         | 13381/1000000 [58:24<2501:12:26,  9.13s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [13381], local_loss=0.0209711492061615, train_loss=0.09135176241397858, time_cost=1.3142693042755127
Steps:   1%|▏         | 13381/1000000 [58:24<2501:12:26,  9.13s/it, lr=1e-5, step_loss=0.021] Steps:   1%|▏         | 13382/1000000 [58:29<2176:04:16,  7.94s/it, lr=1e-5, step_loss=0.021][RANK-0]: Step: [13382], local_loss=0.024780811741948128, train_loss=0.05301811918616295, time_cost=2.263522148132324
Steps:   1%|▏         | 13382/1000000 [58:29<2176:04:16,  7.94s/it, lr=1e-5, step_loss=0.0248]Steps:   1%|▏         | 13383/1000000 [58:38<2242:30:54,  8.18s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [13383], local_loss=0.014243857935070992, train_loss=0.025038016960024834, time_cost=2.737236499786377
Steps:   1%|▏         | 13383/1000000 [58:38<2242:30:54,  8.18s/it, lr=1e-5, step_loss=0.0142]Steps:   1%|▏         | 13384/1000000 [58:52<2677:05:14,  9.77s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [13384], local_loss=0.091873399913311, train_loss=0.0508151650428772, time_cost=1.3255279064178467
Steps:   1%|▏         | 13384/1000000 [58:52<2677:05:14,  9.77s/it, lr=1e-5, step_loss=0.0919]Steps:   1%|▏         | 13385/1000000 [59:00<2531:35:36,  9.24s/it, lr=1e-5, step_loss=0.0919][RANK-0]: Step: [13385], local_loss=0.04976430535316467, train_loss=0.03199118375778198, time_cost=4.015051603317261
Steps:   1%|▏         | 13385/1000000 [59:00<2531:35:36,  9.24s/it, lr=1e-5, step_loss=0.0498]Steps:   1%|▏         | 13386/1000000 [59:13<2896:57:57, 10.57s/it, lr=1e-5, step_loss=0.0498][RANK-0]: Step: [13386], local_loss=0.07710816711187363, train_loss=0.03868410736322403, time_cost=4.471138000488281
Steps:   1%|▏         | 13386/1000000 [59:13<2896:57:57, 10.57s/it, lr=1e-5, step_loss=0.0771]Steps:   1%|▏         | 13387/1000000 [59:19<2469:16:38,  9.01s/it, lr=1e-5, step_loss=0.0771][RANK-0]: Step: [13387], local_loss=0.043587006628513336, train_loss=0.06240995228290558, time_cost=2.843569040298462
Steps:   1%|▏         | 13387/1000000 [59:19<2469:16:38,  9.01s/it, lr=1e-5, step_loss=0.0436]Steps:   1%|▏         | 13388/1000000 [59:28<2504:12:59,  9.14s/it, lr=1e-5, step_loss=0.0436][RANK-0]: Step: [13388], local_loss=0.4195859134197235, train_loss=0.08260181546211243, time_cost=3.278897523880005
Steps:   1%|▏         | 13388/1000000 [59:28<2504:12:59,  9.14s/it, lr=1e-5, step_loss=0.42]  Steps:   1%|▏         | 13389/1000000 [59:34<2211:39:00,  8.07s/it, lr=1e-5, step_loss=0.42][RANK-0]: Step: [13389], local_loss=0.033519960939884186, train_loss=0.0991690456867218, time_cost=2.9549012184143066
Steps:   1%|▏         | 13389/1000000 [59:34<2211:39:00,  8.07s/it, lr=1e-5, step_loss=0.0335]Steps:   1%|▏         | 13390/1000000 [59:39<1975:12:14,  7.21s/it, lr=1e-5, step_loss=0.0335][RANK-0]: Step: [13390], local_loss=0.0353257916867733, train_loss=0.03446975350379944, time_cost=1.210618019104004
Steps:   1%|▏         | 13390/1000000 [59:39<1975:12:14,  7.21s/it, lr=1e-5, step_loss=0.0353]Steps:   1%|▏         | 13391/1000000 [59:48<2121:49:28,  7.74s/it, lr=1e-5, step_loss=0.0353][RANK-0]: Step: [13391], local_loss=0.03633086010813713, train_loss=0.07132652401924133, time_cost=2.788881778717041
Steps:   1%|▏         | 13391/1000000 [59:48<2121:49:28,  7.74s/it, lr=1e-5, step_loss=0.0363]Steps:   1%|▏         | 13392/1000000 [59:54<1983:08:40,  7.24s/it, lr=1e-5, step_loss=0.0363][RANK-0]: Step: [13392], local_loss=0.010344509035348892, train_loss=0.03688613325357437, time_cost=1.763657808303833
Steps:   1%|▏         | 13392/1000000 [59:54<1983:08:40,  7.24s/it, lr=1e-5, step_loss=0.0103]Steps:   1%|▏         | 13393/1000000 [1:00:10<2722:59:46,  9.94s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [13393], local_loss=0.03756529465317726, train_loss=35.9518928527832, time_cost=4.62352180480957
Steps:   1%|▏         | 13393/1000000 [1:00:10<2722:59:46,  9.94s/it, lr=1e-5, step_loss=0.0376]Steps:   1%|▏         | 13394/1000000 [1:00:16<2412:15:24,  8.80s/it, lr=1e-5, step_loss=0.0376][RANK-0]: Step: [13394], local_loss=0.008721912279725075, train_loss=0.06465691328048706, time_cost=1.7620854377746582
Steps:   1%|▏         | 13394/1000000 [1:00:16<2412:15:24,  8.80s/it, lr=1e-5, step_loss=0.00872]Steps:   1%|▏         | 13395/1000000 [1:00:21<2112:15:11,  7.71s/it, lr=1e-5, step_loss=0.00872][RANK-0]: Step: [13395], local_loss=0.016787080094218254, train_loss=0.026608088985085487, time_cost=3.070619821548462
Steps:   1%|▏         | 13395/1000000 [1:00:21<2112:15:11,  7.71s/it, lr=1e-5, step_loss=0.0168] Steps:   1%|▏         | 13396/1000000 [1:00:26<1880:02:26,  6.86s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [13396], local_loss=0.04872794821858406, train_loss=0.1839793622493744, time_cost=1.2264814376831055
Steps:   1%|▏         | 13396/1000000 [1:00:26<1880:02:26,  6.86s/it, lr=1e-5, step_loss=0.0487]Steps:   1%|▏         | 13397/1000000 [1:00:36<2082:32:02,  7.60s/it, lr=1e-5, step_loss=0.0487][RANK-0]: Step: [13397], local_loss=0.05830727145075798, train_loss=0.16490785777568817, time_cost=3.180774688720703
Steps:   1%|▏         | 13397/1000000 [1:00:36<2082:32:02,  7.60s/it, lr=1e-5, step_loss=0.0583]Steps:   1%|▏         | 13398/1000000 [1:00:49<2574:00:15,  9.39s/it, lr=1e-5, step_loss=0.0583][RANK-0]: Step: [13398], local_loss=0.01830042526125908, train_loss=0.04398070275783539, time_cost=4.361066579818726
Steps:   1%|▏         | 13398/1000000 [1:00:49<2574:00:15,  9.39s/it, lr=1e-5, step_loss=0.0183]Steps:   1%|▏         | 13399/1000000 [1:00:57<2450:28:59,  8.94s/it, lr=1e-5, step_loss=0.0183][RANK-0]: Step: [13399], local_loss=0.014929658733308315, train_loss=0.22068187594413757, time_cost=2.3745977878570557
Steps:   1%|▏         | 13399/1000000 [1:00:57<2450:28:59,  8.94s/it, lr=1e-5, step_loss=0.0149]Steps:   1%|▏         | 13400/1000000 [1:01:03<2223:34:54,  8.11s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [13400], local_loss=0.04520266875624657, train_loss=0.029418999329209328, time_cost=1.5569522380828857
Steps:   1%|▏         | 13400/1000000 [1:01:03<2223:34:54,  8.11s/it, lr=1e-5, step_loss=0.0452]Steps:   1%|▏         | 13401/1000000 [1:01:13<2372:46:14,  8.66s/it, lr=1e-5, step_loss=0.0452][RANK-0]: Step: [13401], local_loss=0.01987704634666443, train_loss=0.04367604851722717, time_cost=1.5681984424591064
Steps:   1%|▏         | 13401/1000000 [1:01:13<2372:46:14,  8.66s/it, lr=1e-5, step_loss=0.0199]Steps:   1%|▏         | 13402/1000000 [1:01:24<2559:50:44,  9.34s/it, lr=1e-5, step_loss=0.0199][RANK-0]: Step: [13402], local_loss=0.03814798966050148, train_loss=0.021018000319600105, time_cost=7.819523096084595
Steps:   1%|▏         | 13402/1000000 [1:01:24<2559:50:44,  9.34s/it, lr=1e-5, step_loss=0.0381]Steps:   1%|▏         | 13403/1000000 [1:01:31<2381:50:43,  8.69s/it, lr=1e-5, step_loss=0.0381][RANK-0]: Step: [13403], local_loss=0.040169019252061844, train_loss=0.06764864176511765, time_cost=1.411731481552124
Steps:   1%|▏         | 13403/1000000 [1:01:31<2381:50:43,  8.69s/it, lr=1e-5, step_loss=0.0402]Steps:   1%|▏         | 13404/1000000 [1:01:40<2362:23:40,  8.62s/it, lr=1e-5, step_loss=0.0402][RANK-0]: Step: [13404], local_loss=0.02446884661912918, train_loss=0.10064812004566193, time_cost=3.2313289642333984
Steps:   1%|▏         | 13404/1000000 [1:01:40<2362:23:40,  8.62s/it, lr=1e-5, step_loss=0.0245]Steps:   1%|▏         | 13405/1000000 [1:01:47<2214:24:23,  8.08s/it, lr=1e-5, step_loss=0.0245][RANK-0]: Step: [13405], local_loss=0.0499863363802433, train_loss=0.03861695155501366, time_cost=4.092482089996338
Steps:   1%|▏         | 13405/1000000 [1:01:47<2214:24:23,  8.08s/it, lr=1e-5, step_loss=0.05]  Steps:   1%|▏         | 13406/1000000 [1:01:58<2483:52:03,  9.06s/it, lr=1e-5, step_loss=0.05][RANK-0]: Step: [13406], local_loss=0.06053977087140083, train_loss=0.028553897514939308, time_cost=1.4095499515533447
Steps:   1%|▏         | 13406/1000000 [1:01:58<2483:52:03,  9.06s/it, lr=1e-5, step_loss=0.0605]Steps:   1%|▏         | 13407/1000000 [1:02:02<2109:47:09,  7.70s/it, lr=1e-5, step_loss=0.0605][RANK-0]: Step: [13407], local_loss=0.02082095853984356, train_loss=0.017203906551003456, time_cost=1.7036778926849365
Steps:   1%|▏         | 13407/1000000 [1:02:02<2109:47:09,  7.70s/it, lr=1e-5, step_loss=0.0208]Steps:   1%|▏         | 13408/1000000 [1:02:13<2349:27:44,  8.57s/it, lr=1e-5, step_loss=0.0208][RANK-0]: Step: [13408], local_loss=0.12504081428050995, train_loss=0.04624281823635101, time_cost=1.2161426544189453
Steps:   1%|▏         | 13408/1000000 [1:02:13<2349:27:44,  8.57s/it, lr=1e-5, step_loss=0.125] Steps:   1%|▏         | 13409/1000000 [1:02:26<2721:16:38,  9.93s/it, lr=1e-5, step_loss=0.125][RANK-0]: Step: [13409], local_loss=0.007445784285664558, train_loss=0.01663006655871868, time_cost=3.7761425971984863
Steps:   1%|▏         | 13409/1000000 [1:02:26<2721:16:38,  9.93s/it, lr=1e-5, step_loss=0.00745]Steps:   1%|▏         | 13410/1000000 [1:02:35<2598:25:14,  9.48s/it, lr=1e-5, step_loss=0.00745][RANK-0]: Step: [13410], local_loss=0.014580187387764454, train_loss=0.2640576958656311, time_cost=1.6262142658233643
Steps:   1%|▏         | 13410/1000000 [1:02:35<2598:25:14,  9.48s/it, lr=1e-5, step_loss=0.0146] Steps:   1%|▏         | 13411/1000000 [1:02:42<2394:48:07,  8.74s/it, lr=1e-5, step_loss=0.0146][RANK-0]: Step: [13411], local_loss=0.0389036163687706, train_loss=0.019887376576662064, time_cost=2.7340242862701416
Steps:   1%|▏         | 13411/1000000 [1:02:42<2394:48:07,  8.74s/it, lr=1e-5, step_loss=0.0389]Steps:   1%|▏         | 13412/1000000 [1:02:56<2834:09:11, 10.34s/it, lr=1e-5, step_loss=0.0389][RANK-0]: Step: [13412], local_loss=0.03187441825866699, train_loss=0.15637657046318054, time_cost=4.434034824371338
Steps:   1%|▏         | 13412/1000000 [1:02:56<2834:09:11, 10.34s/it, lr=1e-5, step_loss=0.0319]Steps:   1%|▏         | 13413/1000000 [1:03:07<2886:16:16, 10.53s/it, lr=1e-5, step_loss=0.0319][RANK-0]: Step: [13413], local_loss=0.01521142665296793, train_loss=0.03691333532333374, time_cost=2.227590322494507
Steps:   1%|▏         | 13413/1000000 [1:03:07<2886:16:16, 10.53s/it, lr=1e-5, step_loss=0.0152]Steps:   1%|▏         | 13414/1000000 [1:03:18<2975:25:01, 10.86s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [13414], local_loss=0.025149138644337654, train_loss=0.018655460327863693, time_cost=2.8614368438720703
Steps:   1%|▏         | 13414/1000000 [1:03:18<2975:25:01, 10.86s/it, lr=1e-5, step_loss=0.0251]Steps:   1%|▏         | 13415/1000000 [1:03:29<3003:42:43, 10.96s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [13415], local_loss=0.007679829839617014, train_loss=0.04139535501599312, time_cost=1.2413816452026367
Steps:   1%|▏         | 13415/1000000 [1:03:29<3003:42:43, 10.96s/it, lr=1e-5, step_loss=0.00768]Steps:   1%|▏         | 13416/1000000 [1:03:40<2941:13:59, 10.73s/it, lr=1e-5, step_loss=0.00768][RANK-0]: Step: [13416], local_loss=0.3926008343696594, train_loss=0.07707295566797256, time_cost=4.5992913246154785
Steps:   1%|▏         | 13416/1000000 [1:03:40<2941:13:59, 10.73s/it, lr=1e-5, step_loss=0.393]  Steps:   1%|▏         | 13417/1000000 [1:03:45<2489:38:42,  9.08s/it, lr=1e-5, step_loss=0.393][RANK-0]: Step: [13417], local_loss=0.013426109217107296, train_loss=0.0401192270219326, time_cost=2.1638379096984863
Steps:   1%|▏         | 13417/1000000 [1:03:45<2489:38:42,  9.08s/it, lr=1e-5, step_loss=0.0134]Steps:   1%|▏         | 13418/1000000 [1:03:54<2460:21:01,  8.98s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [13418], local_loss=0.03932974487543106, train_loss=0.01973990723490715, time_cost=1.5112485885620117
Steps:   1%|▏         | 13418/1000000 [1:03:54<2460:21:01,  8.98s/it, lr=1e-5, step_loss=0.0393]Steps:   1%|▏         | 13419/1000000 [1:04:08<2894:41:24, 10.56s/it, lr=1e-5, step_loss=0.0393][RANK-0]: Step: [13419], local_loss=0.012399469502270222, train_loss=0.04070045053958893, time_cost=4.944052219390869
Steps:   1%|▏         | 13419/1000000 [1:04:08<2894:41:24, 10.56s/it, lr=1e-5, step_loss=0.0124]Steps:   1%|▏         | 13420/1000000 [1:04:26<3544:45:09, 12.93s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [13420], local_loss=0.0083867646753788, train_loss=0.0622248612344265, time_cost=9.73266077041626
Steps:   1%|▏         | 13420/1000000 [1:04:26<3544:45:09, 12.93s/it, lr=1e-5, step_loss=0.00839]Steps:   1%|▏         | 13421/1000000 [1:04:32<2956:36:09, 10.79s/it, lr=1e-5, step_loss=0.00839][RANK-0]: Step: [13421], local_loss=0.028450682759284973, train_loss=0.0609433688223362, time_cost=2.4317891597747803
Steps:   1%|▏         | 13421/1000000 [1:04:32<2956:36:09, 10.79s/it, lr=1e-5, step_loss=0.0285] Steps:   1%|▏         | 13422/1000000 [1:04:47<3319:36:15, 12.11s/it, lr=1e-5, step_loss=0.0285][RANK-0]: Step: [13422], local_loss=0.030676597729325294, train_loss=0.035663001239299774, time_cost=6.660227298736572
Steps:   1%|▏         | 13422/1000000 [1:04:47<3319:36:15, 12.11s/it, lr=1e-5, step_loss=0.0307]Steps:   1%|▏         | 13423/1000000 [1:05:00<3328:46:37, 12.15s/it, lr=1e-5, step_loss=0.0307][RANK-0]: Step: [13423], local_loss=0.007248851470649242, train_loss=0.07775641977787018, time_cost=3.1849217414855957
Steps:   1%|▏         | 13423/1000000 [1:05:00<3328:46:37, 12.15s/it, lr=1e-5, step_loss=0.00725]Steps:   1%|▏         | 13424/1000000 [1:05:05<2807:59:42, 10.25s/it, lr=1e-5, step_loss=0.00725][RANK-0]: Step: [13424], local_loss=0.017919132485985756, train_loss=0.015421522781252861, time_cost=1.4149558544158936
Steps:   1%|▏         | 13424/1000000 [1:05:05<2807:59:42, 10.25s/it, lr=1e-5, step_loss=0.0179] Steps:   1%|▏         | 13425/1000000 [1:05:11<2412:29:05,  8.80s/it, lr=1e-5, step_loss=0.0179][RANK-0]: Step: [13425], local_loss=0.032874319702386856, train_loss=0.037880443036556244, time_cost=2.9946932792663574
Steps:   1%|▏         | 13425/1000000 [1:05:11<2412:29:05,  8.80s/it, lr=1e-5, step_loss=0.0329]Steps:   1%|▏         | 13426/1000000 [1:05:25<2821:19:06, 10.29s/it, lr=1e-5, step_loss=0.0329][RANK-0]: Step: [13426], local_loss=0.2733602523803711, train_loss=0.1749114990234375, time_cost=5.941072702407837
Steps:   1%|▏         | 13426/1000000 [1:05:25<2821:19:06, 10.29s/it, lr=1e-5, step_loss=0.273] Steps:   1%|▏         | 13427/1000000 [1:05:40<3265:56:13, 11.92s/it, lr=1e-5, step_loss=0.273][RANK-0]: Step: [13427], local_loss=0.018469523638486862, train_loss=0.01541188731789589, time_cost=7.081875562667847
Steps:   1%|▏         | 13427/1000000 [1:05:40<3265:56:13, 11.92s/it, lr=1e-5, step_loss=0.0185]Steps:   1%|▏         | 13428/1000000 [1:05:48<2897:18:34, 10.57s/it, lr=1e-5, step_loss=0.0185][RANK-0]: Step: [13428], local_loss=0.062484100461006165, train_loss=0.03922051563858986, time_cost=1.3582870960235596
Steps:   1%|▏         | 13428/1000000 [1:05:48<2897:18:34, 10.57s/it, lr=1e-5, step_loss=0.0625]Steps:   1%|▏         | 13429/1000000 [1:05:56<2733:36:03,  9.97s/it, lr=1e-5, step_loss=0.0625][RANK-0]: Step: [13429], local_loss=0.14889773726463318, train_loss=0.0936734527349472, time_cost=1.480560541152954
Steps:   1%|▏         | 13429/1000000 [1:05:56<2733:36:03,  9.97s/it, lr=1e-5, step_loss=0.149] Steps:   1%|▏         | 13430/1000000 [1:06:13<3296:13:04, 12.03s/it, lr=1e-5, step_loss=0.149][RANK-0]: Step: [13430], local_loss=0.022045768797397614, train_loss=0.024541834369301796, time_cost=14.242629766464233
Steps:   1%|▏         | 13430/1000000 [1:06:13<3296:13:04, 12.03s/it, lr=1e-5, step_loss=0.022]Steps:   1%|▏         | 13431/1000000 [1:06:18<2723:09:33,  9.94s/it, lr=1e-5, step_loss=0.022][RANK-0]: Step: [13431], local_loss=0.07407911866903305, train_loss=0.037950240075588226, time_cost=1.789142370223999
Steps:   1%|▏         | 13431/1000000 [1:06:18<2723:09:33,  9.94s/it, lr=1e-5, step_loss=0.0741]Steps:   1%|▏         | 13432/1000000 [1:06:25<2490:03:54,  9.09s/it, lr=1e-5, step_loss=0.0741][RANK-0]: Step: [13432], local_loss=0.18828965723514557, train_loss=0.06866196542978287, time_cost=2.923959732055664
Steps:   1%|▏         | 13432/1000000 [1:06:25<2490:03:54,  9.09s/it, lr=1e-5, step_loss=0.188] Steps:   1%|▏         | 13433/1000000 [1:06:32<2304:34:15,  8.41s/it, lr=1e-5, step_loss=0.188][RANK-0]: Step: [13433], local_loss=0.03707019239664078, train_loss=0.05139297991991043, time_cost=2.082620859146118
Steps:   1%|▏         | 13433/1000000 [1:06:32<2304:34:15,  8.41s/it, lr=1e-5, step_loss=0.0371]Steps:   1%|▏         | 13434/1000000 [1:06:40<2291:45:10,  8.36s/it, lr=1e-5, step_loss=0.0371][RANK-0]: Step: [13434], local_loss=0.016176434233784676, train_loss=32.80952453613281, time_cost=7.181689739227295
Steps:   1%|▏         | 13434/1000000 [1:06:40<2291:45:10,  8.36s/it, lr=1e-5, step_loss=0.0162]Steps:   1%|▏         | 13435/1000000 [1:06:48<2192:42:23,  8.00s/it, lr=1e-5, step_loss=0.0162][RANK-0]: Step: [13435], local_loss=0.05516984686255455, train_loss=0.05498719960451126, time_cost=1.4438543319702148
Steps:   1%|▏         | 13435/1000000 [1:06:48<2192:42:23,  8.00s/it, lr=1e-5, step_loss=0.0552]Steps:   1%|▏         | 13436/1000000 [1:06:55<2132:14:08,  7.78s/it, lr=1e-5, step_loss=0.0552][RANK-0]: Step: [13436], local_loss=0.01519696693867445, train_loss=0.04781854897737503, time_cost=2.5932843685150146
Steps:   1%|▏         | 13436/1000000 [1:06:55<2132:14:08,  7.78s/it, lr=1e-5, step_loss=0.0152]Steps:   1%|▏         | 13437/1000000 [1:07:06<2438:55:55,  8.90s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [13437], local_loss=0.10526491701602936, train_loss=0.16375082731246948, time_cost=2.04752779006958
Steps:   1%|▏         | 13437/1000000 [1:07:06<2438:55:55,  8.90s/it, lr=1e-5, step_loss=0.105] Steps:   1%|▏         | 13438/1000000 [1:07:15<2436:19:05,  8.89s/it, lr=1e-5, step_loss=0.105][RANK-0]: Step: [13438], local_loss=0.006354304030537605, train_loss=0.04539300128817558, time_cost=1.2842450141906738
Steps:   1%|▏         | 13438/1000000 [1:07:15<2436:19:05,  8.89s/it, lr=1e-5, step_loss=0.00635]Steps:   1%|▏         | 13439/1000000 [1:07:20<2125:44:30,  7.76s/it, lr=1e-5, step_loss=0.00635][RANK-0]: Step: [13439], local_loss=0.06425725668668747, train_loss=0.028269357979297638, time_cost=4.378046274185181
Steps:   1%|▏         | 13439/1000000 [1:07:20<2125:44:30,  7.76s/it, lr=1e-5, step_loss=0.0643] Steps:   1%|▏         | 13440/1000000 [1:07:26<1975:43:29,  7.21s/it, lr=1e-5, step_loss=0.0643][RANK-0]: Step: [13440], local_loss=0.024249164387583733, train_loss=0.025916853919625282, time_cost=1.5114312171936035
Steps:   1%|▏         | 13440/1000000 [1:07:26<1975:43:29,  7.21s/it, lr=1e-5, step_loss=0.0242]Steps:   1%|▏         | 13441/1000000 [1:07:40<2527:43:14,  9.22s/it, lr=1e-5, step_loss=0.0242][RANK-0]: Step: [13441], local_loss=0.172204852104187, train_loss=0.0772193893790245, time_cost=2.7295024394989014
Steps:   1%|▏         | 13441/1000000 [1:07:40<2527:43:14,  9.22s/it, lr=1e-5, step_loss=0.172] Steps:   1%|▏         | 13442/1000000 [1:07:51<2688:15:18,  9.81s/it, lr=1e-5, step_loss=0.172][RANK-0]: Step: [13442], local_loss=0.024368636310100555, train_loss=0.027115536853671074, time_cost=2.54191255569458
Steps:   1%|▏         | 13442/1000000 [1:07:51<2688:15:18,  9.81s/it, lr=1e-5, step_loss=0.0244]Steps:   1%|▏         | 13443/1000000 [1:07:57<2329:52:39,  8.50s/it, lr=1e-5, step_loss=0.0244][RANK-0]: Step: [13443], local_loss=0.004216600209474564, train_loss=0.017986886203289032, time_cost=2.0832302570343018
Steps:   1%|▏         | 13443/1000000 [1:07:57<2329:52:39,  8.50s/it, lr=1e-5, step_loss=0.00422]Steps:   1%|▏         | 13444/1000000 [1:08:11<2786:12:59, 10.17s/it, lr=1e-5, step_loss=0.00422][RANK-0]: Step: [13444], local_loss=0.025516433641314507, train_loss=0.07759125530719757, time_cost=1.3235478401184082
Steps:   1%|▏         | 13444/1000000 [1:08:11<2786:12:59, 10.17s/it, lr=1e-5, step_loss=0.0255] Steps:   1%|▏         | 13445/1000000 [1:08:21<2774:00:56, 10.12s/it, lr=1e-5, step_loss=0.0255][RANK-0]: Step: [13445], local_loss=0.0274177398532629, train_loss=0.061729416251182556, time_cost=3.270811080932617
Steps:   1%|▏         | 13445/1000000 [1:08:21<2774:00:56, 10.12s/it, lr=1e-5, step_loss=0.0274]Steps:   1%|▏         | 13446/1000000 [1:08:30<2707:12:18,  9.88s/it, lr=1e-5, step_loss=0.0274][RANK-0]: Step: [13446], local_loss=0.029917854815721512, train_loss=0.06421303749084473, time_cost=2.016934394836426
Steps:   1%|▏         | 13446/1000000 [1:08:30<2707:12:18,  9.88s/it, lr=1e-5, step_loss=0.0299]Steps:   1%|▏         | 13447/1000000 [1:08:36<2401:39:49,  8.76s/it, lr=1e-5, step_loss=0.0299][RANK-0]: Step: [13447], local_loss=0.31477823853492737, train_loss=0.10013383626937866, time_cost=1.3234570026397705
Steps:   1%|▏         | 13447/1000000 [1:08:36<2401:39:49,  8.76s/it, lr=1e-5, step_loss=0.315] Steps:   1%|▏         | 13448/1000000 [1:08:47<2599:14:58,  9.48s/it, lr=1e-5, step_loss=0.315][RANK-0]: Step: [13448], local_loss=0.08251605182886124, train_loss=0.10633190721273422, time_cost=2.8150486946105957
Steps:   1%|▏         | 13448/1000000 [1:08:47<2599:14:58,  9.48s/it, lr=1e-5, step_loss=0.0825]Steps:   1%|▏         | 13449/1000000 [1:08:59<2753:02:49, 10.05s/it, lr=1e-5, step_loss=0.0825][RANK-0]: Step: [13449], local_loss=0.006495151203125715, train_loss=0.01513778604567051, time_cost=1.9726784229278564
Steps:   1%|▏         | 13449/1000000 [1:08:59<2753:02:49, 10.05s/it, lr=1e-5, step_loss=0.0065]Steps:   1%|▏         | 13450/1000000 [1:09:04<2342:56:58,  8.55s/it, lr=1e-5, step_loss=0.0065][RANK-0]: Step: [13450], local_loss=0.03894970566034317, train_loss=0.04564206302165985, time_cost=1.8264243602752686
Steps:   1%|▏         | 13450/1000000 [1:09:04<2342:56:58,  8.55s/it, lr=1e-5, step_loss=0.0389]Steps:   1%|▏         | 13451/1000000 [1:09:11<2196:30:22,  8.02s/it, lr=1e-5, step_loss=0.0389][RANK-0]: Step: [13451], local_loss=0.3929636478424072, train_loss=0.13453862071037292, time_cost=4.89240574836731
Steps:   1%|▏         | 13451/1000000 [1:09:11<2196:30:22,  8.02s/it, lr=1e-5, step_loss=0.393] Steps:   1%|▏         | 13452/1000000 [1:09:22<2473:44:14,  9.03s/it, lr=1e-5, step_loss=0.393][RANK-0]: Step: [13452], local_loss=0.08991958945989609, train_loss=0.04613839089870453, time_cost=2.65274715423584
Steps:   1%|▏         | 13452/1000000 [1:09:22<2473:44:14,  9.03s/it, lr=1e-5, step_loss=0.0899]Steps:   1%|▏         | 13453/1000000 [1:09:34<2747:06:12, 10.02s/it, lr=1e-5, step_loss=0.0899][RANK-0]: Step: [13453], local_loss=0.02387641742825508, train_loss=0.01821312867105007, time_cost=4.851022720336914
Steps:   1%|▏         | 13453/1000000 [1:09:34<2747:06:12, 10.02s/it, lr=1e-5, step_loss=0.0239]Steps:   1%|▏         | 13454/1000000 [1:09:50<3175:08:21, 11.59s/it, lr=1e-5, step_loss=0.0239][RANK-0]: Step: [13454], local_loss=0.07020364701747894, train_loss=0.032888263463974, time_cost=5.270947694778442
Steps:   1%|▏         | 13454/1000000 [1:09:50<3175:08:21, 11.59s/it, lr=1e-5, step_loss=0.0702]Steps:   1%|▏         | 13455/1000000 [1:10:02<3248:16:19, 11.85s/it, lr=1e-5, step_loss=0.0702][RANK-0]: Step: [13455], local_loss=0.011015107855200768, train_loss=0.057356689125299454, time_cost=4.468997955322266
Steps:   1%|▏         | 13455/1000000 [1:10:02<3248:16:19, 11.85s/it, lr=1e-5, step_loss=0.011] Steps:   1%|▏         | 13456/1000000 [1:10:09<2875:33:12, 10.49s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [13456], local_loss=0.011571062728762627, train_loss=0.02337290160357952, time_cost=1.3196706771850586
Steps:   1%|▏         | 13456/1000000 [1:10:09<2875:33:12, 10.49s/it, lr=1e-5, step_loss=0.0116]Steps:   1%|▏         | 13457/1000000 [1:10:14<2378:07:58,  8.68s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [13457], local_loss=0.024676410481333733, train_loss=0.041536152362823486, time_cost=1.3240666389465332
Steps:   1%|▏         | 13457/1000000 [1:10:14<2378:07:58,  8.68s/it, lr=1e-5, step_loss=0.0247]Steps:   1%|▏         | 13458/1000000 [1:10:28<2822:30:17, 10.30s/it, lr=1e-5, step_loss=0.0247][RANK-0]: Step: [13458], local_loss=0.07060454040765762, train_loss=0.030306223779916763, time_cost=5.2901716232299805
Steps:   1%|▏         | 13458/1000000 [1:10:28<2822:30:17, 10.30s/it, lr=1e-5, step_loss=0.0706]Steps:   1%|▏         | 13459/1000000 [1:10:42<3170:24:54, 11.57s/it, lr=1e-5, step_loss=0.0706][RANK-0]: Step: [13459], local_loss=0.03112248331308365, train_loss=0.051696911454200745, time_cost=5.829628944396973
Steps:   1%|▏         | 13459/1000000 [1:10:42<3170:24:54, 11.57s/it, lr=1e-5, step_loss=0.0311]Steps:   1%|▏         | 13460/1000000 [1:10:52<2995:35:15, 10.93s/it, lr=1e-5, step_loss=0.0311][RANK-0]: Step: [13460], local_loss=0.010440787300467491, train_loss=0.013565733097493649, time_cost=4.139368772506714
Steps:   1%|▏         | 13460/1000000 [1:10:52<2995:35:15, 10.93s/it, lr=1e-5, step_loss=0.0104]Steps:   1%|▏         | 13461/1000000 [1:11:03<3014:09:34, 11.00s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [13461], local_loss=145.44522094726562, train_loss=18.205745697021484, time_cost=1.240164041519165
Steps:   1%|▏         | 13461/1000000 [1:11:03<3014:09:34, 11.00s/it, lr=1e-5, step_loss=145]   Steps:   1%|▏         | 13462/1000000 [1:11:10<2677:28:32,  9.77s/it, lr=1e-5, step_loss=145][RANK-0]: Step: [13462], local_loss=0.07776476442813873, train_loss=0.07336530089378357, time_cost=2.666696548461914
Steps:   1%|▏         | 13462/1000000 [1:11:10<2677:28:32,  9.77s/it, lr=1e-5, step_loss=0.0778]Steps:   1%|▏         | 13463/1000000 [1:11:28<3351:40:52, 12.23s/it, lr=1e-5, step_loss=0.0778][RANK-0]: Step: [13463], local_loss=0.035174909979104996, train_loss=0.10648418217897415, time_cost=2.39044451713562
Steps:   1%|▏         | 13463/1000000 [1:11:28<3351:40:52, 12.23s/it, lr=1e-5, step_loss=0.0352]Steps:   1%|▏         | 13464/1000000 [1:11:33<2770:37:13, 10.11s/it, lr=1e-5, step_loss=0.0352][RANK-0]: Step: [13464], local_loss=0.0077007003128528595, train_loss=0.04158441722393036, time_cost=2.380465030670166
Steps:   1%|▏         | 13464/1000000 [1:11:33<2770:37:13, 10.11s/it, lr=1e-5, step_loss=0.0077]Steps:   1%|▏         | 13465/1000000 [1:11:46<3028:11:33, 11.05s/it, lr=1e-5, step_loss=0.0077][RANK-0]: Step: [13465], local_loss=0.010959434323012829, train_loss=0.04304429516196251, time_cost=3.4604055881500244
Steps:   1%|▏         | 13465/1000000 [1:11:46<3028:11:33, 11.05s/it, lr=1e-5, step_loss=0.011] Steps:   1%|▏         | 13466/1000000 [1:11:56<2893:46:33, 10.56s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [13466], local_loss=0.008379964157938957, train_loss=0.05783399939537048, time_cost=2.1544501781463623
Steps:   1%|▏         | 13466/1000000 [1:11:56<2893:46:33, 10.56s/it, lr=1e-5, step_loss=0.00838]Steps:   1%|▏         | 13467/1000000 [1:12:01<2448:10:59,  8.93s/it, lr=1e-5, step_loss=0.00838][RANK-0]: Step: [13467], local_loss=0.17421448230743408, train_loss=63.01335525512695, time_cost=1.2231040000915527
Steps:   1%|▏         | 13467/1000000 [1:12:01<2448:10:59,  8.93s/it, lr=1e-5, step_loss=0.174]  Steps:   1%|▏         | 13468/1000000 [1:12:08<2277:54:02,  8.31s/it, lr=1e-5, step_loss=0.174][RANK-0]: Step: [13468], local_loss=0.05589023232460022, train_loss=0.07840459793806076, time_cost=2.330594301223755
Steps:   1%|▏         | 13468/1000000 [1:12:08<2277:54:02,  8.31s/it, lr=1e-5, step_loss=0.0559]Steps:   1%|▏         | 13469/1000000 [1:12:19<2536:45:00,  9.26s/it, lr=1e-5, step_loss=0.0559][RANK-0]: Step: [13469], local_loss=0.03643672540783882, train_loss=0.10711498558521271, time_cost=3.538748264312744
Steps:   1%|▏         | 13469/1000000 [1:12:19<2536:45:00,  9.26s/it, lr=1e-5, step_loss=0.0364]Steps:   1%|▏         | 13470/1000000 [1:12:31<2746:30:09, 10.02s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [13470], local_loss=0.009278764016926289, train_loss=0.0403079092502594, time_cost=2.227555513381958
Steps:   1%|▏         | 13470/1000000 [1:12:31<2746:30:09, 10.02s/it, lr=1e-5, step_loss=0.00928]Steps:   1%|▏         | 13471/1000000 [1:12:42<2831:26:30, 10.33s/it, lr=1e-5, step_loss=0.00928][RANK-0]: Step: [13471], local_loss=0.025980714708566666, train_loss=0.039562925696372986, time_cost=1.244180679321289
Steps:   1%|▏         | 13471/1000000 [1:12:42<2831:26:30, 10.33s/it, lr=1e-5, step_loss=0.026]  Steps:   1%|▏         | 13472/1000000 [1:12:48<2447:22:35,  8.93s/it, lr=1e-5, step_loss=0.026][RANK-0]: Step: [13472], local_loss=0.038514383137226105, train_loss=0.25180375576019287, time_cost=1.2421250343322754
Steps:   1%|▏         | 13472/1000000 [1:12:48<2447:22:35,  8.93s/it, lr=1e-5, step_loss=0.0385]Steps:   1%|▏         | 13473/1000000 [1:12:52<2100:29:09,  7.67s/it, lr=1e-5, step_loss=0.0385][RANK-0]: Step: [13473], local_loss=0.007490531541407108, train_loss=0.039226457476615906, time_cost=2.271483898162842
Steps:   1%|▏         | 13473/1000000 [1:12:52<2100:29:09,  7.67s/it, lr=1e-5, step_loss=0.00749]Steps:   1%|▏         | 13474/1000000 [1:12:57<1834:22:06,  6.69s/it, lr=1e-5, step_loss=0.00749][RANK-0]: Step: [13474], local_loss=0.04528864100575447, train_loss=0.05077015236020088, time_cost=1.582387924194336
Steps:   1%|▏         | 13474/1000000 [1:12:57<1834:22:06,  6.69s/it, lr=1e-5, step_loss=0.0453] Steps:   1%|▏         | 13475/1000000 [1:13:02<1729:05:07,  6.31s/it, lr=1e-5, step_loss=0.0453][RANK-0]: Step: [13475], local_loss=0.007025555707514286, train_loss=0.034066349267959595, time_cost=2.2898449897766113
Steps:   1%|▏         | 13475/1000000 [1:13:02<1729:05:07,  6.31s/it, lr=1e-5, step_loss=0.00703]Steps:   1%|▏         | 13476/1000000 [1:13:15<2229:57:22,  8.14s/it, lr=1e-5, step_loss=0.00703][RANK-0]: Step: [13476], local_loss=0.07442154735326767, train_loss=0.04415661469101906, time_cost=3.053424596786499
Steps:   1%|▏         | 13476/1000000 [1:13:15<2229:57:22,  8.14s/it, lr=1e-5, step_loss=0.0744] Steps:   1%|▏         | 13477/1000000 [1:13:25<2432:15:20,  8.88s/it, lr=1e-5, step_loss=0.0744][RANK-0]: Step: [13477], local_loss=0.06249763444066048, train_loss=0.02724355086684227, time_cost=1.2134387493133545
Steps:   1%|▏         | 13477/1000000 [1:13:25<2432:15:20,  8.88s/it, lr=1e-5, step_loss=0.0625]Steps:   1%|▏         | 13478/1000000 [1:13:30<2052:04:24,  7.49s/it, lr=1e-5, step_loss=0.0625][RANK-0]: Step: [13478], local_loss=0.03631168603897095, train_loss=0.019536221399903297, time_cost=1.2938117980957031
Steps:   1%|▏         | 13478/1000000 [1:13:30<2052:04:24,  7.49s/it, lr=1e-5, step_loss=0.0363]Steps:   1%|▏         | 13479/1000000 [1:13:41<2397:28:27,  8.75s/it, lr=1e-5, step_loss=0.0363][RANK-0]: Step: [13479], local_loss=0.022229589521884918, train_loss=0.017340252175927162, time_cost=8.956727981567383
Steps:   1%|▏         | 13479/1000000 [1:13:41<2397:28:27,  8.75s/it, lr=1e-5, step_loss=0.0222]Steps:   1%|▏         | 13480/1000000 [1:13:46<2079:23:59,  7.59s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [13480], local_loss=0.0781027153134346, train_loss=0.037299156188964844, time_cost=1.245403528213501
Steps:   1%|▏         | 13480/1000000 [1:13:46<2079:23:59,  7.59s/it, lr=1e-5, step_loss=0.0781]Steps:   1%|▏         | 13481/1000000 [1:14:01<2646:34:09,  9.66s/it, lr=1e-5, step_loss=0.0781][RANK-0]: Step: [13481], local_loss=0.03694213181734085, train_loss=0.03324352577328682, time_cost=4.405088663101196
Steps:   1%|▏         | 13481/1000000 [1:14:01<2646:34:09,  9.66s/it, lr=1e-5, step_loss=0.0369]Steps:   1%|▏         | 13482/1000000 [1:14:06<2332:22:16,  8.51s/it, lr=1e-5, step_loss=0.0369][RANK-0]: Step: [13482], local_loss=0.0179352518171072, train_loss=0.02694975584745407, time_cost=3.042612075805664
Steps:   1%|▏         | 13482/1000000 [1:14:06<2332:22:16,  8.51s/it, lr=1e-5, step_loss=0.0179]Steps:   1%|▏         | 13483/1000000 [1:14:18<2542:20:25,  9.28s/it, lr=1e-5, step_loss=0.0179][RANK-0]: Step: [13483], local_loss=0.05038916692137718, train_loss=26.54259490966797, time_cost=4.580181837081909
Steps:   1%|▏         | 13483/1000000 [1:14:18<2542:20:25,  9.28s/it, lr=1e-5, step_loss=0.0504]||/||/|Steps:   1%|▏         | 13484/1000000 [1:14:28<2607:09:08,  9.51s/it, lr=1e-5, step_loss=0.0504][RANK-0]: Step: [13484], local_loss=0.006762497592717409, train_loss=0.050267599523067474, time_cost=1.2682929039001465
Steps:   1%|▏         | 13484/1000000 [1:14:28<2607:09:08,  9.51s/it, lr=1e-5, step_loss=0.00676]//-/|/-/Steps:   1%|▏         | 13485/1000000 [1:14:41<2942:37:54, 10.74s/it, lr=1e-5, step_loss=0.00676][RANK-0]: Step: [13485], local_loss=0.08640918135643005, train_loss=0.02978549711406231, time_cost=2.5366547107696533
Steps:   1%|▏         | 13485/1000000 [1:14:41<2942:37:54, 10.74s/it, lr=1e-5, step_loss=0.0864] Steps:   1%|▏         | 13486/1000000 [1:14:58<3404:41:30, 12.42s/it, lr=1e-5, step_loss=0.0864][RANK-0]: Step: [13486], local_loss=0.019935771822929382, train_loss=0.017678361386060715, time_cost=8.261767864227295
Steps:   1%|▏         | 13486/1000000 [1:14:58<3404:41:30, 12.42s/it, lr=1e-5, step_loss=0.0199]Steps:   1%|▏         | 13487/1000000 [1:15:04<2920:20:35, 10.66s/it, lr=1e-5, step_loss=0.0199][RANK-0]: Step: [13487], local_loss=1.0003952980041504, train_loss=0.13789281249046326, time_cost=1.2041471004486084
Steps:   1%|▏         | 13487/1000000 [1:15:04<2920:20:35, 10.66s/it, lr=1e-5, step_loss=1]     Steps:   1%|▏         | 13488/1000000 [1:15:10<2531:25:11,  9.24s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [13488], local_loss=0.02293170429766178, train_loss=0.04117806255817413, time_cost=1.531876802444458
Steps:   1%|▏         | 13488/1000000 [1:15:10<2531:25:11,  9.24s/it, lr=1e-5, step_loss=0.0229]Steps:   1%|▏         | 13489/1000000 [1:15:21<2691:03:57,  9.82s/it, lr=1e-5, step_loss=0.0229][RANK-0]: Step: [13489], local_loss=0.12880438566207886, train_loss=0.05084838718175888, time_cost=1.7156214714050293
Steps:   1%|▏         | 13489/1000000 [1:15:21<2691:03:57,  9.82s/it, lr=1e-5, step_loss=0.129] Steps:   1%|▏         | 13490/1000000 [1:15:29<2528:20:17,  9.23s/it, lr=1e-5, step_loss=0.129][RANK-0]: Step: [13490], local_loss=0.01214587315917015, train_loss=0.020175890997052193, time_cost=1.5786104202270508
Steps:   1%|▏         | 13490/1000000 [1:15:29<2528:20:17,  9.23s/it, lr=1e-5, step_loss=0.0121]Steps:   1%|▏         | 13491/1000000 [1:15:46<3178:33:38, 11.60s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [13491], local_loss=0.034356843680143356, train_loss=0.03220405802130699, time_cost=9.639241933822632
Steps:   1%|▏         | 13491/1000000 [1:15:46<3178:33:38, 11.60s/it, lr=1e-5, step_loss=0.0344]Steps:   1%|▏         | 13492/1000000 [1:15:51<2634:27:47,  9.61s/it, lr=1e-5, step_loss=0.0344][RANK-0]: Step: [13492], local_loss=0.010254329070448875, train_loss=0.02390408329665661, time_cost=2.0443167686462402
Steps:   1%|▏         | 13492/1000000 [1:15:51<2634:27:47,  9.61s/it, lr=1e-5, step_loss=0.0103]Steps:   1%|▏         | 13493/1000000 [1:15:57<2327:08:55,  8.49s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [13493], local_loss=0.043622273951768875, train_loss=0.03242401033639908, time_cost=1.3295061588287354
Steps:   1%|▏         | 13493/1000000 [1:15:57<2327:08:55,  8.49s/it, lr=1e-5, step_loss=0.0436]Steps:   1%|▏         | 13494/1000000 [1:16:04<2196:56:58,  8.02s/it, lr=1e-5, step_loss=0.0436][RANK-0]: Step: [13494], local_loss=0.20824414491653442, train_loss=0.08121237903833389, time_cost=3.8494186401367188
Steps:   1%|▏         | 13494/1000000 [1:16:04<2196:56:58,  8.02s/it, lr=1e-5, step_loss=0.208] Steps:   1%|▏         | 13495/1000000 [1:16:16<2515:56:45,  9.18s/it, lr=1e-5, step_loss=0.208][RANK-0]: Step: [13495], local_loss=0.07659745961427689, train_loss=0.06904137134552002, time_cost=3.7649996280670166
Steps:   1%|▏         | 13495/1000000 [1:16:16<2515:56:45,  9.18s/it, lr=1e-5, step_loss=0.0766]Steps:   1%|▏         | 13496/1000000 [1:16:23<2331:43:17,  8.51s/it, lr=1e-5, step_loss=0.0766][RANK-0]: Step: [13496], local_loss=0.01557248830795288, train_loss=0.02028432860970497, time_cost=2.046816349029541
Steps:   1%|▏         | 13496/1000000 [1:16:23<2331:43:17,  8.51s/it, lr=1e-5, step_loss=0.0156]Steps:   1%|▏         | 13497/1000000 [1:16:36<2689:20:17,  9.81s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [13497], local_loss=0.012823191471397877, train_loss=0.06567222625017166, time_cost=1.279653549194336
Steps:   1%|▏         | 13497/1000000 [1:16:36<2689:20:17,  9.81s/it, lr=1e-5, step_loss=0.0128]Steps:   1%|▏         | 13498/1000000 [1:16:45<2627:42:02,  9.59s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [13498], local_loss=0.014527659863233566, train_loss=0.04903150349855423, time_cost=2.826890707015991
Steps:   1%|▏         | 13498/1000000 [1:16:45<2627:42:02,  9.59s/it, lr=1e-5, step_loss=0.0145]Steps:   1%|▏         | 13499/1000000 [1:16:58<2926:19:42, 10.68s/it, lr=1e-5, step_loss=0.0145][RANK-0]: Step: [13499], local_loss=0.028670791536569595, train_loss=0.0602911040186882, time_cost=2.7523529529571533
Steps:   1%|▏         | 13499/1000000 [1:16:58<2926:19:42, 10.68s/it, lr=1e-5, step_loss=0.0287]Steps:   1%|▏         | 13500/1000000 [1:17:09<2949:10:14, 10.76s/it, lr=1e-5, step_loss=0.0287][RANK-0]: Step: [13500], local_loss=0.07678918540477753, train_loss=0.03560516983270645, time_cost=2.3127293586730957
Steps:   1%|▏         | 13500/1000000 [1:17:09<2949:10:14, 10.76s/it, lr=1e-5, step_loss=0.0768]Steps:   1%|▏         | 13501/1000000 [1:17:20<2970:32:11, 10.84s/it, lr=1e-5, step_loss=0.0768][RANK-0]: Step: [13501], local_loss=0.018153242766857147, train_loss=0.02459515631198883, time_cost=3.625596761703491
Steps:   1%|▏         | 13501/1000000 [1:17:20<2970:32:11, 10.84s/it, lr=1e-5, step_loss=0.0182]Steps:   1%|▏         | 13502/1000000 [1:17:25<2520:15:09,  9.20s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [13502], local_loss=0.06076524034142494, train_loss=0.18084953725337982, time_cost=1.9896702766418457
Steps:   1%|▏         | 13502/1000000 [1:17:25<2520:15:09,  9.20s/it, lr=1e-5, step_loss=0.0608]Steps:   1%|▏         | 13503/1000000 [1:17:32<2291:23:15,  8.36s/it, lr=1e-5, step_loss=0.0608][RANK-0]: Step: [13503], local_loss=0.023337136954069138, train_loss=0.040236085653305054, time_cost=1.2813355922698975
Steps:   1%|▏         | 13503/1000000 [1:17:32<2291:23:15,  8.36s/it, lr=1e-5, step_loss=0.0233]Steps:   1%|▏         | 13504/1000000 [1:17:41<2393:07:24,  8.73s/it, lr=1e-5, step_loss=0.0233][RANK-0]: Step: [13504], local_loss=0.021319802850484848, train_loss=0.1643945425748825, time_cost=3.3399975299835205
Steps:   1%|▏         | 13504/1000000 [1:17:41<2393:07:24,  8.73s/it, lr=1e-5, step_loss=0.0213]Steps:   1%|▏         | 13505/1000000 [1:17:47<2175:50:21,  7.94s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [13505], local_loss=0.05695595592260361, train_loss=0.03901471197605133, time_cost=1.6883418560028076
Steps:   1%|▏         | 13505/1000000 [1:17:47<2175:50:21,  7.94s/it, lr=1e-5, step_loss=0.057] Steps:   1%|▏         | 13506/1000000 [1:17:59<2472:08:18,  9.02s/it, lr=1e-5, step_loss=0.057][RANK-0]: Step: [13506], local_loss=0.04263490065932274, train_loss=0.017678624019026756, time_cost=2.260347843170166
Steps:   1%|▏         | 13506/1000000 [1:17:59<2472:08:18,  9.02s/it, lr=1e-5, step_loss=0.0426]Steps:   1%|▏         | 13507/1000000 [1:18:03<2074:30:00,  7.57s/it, lr=1e-5, step_loss=0.0426][RANK-0]: Step: [13507], local_loss=0.10694895684719086, train_loss=0.04344388097524643, time_cost=1.2790753841400146
Steps:   1%|▏         | 13507/1000000 [1:18:03<2074:30:00,  7.57s/it, lr=1e-5, step_loss=0.107] Steps:   1%|▏         | 13508/1000000 [1:18:10<2010:32:02,  7.34s/it, lr=1e-5, step_loss=0.107][RANK-0]: Step: [13508], local_loss=0.02612791582942009, train_loss=0.10584457218647003, time_cost=2.1338212490081787
Steps:   1%|▏         | 13508/1000000 [1:18:10<2010:32:02,  7.34s/it, lr=1e-5, step_loss=0.0261]Steps:   1%|▏         | 13509/1000000 [1:18:15<1828:27:38,  6.67s/it, lr=1e-5, step_loss=0.0261][RANK-0]: Step: [13509], local_loss=0.007091263309121132, train_loss=0.15227589011192322, time_cost=2.293788194656372
Steps:   1%|▏         | 13509/1000000 [1:18:15<1828:27:38,  6.67s/it, lr=1e-5, step_loss=0.00709]Steps:   1%|▏         | 13510/1000000 [1:18:20<1717:24:38,  6.27s/it, lr=1e-5, step_loss=0.00709][RANK-0]: Step: [13510], local_loss=0.08214671909809113, train_loss=0.07367546856403351, time_cost=3.207035541534424
Steps:   1%|▏         | 13510/1000000 [1:18:20<1717:24:38,  6.27s/it, lr=1e-5, step_loss=0.0821] Steps:   1%|▏         | 13511/1000000 [1:18:28<1819:42:48,  6.64s/it, lr=1e-5, step_loss=0.0821][RANK-0]: Step: [13511], local_loss=0.08467753976583481, train_loss=18.818492889404297, time_cost=1.6404848098754883
Steps:   1%|▏         | 13511/1000000 [1:18:28<1819:42:48,  6.64s/it, lr=1e-5, step_loss=0.0847]Steps:   1%|▏         | 13512/1000000 [1:18:34<1805:24:13,  6.59s/it, lr=1e-5, step_loss=0.0847][RANK-0]: Step: [13512], local_loss=0.0378742553293705, train_loss=0.01885201595723629, time_cost=2.7032949924468994
Steps:   1%|▏         | 13512/1000000 [1:18:34<1805:24:13,  6.59s/it, lr=1e-5, step_loss=0.0379]Steps:   1%|▏         | 13513/1000000 [1:18:40<1692:58:02,  6.18s/it, lr=1e-5, step_loss=0.0379][RANK-0]: Step: [13513], local_loss=0.021657461300492287, train_loss=0.030979469418525696, time_cost=1.2116124629974365
Steps:   1%|▏         | 13513/1000000 [1:18:40<1692:58:02,  6.18s/it, lr=1e-5, step_loss=0.0217]Steps:   1%|▏         | 13514/1000000 [1:18:50<2010:28:00,  7.34s/it, lr=1e-5, step_loss=0.0217][RANK-0]: Step: [13514], local_loss=0.09828627109527588, train_loss=0.0457051545381546, time_cost=4.240977048873901
Steps:   1%|▏         | 13514/1000000 [1:18:50<2010:28:00,  7.34s/it, lr=1e-5, step_loss=0.0983]Steps:   1%|▏         | 13515/1000000 [1:18:55<1844:35:45,  6.73s/it, lr=1e-5, step_loss=0.0983][RANK-0]: Step: [13515], local_loss=0.05152630805969238, train_loss=0.03728126734495163, time_cost=2.2323992252349854
Steps:   1%|▏         | 13515/1000000 [1:18:55<1844:35:45,  6.73s/it, lr=1e-5, step_loss=0.0515]Steps:   1%|▏         | 13516/1000000 [1:18:59<1650:33:30,  6.02s/it, lr=1e-5, step_loss=0.0515][RANK-0]: Step: [13516], local_loss=0.010977016761898994, train_loss=0.12276202440261841, time_cost=1.4882874488830566
Steps:   1%|▏         | 13516/1000000 [1:18:59<1650:33:30,  6.02s/it, lr=1e-5, step_loss=0.011] Steps:   1%|▏         | 13517/1000000 [1:19:05<1647:27:40,  6.01s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [13517], local_loss=0.024564852938055992, train_loss=0.03463781625032425, time_cost=1.671367883682251
Steps:   1%|▏         | 13517/1000000 [1:19:05<1647:27:40,  6.01s/it, lr=1e-5, step_loss=0.0246]Steps:   1%|▏         | 13518/1000000 [1:19:15<1941:39:23,  7.09s/it, lr=1e-5, step_loss=0.0246][RANK-0]: Step: [13518], local_loss=0.0070060668513178825, train_loss=0.10591447353363037, time_cost=2.1797521114349365
Steps:   1%|▏         | 13518/1000000 [1:19:15<1941:39:23,  7.09s/it, lr=1e-5, step_loss=0.00701]Steps:   1%|▏         | 13519/1000000 [1:19:24<2121:07:20,  7.74s/it, lr=1e-5, step_loss=0.00701][RANK-0]: Step: [13519], local_loss=0.06387892365455627, train_loss=0.05861004814505577, time_cost=3.2255077362060547
Steps:   1%|▏         | 13519/1000000 [1:19:24<2121:07:20,  7.74s/it, lr=1e-5, step_loss=0.0639] Steps:   1%|▏         | 13520/1000000 [1:19:30<1980:23:59,  7.23s/it, lr=1e-5, step_loss=0.0639][RANK-0]: Step: [13520], local_loss=0.012081848457455635, train_loss=0.027945848181843758, time_cost=1.3186514377593994
Steps:   1%|▏         | 13520/1000000 [1:19:30<1980:23:59,  7.23s/it, lr=1e-5, step_loss=0.0121]Steps:   1%|▏         | 13521/1000000 [1:19:37<1970:41:20,  7.19s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [13521], local_loss=0.009671962819993496, train_loss=0.024932604283094406, time_cost=2.8769123554229736
Steps:   1%|▏         | 13521/1000000 [1:19:37<1970:41:20,  7.19s/it, lr=1e-5, step_loss=0.00967]Steps:   1%|▏         | 13522/1000000 [1:19:48<2263:02:59,  8.26s/it, lr=1e-5, step_loss=0.00967][RANK-0]: Step: [13522], local_loss=0.01791446842253208, train_loss=0.0479484423995018, time_cost=5.3638739585876465
Steps:   1%|▏         | 13522/1000000 [1:19:48<2263:02:59,  8.26s/it, lr=1e-5, step_loss=0.0179] Steps:   1%|▏         | 13523/1000000 [1:19:55<2190:32:24,  7.99s/it, lr=1e-5, step_loss=0.0179][RANK-0]: Step: [13523], local_loss=0.08896106481552124, train_loss=0.2303117960691452, time_cost=1.5920085906982422
Steps:   1%|▏         | 13523/1000000 [1:19:55<2190:32:24,  7.99s/it, lr=1e-5, step_loss=0.089] Steps:   1%|▏         | 13524/1000000 [1:20:05<2309:44:02,  8.43s/it, lr=1e-5, step_loss=0.089][RANK-0]: Step: [13524], local_loss=0.061960369348526, train_loss=0.06470860540866852, time_cost=3.4117941856384277
Steps:   1%|▏         | 13524/1000000 [1:20:05<2309:44:02,  8.43s/it, lr=1e-5, step_loss=0.062]Steps:   1%|▏         | 13525/1000000 [1:20:10<2043:56:00,  7.46s/it, lr=1e-5, step_loss=0.062][RANK-0]: Step: [13525], local_loss=0.05926484242081642, train_loss=0.04549054056406021, time_cost=2.0794193744659424
Steps:   1%|▏         | 13525/1000000 [1:20:10<2043:56:00,  7.46s/it, lr=1e-5, step_loss=0.0593]Steps:   1%|▏         | 13526/1000000 [1:20:21<2346:51:00,  8.56s/it, lr=1e-5, step_loss=0.0593][RANK-0]: Step: [13526], local_loss=0.015361077152192593, train_loss=0.07941398024559021, time_cost=1.904160499572754
Steps:   1%|▏         | 13526/1000000 [1:20:21<2346:51:00,  8.56s/it, lr=1e-5, step_loss=0.0154]Steps:   1%|▏         | 13527/1000000 [1:20:34<2675:15:34,  9.76s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [13527], local_loss=0.05643894150853157, train_loss=0.06736813485622406, time_cost=2.4665770530700684
Steps:   1%|▏         | 13527/1000000 [1:20:34<2675:15:34,  9.76s/it, lr=1e-5, step_loss=0.0564]Steps:   1%|▏         | 13528/1000000 [1:20:44<2697:07:21,  9.84s/it, lr=1e-5, step_loss=0.0564][RANK-0]: Step: [13528], local_loss=0.007376055233180523, train_loss=0.038642510771751404, time_cost=3.5097222328186035
Steps:   1%|▏         | 13528/1000000 [1:20:44<2697:07:21,  9.84s/it, lr=1e-5, step_loss=0.00738]Steps:   1%|▏         | 13529/1000000 [1:20:57<3007:19:19, 10.97s/it, lr=1e-5, step_loss=0.00738][RANK-0]: Step: [13529], local_loss=0.024697743356227875, train_loss=0.34595799446105957, time_cost=5.433651447296143
Steps:   1%|▏         | 13529/1000000 [1:20:57<3007:19:19, 10.97s/it, lr=1e-5, step_loss=0.0247] Steps:   1%|▏         | 13530/1000000 [1:21:11<3201:32:34, 11.68s/it, lr=1e-5, step_loss=0.0247][RANK-0]: Step: [13530], local_loss=0.00617164745926857, train_loss=0.0214274600148201, time_cost=3.0830891132354736
Steps:   1%|▏         | 13530/1000000 [1:21:11<3201:32:34, 11.68s/it, lr=1e-5, step_loss=0.00617]Steps:   1%|▏         | 13531/1000000 [1:21:16<2668:12:09,  9.74s/it, lr=1e-5, step_loss=0.00617][RANK-0]: Step: [13531], local_loss=0.294655978679657, train_loss=0.10106628388166428, time_cost=1.2993834018707275
Steps:   1%|▏         | 13531/1000000 [1:21:16<2668:12:09,  9.74s/it, lr=1e-5, step_loss=0.295]  Steps:   1%|▏         | 13532/1000000 [1:21:27<2768:56:30, 10.10s/it, lr=1e-5, step_loss=0.295][RANK-0]: Step: [13532], local_loss=0.044595953077077866, train_loss=0.06720365583896637, time_cost=2.8912997245788574
Steps:   1%|▏         | 13532/1000000 [1:21:27<2768:56:30, 10.10s/it, lr=1e-5, step_loss=0.0446]Steps:   1%|▏         | 13533/1000000 [1:21:31<2295:51:54,  8.38s/it, lr=1e-5, step_loss=0.0446][RANK-0]: Step: [13533], local_loss=0.008885572664439678, train_loss=0.042855486273765564, time_cost=1.2913358211517334
Steps:   1%|▏         | 13533/1000000 [1:21:31<2295:51:54,  8.38s/it, lr=1e-5, step_loss=0.00889]Steps:   1%|▏         | 13534/1000000 [1:21:45<2714:21:51,  9.91s/it, lr=1e-5, step_loss=0.00889][RANK-0]: Step: [13534], local_loss=0.29790836572647095, train_loss=0.08268847316503525, time_cost=4.0549821853637695
Steps:   1%|▏         | 13534/1000000 [1:21:45<2714:21:51,  9.91s/it, lr=1e-5, step_loss=0.298]  Steps:   1%|▏         | 13535/1000000 [1:21:56<2840:09:08, 10.36s/it, lr=1e-5, step_loss=0.298][RANK-0]: Step: [13535], local_loss=0.010866482742130756, train_loss=0.04164379462599754, time_cost=3.690647840499878
Steps:   1%|▏         | 13535/1000000 [1:21:56<2840:09:08, 10.36s/it, lr=1e-5, step_loss=0.0109]Steps:   1%|▏         | 13536/1000000 [1:22:06<2828:19:05, 10.32s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [13536], local_loss=0.10009956359863281, train_loss=0.03721529245376587, time_cost=4.6367878913879395
Steps:   1%|▏         | 13536/1000000 [1:22:06<2828:19:05, 10.32s/it, lr=1e-5, step_loss=0.1]   Steps:   1%|▏         | 13537/1000000 [1:22:12<2426:12:09,  8.85s/it, lr=1e-5, step_loss=0.1][RANK-0]: Step: [13537], local_loss=0.007584104780107737, train_loss=0.03518504649400711, time_cost=2.145461320877075
Steps:   1%|▏         | 13537/1000000 [1:22:12<2426:12:09,  8.85s/it, lr=1e-5, step_loss=0.00758]Steps:   1%|▏         | 13538/1000000 [1:22:19<2257:07:10,  8.24s/it, lr=1e-5, step_loss=0.00758][RANK-0]: Step: [13538], local_loss=0.01852034218609333, train_loss=16.444406509399414, time_cost=2.147953987121582
Steps:   1%|▏         | 13538/1000000 [1:22:19<2257:07:10,  8.24s/it, lr=1e-5, step_loss=0.0185] Steps:   1%|▏         | 13539/1000000 [1:22:23<1961:22:14,  7.16s/it, lr=1e-5, step_loss=0.0185][RANK-0]: Step: [13539], local_loss=0.010879885405302048, train_loss=0.0403568372130394, time_cost=3.5872716903686523
Steps:   1%|▏         | 13539/1000000 [1:22:23<1961:22:14,  7.16s/it, lr=1e-5, step_loss=0.0109]Steps:   1%|▏         | 13540/1000000 [1:22:34<2279:51:05,  8.32s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [13540], local_loss=0.03739374503493309, train_loss=0.03591972216963768, time_cost=1.882869005203247
Steps:   1%|▏         | 13540/1000000 [1:22:34<2279:51:05,  8.32s/it, lr=1e-5, step_loss=0.0374]Steps:   1%|▏         | 13541/1000000 [1:22:43<2337:10:17,  8.53s/it, lr=1e-5, step_loss=0.0374][RANK-0]: Step: [13541], local_loss=0.012886463664472103, train_loss=0.07567234337329865, time_cost=6.588395357131958
Steps:   1%|▏         | 13541/1000000 [1:22:43<2337:10:17,  8.53s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 13542/1000000 [1:22:53<2399:17:42,  8.76s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [13542], local_loss=0.08386404812335968, train_loss=0.056719645857810974, time_cost=3.0393552780151367
Steps:   1%|▏         | 13542/1000000 [1:22:53<2399:17:42,  8.76s/it, lr=1e-5, step_loss=0.0839]Steps:   1%|▏         | 13543/1000000 [1:22:58<2111:35:54,  7.71s/it, lr=1e-5, step_loss=0.0839][RANK-0]: Step: [13543], local_loss=0.09219960123300552, train_loss=0.041891910135746, time_cost=3.1553447246551514
Steps:   1%|▏         | 13543/1000000 [1:22:58<2111:35:54,  7.71s/it, lr=1e-5, step_loss=0.0922]Steps:   1%|▏         | 13544/1000000 [1:23:10<2479:35:19,  9.05s/it, lr=1e-5, step_loss=0.0922][RANK-0]: Step: [13544], local_loss=0.04662865027785301, train_loss=0.04670669883489609, time_cost=1.210752010345459
Steps:   1%|▏         | 13544/1000000 [1:23:10<2479:35:19,  9.05s/it, lr=1e-5, step_loss=0.0466]Steps:   1%|▏         | 13545/1000000 [1:23:16<2210:22:42,  8.07s/it, lr=1e-5, step_loss=0.0466][RANK-0]: Step: [13545], local_loss=0.022356124594807625, train_loss=0.02857118658721447, time_cost=3.0753180980682373
Steps:   1%|▏         | 13545/1000000 [1:23:16<2210:22:42,  8.07s/it, lr=1e-5, step_loss=0.0224]Steps:   1%|▏         | 13546/1000000 [1:23:22<2056:51:06,  7.51s/it, lr=1e-5, step_loss=0.0224][RANK-0]: Step: [13546], local_loss=0.01905054599046707, train_loss=0.0399710014462471, time_cost=2.616689443588257
Steps:   1%|▏         | 13546/1000000 [1:23:22<2056:51:06,  7.51s/it, lr=1e-5, step_loss=0.0191]Steps:   1%|▏         | 13547/1000000 [1:23:30<2127:19:43,  7.76s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [13547], local_loss=0.04478845372796059, train_loss=0.0734330415725708, time_cost=2.164574384689331
Steps:   1%|▏         | 13547/1000000 [1:23:30<2127:19:43,  7.76s/it, lr=1e-5, step_loss=0.0448]Steps:   1%|▏         | 13548/1000000 [1:23:42<2440:51:18,  8.91s/it, lr=1e-5, step_loss=0.0448][RANK-0]: Step: [13548], local_loss=0.02180783450603485, train_loss=0.06082848459482193, time_cost=5.007571697235107
Steps:   1%|▏         | 13548/1000000 [1:23:42<2440:51:18,  8.91s/it, lr=1e-5, step_loss=0.0218]Steps:   1%|▏         | 13549/1000000 [1:23:55<2766:12:33, 10.10s/it, lr=1e-5, step_loss=0.0218][RANK-0]: Step: [13549], local_loss=0.012904969044029713, train_loss=0.12385768443346024, time_cost=6.0099828243255615
Steps:   1%|▏         | 13549/1000000 [1:23:55<2766:12:33, 10.10s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 13550/1000000 [1:24:00<2360:40:05,  8.62s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [13550], local_loss=0.10364852845668793, train_loss=0.043477773666381836, time_cost=1.2643215656280518
Steps:   1%|▏         | 13550/1000000 [1:24:00<2360:40:05,  8.62s/it, lr=1e-5, step_loss=0.104] Steps:   1%|▏         | 13551/1000000 [1:24:14<2795:02:06, 10.20s/it, lr=1e-5, step_loss=0.104][RANK-0]: Step: [13551], local_loss=0.03309439495205879, train_loss=0.030365465208888054, time_cost=3.3470065593719482
Steps:   1%|▏         | 13551/1000000 [1:24:14<2795:02:06, 10.20s/it, lr=1e-5, step_loss=0.0331]Steps:   1%|▏         | 13552/1000000 [1:24:24<2828:49:58, 10.32s/it, lr=1e-5, step_loss=0.0331][RANK-0]: Step: [13552], local_loss=0.5384688973426819, train_loss=0.11389186978340149, time_cost=1.930778980255127
Steps:   1%|▏         | 13552/1000000 [1:24:24<2828:49:58, 10.32s/it, lr=1e-5, step_loss=0.538] Steps:   1%|▏         | 13553/1000000 [1:24:30<2431:57:34,  8.88s/it, lr=1e-5, step_loss=0.538][RANK-0]: Step: [13553], local_loss=0.010410747490823269, train_loss=0.030582236126065254, time_cost=2.441148042678833
Steps:   1%|▏         | 13553/1000000 [1:24:30<2431:57:34,  8.88s/it, lr=1e-5, step_loss=0.0104]Steps:   1%|▏         | 13554/1000000 [1:24:37<2278:02:52,  8.31s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [13554], local_loss=0.015203110873699188, train_loss=0.14712998270988464, time_cost=1.917569637298584
Steps:   1%|▏         | 13554/1000000 [1:24:37<2278:02:52,  8.31s/it, lr=1e-5, step_loss=0.0152]Steps:   1%|▏         | 13555/1000000 [1:24:49<2569:17:56,  9.38s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [13555], local_loss=0.06938642263412476, train_loss=0.07082715630531311, time_cost=1.6910622119903564
Steps:   1%|▏         | 13555/1000000 [1:24:49<2569:17:56,  9.38s/it, lr=1e-5, step_loss=0.0694]Steps:   1%|▏         | 13556/1000000 [1:24:54<2233:55:59,  8.15s/it, lr=1e-5, step_loss=0.0694][RANK-0]: Step: [13556], local_loss=0.017687227576971054, train_loss=0.029077846556901932, time_cost=2.021012783050537
Steps:   1%|▏         | 13556/1000000 [1:24:54<2233:55:59,  8.15s/it, lr=1e-5, step_loss=0.0177]Steps:   1%|▏         | 13557/1000000 [1:25:03<2310:58:08,  8.43s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [13557], local_loss=0.006569851189851761, train_loss=0.034569986164569855, time_cost=3.7972843647003174
Steps:   1%|▏         | 13557/1000000 [1:25:03<2310:58:08,  8.43s/it, lr=1e-5, step_loss=0.00657]Steps:   1%|▏         | 13558/1000000 [1:25:16<2684:01:58,  9.80s/it, lr=1e-5, step_loss=0.00657][RANK-0]: Step: [13558], local_loss=0.006246811710298061, train_loss=0.02183774672448635, time_cost=5.08479642868042
Steps:   1%|▏         | 13558/1000000 [1:25:16<2684:01:58,  9.80s/it, lr=1e-5, step_loss=0.00625]Steps:   1%|▏         | 13559/1000000 [1:25:23<2454:13:48,  8.96s/it, lr=1e-5, step_loss=0.00625][RANK-0]: Step: [13559], local_loss=0.020867537707090378, train_loss=0.0643685832619667, time_cost=2.6174442768096924
Steps:   1%|▏         | 13559/1000000 [1:25:23<2454:13:48,  8.96s/it, lr=1e-5, step_loss=0.0209] Steps:   1%|▏         | 13560/1000000 [1:25:38<2930:07:42, 10.69s/it, lr=1e-5, step_loss=0.0209][RANK-0]: Step: [13560], local_loss=0.047534916549921036, train_loss=0.028591744601726532, time_cost=1.2117328643798828
Steps:   1%|▏         | 13560/1000000 [1:25:38<2930:07:42, 10.69s/it, lr=1e-5, step_loss=0.0475]Steps:   1%|▏         | 13561/1000000 [1:25:46<2733:52:16,  9.98s/it, lr=1e-5, step_loss=0.0475][RANK-0]: Step: [13561], local_loss=0.07666411995887756, train_loss=0.04567226022481918, time_cost=2.289416790008545
Steps:   1%|▏         | 13561/1000000 [1:25:46<2733:52:16,  9.98s/it, lr=1e-5, step_loss=0.0767]Steps:   1%|▏         | 13562/1000000 [1:25:53<2497:19:05,  9.11s/it, lr=1e-5, step_loss=0.0767][RANK-0]: Step: [13562], local_loss=0.057612281292676926, train_loss=0.04583393782377243, time_cost=2.5697951316833496
Steps:   1%|▏         | 13562/1000000 [1:25:53<2497:19:05,  9.11s/it, lr=1e-5, step_loss=0.0576]Steps:   1%|▏         | 13563/1000000 [1:26:04<2594:59:09,  9.47s/it, lr=1e-5, step_loss=0.0576][RANK-0]: Step: [13563], local_loss=0.008948611095547676, train_loss=0.03311866149306297, time_cost=4.8264970779418945
Steps:   1%|▏         | 13563/1000000 [1:26:04<2594:59:09,  9.47s/it, lr=1e-5, step_loss=0.00895]Steps:   1%|▏         | 13564/1000000 [1:26:14<2675:39:37,  9.76s/it, lr=1e-5, step_loss=0.00895][RANK-0]: Step: [13564], local_loss=0.022727997973561287, train_loss=0.04403404891490936, time_cost=2.8713760375976562
Steps:   1%|▏         | 13564/1000000 [1:26:14<2675:39:37,  9.76s/it, lr=1e-5, step_loss=0.0227] Steps:   1%|▏         | 13565/1000000 [1:26:22<2510:10:44,  9.16s/it, lr=1e-5, step_loss=0.0227][RANK-0]: Step: [13565], local_loss=0.010449697263538837, train_loss=0.034252382814884186, time_cost=3.03513765335083
Steps:   1%|▏         | 13565/1000000 [1:26:22<2510:10:44,  9.16s/it, lr=1e-5, step_loss=0.0104]Steps:   1%|▏         | 13566/1000000 [1:26:29<2322:21:47,  8.48s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [13566], local_loss=0.009560049511492252, train_loss=0.0808768942952156, time_cost=2.2973482608795166
Steps:   1%|▏         | 13566/1000000 [1:26:29<2322:21:47,  8.48s/it, lr=1e-5, step_loss=0.00956]Steps:   1%|▏         | 13567/1000000 [1:26:42<2694:55:44,  9.84s/it, lr=1e-5, step_loss=0.00956][RANK-0]: Step: [13567], local_loss=0.011594499461352825, train_loss=0.038776181638240814, time_cost=5.175064325332642
Steps:   1%|▏         | 13567/1000000 [1:26:42<2694:55:44,  9.84s/it, lr=1e-5, step_loss=0.0116] Steps:   1%|▏         | 13568/1000000 [1:26:53<2853:47:08, 10.41s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [13568], local_loss=0.007312936708331108, train_loss=0.02666979655623436, time_cost=3.4778354167938232
Steps:   1%|▏         | 13568/1000000 [1:26:53<2853:47:08, 10.41s/it, lr=1e-5, step_loss=0.00731]Steps:   1%|▏         | 13569/1000000 [1:27:05<2924:25:31, 10.67s/it, lr=1e-5, step_loss=0.00731][RANK-0]: Step: [13569], local_loss=0.02685626968741417, train_loss=0.05848403647542, time_cost=1.2518281936645508
Steps:   1%|▏         | 13569/1000000 [1:27:05<2924:25:31, 10.67s/it, lr=1e-5, step_loss=0.0269] Steps:   1%|▏         | 13570/1000000 [1:27:14<2770:12:28, 10.11s/it, lr=1e-5, step_loss=0.0269][RANK-0]: Step: [13570], local_loss=0.1368994265794754, train_loss=0.03895565867424011, time_cost=2.6095175743103027
Steps:   1%|▏         | 13570/1000000 [1:27:14<2770:12:28, 10.11s/it, lr=1e-5, step_loss=0.137] Steps:   1%|▏         | 13571/1000000 [1:27:27<3080:04:27, 11.24s/it, lr=1e-5, step_loss=0.137][RANK-0]: Step: [13571], local_loss=0.020042551681399345, train_loss=0.02258184924721718, time_cost=1.24021577835083
Steps:   1%|▏         | 13571/1000000 [1:27:27<3080:04:27, 11.24s/it, lr=1e-5, step_loss=0.02] Steps:   1%|▏         | 13572/1000000 [1:27:40<3156:42:22, 11.52s/it, lr=1e-5, step_loss=0.02][RANK-0]: Step: [13572], local_loss=0.08115807175636292, train_loss=0.07391180098056793, time_cost=2.524873733520508
Steps:   1%|▏         | 13572/1000000 [1:27:40<3156:42:22, 11.52s/it, lr=1e-5, step_loss=0.0812]Steps:   1%|▏         | 13573/1000000 [1:27:51<3174:23:22, 11.59s/it, lr=1e-5, step_loss=0.0812][RANK-0]: Step: [13573], local_loss=0.011445179581642151, train_loss=0.03889039158821106, time_cost=1.3392577171325684
Steps:   1%|▏         | 13573/1000000 [1:27:51<3174:23:22, 11.59s/it, lr=1e-5, step_loss=0.0114]Steps:   1%|▏         | 13574/1000000 [1:28:00<2975:33:20, 10.86s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [13574], local_loss=0.13295848667621613, train_loss=0.06316057592630386, time_cost=2.0233309268951416
Steps:   1%|▏         | 13574/1000000 [1:28:00<2975:33:20, 10.86s/it, lr=1e-5, step_loss=0.133] Steps:   1%|▏         | 13575/1000000 [1:28:09<2768:52:14, 10.11s/it, lr=1e-5, step_loss=0.133][RANK-0]: Step: [13575], local_loss=0.016432328149676323, train_loss=0.029164109379053116, time_cost=2.8716626167297363
Steps:   1%|▏         | 13575/1000000 [1:28:09<2768:52:14, 10.11s/it, lr=1e-5, step_loss=0.0164]Steps:   1%|▏         | 13576/1000000 [1:28:15<2470:15:52,  9.02s/it, lr=1e-5, step_loss=0.0164][RANK-0]: Step: [13576], local_loss=0.050703052431344986, train_loss=0.0404706709086895, time_cost=1.3780603408813477
Steps:   1%|▏         | 13576/1000000 [1:28:15<2470:15:52,  9.02s/it, lr=1e-5, step_loss=0.0507]Steps:   1%|▏         | 13577/1000000 [1:28:29<2829:25:27, 10.33s/it, lr=1e-5, step_loss=0.0507][RANK-0]: Step: [13577], local_loss=0.0406213104724884, train_loss=0.07380657643079758, time_cost=5.398955583572388
Steps:   1%|▏         | 13577/1000000 [1:28:29<2829:25:27, 10.33s/it, lr=1e-5, step_loss=0.0406]Steps:   1%|▏         | 13578/1000000 [1:28:44<3203:09:44, 11.69s/it, lr=1e-5, step_loss=0.0406][RANK-0]: Step: [13578], local_loss=0.02099902182817459, train_loss=0.04503826051950455, time_cost=4.338331699371338
Steps:   1%|▏         | 13578/1000000 [1:28:44<3203:09:44, 11.69s/it, lr=1e-5, step_loss=0.021] Steps:   1%|▏         | 13579/1000000 [1:28:48<2616:12:25,  9.55s/it, lr=1e-5, step_loss=0.021][RANK-0]: Step: [13579], local_loss=0.07014869898557663, train_loss=0.04097539186477661, time_cost=1.416116714477539
Steps:   1%|▏         | 13579/1000000 [1:28:48<2616:12:25,  9.55s/it, lr=1e-5, step_loss=0.0701]Steps:   1%|▏         | 13580/1000000 [1:28:57<2561:19:36,  9.35s/it, lr=1e-5, step_loss=0.0701][RANK-0]: Step: [13580], local_loss=0.02893897332251072, train_loss=0.05373413860797882, time_cost=3.6566107273101807
Steps:   1%|▏         | 13580/1000000 [1:28:57<2561:19:36,  9.35s/it, lr=1e-5, step_loss=0.0289]Steps:   1%|▏         | 13581/1000000 [1:29:08<2733:13:43,  9.98s/it, lr=1e-5, step_loss=0.0289][RANK-0]: Step: [13581], local_loss=0.05747728794813156, train_loss=0.06227482855319977, time_cost=8.217947483062744
Steps:   1%|▏         | 13581/1000000 [1:29:08<2733:13:43,  9.98s/it, lr=1e-5, step_loss=0.0575]Steps:   1%|▏         | 13582/1000000 [1:29:17<2591:21:38,  9.46s/it, lr=1e-5, step_loss=0.0575][RANK-0]: Step: [13582], local_loss=0.23849596083164215, train_loss=0.07489500939846039, time_cost=1.2329163551330566
Steps:   1%|▏         | 13582/1000000 [1:29:17<2591:21:38,  9.46s/it, lr=1e-5, step_loss=0.238] Steps:   1%|▏         | 13583/1000000 [1:29:30<2916:17:55, 10.64s/it, lr=1e-5, step_loss=0.238][RANK-0]: Step: [13583], local_loss=0.01086368877440691, train_loss=0.02826532907783985, time_cost=3.920062780380249
Steps:   1%|▏         | 13583/1000000 [1:29:30<2916:17:55, 10.64s/it, lr=1e-5, step_loss=0.0109]Steps:   1%|▏         | 13584/1000000 [1:29:34<2397:40:30,  8.75s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [13584], local_loss=0.019175589084625244, train_loss=0.036905523389577866, time_cost=1.2894947528839111
Steps:   1%|▏         | 13584/1000000 [1:29:34<2397:40:30,  8.75s/it, lr=1e-5, step_loss=0.0192]Steps:   1%|▏         | 13585/1000000 [1:29:48<2794:04:11, 10.20s/it, lr=1e-5, step_loss=0.0192][RANK-0]: Step: [13585], local_loss=0.02734476327896118, train_loss=0.06398456543684006, time_cost=1.2342252731323242
Steps:   1%|▏         | 13585/1000000 [1:29:48<2794:04:11, 10.20s/it, lr=1e-5, step_loss=0.0273]Steps:   1%|▏         | 13586/1000000 [1:29:58<2743:53:26, 10.01s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [13586], local_loss=0.9979109764099121, train_loss=0.15505920350551605, time_cost=1.2731409072875977
Steps:   1%|▏         | 13586/1000000 [1:29:58<2743:53:26, 10.01s/it, lr=1e-5, step_loss=0.998] Steps:   1%|▏         | 13587/1000000 [1:30:05<2506:53:06,  9.15s/it, lr=1e-5, step_loss=0.998][RANK-0]: Step: [13587], local_loss=0.03649694845080376, train_loss=0.028935490176081657, time_cost=2.143374443054199
Steps:   1%|▏         | 13587/1000000 [1:30:05<2506:53:06,  9.15s/it, lr=1e-5, step_loss=0.0365]Steps:   1%|▏         | 13588/1000000 [1:30:17<2737:09:27,  9.99s/it, lr=1e-5, step_loss=0.0365][RANK-0]: Step: [13588], local_loss=0.040028300136327744, train_loss=0.028529725968837738, time_cost=4.069651365280151
Steps:   1%|▏         | 13588/1000000 [1:30:17<2737:09:27,  9.99s/it, lr=1e-5, step_loss=0.04]  Steps:   1%|▏         | 13589/1000000 [1:30:24<2547:57:25,  9.30s/it, lr=1e-5, step_loss=0.04][RANK-0]: Step: [13589], local_loss=0.020380057394504547, train_loss=0.07821429520845413, time_cost=1.8310763835906982
Steps:   1%|▏         | 13589/1000000 [1:30:24<2547:57:25,  9.30s/it, lr=1e-5, step_loss=0.0204]Steps:   1%|▏         | 13590/1000000 [1:30:40<3100:01:51, 11.31s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [13590], local_loss=0.014412648044526577, train_loss=0.15341705083847046, time_cost=6.944220066070557
Steps:   1%|▏         | 13590/1000000 [1:30:40<3100:01:51, 11.31s/it, lr=1e-5, step_loss=0.0144]Steps:   1%|▏         | 13591/1000000 [1:30:51<3021:03:05, 11.03s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [13591], local_loss=0.015563737601041794, train_loss=0.012792417779564857, time_cost=5.2547996044158936
Steps:   1%|▏         | 13591/1000000 [1:30:51<3021:03:05, 11.03s/it, lr=1e-5, step_loss=0.0156]Steps:   1%|▏         | 13592/1000000 [1:30:59<2798:08:38, 10.21s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [13592], local_loss=0.030842158943414688, train_loss=0.03595426306128502, time_cost=6.1790430545806885
Steps:   1%|▏         | 13592/1000000 [1:30:59<2798:08:38, 10.21s/it, lr=1e-5, step_loss=0.0308]Steps:   1%|▏         | 13593/1000000 [1:31:04<2385:40:32,  8.71s/it, lr=1e-5, step_loss=0.0308][RANK-0]: Step: [13593], local_loss=0.061168041080236435, train_loss=0.03631541132926941, time_cost=2.5859692096710205
Steps:   1%|▏         | 13593/1000000 [1:31:04<2385:40:32,  8.71s/it, lr=1e-5, step_loss=0.0612]Steps:   1%|▏         | 13594/1000000 [1:31:11<2245:57:06,  8.20s/it, lr=1e-5, step_loss=0.0612][RANK-0]: Step: [13594], local_loss=0.08633250743150711, train_loss=0.19733968377113342, time_cost=2.3164772987365723
Steps:   1%|▏         | 13594/1000000 [1:31:11<2245:57:06,  8.20s/it, lr=1e-5, step_loss=0.0863]Steps:   1%|▏         | 13595/1000000 [1:31:22<2418:46:14,  8.83s/it, lr=1e-5, step_loss=0.0863][RANK-0]: Step: [13595], local_loss=0.011421024799346924, train_loss=0.019369522109627724, time_cost=4.136067152023315
Steps:   1%|▏         | 13595/1000000 [1:31:22<2418:46:14,  8.83s/it, lr=1e-5, step_loss=0.0114]Steps:   1%|▏         | 13596/1000000 [1:31:28<2258:51:09,  8.24s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [13596], local_loss=0.01145812775939703, train_loss=0.06440046429634094, time_cost=2.175340175628662
Steps:   1%|▏         | 13596/1000000 [1:31:28<2258:51:09,  8.24s/it, lr=1e-5, step_loss=0.0115]Steps:   1%|▏         | 13597/1000000 [1:31:37<2283:53:20,  8.34s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [13597], local_loss=0.026593519374728203, train_loss=0.04268699884414673, time_cost=2.509920120239258
Steps:   1%|▏         | 13597/1000000 [1:31:37<2283:53:20,  8.34s/it, lr=1e-5, step_loss=0.0266]Steps:   1%|▏         | 13598/1000000 [1:31:44<2216:48:14,  8.09s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [13598], local_loss=0.014432608149945736, train_loss=0.06231778860092163, time_cost=1.2352612018585205
Steps:   1%|▏         | 13598/1000000 [1:31:44<2216:48:14,  8.09s/it, lr=1e-5, step_loss=0.0144]Steps:   1%|▏         | 13599/1000000 [1:31:53<2252:18:58,  8.22s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [13599], local_loss=0.05084170028567314, train_loss=0.035098105669021606, time_cost=1.8856046199798584
Steps:   1%|▏         | 13599/1000000 [1:31:53<2252:18:58,  8.22s/it, lr=1e-5, step_loss=0.0508]Steps:   1%|▏         | 13600/1000000 [1:32:04<2477:08:09,  9.04s/it, lr=1e-5, step_loss=0.0508][RANK-0]: Step: [13600], local_loss=0.04254422336816788, train_loss=0.052663370966911316, time_cost=3.1754400730133057
Steps:   1%|▏         | 13600/1000000 [1:32:04<2477:08:09,  9.04s/it, lr=1e-5, step_loss=0.0425]Steps:   1%|▏         | 13601/1000000 [1:32:10<2251:50:57,  8.22s/it, lr=1e-5, step_loss=0.0425][RANK-0]: Step: [13601], local_loss=0.01370675303041935, train_loss=0.033465173095464706, time_cost=1.684713363647461
Steps:   1%|▏         | 13601/1000000 [1:32:10<2251:50:57,  8.22s/it, lr=1e-5, step_loss=0.0137]Steps:   1%|▏         | 13602/1000000 [1:32:15<1946:27:06,  7.10s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [13602], local_loss=0.04374246299266815, train_loss=0.049179233610630035, time_cost=2.248624563217163
Steps:   1%|▏         | 13602/1000000 [1:32:15<1946:27:06,  7.10s/it, lr=1e-5, step_loss=0.0437]Steps:   1%|▏         | 13603/1000000 [1:32:27<2409:13:09,  8.79s/it, lr=1e-5, step_loss=0.0437][RANK-0]: Step: [13603], local_loss=0.05002579838037491, train_loss=0.03852646052837372, time_cost=4.321326017379761
Steps:   1%|▏         | 13603/1000000 [1:32:27<2409:13:09,  8.79s/it, lr=1e-5, step_loss=0.05]  Steps:   1%|▏         | 13604/1000000 [1:32:38<2584:09:36,  9.43s/it, lr=1e-5, step_loss=0.05][RANK-0]: Step: [13604], local_loss=0.006990035064518452, train_loss=0.04080234467983246, time_cost=2.9767262935638428
Steps:   1%|▏         | 13604/1000000 [1:32:38<2584:09:36,  9.43s/it, lr=1e-5, step_loss=0.00699]Steps:   1%|▏         | 13605/1000000 [1:32:43<2189:17:47,  7.99s/it, lr=1e-5, step_loss=0.00699][RANK-0]: Step: [13605], local_loss=0.01164232101291418, train_loss=24.524015426635742, time_cost=1.9553699493408203
Steps:   1%|▏         | 13605/1000000 [1:32:43<2189:17:47,  7.99s/it, lr=1e-5, step_loss=0.0116] Steps:   1%|▏         | 13606/1000000 [1:32:48<1910:18:35,  6.97s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [13606], local_loss=0.04283353313803673, train_loss=0.1034206822514534, time_cost=3.8076605796813965
Steps:   1%|▏         | 13606/1000000 [1:32:48<1910:18:35,  6.97s/it, lr=1e-5, step_loss=0.0428]Steps:   1%|▏         | 13607/1000000 [1:32:57<2127:57:45,  7.77s/it, lr=1e-5, step_loss=0.0428][RANK-0]: Step: [13607], local_loss=0.039047498255968094, train_loss=0.14072340726852417, time_cost=4.588254928588867
Steps:   1%|▏         | 13607/1000000 [1:32:57<2127:57:45,  7.77s/it, lr=1e-5, step_loss=0.039] Steps:   1%|▏         | 13608/1000000 [1:33:04<2082:19:07,  7.60s/it, lr=1e-5, step_loss=0.039][RANK-0]: Step: [13608], local_loss=0.01180798839777708, train_loss=0.03480500355362892, time_cost=1.2517046928405762
Steps:   1%|▏         | 13608/1000000 [1:33:04<2082:19:07,  7.60s/it, lr=1e-5, step_loss=0.0118]Steps:   1%|▏         | 13609/1000000 [1:33:10<1874:38:13,  6.84s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [13609], local_loss=0.013677260838449001, train_loss=0.05991987884044647, time_cost=2.0830295085906982
Steps:   1%|▏         | 13609/1000000 [1:33:10<1874:38:13,  6.84s/it, lr=1e-5, step_loss=0.0137]Steps:   1%|▏         | 13610/1000000 [1:33:15<1796:31:03,  6.56s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [13610], local_loss=0.05074771121144295, train_loss=0.025802452117204666, time_cost=1.4035165309906006
Steps:   1%|▏         | 13610/1000000 [1:33:15<1796:31:03,  6.56s/it, lr=1e-5, step_loss=0.0507]Steps:   1%|▏         | 13611/1000000 [1:33:23<1891:12:36,  6.90s/it, lr=1e-5, step_loss=0.0507][RANK-0]: Step: [13611], local_loss=0.01238885149359703, train_loss=0.052031636238098145, time_cost=1.2803521156311035
Steps:   1%|▏         | 13611/1000000 [1:33:23<1891:12:36,  6.90s/it, lr=1e-5, step_loss=0.0124]Steps:   1%|▏         | 13612/1000000 [1:33:28<1732:16:57,  6.32s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [13612], local_loss=0.015490403398871422, train_loss=0.034821514040231705, time_cost=1.900383710861206
Steps:   1%|▏         | 13612/1000000 [1:33:28<1732:16:57,  6.32s/it, lr=1e-5, step_loss=0.0155]Steps:   1%|▏         | 13613/1000000 [1:33:38<2002:29:43,  7.31s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [13613], local_loss=0.005529902409762144, train_loss=0.021708142012357712, time_cost=3.6527438163757324
Steps:   1%|▏         | 13613/1000000 [1:33:38<2002:29:43,  7.31s/it, lr=1e-5, step_loss=0.00553]Steps:   1%|▏         | 13614/1000000 [1:33:48<2214:38:39,  8.08s/it, lr=1e-5, step_loss=0.00553][RANK-0]: Step: [13614], local_loss=0.010357033461332321, train_loss=0.043445710092782974, time_cost=1.2155086994171143
Steps:   1%|▏         | 13614/1000000 [1:33:48<2214:38:39,  8.08s/it, lr=1e-5, step_loss=0.0104] Steps:   1%|▏         | 13615/1000000 [1:33:53<1957:50:00,  7.15s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [13615], local_loss=0.05093826353549957, train_loss=0.059381477534770966, time_cost=1.7824983596801758
Steps:   1%|▏         | 13615/1000000 [1:33:53<1957:50:00,  7.15s/it, lr=1e-5, step_loss=0.0509]Steps:   1%|▏         | 13616/1000000 [1:34:03<2263:57:52,  8.26s/it, lr=1e-5, step_loss=0.0509][RANK-0]: Step: [13616], local_loss=0.0973222479224205, train_loss=0.04454312101006508, time_cost=1.2466611862182617
Steps:   1%|▏         | 13616/1000000 [1:34:03<2263:57:52,  8.26s/it, lr=1e-5, step_loss=0.0973]Steps:   1%|▏         | 13617/1000000 [1:34:14<2493:38:05,  9.10s/it, lr=1e-5, step_loss=0.0973][RANK-0]: Step: [13617], local_loss=0.07337404042482376, train_loss=0.11921750009059906, time_cost=3.827188730239868
Steps:   1%|▏         | 13617/1000000 [1:34:14<2493:38:05,  9.10s/it, lr=1e-5, step_loss=0.0734]Steps:   1%|▏         | 13618/1000000 [1:34:28<2834:41:18, 10.35s/it, lr=1e-5, step_loss=0.0734][RANK-0]: Step: [13618], local_loss=0.020648537203669548, train_loss=36.40310287475586, time_cost=4.47575306892395
Steps:   1%|▏         | 13618/1000000 [1:34:28<2834:41:18, 10.35s/it, lr=1e-5, step_loss=0.0206]Steps:   1%|▏         | 13619/1000000 [1:34:35<2586:24:21,  9.44s/it, lr=1e-5, step_loss=0.0206][RANK-0]: Step: [13619], local_loss=0.011239544488489628, train_loss=0.13868866860866547, time_cost=5.4403369426727295
Steps:   1%|▏         | 13619/1000000 [1:34:35<2586:24:21,  9.44s/it, lr=1e-5, step_loss=0.0112]Steps:   1%|▏         | 13620/1000000 [1:34:43<2437:33:31,  8.90s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [13620], local_loss=0.03475087136030197, train_loss=0.02688005194067955, time_cost=3.206758975982666
Steps:   1%|▏         | 13620/1000000 [1:34:43<2437:33:31,  8.90s/it, lr=1e-5, step_loss=0.0348]Steps:   1%|▏         | 13621/1000000 [1:34:48<2126:10:49,  7.76s/it, lr=1e-5, step_loss=0.0348][RANK-0]: Step: [13621], local_loss=0.05692543089389801, train_loss=0.030183644965291023, time_cost=1.211411476135254
Steps:   1%|▏         | 13621/1000000 [1:34:48<2126:10:49,  7.76s/it, lr=1e-5, step_loss=0.0569]Steps:   1%|▏         | 13622/1000000 [1:34:57<2254:21:38,  8.23s/it, lr=1e-5, step_loss=0.0569][RANK-0]: Step: [13622], local_loss=0.0181175135076046, train_loss=0.024288242682814598, time_cost=3.701101779937744
Steps:   1%|▏         | 13622/1000000 [1:34:57<2254:21:38,  8.23s/it, lr=1e-5, step_loss=0.0181]Steps:   1%|▏         | 13623/1000000 [1:35:09<2581:44:37,  9.42s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [13623], local_loss=0.02293536253273487, train_loss=0.054931849241256714, time_cost=1.2299585342407227
Steps:   1%|▏         | 13623/1000000 [1:35:09<2581:44:37,  9.42s/it, lr=1e-5, step_loss=0.0229]Steps:   1%|▏         | 13624/1000000 [1:35:17<2461:03:34,  8.98s/it, lr=1e-5, step_loss=0.0229][RANK-0]: Step: [13624], local_loss=0.38393667340278625, train_loss=0.06821141391992569, time_cost=4.070836782455444
Steps:   1%|▏         | 13624/1000000 [1:35:17<2461:03:34,  8.98s/it, lr=1e-5, step_loss=0.384] Steps:   1%|▏         | 13625/1000000 [1:35:23<2195:23:09,  8.01s/it, lr=1e-5, step_loss=0.384][RANK-0]: Step: [13625], local_loss=0.031510189175605774, train_loss=0.023498352617025375, time_cost=3.0918049812316895
Steps:   1%|▏         | 13625/1000000 [1:35:23<2195:23:09,  8.01s/it, lr=1e-5, step_loss=0.0315]Steps:   1%|▏         | 13626/1000000 [1:35:30<2128:30:21,  7.77s/it, lr=1e-5, step_loss=0.0315][RANK-0]: Step: [13626], local_loss=0.09595772624015808, train_loss=0.3001069128513336, time_cost=2.822772264480591
Steps:   1%|▏         | 13626/1000000 [1:35:30<2128:30:21,  7.77s/it, lr=1e-5, step_loss=0.096] Steps:   1%|▏         | 13627/1000000 [1:35:47<2856:27:50, 10.43s/it, lr=1e-5, step_loss=0.096][RANK-0]: Step: [13627], local_loss=0.007267650682479143, train_loss=0.09020930528640747, time_cost=11.612439393997192
Steps:   1%|▏         | 13627/1000000 [1:35:47<2856:27:50, 10.43s/it, lr=1e-5, step_loss=0.00727]Steps:   1%|▏         | 13628/1000000 [1:36:00<3077:33:43, 11.23s/it, lr=1e-5, step_loss=0.00727][RANK-0]: Step: [13628], local_loss=0.020827775821089745, train_loss=0.031315166503190994, time_cost=5.713529586791992
Steps:   1%|▏         | 13628/1000000 [1:36:00<3077:33:43, 11.23s/it, lr=1e-5, step_loss=0.0208] Steps:   1%|▏         | 13629/1000000 [1:36:13<3236:48:01, 11.81s/it, lr=1e-5, step_loss=0.0208][RANK-0]: Step: [13629], local_loss=0.010453813709318638, train_loss=0.062221959233284, time_cost=1.681931495666504
Steps:   1%|▏         | 13629/1000000 [1:36:13<3236:48:01, 11.81s/it, lr=1e-5, step_loss=0.0105]Steps:   1%|▏         | 13630/1000000 [1:36:18<2685:05:39,  9.80s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [13630], local_loss=0.024534516036510468, train_loss=0.01653997227549553, time_cost=2.1690595149993896
Steps:   1%|▏         | 13630/1000000 [1:36:18<2685:05:39,  9.80s/it, lr=1e-5, step_loss=0.0245]Steps:   1%|▏         | 13631/1000000 [1:36:30<2873:59:29, 10.49s/it, lr=1e-5, step_loss=0.0245][RANK-0]: Step: [13631], local_loss=0.015029976144433022, train_loss=0.01885218918323517, time_cost=2.9521372318267822
Steps:   1%|▏         | 13631/1000000 [1:36:30<2873:59:29, 10.49s/it, lr=1e-5, step_loss=0.015] Steps:   1%|▏         | 13632/1000000 [1:36:44<3159:40:39, 11.53s/it, lr=1e-5, step_loss=0.015][RANK-0]: Step: [13632], local_loss=0.0066606951877474785, train_loss=0.022280516102910042, time_cost=3.970038890838623
Steps:   1%|▏         | 13632/1000000 [1:36:44<3159:40:39, 11.53s/it, lr=1e-5, step_loss=0.00666]Steps:   1%|▏         | 13633/1000000 [1:36:50<2703:40:13,  9.87s/it, lr=1e-5, step_loss=0.00666][RANK-0]: Step: [13633], local_loss=0.025211358442902565, train_loss=0.06101243942975998, time_cost=2.0979926586151123
Steps:   1%|▏         | 13633/1000000 [1:36:50<2703:40:13,  9.87s/it, lr=1e-5, step_loss=0.0252] Steps:   1%|▏         | 13634/1000000 [1:37:01<2756:29:46, 10.06s/it, lr=1e-5, step_loss=0.0252][RANK-0]: Step: [13634], local_loss=0.011787773109972477, train_loss=0.03715755045413971, time_cost=1.8030998706817627
Steps:   1%|▏         | 13634/1000000 [1:37:01<2756:29:46, 10.06s/it, lr=1e-5, step_loss=0.0118]Steps:   1%|▏         | 13635/1000000 [1:37:07<2430:39:55,  8.87s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [13635], local_loss=0.02816508337855339, train_loss=0.03225202113389969, time_cost=1.3118896484375
Steps:   1%|▏         | 13635/1000000 [1:37:07<2430:39:55,  8.87s/it, lr=1e-5, step_loss=0.0282]Steps:   1%|▏         | 13636/1000000 [1:37:12<2117:35:29,  7.73s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [13636], local_loss=0.00791912991553545, train_loss=0.03116568736732006, time_cost=1.9275295734405518
Steps:   1%|▏         | 13636/1000000 [1:37:12<2117:35:29,  7.73s/it, lr=1e-5, step_loss=0.00792]Steps:   1%|▏         | 13637/1000000 [1:37:23<2360:50:16,  8.62s/it, lr=1e-5, step_loss=0.00792][RANK-0]: Step: [13637], local_loss=0.0094273891299963, train_loss=0.057307593524456024, time_cost=1.5763065814971924
Steps:   1%|▏         | 13637/1000000 [1:37:23<2360:50:16,  8.62s/it, lr=1e-5, step_loss=0.00943]Steps:   1%|▏         | 13638/1000000 [1:37:34<2607:45:02,  9.52s/it, lr=1e-5, step_loss=0.00943][RANK-0]: Step: [13638], local_loss=0.012045128270983696, train_loss=4.077707767486572, time_cost=8.53620433807373
Steps:   1%|▏         | 13638/1000000 [1:37:34<2607:45:02,  9.52s/it, lr=1e-5, step_loss=0.012]  Steps:   1%|▏         | 13639/1000000 [1:37:47<2845:39:14, 10.39s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [13639], local_loss=0.06398788094520569, train_loss=0.04501717537641525, time_cost=3.338911294937134
Steps:   1%|▏         | 13639/1000000 [1:37:47<2845:39:14, 10.39s/it, lr=1e-5, step_loss=0.064]Steps:   1%|▏         | 13640/1000000 [1:37:59<2986:19:13, 10.90s/it, lr=1e-5, step_loss=0.064][RANK-0]: Step: [13640], local_loss=0.016850246116518974, train_loss=0.02864188328385353, time_cost=2.5375735759735107
Steps:   1%|▏         | 13640/1000000 [1:37:59<2986:19:13, 10.90s/it, lr=1e-5, step_loss=0.0169]Steps:   1%|▏         | 13641/1000000 [1:38:06<2691:10:35,  9.82s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [13641], local_loss=0.011878646910190582, train_loss=0.03590576350688934, time_cost=1.231719970703125
Steps:   1%|▏         | 13641/1000000 [1:38:06<2691:10:35,  9.82s/it, lr=1e-5, step_loss=0.0119]Steps:   1%|▏         | 13642/1000000 [1:38:18<2825:25:44, 10.31s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [13642], local_loss=0.013182628899812698, train_loss=0.08752206712961197, time_cost=1.2113397121429443
Steps:   1%|▏         | 13642/1000000 [1:38:18<2825:25:44, 10.31s/it, lr=1e-5, step_loss=0.0132]Steps:   1%|▏         | 13643/1000000 [1:38:33<3236:17:20, 11.81s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [13643], local_loss=0.010245371609926224, train_loss=0.015742190182209015, time_cost=4.730705976486206
Steps:   1%|▏         | 13643/1000000 [1:38:33<3236:17:20, 11.81s/it, lr=1e-5, step_loss=0.0102]Steps:   1%|▏         | 13644/1000000 [1:38:39<2757:34:39, 10.06s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [13644], local_loss=0.2553240656852722, train_loss=0.058710433542728424, time_cost=1.6369693279266357
Steps:   1%|▏         | 13644/1000000 [1:38:39<2757:34:39, 10.06s/it, lr=1e-5, step_loss=0.255] Steps:   1%|▏         | 13645/1000000 [1:38:49<2776:53:52, 10.14s/it, lr=1e-5, step_loss=0.255][RANK-0]: Step: [13645], local_loss=0.025033816695213318, train_loss=0.07249405980110168, time_cost=3.845902442932129
Steps:   1%|▏         | 13645/1000000 [1:38:49<2776:53:52, 10.14s/it, lr=1e-5, step_loss=0.025]Steps:   1%|▏         | 13646/1000000 [1:38:54<2323:10:11,  8.48s/it, lr=1e-5, step_loss=0.025][RANK-0]: Step: [13646], local_loss=0.031207073479890823, train_loss=0.027780286967754364, time_cost=3.544386386871338
Steps:   1%|▏         | 13646/1000000 [1:38:54<2323:10:11,  8.48s/it, lr=1e-5, step_loss=0.0312]Steps:   1%|▏         | 13647/1000000 [1:39:01<2211:22:54,  8.07s/it, lr=1e-5, step_loss=0.0312][RANK-0]: Step: [13647], local_loss=0.04694930464029312, train_loss=0.05757085233926773, time_cost=1.5386412143707275
Steps:   1%|▏         | 13647/1000000 [1:39:01<2211:22:54,  8.07s/it, lr=1e-5, step_loss=0.0469]Steps:   1%|▏         | 13648/1000000 [1:39:12<2466:53:01,  9.00s/it, lr=1e-5, step_loss=0.0469][RANK-0]: Step: [13648], local_loss=0.011566980741918087, train_loss=0.13291969895362854, time_cost=2.720949411392212
Steps:   1%|▏         | 13648/1000000 [1:39:12<2466:53:01,  9.00s/it, lr=1e-5, step_loss=0.0116]Steps:   1%|▏         | 13649/1000000 [1:39:20<2341:58:15,  8.55s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [13649], local_loss=0.020444203168153763, train_loss=0.058333080261945724, time_cost=2.879676580429077
Steps:   1%|▏         | 13649/1000000 [1:39:20<2341:58:15,  8.55s/it, lr=1e-5, step_loss=0.0204]Steps:   1%|▏         | 13650/1000000 [1:39:27<2230:16:02,  8.14s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [13650], local_loss=0.0062948730774223804, train_loss=0.017876196652650833, time_cost=1.2669579982757568
Steps:   1%|▏         | 13650/1000000 [1:39:27<2230:16:02,  8.14s/it, lr=1e-5, step_loss=0.00629]Steps:   1%|▏         | 13651/1000000 [1:39:34<2161:38:44,  7.89s/it, lr=1e-5, step_loss=0.00629][RANK-0]: Step: [13651], local_loss=0.4798754155635834, train_loss=0.133336141705513, time_cost=2.6413519382476807
Steps:   1%|▏         | 13651/1000000 [1:39:34<2161:38:44,  7.89s/it, lr=1e-5, step_loss=0.48]   Steps:   1%|▏         | 13652/1000000 [1:39:48<2679:26:07,  9.78s/it, lr=1e-5, step_loss=0.48][RANK-0]: Step: [13652], local_loss=0.07464351505041122, train_loss=0.07065747678279877, time_cost=5.952864646911621
Steps:   1%|▏         | 13652/1000000 [1:39:48<2679:26:07,  9.78s/it, lr=1e-5, step_loss=0.0746]Steps:   1%|▏         | 13653/1000000 [1:40:02<3030:15:37, 11.06s/it, lr=1e-5, step_loss=0.0746][RANK-0]: Step: [13653], local_loss=0.015069162473082542, train_loss=0.022486679255962372, time_cost=4.920918941497803
Steps:   1%|▏         | 13653/1000000 [1:40:02<3030:15:37, 11.06s/it, lr=1e-5, step_loss=0.0151]Steps:   1%|▏         | 13654/1000000 [1:40:08<2620:49:55,  9.57s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [13654], local_loss=0.010722649283707142, train_loss=0.021509157493710518, time_cost=2.014645576477051
Steps:   1%|▏         | 13654/1000000 [1:40:08<2620:49:55,  9.57s/it, lr=1e-5, step_loss=0.0107]Steps:   1%|▏         | 13655/1000000 [1:40:14<2322:31:36,  8.48s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [13655], local_loss=0.07417643070220947, train_loss=0.02961643785238266, time_cost=1.9427928924560547
Steps:   1%|▏         | 13655/1000000 [1:40:14<2322:31:36,  8.48s/it, lr=1e-5, step_loss=0.0742]Steps:   1%|▏         | 13656/1000000 [1:40:21<2177:17:15,  7.95s/it, lr=1e-5, step_loss=0.0742][RANK-0]: Step: [13656], local_loss=0.0790317952632904, train_loss=0.02936512604355812, time_cost=1.2421324253082275
Steps:   1%|▏         | 13656/1000000 [1:40:21<2177:17:15,  7.95s/it, lr=1e-5, step_loss=0.079] Steps:   1%|▏         | 13657/1000000 [1:40:26<1953:55:35,  7.13s/it, lr=1e-5, step_loss=0.079][RANK-0]: Step: [13657], local_loss=0.018067877739667892, train_loss=0.017687005922198296, time_cost=2.067405939102173
Steps:   1%|▏         | 13657/1000000 [1:40:26<1953:55:35,  7.13s/it, lr=1e-5, step_loss=0.0181]Steps:   1%|▏         | 13658/1000000 [1:40:31<1771:35:47,  6.47s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [13658], local_loss=0.062221113592386246, train_loss=0.035283833742141724, time_cost=2.0195000171661377
Steps:   1%|▏         | 13658/1000000 [1:40:31<1771:35:47,  6.47s/it, lr=1e-5, step_loss=0.0622]Steps:   1%|▏         | 13659/1000000 [1:40:43<2201:42:56,  8.04s/it, lr=1e-5, step_loss=0.0622][RANK-0]: Step: [13659], local_loss=0.05848647654056549, train_loss=0.025286540389060974, time_cost=2.747652292251587
Steps:   1%|▏         | 13659/1000000 [1:40:43<2201:42:56,  8.04s/it, lr=1e-5, step_loss=0.0585]Steps:   1%|▏         | 13660/1000000 [1:40:52<2268:07:34,  8.28s/it, lr=1e-5, step_loss=0.0585][RANK-0]: Step: [13660], local_loss=0.01624475046992302, train_loss=0.040817152708768845, time_cost=2.8382210731506348
Steps:   1%|▏         | 13660/1000000 [1:40:52<2268:07:34,  8.28s/it, lr=1e-5, step_loss=0.0162]Steps:   1%|▏         | 13661/1000000 [1:40:58<2081:07:44,  7.60s/it, lr=1e-5, step_loss=0.0162][RANK-0]: Step: [13661], local_loss=0.06141111999750137, train_loss=0.0514850988984108, time_cost=1.3410024642944336
Steps:   1%|▏         | 13661/1000000 [1:40:58<2081:07:44,  7.60s/it, lr=1e-5, step_loss=0.0614]Steps:   1%|▏         | 13662/1000000 [1:41:09<2378:14:19,  8.68s/it, lr=1e-5, step_loss=0.0614][RANK-0]: Step: [13662], local_loss=0.0643700584769249, train_loss=0.048139993101358414, time_cost=1.6367337703704834
Steps:   1%|▏         | 13662/1000000 [1:41:09<2378:14:19,  8.68s/it, lr=1e-5, step_loss=0.0644]Steps:   1%|▏         | 13663/1000000 [1:41:15<2156:41:17,  7.87s/it, lr=1e-5, step_loss=0.0644][RANK-0]: Step: [13663], local_loss=0.05782737955451012, train_loss=0.03485541418194771, time_cost=1.7796871662139893
Steps:   1%|▏         | 13663/1000000 [1:41:15<2156:41:17,  7.87s/it, lr=1e-5, step_loss=0.0578]Steps:   1%|▏         | 13664/1000000 [1:41:19<1855:43:13,  6.77s/it, lr=1e-5, step_loss=0.0578][RANK-0]: Step: [13664], local_loss=0.014833813533186913, train_loss=0.05034530162811279, time_cost=1.4427664279937744
Steps:   1%|▏         | 13664/1000000 [1:41:19<1855:43:13,  6.77s/it, lr=1e-5, step_loss=0.0148]Steps:   1%|▏         | 13665/1000000 [1:41:32<2365:50:40,  8.64s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [13665], local_loss=0.01635146699845791, train_loss=0.036354321986436844, time_cost=5.040584564208984
Steps:   1%|▏         | 13665/1000000 [1:41:32<2365:50:40,  8.64s/it, lr=1e-5, step_loss=0.0164]Steps:   1%|▏         | 13666/1000000 [1:41:36<2015:58:05,  7.36s/it, lr=1e-5, step_loss=0.0164][RANK-0]: Step: [13666], local_loss=0.01070463564246893, train_loss=0.023142311722040176, time_cost=3.0299172401428223
Steps:   1%|▏         | 13666/1000000 [1:41:36<2015:58:05,  7.36s/it, lr=1e-5, step_loss=0.0107]Steps:   1%|▏         | 13667/1000000 [1:41:48<2341:33:59,  8.55s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [13667], local_loss=0.15503916144371033, train_loss=0.048739612102508545, time_cost=2.283646583557129
Steps:   1%|▏         | 13667/1000000 [1:41:48<2341:33:59,  8.55s/it, lr=1e-5, step_loss=0.155] Steps:   1%|▏         | 13668/1000000 [1:42:00<2604:11:49,  9.51s/it, lr=1e-5, step_loss=0.155][RANK-0]: Step: [13668], local_loss=0.046282075345516205, train_loss=0.05131738632917404, time_cost=1.2478504180908203
Steps:   1%|▏         | 13668/1000000 [1:42:00<2604:11:49,  9.51s/it, lr=1e-5, step_loss=0.0463]Steps:   1%|▏         | 13669/1000000 [1:42:09<2591:17:15,  9.46s/it, lr=1e-5, step_loss=0.0463][RANK-0]: Step: [13669], local_loss=0.011173415929079056, train_loss=0.26772570610046387, time_cost=1.6738979816436768
Steps:   1%|▏         | 13669/1000000 [1:42:09<2591:17:15,  9.46s/it, lr=1e-5, step_loss=0.0112]Steps:   1%|▏         | 13670/1000000 [1:42:13<2170:14:39,  7.92s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [13670], local_loss=0.05215770751237869, train_loss=0.03978104144334793, time_cost=3.2591331005096436
Steps:   1%|▏         | 13670/1000000 [1:42:13<2170:14:39,  7.92s/it, lr=1e-5, step_loss=0.0522]Steps:   1%|▏         | 13671/1000000 [1:42:26<2587:21:00,  9.44s/it, lr=1e-5, step_loss=0.0522][RANK-0]: Step: [13671], local_loss=0.02339811623096466, train_loss=0.02032451517879963, time_cost=4.111645221710205
Steps:   1%|▏         | 13671/1000000 [1:42:26<2587:21:00,  9.44s/it, lr=1e-5, step_loss=0.0234]Steps:   1%|▏         | 13672/1000000 [1:42:31<2246:41:55,  8.20s/it, lr=1e-5, step_loss=0.0234][RANK-0]: Step: [13672], local_loss=0.019694969058036804, train_loss=0.034996483474969864, time_cost=4.466184854507446
Steps:   1%|▏         | 13672/1000000 [1:42:31<2246:41:55,  8.20s/it, lr=1e-5, step_loss=0.0197]Steps:   1%|▏         | 13673/1000000 [1:42:37<2064:36:13,  7.54s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [13673], local_loss=0.09015616774559021, train_loss=0.04787886515259743, time_cost=1.4015872478485107
Steps:   1%|▏         | 13673/1000000 [1:42:37<2064:36:13,  7.54s/it, lr=1e-5, step_loss=0.0902]Steps:   1%|▏         | 13674/1000000 [1:42:45<2049:05:49,  7.48s/it, lr=1e-5, step_loss=0.0902][RANK-0]: Step: [13674], local_loss=0.019054582342505455, train_loss=0.06035039573907852, time_cost=3.22062611579895
Steps:   1%|▏         | 13674/1000000 [1:42:45<2049:05:49,  7.48s/it, lr=1e-5, step_loss=0.0191]Steps:   1%|▏         | 13675/1000000 [1:42:52<2027:31:53,  7.40s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [13675], local_loss=0.18316175043582916, train_loss=0.06220048666000366, time_cost=2.722135305404663
Steps:   1%|▏         | 13675/1000000 [1:42:52<2027:31:53,  7.40s/it, lr=1e-5, step_loss=0.183] Steps:   1%|▏         | 13676/1000000 [1:42:59<1992:50:49,  7.27s/it, lr=1e-5, step_loss=0.183][RANK-0]: Step: [13676], local_loss=0.012906844727694988, train_loss=0.03942825645208359, time_cost=2.816640615463257
Steps:   1%|▏         | 13676/1000000 [1:42:59<1992:50:49,  7.27s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 13677/1000000 [1:43:10<2323:28:31,  8.48s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [13677], local_loss=0.009973116219043732, train_loss=0.04687696322798729, time_cost=2.028817892074585
Steps:   1%|▏         | 13677/1000000 [1:43:10<2323:28:31,  8.48s/it, lr=1e-5, step_loss=0.00997]Steps:   1%|▏         | 13678/1000000 [1:43:27<3001:21:02, 10.95s/it, lr=1e-5, step_loss=0.00997][RANK-0]: Step: [13678], local_loss=0.0849977508187294, train_loss=0.07331053912639618, time_cost=8.22209644317627
Steps:   1%|▏         | 13678/1000000 [1:43:27<3001:21:02, 10.95s/it, lr=1e-5, step_loss=0.085]  Steps:   1%|▏         | 13679/1000000 [1:43:33<2612:29:17,  9.54s/it, lr=1e-5, step_loss=0.085][RANK-0]: Step: [13679], local_loss=0.008660225197672844, train_loss=0.0793282687664032, time_cost=2.1498262882232666
Steps:   1%|▏         | 13679/1000000 [1:43:33<2612:29:17,  9.54s/it, lr=1e-5, step_loss=0.00866]Steps:   1%|▏         | 13680/1000000 [1:43:47<2937:45:21, 10.72s/it, lr=1e-5, step_loss=0.00866][RANK-0]: Step: [13680], local_loss=0.02579498291015625, train_loss=13.556774139404297, time_cost=3.49575138092041
Steps:   1%|▏         | 13680/1000000 [1:43:47<2937:45:21, 10.72s/it, lr=1e-5, step_loss=0.0258] Steps:   1%|▏         | 13681/1000000 [1:43:52<2498:52:04,  9.12s/it, lr=1e-5, step_loss=0.0258][RANK-0]: Step: [13681], local_loss=0.013093356043100357, train_loss=0.09753067791461945, time_cost=2.0787463188171387
Steps:   1%|▏         | 13681/1000000 [1:43:52<2498:52:04,  9.12s/it, lr=1e-5, step_loss=0.0131]Steps:   1%|▏         | 13682/1000000 [1:43:59<2288:21:12,  8.35s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [13682], local_loss=0.009913425892591476, train_loss=0.036715492606163025, time_cost=1.8794424533843994
Steps:   1%|▏         | 13682/1000000 [1:43:59<2288:21:12,  8.35s/it, lr=1e-5, step_loss=0.00991]Steps:   1%|▏         | 13683/1000000 [1:44:16<2994:00:01, 10.93s/it, lr=1e-5, step_loss=0.00991][RANK-0]: Step: [13683], local_loss=0.02382991462945938, train_loss=0.036759309470653534, time_cost=1.2548470497131348
Steps:   1%|▏         | 13683/1000000 [1:44:16<2994:00:01, 10.93s/it, lr=1e-5, step_loss=0.0238] Steps:   1%|▏         | 13684/1000000 [1:44:20<2460:43:55,  8.98s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [13684], local_loss=0.06357035040855408, train_loss=0.0458163283765316, time_cost=1.4800879955291748
Steps:   1%|▏         | 13684/1000000 [1:44:20<2460:43:55,  8.98s/it, lr=1e-5, step_loss=0.0636]Steps:   1%|▏         | 13685/1000000 [1:44:25<2138:44:55,  7.81s/it, lr=1e-5, step_loss=0.0636][RANK-0]: Step: [13685], local_loss=0.05293998122215271, train_loss=0.2320273071527481, time_cost=2.20798397064209
Steps:   1%|▏         | 13685/1000000 [1:44:25<2138:44:55,  7.81s/it, lr=1e-5, step_loss=0.0529]Steps:   1%|▏         | 13686/1000000 [1:44:37<2442:38:28,  8.92s/it, lr=1e-5, step_loss=0.0529][RANK-0]: Step: [13686], local_loss=0.0051379078067839146, train_loss=0.04023822396993637, time_cost=1.9959726333618164
Steps:   1%|▏         | 13686/1000000 [1:44:37<2442:38:28,  8.92s/it, lr=1e-5, step_loss=0.00514]Steps:   1%|▏         | 13687/1000000 [1:44:44<2292:56:16,  8.37s/it, lr=1e-5, step_loss=0.00514][RANK-0]: Step: [13687], local_loss=0.017663555219769478, train_loss=0.016414053738117218, time_cost=2.120128631591797
Steps:   1%|▏         | 13687/1000000 [1:44:44<2292:56:16,  8.37s/it, lr=1e-5, step_loss=0.0177] Steps:   1%|▏         | 13688/1000000 [1:44:56<2591:58:28,  9.46s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [13688], local_loss=0.017187874764204025, train_loss=0.13866320252418518, time_cost=4.449982404708862
Steps:   1%|▏         | 13688/1000000 [1:44:56<2591:58:28,  9.46s/it, lr=1e-5, step_loss=0.0172]Steps:   1%|▏         | 13689/1000000 [1:45:10<2991:24:54, 10.92s/it, lr=1e-5, step_loss=0.0172][RANK-0]: Step: [13689], local_loss=0.021112162619829178, train_loss=0.195975199341774, time_cost=6.280687093734741
Steps:   1%|▏         | 13689/1000000 [1:45:10<2991:24:54, 10.92s/it, lr=1e-5, step_loss=0.0211]Steps:   1%|▏         | 13690/1000000 [1:45:18<2730:36:54,  9.97s/it, lr=1e-5, step_loss=0.0211][RANK-0]: Step: [13690], local_loss=0.014057999476790428, train_loss=0.01723787933588028, time_cost=3.910188674926758
Steps:   1%|▏         | 13690/1000000 [1:45:18<2730:36:54,  9.97s/it, lr=1e-5, step_loss=0.0141]Steps:   1%|▏         | 13691/1000000 [1:45:32<3098:38:10, 11.31s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [13691], local_loss=0.01550926361232996, train_loss=0.030586693435907364, time_cost=4.940930604934692
Steps:   1%|▏         | 13691/1000000 [1:45:32<3098:38:10, 11.31s/it, lr=1e-5, step_loss=0.0155]Steps:   1%|▏         | 13692/1000000 [1:45:41<2916:21:42, 10.64s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [13692], local_loss=0.012512005865573883, train_loss=0.04458954185247421, time_cost=2.9600582122802734
Steps:   1%|▏         | 13692/1000000 [1:45:41<2916:21:42, 10.64s/it, lr=1e-5, step_loss=0.0125]Steps:   1%|▏         | 13693/1000000 [1:45:48<2618:44:01,  9.56s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [13693], local_loss=0.03683013468980789, train_loss=0.04502797871828079, time_cost=1.95859956741333
Steps:   1%|▏         | 13693/1000000 [1:45:48<2618:44:01,  9.56s/it, lr=1e-5, step_loss=0.0368]Steps:   1%|▏         | 13694/1000000 [1:46:00<2802:09:34, 10.23s/it, lr=1e-5, step_loss=0.0368][RANK-0]: Step: [13694], local_loss=0.06914003193378448, train_loss=0.037463679909706116, time_cost=1.2526881694793701
Steps:   1%|▏         | 13694/1000000 [1:46:00<2802:09:34, 10.23s/it, lr=1e-5, step_loss=0.0691]Steps:   1%|▏         | 13695/1000000 [1:46:05<2387:27:34,  8.71s/it, lr=1e-5, step_loss=0.0691][RANK-0]: Step: [13695], local_loss=0.08578052371740341, train_loss=0.07684270292520523, time_cost=2.07165265083313
Steps:   1%|▏         | 13695/1000000 [1:46:05<2387:27:34,  8.71s/it, lr=1e-5, step_loss=0.0858]Steps:   1%|▏         | 13696/1000000 [1:46:10<2033:52:56,  7.42s/it, lr=1e-5, step_loss=0.0858][RANK-0]: Step: [13696], local_loss=0.013842469081282616, train_loss=0.025684330612421036, time_cost=1.3901774883270264
Steps:   1%|▏         | 13696/1000000 [1:46:10<2033:52:56,  7.42s/it, lr=1e-5, step_loss=0.0138]Steps:   1%|▏         | 13697/1000000 [1:46:20<2264:37:26,  8.27s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [13697], local_loss=0.051931221038103104, train_loss=5.059032440185547, time_cost=7.100661039352417
Steps:   1%|▏         | 13697/1000000 [1:46:20<2264:37:26,  8.27s/it, lr=1e-5, step_loss=0.0519]Steps:   1%|▏         | 13698/1000000 [1:46:32<2537:50:02,  9.26s/it, lr=1e-5, step_loss=0.0519][RANK-0]: Step: [13698], local_loss=0.10318129509687424, train_loss=0.033564385026693344, time_cost=2.6615445613861084
Steps:   1%|▏         | 13698/1000000 [1:46:32<2537:50:02,  9.26s/it, lr=1e-5, step_loss=0.103] Steps:   1%|▏         | 13699/1000000 [1:46:43<2675:48:34,  9.77s/it, lr=1e-5, step_loss=0.103][RANK-0]: Step: [13699], local_loss=0.048107098788022995, train_loss=0.06670451909303665, time_cost=1.5867247581481934
Steps:   1%|▏         | 13699/1000000 [1:46:43<2675:48:34,  9.77s/it, lr=1e-5, step_loss=0.0481]Steps:   1%|▏         | 13700/1000000 [1:46:51<2603:01:39,  9.50s/it, lr=1e-5, step_loss=0.0481][RANK-0]: Step: [13700], local_loss=0.03585526719689369, train_loss=0.02040174975991249, time_cost=1.610973596572876
Steps:   1%|▏         | 13700/1000000 [1:46:51<2603:01:39,  9.50s/it, lr=1e-5, step_loss=0.0359]Steps:   1%|▏         | 13701/1000000 [1:46:59<2439:06:22,  8.90s/it, lr=1e-5, step_loss=0.0359][RANK-0]: Step: [13701], local_loss=0.016830680891871452, train_loss=0.028272081166505814, time_cost=1.2496554851531982
Steps:   1%|▏         | 13701/1000000 [1:46:59<2439:06:22,  8.90s/it, lr=1e-5, step_loss=0.0168]Steps:   1%|▏         | 13702/1000000 [1:47:08<2464:03:42,  8.99s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [13702], local_loss=0.027774110436439514, train_loss=0.02818339690566063, time_cost=3.713304281234741
Steps:   1%|▏         | 13702/1000000 [1:47:08<2464:03:42,  8.99s/it, lr=1e-5, step_loss=0.0278]Steps:   1%|▏         | 13703/1000000 [1:47:16<2358:08:39,  8.61s/it, lr=1e-5, step_loss=0.0278][RANK-0]: Step: [13703], local_loss=0.08215081691741943, train_loss=0.06158149614930153, time_cost=6.20256495475769
Steps:   1%|▏         | 13703/1000000 [1:47:16<2358:08:39,  8.61s/it, lr=1e-5, step_loss=0.0822]Steps:   1%|▏         | 13704/1000000 [1:47:23<2277:32:10,  8.31s/it, lr=1e-5, step_loss=0.0822][RANK-0]: Step: [13704], local_loss=0.027288828045129776, train_loss=0.017419878393411636, time_cost=1.2343072891235352
Steps:   1%|▏         | 13704/1000000 [1:47:23<2277:32:10,  8.31s/it, lr=1e-5, step_loss=0.0273]Steps:   1%|▏         | 13705/1000000 [1:47:40<2944:45:04, 10.75s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [13705], local_loss=0.09543313831090927, train_loss=0.07571326196193695, time_cost=7.199016809463501
Steps:   1%|▏         | 13705/1000000 [1:47:40<2944:45:04, 10.75s/it, lr=1e-5, step_loss=0.0954]Steps:   1%|▏         | 13706/1000000 [1:47:53<3163:20:41, 11.55s/it, lr=1e-5, step_loss=0.0954][RANK-0]: Step: [13706], local_loss=0.07298309355974197, train_loss=0.031843505799770355, time_cost=5.4444520473480225
Steps:   1%|▏         | 13706/1000000 [1:47:53<3163:20:41, 11.55s/it, lr=1e-5, step_loss=0.073] Steps:   1%|▏         | 13707/1000000 [1:48:01<2847:36:07, 10.39s/it, lr=1e-5, step_loss=0.073][RANK-0]: Step: [13707], local_loss=0.022299204021692276, train_loss=0.06147013232111931, time_cost=1.3164875507354736
Steps:   1%|▏         | 13707/1000000 [1:48:01<2847:36:07, 10.39s/it, lr=1e-5, step_loss=0.0223]Steps:   1%|▏         | 13708/1000000 [1:48:16<3192:50:42, 11.65s/it, lr=1e-5, step_loss=0.0223][RANK-0]: Step: [13708], local_loss=0.008765583857893944, train_loss=0.1305309385061264, time_cost=6.076997518539429
Steps:   1%|▏         | 13708/1000000 [1:48:16<3192:50:42, 11.65s/it, lr=1e-5, step_loss=0.00877]Steps:   1%|▏         | 13709/1000000 [1:48:24<2924:42:39, 10.68s/it, lr=1e-5, step_loss=0.00877][RANK-0]: Step: [13709], local_loss=0.026156209409236908, train_loss=0.05020046979188919, time_cost=1.2251124382019043
Steps:   1%|▏         | 13709/1000000 [1:48:24<2924:42:39, 10.68s/it, lr=1e-5, step_loss=0.0262] Steps:   1%|▏         | 13710/1000000 [1:48:37<3147:21:10, 11.49s/it, lr=1e-5, step_loss=0.0262][RANK-0]: Step: [13710], local_loss=0.5090155005455017, train_loss=0.09470922499895096, time_cost=7.221095561981201
Steps:   1%|▏         | 13710/1000000 [1:48:37<3147:21:10, 11.49s/it, lr=1e-5, step_loss=0.509] Steps:   1%|▏         | 13711/1000000 [1:48:43<2686:03:29,  9.80s/it, lr=1e-5, step_loss=0.509][RANK-0]: Step: [13711], local_loss=0.05346790328621864, train_loss=0.046264585107564926, time_cost=1.277698278427124
Steps:   1%|▏         | 13711/1000000 [1:48:43<2686:03:29,  9.80s/it, lr=1e-5, step_loss=0.0535]Steps:   1%|▏         | 13712/1000000 [1:49:00<3250:57:37, 11.87s/it, lr=1e-5, step_loss=0.0535][RANK-0]: Step: [13712], local_loss=0.012692458927631378, train_loss=0.027796011418104172, time_cost=7.856192588806152
Steps:   1%|▏         | 13712/1000000 [1:49:00<3250:57:37, 11.87s/it, lr=1e-5, step_loss=0.0127]Steps:   1%|▏         | 13713/1000000 [1:49:15<3501:28:20, 12.78s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [13713], local_loss=0.021344201639294624, train_loss=0.01999146118760109, time_cost=3.018245220184326
Steps:   1%|▏         | 13713/1000000 [1:49:15<3501:28:20, 12.78s/it, lr=1e-5, step_loss=0.0213]Steps:   1%|▏         | 13714/1000000 [1:49:31<3819:47:05, 13.94s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [13714], local_loss=0.01386092696338892, train_loss=0.02408764697611332, time_cost=7.3370466232299805
Steps:   1%|▏         | 13714/1000000 [1:49:31<3819:47:05, 13.94s/it, lr=1e-5, step_loss=0.0139]Steps:   1%|▏         | 13715/1000000 [1:49:39<3282:20:34, 11.98s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [13715], local_loss=1.0228506326675415, train_loss=0.2627677917480469, time_cost=1.463663101196289
Steps:   1%|▏         | 13715/1000000 [1:49:39<3282:20:34, 11.98s/it, lr=1e-5, step_loss=1.02]  Steps:   1%|▏         | 13716/1000000 [1:49:53<3431:41:17, 12.53s/it, lr=1e-5, step_loss=1.02][RANK-0]: Step: [13716], local_loss=0.028099866583943367, train_loss=0.05084552988409996, time_cost=4.248777389526367
Steps:   1%|▏         | 13716/1000000 [1:49:53<3431:41:17, 12.53s/it, lr=1e-5, step_loss=0.0281]Steps:   1%|▏         | 13717/1000000 [1:49:57<2773:18:54, 10.12s/it, lr=1e-5, step_loss=0.0281][RANK-0]: Step: [13717], local_loss=0.01745014637708664, train_loss=0.05214826390147209, time_cost=1.581099033355713
Steps:   1%|▏         | 13717/1000000 [1:49:57<2773:18:54, 10.12s/it, lr=1e-5, step_loss=0.0175]Steps:   1%|▏         | 13718/1000000 [1:50:02<2354:49:37,  8.60s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [13718], local_loss=0.08713176846504211, train_loss=0.05638888105750084, time_cost=2.1076788902282715
Steps:   1%|▏         | 13718/1000000 [1:50:02<2354:49:37,  8.60s/it, lr=1e-5, step_loss=0.0871]Steps:   1%|▏         | 13719/1000000 [1:50:15<2693:29:35,  9.83s/it, lr=1e-5, step_loss=0.0871][RANK-0]: Step: [13719], local_loss=0.043118055909872055, train_loss=0.15380170941352844, time_cost=1.249208688735962
Steps:   1%|▏         | 13719/1000000 [1:50:15<2693:29:35,  9.83s/it, lr=1e-5, step_loss=0.0431]Steps:   1%|▏         | 13720/1000000 [1:50:21<2349:39:12,  8.58s/it, lr=1e-5, step_loss=0.0431][RANK-0]: Step: [13720], local_loss=0.028360342606902122, train_loss=0.01805197447538376, time_cost=1.4757487773895264
Steps:   1%|▏         | 13720/1000000 [1:50:21<2349:39:12,  8.58s/it, lr=1e-5, step_loss=0.0284]Steps:   1%|▏         | 13721/1000000 [1:50:26<2086:43:48,  7.62s/it, lr=1e-5, step_loss=0.0284][RANK-0]: Step: [13721], local_loss=0.025459831580519676, train_loss=0.18876436352729797, time_cost=2.429863214492798
Steps:   1%|▏         | 13721/1000000 [1:50:26<2086:43:48,  7.62s/it, lr=1e-5, step_loss=0.0255]Steps:   1%|▏         | 13722/1000000 [1:50:31<1877:26:24,  6.85s/it, lr=1e-5, step_loss=0.0255][RANK-0]: Step: [13722], local_loss=0.07753288745880127, train_loss=0.09439054876565933, time_cost=1.9368929862976074
Steps:   1%|▏         | 13722/1000000 [1:50:31<1877:26:24,  6.85s/it, lr=1e-5, step_loss=0.0775]Steps:   1%|▏         | 13723/1000000 [1:50:43<2266:42:47,  8.27s/it, lr=1e-5, step_loss=0.0775][RANK-0]: Step: [13723], local_loss=0.10086341202259064, train_loss=0.05346358194947243, time_cost=2.8926146030426025
Steps:   1%|▏         | 13723/1000000 [1:50:43<2266:42:47,  8.27s/it, lr=1e-5, step_loss=0.101] Steps:   1%|▏         | 13724/1000000 [1:50:57<2754:27:15, 10.05s/it, lr=1e-5, step_loss=0.101][RANK-0]: Step: [13724], local_loss=0.006982251536101103, train_loss=0.11767801642417908, time_cost=5.031375169754028
Steps:   1%|▏         | 13724/1000000 [1:50:57<2754:27:15, 10.05s/it, lr=1e-5, step_loss=0.00698]Steps:   1%|▏         | 13725/1000000 [1:51:06<2674:39:09,  9.76s/it, lr=1e-5, step_loss=0.00698][RANK-0]: Step: [13725], local_loss=0.008107045665383339, train_loss=0.01728663593530655, time_cost=1.2458784580230713
Steps:   1%|▏         | 13725/1000000 [1:51:06<2674:39:09,  9.76s/it, lr=1e-5, step_loss=0.00811]Steps:   1%|▏         | 13726/1000000 [1:51:21<3126:33:39, 11.41s/it, lr=1e-5, step_loss=0.00811][RANK-0]: Step: [13726], local_loss=0.3182503879070282, train_loss=0.07334840297698975, time_cost=7.434555292129517
Steps:   1%|▏         | 13726/1000000 [1:51:21<3126:33:39, 11.41s/it, lr=1e-5, step_loss=0.318]  Steps:   1%|▏         | 13727/1000000 [1:51:26<2614:32:14,  9.54s/it, lr=1e-5, step_loss=0.318][RANK-0]: Step: [13727], local_loss=0.03905155509710312, train_loss=0.022839562967419624, time_cost=1.217684030532837
Steps:   1%|▏         | 13727/1000000 [1:51:26<2614:32:14,  9.54s/it, lr=1e-5, step_loss=0.0391]Steps:   1%|▏         | 13728/1000000 [1:51:35<2498:44:50,  9.12s/it, lr=1e-5, step_loss=0.0391][RANK-0]: Step: [13728], local_loss=0.1305934637784958, train_loss=0.0676615834236145, time_cost=3.93928861618042
Steps:   1%|▏         | 13728/1000000 [1:51:35<2498:44:50,  9.12s/it, lr=1e-5, step_loss=0.131] Steps:   1%|▏         | 13729/1000000 [1:51:50<3042:56:57, 11.11s/it, lr=1e-5, step_loss=0.131][RANK-0]: Step: [13729], local_loss=0.052403323352336884, train_loss=0.025885650888085365, time_cost=7.172762632369995
Steps:   1%|▏         | 13729/1000000 [1:51:50<3042:56:57, 11.11s/it, lr=1e-5, step_loss=0.0524]Steps:   1%|▏         | 13730/1000000 [1:51:56<2584:25:48,  9.43s/it, lr=1e-5, step_loss=0.0524][RANK-0]: Step: [13730], local_loss=0.012493932619690895, train_loss=0.05225686728954315, time_cost=4.12087345123291
Steps:   1%|▏         | 13730/1000000 [1:51:56<2584:25:48,  9.43s/it, lr=1e-5, step_loss=0.0125]Steps:   1%|▏         | 13731/1000000 [1:52:00<2141:24:31,  7.82s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [13731], local_loss=0.02884313091635704, train_loss=0.07853444665670395, time_cost=1.6217706203460693
Steps:   1%|▏         | 13731/1000000 [1:52:00<2141:24:31,  7.82s/it, lr=1e-5, step_loss=0.0288]Steps:   1%|▏         | 13732/1000000 [1:52:10<2358:36:26,  8.61s/it, lr=1e-5, step_loss=0.0288][RANK-0]: Step: [13732], local_loss=0.05493869259953499, train_loss=0.034181877970695496, time_cost=4.0377373695373535
Steps:   1%|▏         | 13732/1000000 [1:52:10<2358:36:26,  8.61s/it, lr=1e-5, step_loss=0.0549]Steps:   1%|▏         | 13733/1000000 [1:52:19<2403:41:58,  8.77s/it, lr=1e-5, step_loss=0.0549][RANK-0]: Step: [13733], local_loss=0.018395522609353065, train_loss=0.16638712584972382, time_cost=2.6659302711486816
Steps:   1%|▏         | 13733/1000000 [1:52:19<2403:41:58,  8.77s/it, lr=1e-5, step_loss=0.0184]Steps:   1%|▏         | 13734/1000000 [1:52:30<2588:49:13,  9.45s/it, lr=1e-5, step_loss=0.0184][RANK-0]: Step: [13734], local_loss=0.006518612615764141, train_loss=19.935794830322266, time_cost=6.103301763534546
Steps:   1%|▏         | 13734/1000000 [1:52:30<2588:49:13,  9.45s/it, lr=1e-5, step_loss=0.00652]Steps:   1%|▏         | 13735/1000000 [1:52:36<2299:07:03,  8.39s/it, lr=1e-5, step_loss=0.00652][RANK-0]: Step: [13735], local_loss=0.05092192068696022, train_loss=0.03509654104709625, time_cost=2.4574167728424072
Steps:   1%|▏         | 13735/1000000 [1:52:36<2299:07:03,  8.39s/it, lr=1e-5, step_loss=0.0509] Steps:   1%|▏         | 13736/1000000 [1:52:42<2073:04:59,  7.57s/it, lr=1e-5, step_loss=0.0509][RANK-0]: Step: [13736], local_loss=0.030472809448838234, train_loss=0.1501321643590927, time_cost=2.842550754547119
Steps:   1%|▏         | 13736/1000000 [1:52:42<2073:04:59,  7.57s/it, lr=1e-5, step_loss=0.0305]Steps:   1%|▏         | 13737/1000000 [1:52:46<1796:02:08,  6.56s/it, lr=1e-5, step_loss=0.0305][RANK-0]: Step: [13737], local_loss=0.013423732481896877, train_loss=0.22838006913661957, time_cost=1.3215301036834717
Steps:   1%|▏         | 13737/1000000 [1:52:46<1796:02:08,  6.56s/it, lr=1e-5, step_loss=0.0134]Steps:   1%|▏         | 13738/1000000 [1:52:51<1674:26:49,  6.11s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [13738], local_loss=0.014004727825522423, train_loss=0.0546131432056427, time_cost=2.0614171028137207
Steps:   1%|▏         | 13738/1000000 [1:52:51<1674:26:49,  6.11s/it, lr=1e-5, step_loss=0.014] Steps:   1%|▏         | 13739/1000000 [1:53:00<1903:38:05,  6.95s/it, lr=1e-5, step_loss=0.014][RANK-0]: Step: [13739], local_loss=0.011097675189375877, train_loss=0.06859361380338669, time_cost=6.227291822433472
Steps:   1%|▏         | 13739/1000000 [1:53:00<1903:38:05,  6.95s/it, lr=1e-5, step_loss=0.0111]Steps:   1%|▏         | 13740/1000000 [1:53:10<2177:43:10,  7.95s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [13740], local_loss=0.05148248001933098, train_loss=0.08320917934179306, time_cost=7.628913879394531
Steps:   1%|▏         | 13740/1000000 [1:53:10<2177:43:10,  7.95s/it, lr=1e-5, step_loss=0.0515]Steps:   1%|▏         | 13741/1000000 [1:53:16<1965:34:05,  7.17s/it, lr=1e-5, step_loss=0.0515][RANK-0]: Step: [13741], local_loss=0.07269264757633209, train_loss=0.027351275086402893, time_cost=2.279588222503662
Steps:   1%|▏         | 13741/1000000 [1:53:16<1965:34:05,  7.17s/it, lr=1e-5, step_loss=0.0727]Steps:   1%|▏         | 13742/1000000 [1:53:24<2066:43:51,  7.54s/it, lr=1e-5, step_loss=0.0727][RANK-0]: Step: [13742], local_loss=0.02361937053501606, train_loss=0.04765481501817703, time_cost=3.101846933364868
Steps:   1%|▏         | 13742/1000000 [1:53:24<2066:43:51,  7.54s/it, lr=1e-5, step_loss=0.0236]Steps:   1%|▏         | 13743/1000000 [1:53:32<2068:55:06,  7.55s/it, lr=1e-5, step_loss=0.0236][RANK-0]: Step: [13743], local_loss=0.024487268179655075, train_loss=0.04053555428981781, time_cost=2.1359386444091797
Steps:   1%|▏         | 13743/1000000 [1:53:32<2068:55:06,  7.55s/it, lr=1e-5, step_loss=0.0245]Steps:   1%|▏         | 13744/1000000 [1:53:39<2041:15:06,  7.45s/it, lr=1e-5, step_loss=0.0245][RANK-0]: Step: [13744], local_loss=0.015016269870102406, train_loss=0.0677599310874939, time_cost=1.5804667472839355
Steps:   1%|▏         | 13744/1000000 [1:53:39<2041:15:06,  7.45s/it, lr=1e-5, step_loss=0.015] Steps:   1%|▏         | 13745/1000000 [1:53:50<2317:30:54,  8.46s/it, lr=1e-5, step_loss=0.015][RANK-0]: Step: [13745], local_loss=0.07836823910474777, train_loss=0.04083532467484474, time_cost=2.9783084392547607
Steps:   1%|▏         | 13745/1000000 [1:53:50<2317:30:54,  8.46s/it, lr=1e-5, step_loss=0.0784]Steps:   1%|▏         | 13746/1000000 [1:53:59<2395:19:49,  8.74s/it, lr=1e-5, step_loss=0.0784][RANK-0]: Step: [13746], local_loss=0.034018535166978836, train_loss=0.017051417380571365, time_cost=3.120349407196045
Steps:   1%|▏         | 13746/1000000 [1:53:59<2395:19:49,  8.74s/it, lr=1e-5, step_loss=0.034] Steps:   1%|▏         | 13747/1000000 [1:54:15<2966:35:12, 10.83s/it, lr=1e-5, step_loss=0.034][RANK-0]: Step: [13747], local_loss=0.020058318972587585, train_loss=0.04578378051519394, time_cost=7.295003175735474
Steps:   1%|▏         | 13747/1000000 [1:54:15<2966:35:12, 10.83s/it, lr=1e-5, step_loss=0.0201]Steps:   1%|▏         | 13748/1000000 [1:54:28<3158:19:10, 11.53s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [13748], local_loss=0.03189845383167267, train_loss=0.0266916174441576, time_cost=5.374443292617798
Steps:   1%|▏         | 13748/1000000 [1:54:28<3158:19:10, 11.53s/it, lr=1e-5, step_loss=0.0319]Steps:   1%|▏         | 13749/1000000 [1:54:34<2705:46:45,  9.88s/it, lr=1e-5, step_loss=0.0319][RANK-0]: Step: [13749], local_loss=0.013549907132983208, train_loss=0.020133908838033676, time_cost=1.730161190032959
Steps:   1%|▏         | 13749/1000000 [1:54:34<2705:46:45,  9.88s/it, lr=1e-5, step_loss=0.0135]Steps:   1%|▏         | 13750/1000000 [1:54:41<2473:44:05,  9.03s/it, lr=1e-5, step_loss=0.0135][RANK-0]: Step: [13750], local_loss=0.01967829279601574, train_loss=0.06663002818822861, time_cost=2.343904972076416
Steps:   1%|▏         | 13750/1000000 [1:54:41<2473:44:05,  9.03s/it, lr=1e-5, step_loss=0.0197]Steps:   1%|▏         | 13751/1000000 [1:54:52<2653:02:32,  9.68s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [13751], local_loss=0.04740433394908905, train_loss=0.044074125587940216, time_cost=2.606153964996338
Steps:   1%|▏         | 13751/1000000 [1:54:52<2653:02:32,  9.68s/it, lr=1e-5, step_loss=0.0474]Steps:   1%|▏         | 13752/1000000 [1:55:02<2678:25:12,  9.78s/it, lr=1e-5, step_loss=0.0474][RANK-0]: Step: [13752], local_loss=0.03627992421388626, train_loss=0.0558759830892086, time_cost=1.227248191833496
Steps:   1%|▏         | 13752/1000000 [1:55:02<2678:25:12,  9.78s/it, lr=1e-5, step_loss=0.0363]Steps:   1%|▏         | 13753/1000000 [1:55:07<2233:31:34,  8.15s/it, lr=1e-5, step_loss=0.0363][RANK-0]: Step: [13753], local_loss=0.0199672132730484, train_loss=0.05150136351585388, time_cost=1.2467725276947021
Steps:   1%|▏         | 13753/1000000 [1:55:07<2233:31:34,  8.15s/it, lr=1e-5, step_loss=0.02]  Steps:   1%|▏         | 13754/1000000 [1:55:21<2734:53:37,  9.98s/it, lr=1e-5, step_loss=0.02][RANK-0]: Step: [13754], local_loss=0.027242157608270645, train_loss=0.05922781303524971, time_cost=5.722615003585815
Steps:   1%|▏         | 13754/1000000 [1:55:21<2734:53:37,  9.98s/it, lr=1e-5, step_loss=0.0272]Steps:   1%|▏         | 13755/1000000 [1:55:35<3049:58:44, 11.13s/it, lr=1e-5, step_loss=0.0272][RANK-0]: Step: [13755], local_loss=0.022647012025117874, train_loss=0.05003056675195694, time_cost=1.2376437187194824
Steps:   1%|▏         | 13755/1000000 [1:55:35<3049:58:44, 11.13s/it, lr=1e-5, step_loss=0.0226]Steps:   1%|▏         | 13756/1000000 [1:55:42<2754:24:42, 10.05s/it, lr=1e-5, step_loss=0.0226][RANK-0]: Step: [13756], local_loss=0.023785125464200974, train_loss=0.08615999668836594, time_cost=2.556518793106079
Steps:   1%|▏         | 13756/1000000 [1:55:42<2754:24:42, 10.05s/it, lr=1e-5, step_loss=0.0238]Steps:   1%|▏         | 13757/1000000 [1:55:49<2498:47:22,  9.12s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [13757], local_loss=0.009426325559616089, train_loss=0.017838096246123314, time_cost=5.20929741859436
Steps:   1%|▏         | 13757/1000000 [1:55:49<2498:47:22,  9.12s/it, lr=1e-5, step_loss=0.00943]Steps:   1%|▏         | 13758/1000000 [1:56:02<2803:59:20, 10.24s/it, lr=1e-5, step_loss=0.00943][RANK-0]: Step: [13758], local_loss=0.04887557774782181, train_loss=0.07279001176357269, time_cost=6.127429246902466
Steps:   1%|▏         | 13758/1000000 [1:56:02<2803:59:20, 10.24s/it, lr=1e-5, step_loss=0.0489] Steps:   1%|▏         | 13759/1000000 [1:56:08<2449:24:43,  8.94s/it, lr=1e-5, step_loss=0.0489][RANK-0]: Step: [13759], local_loss=0.049442559480667114, train_loss=0.026954293251037598, time_cost=4.60748028755188
Steps:   1%|▏         | 13759/1000000 [1:56:08<2449:24:43,  8.94s/it, lr=1e-5, step_loss=0.0494]Steps:   1%|▏         | 13760/1000000 [1:56:15<2267:27:37,  8.28s/it, lr=1e-5, step_loss=0.0494][RANK-0]: Step: [13760], local_loss=0.05783134698867798, train_loss=0.04905251786112785, time_cost=2.9501078128814697
Steps:   1%|▏         | 13760/1000000 [1:56:15<2267:27:37,  8.28s/it, lr=1e-5, step_loss=0.0578]Steps:   1%|▏         | 13761/1000000 [1:56:20<2019:50:33,  7.37s/it, lr=1e-5, step_loss=0.0578][RANK-0]: Step: [13761], local_loss=0.0584285631775856, train_loss=0.053340282291173935, time_cost=2.4021639823913574
Steps:   1%|▏         | 13761/1000000 [1:56:20<2019:50:33,  7.37s/it, lr=1e-5, step_loss=0.0584]Steps:   1%|▏         | 13762/1000000 [1:56:29<2180:02:50,  7.96s/it, lr=1e-5, step_loss=0.0584][RANK-0]: Step: [13762], local_loss=0.06389649957418442, train_loss=0.041636791080236435, time_cost=3.2257590293884277
Steps:   1%|▏         | 13762/1000000 [1:56:29<2180:02:50,  7.96s/it, lr=1e-5, step_loss=0.0639]Steps:   1%|▏         | 13763/1000000 [1:56:35<2011:16:28,  7.34s/it, lr=1e-5, step_loss=0.0639][RANK-0]: Step: [13763], local_loss=0.03853623941540718, train_loss=0.07785142213106155, time_cost=4.11813497543335
Steps:   1%|▏         | 13763/1000000 [1:56:35<2011:16:28,  7.34s/it, lr=1e-5, step_loss=0.0385]Steps:   1%|▏         | 13764/1000000 [1:56:45<2166:25:40,  7.91s/it, lr=1e-5, step_loss=0.0385][RANK-0]: Step: [13764], local_loss=0.06049160286784172, train_loss=0.036250390112400055, time_cost=2.1750476360321045
Steps:   1%|▏         | 13764/1000000 [1:56:45<2166:25:40,  7.91s/it, lr=1e-5, step_loss=0.0605]Steps:   1%|▏         | 13765/1000000 [1:56:54<2329:01:31,  8.50s/it, lr=1e-5, step_loss=0.0605][RANK-0]: Step: [13765], local_loss=0.09326007217168808, train_loss=0.08064396679401398, time_cost=3.92952823638916
Steps:   1%|▏         | 13765/1000000 [1:56:54<2329:01:31,  8.50s/it, lr=1e-5, step_loss=0.0933]Steps:   1%|▏         | 13766/1000000 [1:57:06<2592:07:44,  9.46s/it, lr=1e-5, step_loss=0.0933][RANK-0]: Step: [13766], local_loss=0.01035093143582344, train_loss=0.030351150780916214, time_cost=2.1537163257598877
Steps:   1%|▏         | 13766/1000000 [1:57:06<2592:07:44,  9.46s/it, lr=1e-5, step_loss=0.0104]Steps:   1%|▏         | 13767/1000000 [1:57:17<2741:38:05, 10.01s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [13767], local_loss=0.029198303818702698, train_loss=0.018988903611898422, time_cost=4.517977237701416
Steps:   1%|▏         | 13767/1000000 [1:57:17<2741:38:05, 10.01s/it, lr=1e-5, step_loss=0.0292]Steps:   1%|▏         | 13768/1000000 [1:57:24<2498:12:20,  9.12s/it, lr=1e-5, step_loss=0.0292][RANK-0]: Step: [13768], local_loss=0.01396426185965538, train_loss=0.03870946913957596, time_cost=1.2637689113616943
Steps:   1%|▏         | 13768/1000000 [1:57:24<2498:12:20,  9.12s/it, lr=1e-5, step_loss=0.014] Steps:   1%|▏         | 13769/1000000 [1:57:39<2983:49:55, 10.89s/it, lr=1e-5, step_loss=0.014][RANK-0]: Step: [13769], local_loss=0.03754132241010666, train_loss=0.03535902500152588, time_cost=1.2764294147491455
Steps:   1%|▏         | 13769/1000000 [1:57:39<2983:49:55, 10.89s/it, lr=1e-5, step_loss=0.0375]Steps:   1%|▏         | 13770/1000000 [1:57:45<2505:39:02,  9.15s/it, lr=1e-5, step_loss=0.0375][RANK-0]: Step: [13770], local_loss=0.02807035483419895, train_loss=0.019101910293102264, time_cost=1.206165075302124
Steps:   1%|▏         | 13770/1000000 [1:57:45<2505:39:02,  9.15s/it, lr=1e-5, step_loss=0.0281]Steps:   1%|▏         | 13771/1000000 [1:57:53<2483:44:32,  9.07s/it, lr=1e-5, step_loss=0.0281][RANK-0]: Step: [13771], local_loss=0.013347203843295574, train_loss=0.02857615239918232, time_cost=1.236379623413086
Steps:   1%|▏         | 13771/1000000 [1:57:53<2483:44:32,  9.07s/it, lr=1e-5, step_loss=0.0133]Steps:   1%|▏         | 13772/1000000 [1:58:04<2601:27:29,  9.50s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [13772], local_loss=0.012800326570868492, train_loss=0.02341354638338089, time_cost=7.55884575843811
Steps:   1%|▏         | 13772/1000000 [1:58:04<2601:27:29,  9.50s/it, lr=1e-5, step_loss=0.0128]Steps:   1%|▏         | 13773/1000000 [1:58:09<2271:39:06,  8.29s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [13773], local_loss=0.026254579424858093, train_loss=0.021691977977752686, time_cost=2.747889995574951
Steps:   1%|▏         | 13773/1000000 [1:58:09<2271:39:06,  8.29s/it, lr=1e-5, step_loss=0.0263]Steps:   1%|▏         | 13774/1000000 [1:58:21<2535:02:00,  9.25s/it, lr=1e-5, step_loss=0.0263][RANK-0]: Step: [13774], local_loss=0.02357030101120472, train_loss=0.0315299890935421, time_cost=1.2170884609222412
Steps:   1%|▏         | 13774/1000000 [1:58:21<2535:02:00,  9.25s/it, lr=1e-5, step_loss=0.0236]Steps:   1%|▏         | 13775/1000000 [1:58:26<2227:44:08,  8.13s/it, lr=1e-5, step_loss=0.0236][RANK-0]: Step: [13775], local_loss=0.12535220384597778, train_loss=0.038658320903778076, time_cost=2.2896475791931152
Steps:   1%|▏         | 13775/1000000 [1:58:26<2227:44:08,  8.13s/it, lr=1e-5, step_loss=0.125] Steps:   1%|▏         | 13776/1000000 [1:58:39<2634:34:36,  9.62s/it, lr=1e-5, step_loss=0.125][RANK-0]: Step: [13776], local_loss=0.04370423033833504, train_loss=0.14299467206001282, time_cost=1.222435712814331
Steps:   1%|▏         | 13776/1000000 [1:58:39<2634:34:36,  9.62s/it, lr=1e-5, step_loss=0.0437]Steps:   1%|▏         | 13777/1000000 [1:58:47<2460:25:52,  8.98s/it, lr=1e-5, step_loss=0.0437][RANK-0]: Step: [13777], local_loss=0.012253125198185444, train_loss=0.14283335208892822, time_cost=2.499677896499634
Steps:   1%|▏         | 13777/1000000 [1:58:47<2460:25:52,  8.98s/it, lr=1e-5, step_loss=0.0123]Steps:   1%|▏         | 13778/1000000 [1:58:54<2300:49:34,  8.40s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [13778], local_loss=0.02018783986568451, train_loss=0.057089388370513916, time_cost=2.4332189559936523
Steps:   1%|▏         | 13778/1000000 [1:58:54<2300:49:34,  8.40s/it, lr=1e-5, step_loss=0.0202]Steps:   1%|▏         | 13779/1000000 [1:58:59<2048:37:05,  7.48s/it, lr=1e-5, step_loss=0.0202][RANK-0]: Step: [13779], local_loss=0.008456987328827381, train_loss=0.022286906838417053, time_cost=4.247040510177612
Steps:   1%|▏         | 13779/1000000 [1:58:59<2048:37:05,  7.48s/it, lr=1e-5, step_loss=0.00846]Steps:   1%|▏         | 13780/1000000 [1:59:10<2337:06:51,  8.53s/it, lr=1e-5, step_loss=0.00846][RANK-0]: Step: [13780], local_loss=0.07376515120267868, train_loss=0.1262854039669037, time_cost=2.3442838191986084
Steps:   1%|▏         | 13780/1000000 [1:59:10<2337:06:51,  8.53s/it, lr=1e-5, step_loss=0.0738] Steps:   1%|▏         | 13781/1000000 [1:59:21<2522:21:57,  9.21s/it, lr=1e-5, step_loss=0.0738][RANK-0]: Step: [13781], local_loss=0.024893922731280327, train_loss=0.013536830432713032, time_cost=2.990837812423706
Steps:   1%|▏         | 13781/1000000 [1:59:21<2522:21:57,  9.21s/it, lr=1e-5, step_loss=0.0249]Steps:   1%|▏         | 13782/1000000 [1:59:26<2186:35:48,  7.98s/it, lr=1e-5, step_loss=0.0249][RANK-0]: Step: [13782], local_loss=0.007212746888399124, train_loss=0.03156011551618576, time_cost=2.0999550819396973
Steps:   1%|▏         | 13782/1000000 [1:59:26<2186:35:48,  7.98s/it, lr=1e-5, step_loss=0.00721]Steps:   1%|▏         | 13783/1000000 [1:59:41<2767:11:12, 10.10s/it, lr=1e-5, step_loss=0.00721][RANK-0]: Step: [13783], local_loss=0.029612435027956963, train_loss=0.037726521492004395, time_cost=10.998513460159302
Steps:   1%|▏         | 13783/1000000 [1:59:41<2767:11:12, 10.10s/it, lr=1e-5, step_loss=0.0296] Steps:   1%|▏         | 13784/1000000 [1:59:54<3007:42:14, 10.98s/it, lr=1e-5, step_loss=0.0296][RANK-0]: Step: [13784], local_loss=0.016788361594080925, train_loss=7.800343990325928, time_cost=3.2731261253356934
Steps:   1%|▏         | 13784/1000000 [1:59:54<3007:42:14, 10.98s/it, lr=1e-5, step_loss=0.0168]Steps:   1%|▏         | 13785/1000000 [2:00:10<3407:15:21, 12.44s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [13785], local_loss=0.01148716639727354, train_loss=0.019653234630823135, time_cost=1.2507407665252686
Steps:   1%|▏         | 13785/1000000 [2:00:10<3407:15:21, 12.44s/it, lr=1e-5, step_loss=0.0115]Steps:   1%|▏         | 13786/1000000 [2:00:18<2996:51:12, 10.94s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [13786], local_loss=0.017197290435433388, train_loss=0.024600911885499954, time_cost=1.2941608428955078
Steps:   1%|▏         | 13786/1000000 [2:00:18<2996:51:12, 10.94s/it, lr=1e-5, step_loss=0.0172]Steps:   1%|▏         | 13787/1000000 [2:00:29<3006:21:41, 10.97s/it, lr=1e-5, step_loss=0.0172][RANK-0]: Step: [13787], local_loss=0.17986111342906952, train_loss=0.11112084984779358, time_cost=8.463845252990723
Steps:   1%|▏         | 13787/1000000 [2:00:29<3006:21:41, 10.97s/it, lr=1e-5, step_loss=0.18]  Steps:   1%|▏         | 13788/1000000 [2:00:38<2877:52:19, 10.51s/it, lr=1e-5, step_loss=0.18][RANK-0]: Step: [13788], local_loss=0.00830318033695221, train_loss=0.022066015750169754, time_cost=2.6133875846862793
Steps:   1%|▏         | 13788/1000000 [2:00:38<2877:52:19, 10.51s/it, lr=1e-5, step_loss=0.0083]Steps:   1%|▏         | 13789/1000000 [2:00:44<2509:37:25,  9.16s/it, lr=1e-5, step_loss=0.0083][RANK-0]: Step: [13789], local_loss=0.055674947798252106, train_loss=0.027808986604213715, time_cost=1.7779419422149658
Steps:   1%|▏         | 13789/1000000 [2:00:44<2509:37:25,  9.16s/it, lr=1e-5, step_loss=0.0557]Steps:   1%|▏         | 13790/1000000 [2:00:51<2309:50:02,  8.43s/it, lr=1e-5, step_loss=0.0557][RANK-0]: Step: [13790], local_loss=0.32173386216163635, train_loss=0.07918243855237961, time_cost=2.795339345932007
Steps:   1%|▏         | 13790/1000000 [2:00:51<2309:50:02,  8.43s/it, lr=1e-5, step_loss=0.322] Steps:   1%|▏         | 13791/1000000 [2:01:05<2762:33:40, 10.08s/it, lr=1e-5, step_loss=0.322][RANK-0]: Step: [13791], local_loss=0.03501340001821518, train_loss=0.031049787998199463, time_cost=5.2560553550720215
Steps:   1%|▏         | 13791/1000000 [2:01:05<2762:33:40, 10.08s/it, lr=1e-5, step_loss=0.035]Steps:   1%|▏         | 13792/1000000 [2:01:18<3018:23:38, 11.02s/it, lr=1e-5, step_loss=0.035][RANK-0]: Step: [13792], local_loss=0.015331710688769817, train_loss=0.044368259608745575, time_cost=1.3792614936828613
Steps:   1%|▏         | 13792/1000000 [2:01:18<3018:23:38, 11.02s/it, lr=1e-5, step_loss=0.0153]Steps:   1%|▏         | 13793/1000000 [2:01:32<3244:52:13, 11.84s/it, lr=1e-5, step_loss=0.0153][RANK-0]: Step: [13793], local_loss=0.11916784197092056, train_loss=0.03222552686929703, time_cost=4.08215069770813
Steps:   1%|▏         | 13793/1000000 [2:01:32<3244:52:13, 11.84s/it, lr=1e-5, step_loss=0.119] Steps:   1%|▏         | 13794/1000000 [2:01:36<2659:14:54,  9.71s/it, lr=1e-5, step_loss=0.119][RANK-0]: Step: [13794], local_loss=0.008388273417949677, train_loss=0.01681290566921234, time_cost=2.1446852684020996
Steps:   1%|▏         | 13794/1000000 [2:01:36<2659:14:54,  9.71s/it, lr=1e-5, step_loss=0.00839]Steps:   1%|▏         | 13795/1000000 [2:01:44<2444:44:32,  8.92s/it, lr=1e-5, step_loss=0.00839][RANK-0]: Step: [13795], local_loss=0.08678115159273148, train_loss=0.1725326031446457, time_cost=2.659148693084717
Steps:   1%|▏         | 13795/1000000 [2:01:44<2444:44:32,  8.92s/it, lr=1e-5, step_loss=0.0868] Steps:   1%|▏         | 13796/1000000 [2:01:57<2856:49:28, 10.43s/it, lr=1e-5, step_loss=0.0868][RANK-0]: Step: [13796], local_loss=0.006482580676674843, train_loss=0.038838762789964676, time_cost=5.441224813461304
Steps:   1%|▏         | 13796/1000000 [2:01:57<2856:49:28, 10.43s/it, lr=1e-5, step_loss=0.00648]Steps:   1%|▏         | 13797/1000000 [2:02:08<2888:48:50, 10.55s/it, lr=1e-5, step_loss=0.00648][RANK-0]: Step: [13797], local_loss=0.011343698017299175, train_loss=0.1847434639930725, time_cost=1.6508674621582031
Steps:   1%|▏         | 13797/1000000 [2:02:08<2888:48:50, 10.55s/it, lr=1e-5, step_loss=0.0113] Steps:   1%|▏         | 13798/1000000 [2:02:18<2818:38:09, 10.29s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [13798], local_loss=0.007663396652787924, train_loss=0.020789382979273796, time_cost=1.5514578819274902
Steps:   1%|▏         | 13798/1000000 [2:02:18<2818:38:09, 10.29s/it, lr=1e-5, step_loss=0.00766]Steps:   1%|▏         | 13799/1000000 [2:02:24<2494:00:43,  9.10s/it, lr=1e-5, step_loss=0.00766][RANK-0]: Step: [13799], local_loss=0.020045896992087364, train_loss=0.025070423260331154, time_cost=1.644887924194336
Steps:   1%|▏         | 13799/1000000 [2:02:24<2494:00:43,  9.10s/it, lr=1e-5, step_loss=0.02]   Steps:   1%|▏         | 13800/1000000 [2:02:29<2151:48:42,  7.85s/it, lr=1e-5, step_loss=0.02][RANK-0]: Step: [13800], local_loss=0.02968878298997879, train_loss=0.16264888644218445, time_cost=1.807671070098877
Steps:   1%|▏         | 13800/1000000 [2:02:29<2151:48:42,  7.85s/it, lr=1e-5, step_loss=0.0297]Steps:   1%|▏         | 13801/1000000 [2:02:43<2666:57:01,  9.74s/it, lr=1e-5, step_loss=0.0297][RANK-0]: Step: [13801], local_loss=0.008464176207780838, train_loss=0.04822885990142822, time_cost=4.174352407455444
Steps:   1%|▏         | 13801/1000000 [2:02:43<2666:57:01,  9.74s/it, lr=1e-5, step_loss=0.00846]Steps:   1%|▏         | 13802/1000000 [2:02:51<2497:30:11,  9.12s/it, lr=1e-5, step_loss=0.00846][RANK-0]: Step: [13802], local_loss=0.009772680699825287, train_loss=0.07192634046077728, time_cost=5.893240690231323
Steps:   1%|▏         | 13802/1000000 [2:02:51<2497:30:11,  9.12s/it, lr=1e-5, step_loss=0.00977]Steps:   1%|▏         | 13803/1000000 [2:02:59<2427:36:53,  8.86s/it, lr=1e-5, step_loss=0.00977][RANK-0]: Step: [13803], local_loss=0.1644420027732849, train_loss=0.06045621633529663, time_cost=3.775536298751831
Steps:   1%|▏         | 13803/1000000 [2:02:59<2427:36:53,  8.86s/it, lr=1e-5, step_loss=0.164]  Steps:   1%|▏         | 13804/1000000 [2:03:05<2179:49:45,  7.96s/it, lr=1e-5, step_loss=0.164][RANK-0]: Step: [13804], local_loss=0.2920246422290802, train_loss=0.07436949014663696, time_cost=1.5408987998962402
Steps:   1%|▏         | 13804/1000000 [2:03:05<2179:49:45,  7.96s/it, lr=1e-5, step_loss=0.292]Steps:   1%|▏         | 13805/1000000 [2:03:17<2516:06:48,  9.18s/it, lr=1e-5, step_loss=0.292][RANK-0]: Step: [13805], local_loss=0.9947744011878967, train_loss=0.16220705211162567, time_cost=3.897627830505371
Steps:   1%|▏         | 13805/1000000 [2:03:17<2516:06:48,  9.18s/it, lr=1e-5, step_loss=0.995]Steps:   1%|▏         | 13806/1000000 [2:03:22<2142:07:45,  7.82s/it, lr=1e-5, step_loss=0.995][RANK-0]: Step: [13806], local_loss=0.023390837013721466, train_loss=0.04057478532195091, time_cost=1.4600343704223633
Steps:   1%|▏         | 13806/1000000 [2:03:22<2142:07:45,  7.82s/it, lr=1e-5, step_loss=0.0234]Steps:   1%|▏         | 13807/1000000 [2:03:31<2265:18:58,  8.27s/it, lr=1e-5, step_loss=0.0234][RANK-0]: Step: [13807], local_loss=0.02294100821018219, train_loss=0.032400280237197876, time_cost=3.229797124862671
Steps:   1%|▏         | 13807/1000000 [2:03:31<2265:18:58,  8.27s/it, lr=1e-5, step_loss=0.0229]Steps:   1%|▏         | 13808/1000000 [2:03:36<1965:24:06,  7.17s/it, lr=1e-5, step_loss=0.0229][RANK-0]: Step: [13808], local_loss=0.026901111006736755, train_loss=0.05834632366895676, time_cost=3.6748411655426025
Steps:   1%|▏         | 13808/1000000 [2:03:36<1965:24:06,  7.17s/it, lr=1e-5, step_loss=0.0269]Steps:   1%|▏         | 13809/1000000 [2:03:43<1949:37:06,  7.12s/it, lr=1e-5, step_loss=0.0269][RANK-0]: Step: [13809], local_loss=0.011293169111013412, train_loss=0.05990799143910408, time_cost=2.5258865356445312
Steps:   1%|▏         | 13809/1000000 [2:03:43<1949:37:06,  7.12s/it, lr=1e-5, step_loss=0.0113]Steps:   1%|▏         | 13810/1000000 [2:03:47<1722:09:44,  6.29s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [13810], local_loss=0.11841903626918793, train_loss=0.16979852318763733, time_cost=1.8974909782409668
Steps:   1%|▏         | 13810/1000000 [2:03:47<1722:09:44,  6.29s/it, lr=1e-5, step_loss=0.118] Steps:   1%|▏         | 13811/1000000 [2:03:53<1695:44:09,  6.19s/it, lr=1e-5, step_loss=0.118][RANK-0]: Step: [13811], local_loss=0.010000551119446754, train_loss=0.05137188732624054, time_cost=1.3697521686553955
Steps:   1%|▏         | 13811/1000000 [2:03:53<1695:44:09,  6.19s/it, lr=1e-5, step_loss=0.01] Steps:   1%|▏         | 13812/1000000 [2:04:05<2138:59:34,  7.81s/it, lr=1e-5, step_loss=0.01][RANK-0]: Step: [13812], local_loss=0.008556229062378407, train_loss=0.07726245373487473, time_cost=4.496408224105835
Steps:   1%|▏         | 13812/1000000 [2:04:05<2138:59:34,  7.81s/it, lr=1e-5, step_loss=0.00856]Steps:   1%|▏         | 13813/1000000 [2:04:09<1846:34:25,  6.74s/it, lr=1e-5, step_loss=0.00856][RANK-0]: Step: [13813], local_loss=0.013431882485747337, train_loss=0.03226893022656441, time_cost=1.3919029235839844
Steps:   1%|▏         | 13813/1000000 [2:04:09<1846:34:25,  6.74s/it, lr=1e-5, step_loss=0.0134] Steps:   1%|▏         | 13814/1000000 [2:04:14<1697:48:01,  6.20s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [13814], local_loss=1.0087385177612305, train_loss=0.15109333395957947, time_cost=2.293173313140869
Steps:   1%|▏         | 13814/1000000 [2:04:14<1697:48:01,  6.20s/it, lr=1e-5, step_loss=1.01]  Steps:   1%|▏         | 13815/1000000 [2:04:25<2071:00:07,  7.56s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [13815], local_loss=0.043529145419597626, train_loss=0.0210406631231308, time_cost=2.887620449066162
Steps:   1%|▏         | 13815/1000000 [2:04:25<2071:00:07,  7.56s/it, lr=1e-5, step_loss=0.0435]Steps:   1%|▏         | 13816/1000000 [2:04:32<2069:39:22,  7.56s/it, lr=1e-5, step_loss=0.0435][RANK-0]: Step: [13816], local_loss=0.010192747227847576, train_loss=19.08844566345215, time_cost=2.6159071922302246
Steps:   1%|▏         | 13816/1000000 [2:04:32<2069:39:22,  7.56s/it, lr=1e-5, step_loss=0.0102]Steps:   1%|▏         | 13817/1000000 [2:04:38<1932:46:21,  7.06s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [13817], local_loss=0.011801824904978275, train_loss=0.038722194731235504, time_cost=4.39163064956665
Steps:   1%|▏         | 13817/1000000 [2:04:38<1932:46:21,  7.06s/it, lr=1e-5, step_loss=0.0118]Steps:   1%|▏         | 13818/1000000 [2:04:46<1982:30:48,  7.24s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [13818], local_loss=0.019985077902674675, train_loss=0.11274802684783936, time_cost=3.3976330757141113
Steps:   1%|▏         | 13818/1000000 [2:04:46<1982:30:48,  7.24s/it, lr=1e-5, step_loss=0.02]  Steps:   1%|▏         | 13819/1000000 [2:04:56<2221:36:14,  8.11s/it, lr=1e-5, step_loss=0.02][RANK-0]: Step: [13819], local_loss=0.0066056689247488976, train_loss=0.07271447777748108, time_cost=1.3243021965026855
Steps:   1%|▏         | 13819/1000000 [2:04:56<2221:36:14,  8.11s/it, lr=1e-5, step_loss=0.00661]Steps:   1%|▏         | 13820/1000000 [2:05:02<2074:56:01,  7.57s/it, lr=1e-5, step_loss=0.00661][RANK-0]: Step: [13820], local_loss=0.026438988745212555, train_loss=0.017764899879693985, time_cost=1.7676663398742676
Steps:   1%|▏         | 13820/1000000 [2:05:02<2074:56:01,  7.57s/it, lr=1e-5, step_loss=0.0264] Steps:   1%|▏         | 13821/1000000 [2:05:08<1892:20:26,  6.91s/it, lr=1e-5, step_loss=0.0264][RANK-0]: Step: [13821], local_loss=0.07752404361963272, train_loss=0.03817079961299896, time_cost=3.049163818359375
Steps:   1%|▏         | 13821/1000000 [2:05:08<1892:20:26,  6.91s/it, lr=1e-5, step_loss=0.0775]Steps:   1%|▏         | 13822/1000000 [2:05:12<1684:10:08,  6.15s/it, lr=1e-5, step_loss=0.0775][RANK-0]: Step: [13822], local_loss=0.05661178007721901, train_loss=0.04511518403887749, time_cost=1.3764605522155762
Steps:   1%|▏         | 13822/1000000 [2:05:12<1684:10:08,  6.15s/it, lr=1e-5, step_loss=0.0566]Steps:   1%|▏         | 13823/1000000 [2:05:26<2323:47:03,  8.48s/it, lr=1e-5, step_loss=0.0566][RANK-0]: Step: [13823], local_loss=0.0939435213804245, train_loss=0.10303159058094025, time_cost=4.0408806800842285
Steps:   1%|▏         | 13823/1000000 [2:05:26<2323:47:03,  8.48s/it, lr=1e-5, step_loss=0.0939]Steps:   1%|▏         | 13824/1000000 [2:05:32<2115:45:40,  7.72s/it, lr=1e-5, step_loss=0.0939][RANK-0]: Step: [13824], local_loss=0.03683236986398697, train_loss=0.0561857670545578, time_cost=1.4516165256500244
Steps:   1%|▏         | 13824/1000000 [2:05:32<2115:45:40,  7.72s/it, lr=1e-5, step_loss=0.0368]Steps:   1%|▏         | 13825/1000000 [2:05:37<1919:20:16,  7.01s/it, lr=1e-5, step_loss=0.0368][RANK-0]: Step: [13825], local_loss=0.16109347343444824, train_loss=0.054147593677043915, time_cost=1.478870153427124
Steps:   1%|▏         | 13825/1000000 [2:05:37<1919:20:16,  7.01s/it, lr=1e-5, step_loss=0.161] Steps:   1%|▏         | 13826/1000000 [2:05:50<2383:08:35,  8.70s/it, lr=1e-5, step_loss=0.161][RANK-0]: Step: [13826], local_loss=0.020477110520005226, train_loss=0.03605804219841957, time_cost=1.461850881576538
Steps:   1%|▏         | 13826/1000000 [2:05:50<2383:08:35,  8.70s/it, lr=1e-5, step_loss=0.0205]Steps:   1%|▏         | 13827/1000000 [2:05:56<2159:27:27,  7.88s/it, lr=1e-5, step_loss=0.0205][RANK-0]: Step: [13827], local_loss=0.017959659919142723, train_loss=0.025373198091983795, time_cost=4.104544162750244
Steps:   1%|▏         | 13827/1000000 [2:05:56<2159:27:27,  7.88s/it, lr=1e-5, step_loss=0.018] Steps:   1%|▏         | 13828/1000000 [2:06:02<2000:35:56,  7.30s/it, lr=1e-5, step_loss=0.018][RANK-0]: Step: [13828], local_loss=0.12320956587791443, train_loss=0.0887274444103241, time_cost=1.7873198986053467
Steps:   1%|▏         | 13828/1000000 [2:06:02<2000:35:56,  7.30s/it, lr=1e-5, step_loss=0.123]Steps:   1%|▏         | 13829/1000000 [2:06:16<2553:36:38,  9.32s/it, lr=1e-5, step_loss=0.123][RANK-0]: Step: [13829], local_loss=0.03654790297150612, train_loss=0.036825746297836304, time_cost=1.7449991703033447
Steps:   1%|▏         | 13829/1000000 [2:06:16<2553:36:38,  9.32s/it, lr=1e-5, step_loss=0.0365]Steps:   1%|▏         | 13830/1000000 [2:06:27<2735:26:13,  9.99s/it, lr=1e-5, step_loss=0.0365][RANK-0]: Step: [13830], local_loss=0.008188759908080101, train_loss=0.023237798362970352, time_cost=3.0570664405822754
Steps:   1%|▏         | 13830/1000000 [2:06:27<2735:26:13,  9.99s/it, lr=1e-5, step_loss=0.00819]Steps:   1%|▏         | 13831/1000000 [2:06:33<2423:31:42,  8.85s/it, lr=1e-5, step_loss=0.00819][RANK-0]: Step: [13831], local_loss=0.018800335004925728, train_loss=0.02115127444267273, time_cost=2.3377745151519775
Steps:   1%|▏         | 13831/1000000 [2:06:33<2423:31:42,  8.85s/it, lr=1e-5, step_loss=0.0188] Steps:   1%|▏         | 13832/1000000 [2:06:39<2159:03:32,  7.88s/it, lr=1e-5, step_loss=0.0188][RANK-0]: Step: [13832], local_loss=0.04178622364997864, train_loss=0.05622434616088867, time_cost=2.2203822135925293
Steps:   1%|▏         | 13832/1000000 [2:06:39<2159:03:32,  7.88s/it, lr=1e-5, step_loss=0.0418]Steps:   1%|▏         | 13833/1000000 [2:06:47<2129:19:13,  7.77s/it, lr=1e-5, step_loss=0.0418][RANK-0]: Step: [13833], local_loss=0.01181013323366642, train_loss=0.07340825349092484, time_cost=1.7070865631103516
Steps:   1%|▏         | 13833/1000000 [2:06:47<2129:19:13,  7.77s/it, lr=1e-5, step_loss=0.0118]Steps:   1%|▏         | 13834/1000000 [2:06:52<1900:11:49,  6.94s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [13834], local_loss=0.0068417564034461975, train_loss=0.04117502272129059, time_cost=1.9736263751983643
Steps:   1%|▏         | 13834/1000000 [2:06:52<1900:11:49,  6.94s/it, lr=1e-5, step_loss=0.00684]Steps:   1%|▏         | 13835/1000000 [2:06:56<1678:36:25,  6.13s/it, lr=1e-5, step_loss=0.00684][RANK-0]: Step: [13835], local_loss=0.01665802113711834, train_loss=0.03885398060083389, time_cost=1.3670740127563477
Steps:   1%|▏         | 13835/1000000 [2:06:56<1678:36:25,  6.13s/it, lr=1e-5, step_loss=0.0167] Steps:   1%|▏         | 13836/1000000 [2:07:04<1810:19:23,  6.61s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [13836], local_loss=0.022335203364491463, train_loss=0.032632797956466675, time_cost=1.3064801692962646
Steps:   1%|▏         | 13836/1000000 [2:07:04<1810:19:23,  6.61s/it, lr=1e-5, step_loss=0.0223]Steps:   1%|▏         | 13837/1000000 [2:07:13<2074:33:36,  7.57s/it, lr=1e-5, step_loss=0.0223][RANK-0]: Step: [13837], local_loss=109.45993041992188, train_loss=13.734854698181152, time_cost=1.2364747524261475
Steps:   1%|▏         | 13837/1000000 [2:07:13<2074:33:36,  7.57s/it, lr=1e-5, step_loss=109]   Steps:   1%|▏         | 13838/1000000 [2:07:22<2171:20:35,  7.93s/it, lr=1e-5, step_loss=109][RANK-0]: Step: [13838], local_loss=0.12617036700248718, train_loss=0.03782140463590622, time_cost=2.6331090927124023
Steps:   1%|▏         | 13838/1000000 [2:07:22<2171:20:35,  7.93s/it, lr=1e-5, step_loss=0.126]Steps:   1%|▏         | 13839/1000000 [2:07:27<1885:31:52,  6.88s/it, lr=1e-5, step_loss=0.126][RANK-0]: Step: [13839], local_loss=0.03739407658576965, train_loss=0.05616656318306923, time_cost=1.6136260032653809
Steps:   1%|▏         | 13839/1000000 [2:07:27<1885:31:52,  6.88s/it, lr=1e-5, step_loss=0.0374]Steps:   1%|▏         | 13840/1000000 [2:07:34<1964:02:14,  7.17s/it, lr=1e-5, step_loss=0.0374][RANK-0]: Step: [13840], local_loss=0.052571430802345276, train_loss=0.05845554918050766, time_cost=6.991995334625244
Steps:   1%|▏         | 13840/1000000 [2:07:34<1964:02:14,  7.17s/it, lr=1e-5, step_loss=0.0526]Steps:   1%|▏         | 13841/1000000 [2:07:47<2403:52:11,  8.78s/it, lr=1e-5, step_loss=0.0526][RANK-0]: Step: [13841], local_loss=0.028045887127518654, train_loss=0.08888570219278336, time_cost=3.1274781227111816
Steps:   1%|▏         | 13841/1000000 [2:07:47<2403:52:11,  8.78s/it, lr=1e-5, step_loss=0.028] Steps:   1%|▏         | 13842/1000000 [2:07:57<2527:42:09,  9.23s/it, lr=1e-5, step_loss=0.028][RANK-0]: Step: [13842], local_loss=1.0001674890518188, train_loss=0.14846689999103546, time_cost=4.670159339904785
Steps:   1%|▏         | 13842/1000000 [2:07:57<2527:42:09,  9.23s/it, lr=1e-5, step_loss=1]    Steps:   1%|▏         | 13843/1000000 [2:08:02<2143:33:39,  7.83s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [13843], local_loss=0.016554085537791252, train_loss=0.04416333884000778, time_cost=1.7419970035552979
Steps:   1%|▏         | 13843/1000000 [2:08:02<2143:33:39,  7.83s/it, lr=1e-5, step_loss=0.0166]Steps:   1%|▏         | 13844/1000000 [2:08:07<1925:23:54,  7.03s/it, lr=1e-5, step_loss=0.0166][RANK-0]: Step: [13844], local_loss=0.019228626042604446, train_loss=0.041390560567379, time_cost=1.208695888519287
Steps:   1%|▏         | 13844/1000000 [2:08:07<1925:23:54,  7.03s/it, lr=1e-5, step_loss=0.0192]Steps:   1%|▏         | 13845/1000000 [2:08:14<1924:57:48,  7.03s/it, lr=1e-5, step_loss=0.0192][RANK-0]: Step: [13845], local_loss=0.0801176056265831, train_loss=0.037220750004053116, time_cost=3.1437814235687256
Steps:   1%|▏         | 13845/1000000 [2:08:14<1924:57:48,  7.03s/it, lr=1e-5, step_loss=0.0801]Steps:   1%|▏         | 13846/1000000 [2:08:24<2162:31:17,  7.89s/it, lr=1e-5, step_loss=0.0801][RANK-0]: Step: [13846], local_loss=0.0051470231264829636, train_loss=0.09390126168727875, time_cost=3.406994342803955
Steps:   1%|▏         | 13846/1000000 [2:08:24<2162:31:17,  7.89s/it, lr=1e-5, step_loss=0.00515]Steps:   1%|▏         | 13847/1000000 [2:08:29<1927:32:39,  7.04s/it, lr=1e-5, step_loss=0.00515][RANK-0]: Step: [13847], local_loss=0.05416449159383774, train_loss=0.18442606925964355, time_cost=3.805711030960083
Steps:   1%|▏         | 13847/1000000 [2:08:29<1927:32:39,  7.04s/it, lr=1e-5, step_loss=0.0542] Steps:   1%|▏         | 13848/1000000 [2:08:37<1980:40:25,  7.23s/it, lr=1e-5, step_loss=0.0542][RANK-0]: Step: [13848], local_loss=0.026795798912644386, train_loss=0.09426717460155487, time_cost=2.438530683517456
Steps:   1%|▏         | 13848/1000000 [2:08:37<1980:40:25,  7.23s/it, lr=1e-5, step_loss=0.0268]Steps:   1%|▏         | 13849/1000000 [2:08:45<2079:28:44,  7.59s/it, lr=1e-5, step_loss=0.0268][RANK-0]: Step: [13849], local_loss=0.01784420572221279, train_loss=0.03766180947422981, time_cost=2.072024345397949
Steps:   1%|▏         | 13849/1000000 [2:08:45<2079:28:44,  7.59s/it, lr=1e-5, step_loss=0.0178]Steps:   1%|▏         | 13850/1000000 [2:09:00<2671:25:48,  9.75s/it, lr=1e-5, step_loss=0.0178][RANK-0]: Step: [13850], local_loss=0.0198868028819561, train_loss=0.043455325067043304, time_cost=4.988530397415161
Steps:   1%|▏         | 13850/1000000 [2:09:00<2671:25:48,  9.75s/it, lr=1e-5, step_loss=0.0199]Steps:   1%|▏         | 13851/1000000 [2:09:07<2462:51:26,  8.99s/it, lr=1e-5, step_loss=0.0199][RANK-0]: Step: [13851], local_loss=0.0322418287396431, train_loss=0.020449725911021233, time_cost=5.319761753082275
Steps:   1%|▏         | 13851/1000000 [2:09:07<2462:51:26,  8.99s/it, lr=1e-5, step_loss=0.0322]Steps:   1%|▏         | 13852/1000000 [2:09:12<2134:54:58,  7.79s/it, lr=1e-5, step_loss=0.0322][RANK-0]: Step: [13852], local_loss=0.05308991298079491, train_loss=0.057096514850854874, time_cost=4.14263653755188
Steps:   1%|▏         | 13852/1000000 [2:09:12<2134:54:58,  7.79s/it, lr=1e-5, step_loss=0.0531]Steps:   1%|▏         | 13853/1000000 [2:09:19<2061:24:34,  7.53s/it, lr=1e-5, step_loss=0.0531][RANK-0]: Step: [13853], local_loss=0.018268758431077003, train_loss=0.020015774294734, time_cost=1.2313225269317627
Steps:   1%|▏         | 13853/1000000 [2:09:19<2061:24:34,  7.53s/it, lr=1e-5, step_loss=0.0183]Steps:   1%|▏         | 13854/1000000 [2:09:24<1834:59:35,  6.70s/it, lr=1e-5, step_loss=0.0183][RANK-0]: Step: [13854], local_loss=0.05821481719613075, train_loss=0.021261397749185562, time_cost=1.5390491485595703
Steps:   1%|▏         | 13854/1000000 [2:09:24<1834:59:35,  6.70s/it, lr=1e-5, step_loss=0.0582]Steps:   1%|▏         | 13855/1000000 [2:09:32<1941:13:45,  7.09s/it, lr=1e-5, step_loss=0.0582][RANK-0]: Step: [13855], local_loss=0.02266460470855236, train_loss=0.05170807987451553, time_cost=2.0036540031433105
Steps:   1%|▏         | 13855/1000000 [2:09:32<1941:13:45,  7.09s/it, lr=1e-5, step_loss=0.0227]Steps:   1%|▏         | 13856/1000000 [2:09:36<1727:40:11,  6.31s/it, lr=1e-5, step_loss=0.0227][RANK-0]: Step: [13856], local_loss=0.010957816615700722, train_loss=0.06896577030420303, time_cost=1.2279486656188965
Steps:   1%|▏         | 13856/1000000 [2:09:36<1727:40:11,  6.31s/it, lr=1e-5, step_loss=0.011] Steps:   1%|▏         | 13857/1000000 [2:09:47<2105:49:17,  7.69s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [13857], local_loss=0.024071821942925453, train_loss=0.041665732860565186, time_cost=7.711802959442139
Steps:   1%|▏         | 13857/1000000 [2:09:47<2105:49:17,  7.69s/it, lr=1e-5, step_loss=0.0241]Steps:   1%|▏         | 13858/1000000 [2:09:52<1904:58:33,  6.95s/it, lr=1e-5, step_loss=0.0241][RANK-0]: Step: [13858], local_loss=0.08740631490945816, train_loss=0.040989577770233154, time_cost=1.286937952041626
Steps:   1%|▏         | 13858/1000000 [2:09:52<1904:58:33,  6.95s/it, lr=1e-5, step_loss=0.0874]Steps:   1%|▏         | 13859/1000000 [2:10:02<2093:53:24,  7.64s/it, lr=1e-5, step_loss=0.0874][RANK-0]: Step: [13859], local_loss=0.015213481150567532, train_loss=0.03914865478873253, time_cost=1.2692253589630127
Steps:   1%|▏         | 13859/1000000 [2:10:02<2093:53:24,  7.64s/it, lr=1e-5, step_loss=0.0152]Steps:   1%|▏         | 13860/1000000 [2:10:11<2225:54:17,  8.13s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [13860], local_loss=0.025295868515968323, train_loss=0.16131621599197388, time_cost=1.2334403991699219
Steps:   1%|▏         | 13860/1000000 [2:10:11<2225:54:17,  8.13s/it, lr=1e-5, step_loss=0.0253]Steps:   1%|▏         | 13861/1000000 [2:10:26<2798:54:55, 10.22s/it, lr=1e-5, step_loss=0.0253][RANK-0]: Step: [13861], local_loss=0.03297623619437218, train_loss=0.02758730761706829, time_cost=6.726881265640259
Steps:   1%|▏         | 13861/1000000 [2:10:26<2798:54:55, 10.22s/it, lr=1e-5, step_loss=0.033] Steps:   1%|▏         | 13862/1000000 [2:10:30<2301:58:16,  8.40s/it, lr=1e-5, step_loss=0.033][RANK-0]: Step: [13862], local_loss=0.012415433302521706, train_loss=0.019963882863521576, time_cost=1.207275390625
Steps:   1%|▏         | 13862/1000000 [2:10:30<2301:58:16,  8.40s/it, lr=1e-5, step_loss=0.0124]Steps:   1%|▏         | 13863/1000000 [2:10:38<2236:53:35,  8.17s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [13863], local_loss=0.2448018193244934, train_loss=0.07514717429876328, time_cost=1.6914172172546387
Steps:   1%|▏         | 13863/1000000 [2:10:38<2236:53:35,  8.17s/it, lr=1e-5, step_loss=0.245] Steps:   1%|▏         | 13864/1000000 [2:10:43<1994:03:59,  7.28s/it, lr=1e-5, step_loss=0.245][RANK-0]: Step: [13864], local_loss=0.015314222313463688, train_loss=0.0265482347458601, time_cost=1.3166608810424805
Steps:   1%|▏         | 13864/1000000 [2:10:43<1994:03:59,  7.28s/it, lr=1e-5, step_loss=0.0153]Steps:   1%|▏         | 13865/1000000 [2:10:54<2314:23:36,  8.45s/it, lr=1e-5, step_loss=0.0153][RANK-0]: Step: [13865], local_loss=0.18777614831924438, train_loss=0.07124517858028412, time_cost=2.12221360206604
Steps:   1%|▏         | 13865/1000000 [2:10:54<2314:23:36,  8.45s/it, lr=1e-5, step_loss=0.188] Steps:   1%|▏         | 13866/1000000 [2:11:00<2080:28:25,  7.60s/it, lr=1e-5, step_loss=0.188][RANK-0]: Step: [13866], local_loss=0.016927897930145264, train_loss=0.14038041234016418, time_cost=1.3847870826721191
Steps:   1%|▏         | 13866/1000000 [2:11:00<2080:28:25,  7.60s/it, lr=1e-5, step_loss=0.0169]Steps:   1%|▏         | 13867/1000000 [2:11:09<2206:51:26,  8.06s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [13867], local_loss=0.09148107469081879, train_loss=0.033564403653144836, time_cost=1.9432055950164795
Steps:   1%|▏         | 13867/1000000 [2:11:09<2206:51:26,  8.06s/it, lr=1e-5, step_loss=0.0915]Steps:   1%|▏         | 13868/1000000 [2:11:17<2190:58:20,  8.00s/it, lr=1e-5, step_loss=0.0915][RANK-0]: Step: [13868], local_loss=0.02790810540318489, train_loss=0.07836422324180603, time_cost=1.756593942642212
Steps:   1%|▏         | 13868/1000000 [2:11:17<2190:58:20,  8.00s/it, lr=1e-5, step_loss=0.0279]Steps:   1%|▏         | 13869/1000000 [2:11:24<2114:13:22,  7.72s/it, lr=1e-5, step_loss=0.0279][RANK-0]: Step: [13869], local_loss=0.015135164372622967, train_loss=0.07367558032274246, time_cost=3.159792423248291
Steps:   1%|▏         | 13869/1000000 [2:11:24<2114:13:22,  7.72s/it, lr=1e-5, step_loss=0.0151]Steps:   1%|▏         | 13870/1000000 [2:11:31<2043:36:01,  7.46s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [13870], local_loss=0.0602445974946022, train_loss=0.07646411657333374, time_cost=2.1619813442230225
Steps:   1%|▏         | 13870/1000000 [2:11:31<2043:36:01,  7.46s/it, lr=1e-5, step_loss=0.0602]Steps:   1%|▏         | 13871/1000000 [2:11:44<2537:51:35,  9.26s/it, lr=1e-5, step_loss=0.0602][RANK-0]: Step: [13871], local_loss=0.07982586324214935, train_loss=0.06614190340042114, time_cost=2.5119211673736572
Steps:   1%|▏         | 13871/1000000 [2:11:44<2537:51:35,  9.26s/it, lr=1e-5, step_loss=0.0798]Steps:   1%|▏         | 13872/1000000 [2:11:59<2959:54:11, 10.81s/it, lr=1e-5, step_loss=0.0798][RANK-0]: Step: [13872], local_loss=0.3292354345321655, train_loss=0.07624556124210358, time_cost=5.180332183837891
Steps:   1%|▏         | 13872/1000000 [2:11:59<2959:54:11, 10.81s/it, lr=1e-5, step_loss=0.329] Steps:   1%|▏         | 13873/1000000 [2:12:12<3194:58:46, 11.66s/it, lr=1e-5, step_loss=0.329][RANK-0]: Step: [13873], local_loss=0.02547931857407093, train_loss=0.3057534694671631, time_cost=4.616315126419067
Steps:   1%|▏         | 13873/1000000 [2:12:12<3194:58:46, 11.66s/it, lr=1e-5, step_loss=0.0255]Steps:   1%|▏         | 13874/1000000 [2:12:17<2598:41:58,  9.49s/it, lr=1e-5, step_loss=0.0255][RANK-0]: Step: [13874], local_loss=0.07866640388965607, train_loss=0.03896919637918472, time_cost=3.4342994689941406
Steps:   1%|▏         | 13874/1000000 [2:12:17<2598:41:58,  9.49s/it, lr=1e-5, step_loss=0.0787]Steps:   1%|▏         | 13875/1000000 [2:12:31<2981:39:46, 10.89s/it, lr=1e-5, step_loss=0.0787][RANK-0]: Step: [13875], local_loss=0.282065212726593, train_loss=0.048223309218883514, time_cost=5.817871570587158
Steps:   1%|▏         | 13875/1000000 [2:12:31<2981:39:46, 10.89s/it, lr=1e-5, step_loss=0.282] Steps:   1%|▏         | 13876/1000000 [2:12:36<2509:27:06,  9.16s/it, lr=1e-5, step_loss=0.282][RANK-0]: Step: [13876], local_loss=0.017664402723312378, train_loss=0.02323583886027336, time_cost=2.2671959400177
Steps:   1%|▏         | 13876/1000000 [2:12:36<2509:27:06,  9.16s/it, lr=1e-5, step_loss=0.0177]Steps:   1%|▏         | 13877/1000000 [2:12:51<3006:48:16, 10.98s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [13877], local_loss=0.05337027460336685, train_loss=0.05740255117416382, time_cost=2.887951135635376
Steps:   1%|▏         | 13877/1000000 [2:12:51<3006:48:16, 10.98s/it, lr=1e-5, step_loss=0.0534]Steps:   1%|▏         | 13878/1000000 [2:13:00<2863:37:43, 10.45s/it, lr=1e-5, step_loss=0.0534][RANK-0]: Step: [13878], local_loss=0.008501541800796986, train_loss=0.09292720258235931, time_cost=2.749316692352295
Steps:   1%|▏         | 13878/1000000 [2:13:00<2863:37:43, 10.45s/it, lr=1e-5, step_loss=0.0085]Steps:   1%|▏         | 13879/1000000 [2:13:06<2465:23:08,  9.00s/it, lr=1e-5, step_loss=0.0085][RANK-0]: Step: [13879], local_loss=137.98504638671875, train_loss=17.262380599975586, time_cost=2.9271836280822754
Steps:   1%|▏         | 13879/1000000 [2:13:06<2465:23:08,  9.00s/it, lr=1e-5, step_loss=138]   Steps:   1%|▏         | 13880/1000000 [2:13:11<2141:17:23,  7.82s/it, lr=1e-5, step_loss=138][RANK-0]: Step: [13880], local_loss=0.013639401644468307, train_loss=0.079152412712574, time_cost=2.034773826599121
Steps:   1%|▏         | 13880/1000000 [2:13:11<2141:17:23,  7.82s/it, lr=1e-5, step_loss=0.0136]Steps:   1%|▏         | 13881/1000000 [2:13:15<1837:00:50,  6.71s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [13881], local_loss=0.03381253778934479, train_loss=0.029882457107305527, time_cost=1.2533504962921143
Steps:   1%|▏         | 13881/1000000 [2:13:15<1837:00:50,  6.71s/it, lr=1e-5, step_loss=0.0338]Steps:   1%|▏         | 13882/1000000 [2:13:31<2609:00:04,  9.52s/it, lr=1e-5, step_loss=0.0338][RANK-0]: Step: [13882], local_loss=0.02272954396903515, train_loss=0.03817672282457352, time_cost=14.214639663696289
Steps:   1%|▏         | 13882/1000000 [2:13:31<2609:00:04,  9.52s/it, lr=1e-5, step_loss=0.0227]Steps:   1%|▏         | 13883/1000000 [2:13:37<2305:35:48,  8.42s/it, lr=1e-5, step_loss=0.0227][RANK-0]: Step: [13883], local_loss=0.058827709406614304, train_loss=0.02618541568517685, time_cost=5.13472580909729
Steps:   1%|▏         | 13883/1000000 [2:13:37<2305:35:48,  8.42s/it, lr=1e-5, step_loss=0.0588]Steps:   1%|▏         | 13884/1000000 [2:13:53<2912:29:20, 10.63s/it, lr=1e-5, step_loss=0.0588][RANK-0]: Step: [13884], local_loss=0.03866958990693092, train_loss=0.06692193448543549, time_cost=7.796393871307373
Steps:   1%|▏         | 13884/1000000 [2:13:53<2912:29:20, 10.63s/it, lr=1e-5, step_loss=0.0387]Steps:   1%|▏         | 13885/1000000 [2:14:03<2846:06:03, 10.39s/it, lr=1e-5, step_loss=0.0387][RANK-0]: Step: [13885], local_loss=0.007940756157040596, train_loss=0.034746333956718445, time_cost=2.9574666023254395
Steps:   1%|▏         | 13885/1000000 [2:14:03<2846:06:03, 10.39s/it, lr=1e-5, step_loss=0.00794]Steps:   1%|▏         | 13886/1000000 [2:14:08<2420:11:55,  8.84s/it, lr=1e-5, step_loss=0.00794][RANK-0]: Step: [13886], local_loss=0.06849949806928635, train_loss=0.018286649137735367, time_cost=2.5636422634124756
Steps:   1%|▏         | 13886/1000000 [2:14:08<2420:11:55,  8.84s/it, lr=1e-5, step_loss=0.0685] Steps:   1%|▏         | 13887/1000000 [2:14:19<2607:53:15,  9.52s/it, lr=1e-5, step_loss=0.0685][RANK-0]: Step: [13887], local_loss=0.020759060978889465, train_loss=0.07153967767953873, time_cost=2.972344398498535
Steps:   1%|▏         | 13887/1000000 [2:14:19<2607:53:15,  9.52s/it, lr=1e-5, step_loss=0.0208]Steps:   1%|▏         | 13888/1000000 [2:14:35<3101:27:51, 11.32s/it, lr=1e-5, step_loss=0.0208][RANK-0]: Step: [13888], local_loss=0.019300853833556175, train_loss=0.047153666615486145, time_cost=7.060593128204346
Steps:   1%|▏         | 13888/1000000 [2:14:35<3101:27:51, 11.32s/it, lr=1e-5, step_loss=0.0193]Steps:   1%|▏         | 13889/1000000 [2:14:43<2829:11:37, 10.33s/it, lr=1e-5, step_loss=0.0193][RANK-0]: Step: [13889], local_loss=0.017948372289538383, train_loss=0.018652353435754776, time_cost=1.9310123920440674
Steps:   1%|▏         | 13889/1000000 [2:14:43<2829:11:37, 10.33s/it, lr=1e-5, step_loss=0.0179]Steps:   1%|▏         | 13890/1000000 [2:14:48<2397:58:04,  8.75s/it, lr=1e-5, step_loss=0.0179][RANK-0]: Step: [13890], local_loss=0.13352519273757935, train_loss=0.05521285533905029, time_cost=2.491014003753662
Steps:   1%|▏         | 13890/1000000 [2:14:48<2397:58:04,  8.75s/it, lr=1e-5, step_loss=0.134] Steps:   1%|▏         | 13891/1000000 [2:14:53<2126:33:17,  7.76s/it, lr=1e-5, step_loss=0.134][RANK-0]: Step: [13891], local_loss=0.029502354562282562, train_loss=0.09944569319486618, time_cost=4.138398885726929
Steps:   1%|▏         | 13891/1000000 [2:14:53<2126:33:17,  7.76s/it, lr=1e-5, step_loss=0.0295]Steps:   1%|▏         | 13892/1000000 [2:15:02<2210:17:54,  8.07s/it, lr=1e-5, step_loss=0.0295][RANK-0]: Step: [13892], local_loss=0.020410973578691483, train_loss=0.05641202628612518, time_cost=6.914560079574585
Steps:   1%|▏         | 13892/1000000 [2:15:02<2210:17:54,  8.07s/it, lr=1e-5, step_loss=0.0204]Steps:   1%|▏         | 13893/1000000 [2:15:17<2787:00:33, 10.17s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [13893], local_loss=0.030811110511422157, train_loss=0.029052481055259705, time_cost=4.447373867034912
Steps:   1%|▏         | 13893/1000000 [2:15:17<2787:00:33, 10.17s/it, lr=1e-5, step_loss=0.0308]Steps:   1%|▏         | 13894/1000000 [2:15:28<2878:13:52, 10.51s/it, lr=1e-5, step_loss=0.0308][RANK-0]: Step: [13894], local_loss=0.04327933117747307, train_loss=0.17968237400054932, time_cost=1.2694616317749023
Steps:   1%|▏         | 13894/1000000 [2:15:28<2878:13:52, 10.51s/it, lr=1e-5, step_loss=0.0433]Steps:   1%|▏         | 13895/1000000 [2:15:38<2790:19:58, 10.19s/it, lr=1e-5, step_loss=0.0433][RANK-0]: Step: [13895], local_loss=0.018199849873781204, train_loss=6.274853229522705, time_cost=4.227587938308716
Steps:   1%|▏         | 13895/1000000 [2:15:38<2790:19:58, 10.19s/it, lr=1e-5, step_loss=0.0182]Steps:   1%|▏         | 13896/1000000 [2:15:49<2908:11:58, 10.62s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [13896], local_loss=0.022860553115606308, train_loss=0.02364087849855423, time_cost=3.436598300933838
Steps:   1%|▏         | 13896/1000000 [2:15:49<2908:11:58, 10.62s/it, lr=1e-5, step_loss=0.0229]Steps:   1%|▏         | 13897/1000000 [2:16:04<3209:14:35, 11.72s/it, lr=1e-5, step_loss=0.0229][RANK-0]: Step: [13897], local_loss=0.03625190258026123, train_loss=29.111547470092773, time_cost=6.377869606018066
Steps:   1%|▏         | 13897/1000000 [2:16:04<3209:14:35, 11.72s/it, lr=1e-5, step_loss=0.0363]Steps:   1%|▏         | 13898/1000000 [2:16:13<3059:24:24, 11.17s/it, lr=1e-5, step_loss=0.0363][RANK-0]: Step: [13898], local_loss=0.00406180415302515, train_loss=0.04863304644823074, time_cost=2.210803270339966
Steps:   1%|▏         | 13898/1000000 [2:16:13<3059:24:24, 11.17s/it, lr=1e-5, step_loss=0.00406]Steps:   1%|▏         | 13899/1000000 [2:16:18<2513:27:19,  9.18s/it, lr=1e-5, step_loss=0.00406][RANK-0]: Step: [13899], local_loss=0.007759891450405121, train_loss=0.04133741557598114, time_cost=1.7333984375
Steps:   1%|▏         | 13899/1000000 [2:16:18<2513:27:19,  9.18s/it, lr=1e-5, step_loss=0.00776]Steps:   1%|▏         | 13900/1000000 [2:16:27<2511:13:38,  9.17s/it, lr=1e-5, step_loss=0.00776][RANK-0]: Step: [13900], local_loss=0.017490746453404427, train_loss=0.03364087641239166, time_cost=3.2666492462158203
Steps:   1%|▏         | 13900/1000000 [2:16:27<2511:13:38,  9.17s/it, lr=1e-5, step_loss=0.0175] Steps:   1%|▏         | 13901/1000000 [2:16:39<2720:16:45,  9.93s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [13901], local_loss=0.04960639029741287, train_loss=12.8719482421875, time_cost=3.058393955230713
Steps:   1%|▏         | 13901/1000000 [2:16:39<2720:16:45,  9.93s/it, lr=1e-5, step_loss=0.0496]Steps:   1%|▏         | 13902/1000000 [2:16:44<2336:26:40,  8.53s/it, lr=1e-5, step_loss=0.0496][RANK-0]: Step: [13902], local_loss=0.014973461627960205, train_loss=0.1716831624507904, time_cost=2.43762469291687
Steps:   1%|▏         | 13902/1000000 [2:16:44<2336:26:40,  8.53s/it, lr=1e-5, step_loss=0.015] Steps:   1%|▏         | 13903/1000000 [2:16:58<2749:19:04, 10.04s/it, lr=1e-5, step_loss=0.015][RANK-0]: Step: [13903], local_loss=0.012381907552480698, train_loss=0.13449986279010773, time_cost=4.799593448638916
Steps:   1%|▏         | 13903/1000000 [2:16:58<2749:19:04, 10.04s/it, lr=1e-5, step_loss=0.0124]Steps:   1%|▏         | 13904/1000000 [2:17:10<2978:30:57, 10.87s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [13904], local_loss=0.01584695093333721, train_loss=0.15375354886054993, time_cost=3.496612310409546
Steps:   1%|▏         | 13904/1000000 [2:17:10<2978:30:57, 10.87s/it, lr=1e-5, step_loss=0.0158]Steps:   1%|▏         | 13905/1000000 [2:17:18<2704:27:15,  9.87s/it, lr=1e-5, step_loss=0.0158][RANK-0]: Step: [13905], local_loss=0.0049604312516748905, train_loss=0.028662294149398804, time_cost=2.475137233734131
Steps:   1%|▏         | 13905/1000000 [2:17:18<2704:27:15,  9.87s/it, lr=1e-5, step_loss=0.00496]Steps:   1%|▏         | 13906/1000000 [2:17:34<3194:59:55, 11.66s/it, lr=1e-5, step_loss=0.00496][RANK-0]: Step: [13906], local_loss=0.007046704180538654, train_loss=0.0666106715798378, time_cost=7.391105890274048
Steps:   1%|▏         | 13906/1000000 [2:17:34<3194:59:55, 11.66s/it, lr=1e-5, step_loss=0.00705]Steps:   1%|▏         | 13907/1000000 [2:17:45<3169:11:56, 11.57s/it, lr=1e-5, step_loss=0.00705][RANK-0]: Step: [13907], local_loss=0.02351759746670723, train_loss=0.0245673730969429, time_cost=6.265113353729248
Steps:   1%|▏         | 13907/1000000 [2:17:45<3169:11:56, 11.57s/it, lr=1e-5, step_loss=0.0235] Steps:   1%|▏         | 13908/1000000 [2:17:59<3344:50:00, 12.21s/it, lr=1e-5, step_loss=0.0235][RANK-0]: Step: [13908], local_loss=0.010520227253437042, train_loss=0.04114904999732971, time_cost=5.7039806842803955
Steps:   1%|▏         | 13908/1000000 [2:17:59<3344:50:00, 12.21s/it, lr=1e-5, step_loss=0.0105]Steps:   1%|▏         | 13909/1000000 [2:18:10<3262:31:10, 11.91s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [13909], local_loss=0.008358615450561047, train_loss=0.036994025111198425, time_cost=4.492232799530029
Steps:   1%|▏         | 13909/1000000 [2:18:10<3262:31:10, 11.91s/it, lr=1e-5, step_loss=0.00836]Steps:   1%|▏         | 13910/1000000 [2:18:17<2829:45:50, 10.33s/it, lr=1e-5, step_loss=0.00836][RANK-0]: Step: [13910], local_loss=0.014594546519219875, train_loss=0.1316487342119217, time_cost=1.925140619277954
Steps:   1%|▏         | 13910/1000000 [2:18:17<2829:45:50, 10.33s/it, lr=1e-5, step_loss=0.0146] Steps:   1%|▏         | 13911/1000000 [2:18:31<3125:26:17, 11.41s/it, lr=1e-5, step_loss=0.0146][RANK-0]: Step: [13911], local_loss=0.025302739813923836, train_loss=0.020870326086878777, time_cost=5.891962051391602
Steps:   1%|▏         | 13911/1000000 [2:18:31<3125:26:17, 11.41s/it, lr=1e-5, step_loss=0.0253]Steps:   1%|▏         | 13912/1000000 [2:18:44<3257:54:08, 11.89s/it, lr=1e-5, step_loss=0.0253][RANK-0]: Step: [13912], local_loss=0.005653458181768656, train_loss=0.015636926516890526, time_cost=3.8079254627227783
Steps:   1%|▏         | 13912/1000000 [2:18:44<3257:54:08, 11.89s/it, lr=1e-5, step_loss=0.00565]Steps:   1%|▏         | 13913/1000000 [2:18:58<3437:17:53, 12.55s/it, lr=1e-5, step_loss=0.00565][RANK-0]: Step: [13913], local_loss=0.019125167280435562, train_loss=0.046647973358631134, time_cost=3.7597596645355225
Steps:   1%|▏         | 13913/1000000 [2:18:58<3437:17:53, 12.55s/it, lr=1e-5, step_loss=0.0191] Steps:   1%|▏         | 13914/1000000 [2:19:03<2844:27:34, 10.38s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [13914], local_loss=0.017023442313075066, train_loss=0.011412972584366798, time_cost=2.510150194168091
Steps:   1%|▏         | 13914/1000000 [2:19:03<2844:27:34, 10.38s/it, lr=1e-5, step_loss=0.017] Steps:   1%|▏         | 13915/1000000 [2:19:16<3080:35:37, 11.25s/it, lr=1e-5, step_loss=0.017][RANK-0]: Step: [13915], local_loss=0.007311233319342136, train_loss=0.08817507326602936, time_cost=5.440118074417114
Steps:   1%|▏         | 13915/1000000 [2:19:16<3080:35:37, 11.25s/it, lr=1e-5, step_loss=0.00731]Steps:   1%|▏         | 13916/1000000 [2:19:25<2834:16:33, 10.35s/it, lr=1e-5, step_loss=0.00731][RANK-0]: Step: [13916], local_loss=0.07247822731733322, train_loss=0.022885460406541824, time_cost=2.511455535888672
Steps:   1%|▏         | 13916/1000000 [2:19:25<2834:16:33, 10.35s/it, lr=1e-5, step_loss=0.0725] Steps:   1%|▏         | 13917/1000000 [2:19:32<2574:48:01,  9.40s/it, lr=1e-5, step_loss=0.0725][RANK-0]: Step: [13917], local_loss=0.10436239838600159, train_loss=0.14092755317687988, time_cost=2.625957727432251
Steps:   1%|▏         | 13917/1000000 [2:19:32<2574:48:01,  9.40s/it, lr=1e-5, step_loss=0.104] Steps:   1%|▏         | 13918/1000000 [2:19:39<2387:44:30,  8.72s/it, lr=1e-5, step_loss=0.104][RANK-0]: Step: [13918], local_loss=0.0092082554474473, train_loss=0.050282664597034454, time_cost=2.4341037273406982
Steps:   1%|▏         | 13918/1000000 [2:19:39<2387:44:30,  8.72s/it, lr=1e-5, step_loss=0.00921]Steps:   1%|▏         | 13919/1000000 [2:19:47<2292:29:04,  8.37s/it, lr=1e-5, step_loss=0.00921][RANK-0]: Step: [13919], local_loss=0.05799794942140579, train_loss=0.040855519473552704, time_cost=1.2557168006896973
Steps:   1%|▏         | 13919/1000000 [2:19:47<2292:29:04,  8.37s/it, lr=1e-5, step_loss=0.058]  Steps:   1%|▏         | 13920/1000000 [2:19:53<2097:39:36,  7.66s/it, lr=1e-5, step_loss=0.058][RANK-0]: Step: [13920], local_loss=0.034368351101875305, train_loss=0.05998283997178078, time_cost=2.428287982940674
Steps:   1%|▏         | 13920/1000000 [2:19:53<2097:39:36,  7.66s/it, lr=1e-5, step_loss=0.0344]Steps:   1%|▏         | 13921/1000000 [2:20:03<2299:06:46,  8.39s/it, lr=1e-5, step_loss=0.0344][RANK-0]: Step: [13921], local_loss=0.39221975207328796, train_loss=0.07539951056241989, time_cost=4.531379222869873
Steps:   1%|▏         | 13921/1000000 [2:20:03<2299:06:46,  8.39s/it, lr=1e-5, step_loss=0.392] Steps:   1%|▏         | 13922/1000000 [2:20:17<2814:58:48, 10.28s/it, lr=1e-5, step_loss=0.392][RANK-0]: Step: [13922], local_loss=0.026608899235725403, train_loss=0.03598642349243164, time_cost=5.426732540130615
Steps:   1%|▏         | 13922/1000000 [2:20:17<2814:58:48, 10.28s/it, lr=1e-5, step_loss=0.0266]Steps:   1%|▏         | 13923/1000000 [2:20:29<2911:27:33, 10.63s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [13923], local_loss=0.06915146112442017, train_loss=0.03253408521413803, time_cost=1.2375202178955078
Steps:   1%|▏         | 13923/1000000 [2:20:29<2911:27:33, 10.63s/it, lr=1e-5, step_loss=0.0692]Steps:   1%|▏         | 13924/1000000 [2:20:40<2934:36:50, 10.71s/it, lr=1e-5, step_loss=0.0692][RANK-0]: Step: [13924], local_loss=0.015040562488138676, train_loss=0.04291630536317825, time_cost=1.7795090675354004
Steps:   1%|▏         | 13924/1000000 [2:20:40<2934:36:50, 10.71s/it, lr=1e-5, step_loss=0.015] Steps:   1%|▏         | 13925/1000000 [2:20:50<2905:58:52, 10.61s/it, lr=1e-5, step_loss=0.015][RANK-0]: Step: [13925], local_loss=0.018820425495505333, train_loss=0.012712251394987106, time_cost=1.303809404373169
Steps:   1%|▏         | 13925/1000000 [2:20:50<2905:58:52, 10.61s/it, lr=1e-5, step_loss=0.0188]Steps:   1%|▏         | 13926/1000000 [2:20:57<2590:26:11,  9.46s/it, lr=1e-5, step_loss=0.0188][RANK-0]: Step: [13926], local_loss=0.027885891497135162, train_loss=0.06036653369665146, time_cost=2.9848849773406982
Steps:   1%|▏         | 13926/1000000 [2:20:57<2590:26:11,  9.46s/it, lr=1e-5, step_loss=0.0279]Steps:   1%|▏         | 13927/1000000 [2:21:02<2236:18:47,  8.16s/it, lr=1e-5, step_loss=0.0279][RANK-0]: Step: [13927], local_loss=0.06363893300294876, train_loss=0.04548349231481552, time_cost=2.4938571453094482
Steps:   1%|▏         | 13927/1000000 [2:21:02<2236:18:47,  8.16s/it, lr=1e-5, step_loss=0.0636]Steps:   1%|▏         | 13928/1000000 [2:21:08<2066:21:46,  7.54s/it, lr=1e-5, step_loss=0.0636][RANK-0]: Step: [13928], local_loss=0.6179894804954529, train_loss=0.11044694483280182, time_cost=1.272446632385254
Steps:   1%|▏         | 13928/1000000 [2:21:08<2066:21:46,  7.54s/it, lr=1e-5, step_loss=0.618] Steps:   1%|▏         | 13929/1000000 [2:21:13<1870:26:14,  6.83s/it, lr=1e-5, step_loss=0.618][RANK-0]: Step: [13929], local_loss=0.9307019114494324, train_loss=0.14755649864673615, time_cost=2.7457354068756104
Steps:   1%|▏         | 13929/1000000 [2:21:13<1870:26:14,  6.83s/it, lr=1e-5, step_loss=0.931]Steps:   1%|▏         | 13930/1000000 [2:21:29<2602:09:58,  9.50s/it, lr=1e-5, step_loss=0.931][RANK-0]: Step: [13930], local_loss=0.03207172825932503, train_loss=0.024637602269649506, time_cost=1.384033203125
Steps:   1%|▏         | 13930/1000000 [2:21:29<2602:09:58,  9.50s/it, lr=1e-5, step_loss=0.0321]Steps:   1%|▏         | 13931/1000000 [2:21:35<2300:42:52,  8.40s/it, lr=1e-5, step_loss=0.0321][RANK-0]: Step: [13931], local_loss=0.009503500536084175, train_loss=0.020275013521313667, time_cost=1.6447393894195557
Steps:   1%|▏         | 13931/1000000 [2:21:35<2300:42:52,  8.40s/it, lr=1e-5, step_loss=0.0095]Steps:   1%|▏         | 13932/1000000 [2:21:49<2799:53:50, 10.22s/it, lr=1e-5, step_loss=0.0095][RANK-0]: Step: [13932], local_loss=0.00820943620055914, train_loss=0.0400080643594265, time_cost=6.265672922134399
Steps:   1%|▏         | 13932/1000000 [2:21:49<2799:53:50, 10.22s/it, lr=1e-5, step_loss=0.00821]Steps:   1%|▏         | 13933/1000000 [2:21:56<2531:51:10,  9.24s/it, lr=1e-5, step_loss=0.00821][RANK-0]: Step: [13933], local_loss=0.020440611988306046, train_loss=0.015506023541092873, time_cost=2.652947425842285
Steps:   1%|▏         | 13933/1000000 [2:21:56<2531:51:10,  9.24s/it, lr=1e-5, step_loss=0.0204] Steps:   1%|▏         | 13934/1000000 [2:22:04<2381:37:45,  8.70s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [13934], local_loss=0.01798976957798004, train_loss=0.16993479430675507, time_cost=2.1064813137054443
Steps:   1%|▏         | 13934/1000000 [2:22:04<2381:37:45,  8.70s/it, lr=1e-5, step_loss=0.018] Steps:   1%|▏         | 13935/1000000 [2:22:11<2311:07:01,  8.44s/it, lr=1e-5, step_loss=0.018][RANK-0]: Step: [13935], local_loss=0.014571252278983593, train_loss=0.16037383675575256, time_cost=2.8578882217407227
Steps:   1%|▏         | 13935/1000000 [2:22:11<2311:07:01,  8.44s/it, lr=1e-5, step_loss=0.0146]Steps:   1%|▏         | 13936/1000000 [2:22:19<2223:46:44,  8.12s/it, lr=1e-5, step_loss=0.0146][RANK-0]: Step: [13936], local_loss=0.751811146736145, train_loss=0.13086704909801483, time_cost=2.702004909515381
Steps:   1%|▏         | 13936/1000000 [2:22:19<2223:46:44,  8.12s/it, lr=1e-5, step_loss=0.752] Steps:   1%|▏         | 13937/1000000 [2:22:32<2677:41:53,  9.78s/it, lr=1e-5, step_loss=0.752][RANK-0]: Step: [13937], local_loss=0.033621106296777725, train_loss=0.04718807339668274, time_cost=9.603124856948853
Steps:   1%|▏         | 13937/1000000 [2:22:32<2677:41:53,  9.78s/it, lr=1e-5, step_loss=0.0336]Steps:   1%|▏         | 13938/1000000 [2:22:45<2867:00:08, 10.47s/it, lr=1e-5, step_loss=0.0336][RANK-0]: Step: [13938], local_loss=0.05445283651351929, train_loss=0.023268036544322968, time_cost=2.1428513526916504
Steps:   1%|▏         | 13938/1000000 [2:22:45<2867:00:08, 10.47s/it, lr=1e-5, step_loss=0.0545]Steps:   1%|▏         | 13939/1000000 [2:22:56<2915:07:32, 10.64s/it, lr=1e-5, step_loss=0.0545][RANK-0]: Step: [13939], local_loss=0.0195587407797575, train_loss=0.04647393524646759, time_cost=3.4864261150360107
Steps:   1%|▏         | 13939/1000000 [2:22:56<2915:07:32, 10.64s/it, lr=1e-5, step_loss=0.0196]Steps:   1%|▏         | 13940/1000000 [2:23:02<2526:25:04,  9.22s/it, lr=1e-5, step_loss=0.0196][RANK-0]: Step: [13940], local_loss=0.023413460701704025, train_loss=0.03864247351884842, time_cost=2.037198305130005
Steps:   1%|▏         | 13940/1000000 [2:23:02<2526:25:04,  9.22s/it, lr=1e-5, step_loss=0.0234]Steps:   1%|▏         | 13941/1000000 [2:23:18<3104:26:27, 11.33s/it, lr=1e-5, step_loss=0.0234][RANK-0]: Step: [13941], local_loss=0.006927527952939272, train_loss=0.1925804316997528, time_cost=5.8729088306427
Steps:   1%|▏         | 13941/1000000 [2:23:18<3104:26:27, 11.33s/it, lr=1e-5, step_loss=0.00693]Steps:   1%|▏         | 13942/1000000 [2:23:24<2675:54:37,  9.77s/it, lr=1e-5, step_loss=0.00693][RANK-0]: Step: [13942], local_loss=0.03280700743198395, train_loss=0.023341583088040352, time_cost=1.5756101608276367
Steps:   1%|▏         | 13942/1000000 [2:23:24<2675:54:37,  9.77s/it, lr=1e-5, step_loss=0.0328] Steps:   1%|▏         | 13943/1000000 [2:23:29<2327:26:10,  8.50s/it, lr=1e-5, step_loss=0.0328][RANK-0]: Step: [13943], local_loss=0.006327126640826464, train_loss=0.014665849506855011, time_cost=2.161663293838501
Steps:   1%|▏         | 13943/1000000 [2:23:29<2327:26:10,  8.50s/it, lr=1e-5, step_loss=0.00633]Steps:   1%|▏         | 13944/1000000 [2:23:37<2219:49:59,  8.10s/it, lr=1e-5, step_loss=0.00633][RANK-0]: Step: [13944], local_loss=0.27946409583091736, train_loss=0.07712849229574203, time_cost=2.4548537731170654
Steps:   1%|▏         | 13944/1000000 [2:23:37<2219:49:59,  8.10s/it, lr=1e-5, step_loss=0.279]  Steps:   1%|▏         | 13945/1000000 [2:23:41<1916:09:29,  7.00s/it, lr=1e-5, step_loss=0.279][RANK-0]: Step: [13945], local_loss=0.02360927313566208, train_loss=0.03076978772878647, time_cost=1.5767269134521484
Steps:   1%|▏         | 13945/1000000 [2:23:41<1916:09:29,  7.00s/it, lr=1e-5, step_loss=0.0236]Steps:   1%|▏         | 13946/1000000 [2:23:46<1766:43:56,  6.45s/it, lr=1e-5, step_loss=0.0236][RANK-0]: Step: [13946], local_loss=0.009728390723466873, train_loss=0.04921375960111618, time_cost=2.5946812629699707
Steps:   1%|▏         | 13946/1000000 [2:23:46<1766:43:56,  6.45s/it, lr=1e-5, step_loss=0.00973]Steps:   1%|▏         | 13947/1000000 [2:23:52<1711:24:40,  6.25s/it, lr=1e-5, step_loss=0.00973][RANK-0]: Step: [13947], local_loss=0.05671807378530502, train_loss=0.17912614345550537, time_cost=1.384352207183838
Steps:   1%|▏         | 13947/1000000 [2:23:52<1711:24:40,  6.25s/it, lr=1e-5, step_loss=0.0567] Steps:   1%|▏         | 13948/1000000 [2:24:02<2032:07:51,  7.42s/it, lr=1e-5, step_loss=0.0567][RANK-0]: Step: [13948], local_loss=0.025005053728818893, train_loss=0.02004118822515011, time_cost=1.2267508506774902
Steps:   1%|▏         | 13948/1000000 [2:24:02<2032:07:51,  7.42s/it, lr=1e-5, step_loss=0.025] Steps:   1%|▏         | 13949/1000000 [2:24:10<2084:22:24,  7.61s/it, lr=1e-5, step_loss=0.025][RANK-0]: Step: [13949], local_loss=0.01177520863711834, train_loss=0.021179014816880226, time_cost=3.6953203678131104
Steps:   1%|▏         | 13949/1000000 [2:24:10<2084:22:24,  7.61s/it, lr=1e-5, step_loss=0.0118]Steps:   1%|▏         | 13950/1000000 [2:24:19<2181:51:35,  7.97s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [13950], local_loss=0.11974762380123138, train_loss=5.383446216583252, time_cost=3.256124973297119
Steps:   1%|▏         | 13950/1000000 [2:24:19<2181:51:35,  7.97s/it, lr=1e-5, step_loss=0.12]  Steps:   1%|▏         | 13951/1000000 [2:24:25<2002:57:08,  7.31s/it, lr=1e-5, step_loss=0.12][RANK-0]: Step: [13951], local_loss=0.011026802472770214, train_loss=0.022808171808719635, time_cost=1.326512336730957
Steps:   1%|▏         | 13951/1000000 [2:24:25<2002:57:08,  7.31s/it, lr=1e-5, step_loss=0.011]Steps:   1%|▏         | 13952/1000000 [2:24:34<2174:04:48,  7.94s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [13952], local_loss=0.12453821301460266, train_loss=0.08164021372795105, time_cost=2.1870803833007812
Steps:   1%|▏         | 13952/1000000 [2:24:34<2174:04:48,  7.94s/it, lr=1e-5, step_loss=0.125]Steps:   1%|▏         | 13953/1000000 [2:24:40<2014:02:27,  7.35s/it, lr=1e-5, step_loss=0.125][RANK-0]: Step: [13953], local_loss=0.006952469237148762, train_loss=0.15395976603031158, time_cost=1.5749890804290771
Steps:   1%|▏         | 13953/1000000 [2:24:40<2014:02:27,  7.35s/it, lr=1e-5, step_loss=0.00695]Steps:   1%|▏         | 13954/1000000 [2:24:48<2076:01:22,  7.58s/it, lr=1e-5, step_loss=0.00695][RANK-0]: Step: [13954], local_loss=0.025180287659168243, train_loss=0.033955734223127365, time_cost=2.4232864379882812
Steps:   1%|▏         | 13954/1000000 [2:24:48<2076:01:22,  7.58s/it, lr=1e-5, step_loss=0.0252] Steps:   1%|▏         | 13955/1000000 [2:24:52<1789:48:18,  6.53s/it, lr=1e-5, step_loss=0.0252][RANK-0]: Step: [13955], local_loss=0.008918399922549725, train_loss=0.03162591531872749, time_cost=1.3970322608947754
Steps:   1%|▏         | 13955/1000000 [2:24:52<1789:48:18,  6.53s/it, lr=1e-5, step_loss=0.00892]Steps:   1%|▏         | 13956/1000000 [2:25:00<1861:26:40,  6.80s/it, lr=1e-5, step_loss=0.00892][RANK-0]: Step: [13956], local_loss=0.016955072060227394, train_loss=0.07833538949489594, time_cost=1.57674241065979
Steps:   1%|▏         | 13956/1000000 [2:25:00<1861:26:40,  6.80s/it, lr=1e-5, step_loss=0.017]  Steps:   1%|▏         | 13957/1000000 [2:25:10<2127:30:17,  7.77s/it, lr=1e-5, step_loss=0.017][RANK-0]: Step: [13957], local_loss=0.017556335777044296, train_loss=0.024320276454091072, time_cost=1.3465261459350586
Steps:   1%|▏         | 13957/1000000 [2:25:10<2127:30:17,  7.77s/it, lr=1e-5, step_loss=0.0176]Steps:   1%|▏         | 13958/1000000 [2:25:23<2541:37:21,  9.28s/it, lr=1e-5, step_loss=0.0176][RANK-0]: Step: [13958], local_loss=0.00851104874163866, train_loss=0.08335734903812408, time_cost=6.220107316970825
Steps:   1%|▏         | 13958/1000000 [2:25:23<2541:37:21,  9.28s/it, lr=1e-5, step_loss=0.00851]Steps:   1%|▏         | 13959/1000000 [2:25:29<2312:28:51,  8.44s/it, lr=1e-5, step_loss=0.00851][RANK-0]: Step: [13959], local_loss=0.02202175185084343, train_loss=0.05121270939707756, time_cost=2.2076518535614014
Steps:   1%|▏         | 13959/1000000 [2:25:29<2312:28:51,  8.44s/it, lr=1e-5, step_loss=0.022]  Steps:   1%|▏         | 13960/1000000 [2:25:36<2226:23:31,  8.13s/it, lr=1e-5, step_loss=0.022][RANK-0]: Step: [13960], local_loss=0.047231726348400116, train_loss=0.03610435873270035, time_cost=2.4333231449127197
Steps:   1%|▏         | 13960/1000000 [2:25:36<2226:23:31,  8.13s/it, lr=1e-5, step_loss=0.0472]Steps:   1%|▏         | 13961/1000000 [2:25:41<1929:37:53,  7.05s/it, lr=1e-5, step_loss=0.0472][RANK-0]: Step: [13961], local_loss=0.01548255980014801, train_loss=0.014152261428534985, time_cost=1.4067423343658447
Steps:   1%|▏         | 13961/1000000 [2:25:41<1929:37:53,  7.05s/it, lr=1e-5, step_loss=0.0155]Steps:   1%|▏         | 13962/1000000 [2:25:53<2320:11:10,  8.47s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [13962], local_loss=0.010553432628512383, train_loss=0.026952732354402542, time_cost=2.7561769485473633
Steps:   1%|▏         | 13962/1000000 [2:25:53<2320:11:10,  8.47s/it, lr=1e-5, step_loss=0.0106]Steps:   1%|▏         | 13963/1000000 [2:26:01<2269:54:27,  8.29s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [13963], local_loss=0.043959129601716995, train_loss=0.03193560987710953, time_cost=2.2001888751983643
Steps:   1%|▏         | 13963/1000000 [2:26:01<2269:54:27,  8.29s/it, lr=1e-5, step_loss=0.044] Steps:   1%|▏         | 13964/1000000 [2:26:08<2184:59:18,  7.98s/it, lr=1e-5, step_loss=0.044][RANK-0]: Step: [13964], local_loss=0.05161320045590401, train_loss=0.04864216968417168, time_cost=1.9983220100402832
Steps:   1%|▏         | 13964/1000000 [2:26:08<2184:59:18,  7.98s/it, lr=1e-5, step_loss=0.0516]Steps:   1%|▏         | 13965/1000000 [2:26:16<2159:35:22,  7.88s/it, lr=1e-5, step_loss=0.0516][RANK-0]: Step: [13965], local_loss=0.024854497984051704, train_loss=0.0963478833436966, time_cost=1.3177671432495117
Steps:   1%|▏         | 13965/1000000 [2:26:16<2159:35:22,  7.88s/it, lr=1e-5, step_loss=0.0249]Steps:   1%|▏         | 13966/1000000 [2:26:21<1990:04:02,  7.27s/it, lr=1e-5, step_loss=0.0249][RANK-0]: Step: [13966], local_loss=0.023268623277544975, train_loss=0.03925035521388054, time_cost=2.991204023361206
Steps:   1%|▏         | 13966/1000000 [2:26:21<1990:04:02,  7.27s/it, lr=1e-5, step_loss=0.0233]Steps:   1%|▏         | 13967/1000000 [2:26:27<1847:26:14,  6.74s/it, lr=1e-5, step_loss=0.0233][RANK-0]: Step: [13967], local_loss=0.014862669631838799, train_loss=0.06506142020225525, time_cost=2.7646970748901367
Steps:   1%|▏         | 13967/1000000 [2:26:27<1847:26:14,  6.74s/it, lr=1e-5, step_loss=0.0149]Steps:   1%|▏         | 13968/1000000 [2:26:34<1869:36:13,  6.83s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [13968], local_loss=0.09115111827850342, train_loss=4.409208297729492, time_cost=2.926248788833618
Steps:   1%|▏         | 13968/1000000 [2:26:34<1869:36:13,  6.83s/it, lr=1e-5, step_loss=0.0912]Steps:   1%|▏         | 13969/1000000 [2:26:45<2234:13:15,  8.16s/it, lr=1e-5, step_loss=0.0912][RANK-0]: Step: [13969], local_loss=0.010378670878708363, train_loss=0.034856460988521576, time_cost=1.3711802959442139
Steps:   1%|▏         | 13969/1000000 [2:26:45<2234:13:15,  8.16s/it, lr=1e-5, step_loss=0.0104]Steps:   1%|▏         | 13970/1000000 [2:26:58<2598:08:38,  9.49s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [13970], local_loss=0.034327432513237, train_loss=0.022683870047330856, time_cost=1.7969965934753418
Steps:   1%|▏         | 13970/1000000 [2:26:58<2598:08:38,  9.49s/it, lr=1e-5, step_loss=0.0343]Steps:   1%|▏         | 13971/1000000 [2:27:04<2307:54:58,  8.43s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [13971], local_loss=0.011122757568955421, train_loss=0.025292446836829185, time_cost=4.001748323440552
Steps:   1%|▏         | 13971/1000000 [2:27:04<2307:54:58,  8.43s/it, lr=1e-5, step_loss=0.0111]Steps:   1%|▏         | 13972/1000000 [2:27:11<2247:20:55,  8.21s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [13972], local_loss=0.04392024502158165, train_loss=0.025246955454349518, time_cost=1.6592438220977783
Steps:   1%|▏         | 13972/1000000 [2:27:11<2247:20:55,  8.21s/it, lr=1e-5, step_loss=0.0439]Steps:   1%|▏         | 13973/1000000 [2:27:17<2060:15:47,  7.52s/it, lr=1e-5, step_loss=0.0439][RANK-0]: Step: [13973], local_loss=0.012984773144125938, train_loss=0.08351240307092667, time_cost=1.6640992164611816
Steps:   1%|▏         | 13973/1000000 [2:27:17<2060:15:47,  7.52s/it, lr=1e-5, step_loss=0.013] Steps:   1%|▏         | 13974/1000000 [2:27:26<2178:06:45,  7.95s/it, lr=1e-5, step_loss=0.013][RANK-0]: Step: [13974], local_loss=0.05240388959646225, train_loss=0.049498144537210464, time_cost=1.5968680381774902
Steps:   1%|▏         | 13974/1000000 [2:27:26<2178:06:45,  7.95s/it, lr=1e-5, step_loss=0.0524]Steps:   1%|▏         | 13975/1000000 [2:27:34<2135:09:32,  7.80s/it, lr=1e-5, step_loss=0.0524][RANK-0]: Step: [13975], local_loss=0.04559936001896858, train_loss=0.03361104801297188, time_cost=3.544879198074341
Steps:   1%|▏         | 13975/1000000 [2:27:34<2135:09:32,  7.80s/it, lr=1e-5, step_loss=0.0456]Steps:   1%|▏         | 13976/1000000 [2:27:41<2060:10:43,  7.52s/it, lr=1e-5, step_loss=0.0456][RANK-0]: Step: [13976], local_loss=0.006344487890601158, train_loss=0.02791912481188774, time_cost=2.460648536682129
Steps:   1%|▏         | 13976/1000000 [2:27:41<2060:10:43,  7.52s/it, lr=1e-5, step_loss=0.00634]Steps:   1%|▏         | 13977/1000000 [2:27:48<2026:21:36,  7.40s/it, lr=1e-5, step_loss=0.00634][RANK-0]: Step: [13977], local_loss=0.006711649242788553, train_loss=0.013874052092432976, time_cost=2.9021012783050537
Steps:   1%|▏         | 13977/1000000 [2:27:48<2026:21:36,  7.40s/it, lr=1e-5, step_loss=0.00671]Steps:   1%|▏         | 13978/1000000 [2:28:01<2517:26:59,  9.19s/it, lr=1e-5, step_loss=0.00671][RANK-0]: Step: [13978], local_loss=0.023772597312927246, train_loss=0.027825193479657173, time_cost=4.778449773788452
Steps:   1%|▏         | 13978/1000000 [2:28:01<2517:26:59,  9.19s/it, lr=1e-5, step_loss=0.0238] Steps:   1%|▏         | 13979/1000000 [2:28:15<2884:31:15, 10.53s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [13979], local_loss=0.007514447905123234, train_loss=0.07027260959148407, time_cost=11.522871971130371
Steps:   1%|▏         | 13979/1000000 [2:28:15<2884:31:15, 10.53s/it, lr=1e-5, step_loss=0.00751]Steps:   1%|▏         | 13980/1000000 [2:28:21<2528:42:52,  9.23s/it, lr=1e-5, step_loss=0.00751][RANK-0]: Step: [13980], local_loss=0.07115288823843002, train_loss=0.02760211005806923, time_cost=1.841858148574829
Steps:   1%|▏         | 13980/1000000 [2:28:21<2528:42:52,  9.23s/it, lr=1e-5, step_loss=0.0712] Steps:   1%|▏         | 13981/1000000 [2:28:26<2190:08:54,  8.00s/it, lr=1e-5, step_loss=0.0712][RANK-0]: Step: [13981], local_loss=0.026065412908792496, train_loss=0.03686344251036644, time_cost=2.0738718509674072
Steps:   1%|▏         | 13981/1000000 [2:28:26<2190:08:54,  8.00s/it, lr=1e-5, step_loss=0.0261]Steps:   1%|▏         | 13982/1000000 [2:28:31<1972:25:45,  7.20s/it, lr=1e-5, step_loss=0.0261][RANK-0]: Step: [13982], local_loss=0.010800600983202457, train_loss=0.05672840029001236, time_cost=1.2393317222595215
Steps:   1%|▏         | 13982/1000000 [2:28:31<1972:25:45,  7.20s/it, lr=1e-5, step_loss=0.0108]Steps:   1%|▏         | 13983/1000000 [2:28:39<2014:49:42,  7.36s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [13983], local_loss=0.0555277056992054, train_loss=0.03445447236299515, time_cost=5.498882293701172
Steps:   1%|▏         | 13983/1000000 [2:28:39<2014:49:42,  7.36s/it, lr=1e-5, step_loss=0.0555]Steps:   1%|▏         | 13984/1000000 [2:28:46<1994:21:39,  7.28s/it, lr=1e-5, step_loss=0.0555][RANK-0]: Step: [13984], local_loss=0.010202717036008835, train_loss=0.01998875103890896, time_cost=2.846552848815918
Steps:   1%|▏         | 13984/1000000 [2:28:46<1994:21:39,  7.28s/it, lr=1e-5, step_loss=0.0102]Steps:   1%|▏         | 13985/1000000 [2:28:57<2279:06:17,  8.32s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [13985], local_loss=0.03283822536468506, train_loss=0.037929367274045944, time_cost=3.5303213596343994
Steps:   1%|▏         | 13985/1000000 [2:28:57<2279:06:17,  8.32s/it, lr=1e-5, step_loss=0.0328]Steps:   1%|▏         | 13986/1000000 [2:29:02<2015:36:12,  7.36s/it, lr=1e-5, step_loss=0.0328][RANK-0]: Step: [13986], local_loss=0.009224774315953255, train_loss=0.07233825325965881, time_cost=1.2703444957733154
Steps:   1%|▏         | 13986/1000000 [2:29:02<2015:36:12,  7.36s/it, lr=1e-5, step_loss=0.00922]Steps:   1%|▏         | 13987/1000000 [2:29:13<2305:44:19,  8.42s/it, lr=1e-5, step_loss=0.00922][RANK-0]: Step: [13987], local_loss=0.024857046082615852, train_loss=0.06949225068092346, time_cost=1.6513848304748535
Steps:   1%|▏         | 13987/1000000 [2:29:13<2305:44:19,  8.42s/it, lr=1e-5, step_loss=0.0249] Steps:   1%|▏         | 13988/1000000 [2:29:20<2172:10:12,  7.93s/it, lr=1e-5, step_loss=0.0249][RANK-0]: Step: [13988], local_loss=0.014689575880765915, train_loss=0.07368277758359909, time_cost=2.5369935035705566
Steps:   1%|▏         | 13988/1000000 [2:29:20<2172:10:12,  7.93s/it, lr=1e-5, step_loss=0.0147]Steps:   1%|▏         | 13989/1000000 [2:29:33<2639:51:22,  9.64s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [13989], local_loss=0.0064382851123809814, train_loss=0.029706507921218872, time_cost=1.2342910766601562
Steps:   1%|▏         | 13989/1000000 [2:29:33<2639:51:22,  9.64s/it, lr=1e-5, step_loss=0.00644]Steps:   1%|▏         | 13990/1000000 [2:29:48<3042:29:17, 11.11s/it, lr=1e-5, step_loss=0.00644][RANK-0]: Step: [13990], local_loss=0.03113647922873497, train_loss=0.02742885984480381, time_cost=2.962455987930298
Steps:   1%|▏         | 13990/1000000 [2:29:48<3042:29:17, 11.11s/it, lr=1e-5, step_loss=0.0311] Steps:   1%|▏         | 13991/1000000 [2:29:58<2922:23:06, 10.67s/it, lr=1e-5, step_loss=0.0311][RANK-0]: Step: [13991], local_loss=0.018779471516609192, train_loss=0.04580472409725189, time_cost=1.930626630783081
Steps:   1%|▏         | 13991/1000000 [2:29:58<2922:23:06, 10.67s/it, lr=1e-5, step_loss=0.0188]Steps:   1%|▏         | 13992/1000000 [2:30:13<3277:54:50, 11.97s/it, lr=1e-5, step_loss=0.0188][RANK-0]: Step: [13992], local_loss=0.019261160865426064, train_loss=0.07657039910554886, time_cost=6.088449954986572
Steps:   1%|▏         | 13992/1000000 [2:30:13<3277:54:50, 11.97s/it, lr=1e-5, step_loss=0.0193]Steps:   1%|▏         | 13993/1000000 [2:30:18<2723:31:48,  9.94s/it, lr=1e-5, step_loss=0.0193][RANK-0]: Step: [13993], local_loss=0.03947850689291954, train_loss=0.022101106122136116, time_cost=2.3462367057800293
Steps:   1%|▏         | 13993/1000000 [2:30:18<2723:31:48,  9.94s/it, lr=1e-5, step_loss=0.0395]Steps:   1%|▏         | 13994/1000000 [2:30:25<2505:19:08,  9.15s/it, lr=1e-5, step_loss=0.0395][RANK-0]: Step: [13994], local_loss=0.03572425618767738, train_loss=0.07372488081455231, time_cost=3.272230386734009
Steps:   1%|▏         | 13994/1000000 [2:30:25<2505:19:08,  9.15s/it, lr=1e-5, step_loss=0.0357]Steps:   1%|▏         | 13995/1000000 [2:30:30<2166:55:54,  7.91s/it, lr=1e-5, step_loss=0.0357][RANK-0]: Step: [13995], local_loss=0.06723524630069733, train_loss=0.030074341222643852, time_cost=2.0409889221191406
Steps:   1%|▏         | 13995/1000000 [2:30:30<2166:55:54,  7.91s/it, lr=1e-5, step_loss=0.0672]Steps:   1%|▏         | 13996/1000000 [2:30:35<1935:12:00,  7.07s/it, lr=1e-5, step_loss=0.0672][RANK-0]: Step: [13996], local_loss=0.06738539785146713, train_loss=0.04798044636845589, time_cost=1.949411153793335
Steps:   1%|▏         | 13996/1000000 [2:30:35<1935:12:00,  7.07s/it, lr=1e-5, step_loss=0.0674]Steps:   1%|▏         | 13997/1000000 [2:30:44<2085:52:07,  7.62s/it, lr=1e-5, step_loss=0.0674][RANK-0]: Step: [13997], local_loss=0.016040772199630737, train_loss=0.028906619176268578, time_cost=2.9294395446777344
Steps:   1%|▏         | 13997/1000000 [2:30:44<2085:52:07,  7.62s/it, lr=1e-5, step_loss=0.016] Steps:   1%|▏         | 13998/1000000 [2:30:48<1812:05:18,  6.62s/it, lr=1e-5, step_loss=0.016][RANK-0]: Step: [13998], local_loss=0.05557297170162201, train_loss=21.07402992248535, time_cost=1.2301440238952637
Steps:   1%|▏         | 13998/1000000 [2:30:48<1812:05:18,  6.62s/it, lr=1e-5, step_loss=0.0556]Steps:   1%|▏         | 13999/1000000 [2:31:04<2515:22:33,  9.18s/it, lr=1e-5, step_loss=0.0556][RANK-0]: Step: [13999], local_loss=0.33451735973358154, train_loss=0.0618312731385231, time_cost=6.531261205673218
Steps:   1%|▏         | 13999/1000000 [2:31:04<2515:22:33,  9.18s/it, lr=1e-5, step_loss=0.335] Steps:   1%|▏         | 14000/1000000 [2:31:17<2879:35:27, 10.51s/it, lr=1e-5, step_loss=0.335][RANK-0]: Step: [14000], local_loss=0.006224147044122219, train_loss=0.14634402096271515, time_cost=1.2015371322631836
09/18/2024 11:55:20 - INFO - accelerate.accelerator - Saving current state to /home/save_dir/runs/allinpaint_stage1/checkpoint-14000
09/18/2024 11:55:20 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-18 11:55:20,639] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ma-user/anaconda3/envs/PyTorch-2.1.0/lib/python3.9/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-09-18 11:55:20,682] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/mp_rank_00_model_states.pt
[2024-09-18 11:55:20,683] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 11:55:38,884] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 11:55:38,923] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2024-09-18 11:55:38,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-18 11:55:38,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
[2024-09-18 11:55:38,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-09-18 11:55:38,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt...
[2024-09-18 11:55:38,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2024-09-18 11:55:38,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt...
[2024-09-18 11:55:38,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt...
[2024-09-18 11:56:11,112] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt.
[2024-09-18 11:56:11,112] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt
[2024-09-18 11:56:11,112] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 11:56:13,138] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt.
[2024-09-18 11:56:13,138] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt
[2024-09-18 11:56:13,139] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 11:56:13,304] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
[2024-09-18 11:56:13,304] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
[2024-09-18 11:56:13,305] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 11:56:14,424] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2024-09-18 11:56:14,424] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[2024-09-18 11:56:14,425] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 11:56:14,667] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2024-09-18 11:56:14,667] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[2024-09-18 11:56:14,667] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 11:56:15,082] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-18 11:56:15,129] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-18 11:56:15,130] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 11:56:15,281] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt.
[2024-09-18 11:56:15,281] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt
[2024-09-18 11:56:15,281] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 11:56:15,298] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-09-18 11:56:15,298] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-09-18 11:56:15,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/18/2024 11:56:15 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/pytorch_model
{'norm_num_groups', 'dropout', 'use_additional_conditions'} was not found in config. Values will be initialized to default values.
Configuration saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/model_ema/config.json
Model weights saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/model_ema/diffusion_pytorch_model.safetensors
Configuration saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/model/config.json
Model weights saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/model/diffusion_pytorch_model.safetensors
09/18/2024 11:57:22 - INFO - accelerate.checkpointing - Scheduler state saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/scheduler.bin
09/18/2024 11:57:22 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/sampler.bin
09/18/2024 11:57:22 - INFO - accelerate.checkpointing - Random states saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-14000/random_states_0.pkl
09/18/2024 11:57:22 - INFO - __main__ - Saved state to /home/save_dir/runs/allinpaint_stage1/checkpoint-14000
Steps:   1%|▏         | 14000/1000000 [2:33:19<2879:35:27, 10.51s/it, lr=1e-5, step_loss=0.00622]Steps:   1%|▏         | 14001/1000000 [2:33:28<12787:31:19, 46.69s/it, lr=1e-5, step_loss=0.00622][RANK-0]: Step: [14001], local_loss=0.07989844679832458, train_loss=0.05981217324733734, time_cost=1.2455110549926758
Steps:   1%|▏         | 14001/1000000 [2:33:28<12787:31:19, 46.69s/it, lr=1e-5, step_loss=0.0799] Steps:   1%|▏         | 14002/1000000 [2:33:40<9896:21:05, 36.13s/it, lr=1e-5, step_loss=0.0799] [RANK-0]: Step: [14002], local_loss=0.015900254249572754, train_loss=0.018778041005134583, time_cost=2.002653121948242
Steps:   1%|▏         | 14002/1000000 [2:33:40<9896:21:05, 36.13s/it, lr=1e-5, step_loss=0.0159]Steps:   1%|▏         | 14003/1000000 [2:33:51<7863:24:02, 28.71s/it, lr=1e-5, step_loss=0.0159][RANK-0]: Step: [14003], local_loss=0.012002825736999512, train_loss=0.03958243504166603, time_cost=3.741004228591919
Steps:   1%|▏         | 14003/1000000 [2:33:51<7863:24:02, 28.71s/it, lr=1e-5, step_loss=0.012] Steps:   1%|▏         | 14004/1000000 [2:34:01<6275:19:09, 22.91s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [14004], local_loss=0.008784138597548008, train_loss=0.03567611426115036, time_cost=6.967105150222778
Steps:   1%|▏         | 14004/1000000 [2:34:01<6275:19:09, 22.91s/it, lr=1e-5, step_loss=0.00878]Steps:   1%|▏         | 14005/1000000 [2:34:07<4887:10:39, 17.84s/it, lr=1e-5, step_loss=0.00878][RANK-0]: Step: [14005], local_loss=0.027099423110485077, train_loss=0.027840010821819305, time_cost=3.325361728668213
Steps:   1%|▏         | 14005/1000000 [2:34:07<4887:10:39, 17.84s/it, lr=1e-5, step_loss=0.0271] Steps:   1%|▏         | 14006/1000000 [2:34:18<4343:01:14, 15.86s/it, lr=1e-5, step_loss=0.0271][RANK-0]: Step: [14006], local_loss=0.0059271203354001045, train_loss=0.023155905306339264, time_cost=1.2164111137390137
Steps:   1%|▏         | 14006/1000000 [2:34:18<4343:01:14, 15.86s/it, lr=1e-5, step_loss=0.00593]Steps:   1%|▏         | 14007/1000000 [2:34:23<3472:18:20, 12.68s/it, lr=1e-5, step_loss=0.00593][RANK-0]: Step: [14007], local_loss=0.05257201939821243, train_loss=0.048712924122810364, time_cost=2.133803129196167
Steps:   1%|▏         | 14007/1000000 [2:34:23<3472:18:20, 12.68s/it, lr=1e-5, step_loss=0.0526] Steps:   1%|▏         | 14008/1000000 [2:34:39<3713:47:25, 13.56s/it, lr=1e-5, step_loss=0.0526][RANK-0]: Step: [14008], local_loss=0.07322961837053299, train_loss=0.03357638418674469, time_cost=4.985657453536987
Steps:   1%|▏         | 14008/1000000 [2:34:39<3713:47:25, 13.56s/it, lr=1e-5, step_loss=0.0732]Steps:   1%|▏         | 14009/1000000 [2:34:45<3100:38:53, 11.32s/it, lr=1e-5, step_loss=0.0732][RANK-0]: Step: [14009], local_loss=0.03354329988360405, train_loss=0.09775905311107635, time_cost=1.4411523342132568
Steps:   1%|▏         | 14009/1000000 [2:34:45<3100:38:53, 11.32s/it, lr=1e-5, step_loss=0.0335]Steps:   1%|▏         | 14010/1000000 [2:34:53<2857:16:24, 10.43s/it, lr=1e-5, step_loss=0.0335][RANK-0]: Step: [14010], local_loss=0.05029839277267456, train_loss=0.06393792480230331, time_cost=4.512723207473755
Steps:   1%|▏         | 14010/1000000 [2:34:53<2857:16:24, 10.43s/it, lr=1e-5, step_loss=0.0503]Steps:   1%|▏         | 14011/1000000 [2:35:04<2884:11:25, 10.53s/it, lr=1e-5, step_loss=0.0503][RANK-0]: Step: [14011], local_loss=0.011801090091466904, train_loss=0.05689328536391258, time_cost=2.87722110748291
Steps:   1%|▏         | 14011/1000000 [2:35:04<2884:11:25, 10.53s/it, lr=1e-5, step_loss=0.0118]Steps:   1%|▏         | 14012/1000000 [2:35:15<2954:12:00, 10.79s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [14012], local_loss=0.03199613094329834, train_loss=0.06366808712482452, time_cost=3.30664324760437
Steps:   1%|▏         | 14012/1000000 [2:35:15<2954:12:00, 10.79s/it, lr=1e-5, step_loss=0.032] Steps:   1%|▏         | 14013/1000000 [2:35:27<3007:25:55, 10.98s/it, lr=1e-5, step_loss=0.032][RANK-0]: Step: [14013], local_loss=0.3194861114025116, train_loss=0.058337219059467316, time_cost=1.2994256019592285
Steps:   1%|▏         | 14013/1000000 [2:35:27<3007:25:55, 10.98s/it, lr=1e-5, step_loss=0.319]Steps:   1%|▏         | 14014/1000000 [2:35:38<3026:34:23, 11.05s/it, lr=1e-5, step_loss=0.319][RANK-0]: Step: [14014], local_loss=0.09385903179645538, train_loss=0.07490015774965286, time_cost=2.1572065353393555
Steps:   1%|▏         | 14014/1000000 [2:35:38<3026:34:23, 11.05s/it, lr=1e-5, step_loss=0.0939]Steps:   1%|▏         | 14015/1000000 [2:35:43<2536:55:09,  9.26s/it, lr=1e-5, step_loss=0.0939][RANK-0]: Step: [14015], local_loss=0.0453365258872509, train_loss=0.026098299771547318, time_cost=1.289269208908081
Steps:   1%|▏         | 14015/1000000 [2:35:43<2536:55:09,  9.26s/it, lr=1e-5, step_loss=0.0453]Steps:   1%|▏         | 14016/1000000 [2:35:49<2237:10:46,  8.17s/it, lr=1e-5, step_loss=0.0453][RANK-0]: Step: [14016], local_loss=0.010922832414507866, train_loss=0.022948505356907845, time_cost=2.507361650466919
Steps:   1%|▏         | 14016/1000000 [2:35:49<2237:10:46,  8.17s/it, lr=1e-5, step_loss=0.0109]Steps:   1%|▏         | 14017/1000000 [2:36:02<2664:06:14,  9.73s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [14017], local_loss=0.009350785054266453, train_loss=0.1852826178073883, time_cost=4.174278974533081
Steps:   1%|▏         | 14017/1000000 [2:36:02<2664:06:14,  9.73s/it, lr=1e-5, step_loss=0.00935]Steps:   1%|▏         | 14018/1000000 [2:36:10<2504:17:36,  9.14s/it, lr=1e-5, step_loss=0.00935][RANK-0]: Step: [14018], local_loss=0.04300945997238159, train_loss=0.031155237928032875, time_cost=5.956053256988525
Steps:   1%|▏         | 14018/1000000 [2:36:10<2504:17:36,  9.14s/it, lr=1e-5, step_loss=0.043]  Steps:   1%|▏         | 14019/1000000 [2:36:17<2345:30:34,  8.56s/it, lr=1e-5, step_loss=0.043][RANK-0]: Step: [14019], local_loss=0.06447087228298187, train_loss=0.07194830477237701, time_cost=2.7870471477508545
Steps:   1%|▏         | 14019/1000000 [2:36:17<2345:30:34,  8.56s/it, lr=1e-5, step_loss=0.0645]Steps:   1%|▏         | 14020/1000000 [2:36:24<2227:30:52,  8.13s/it, lr=1e-5, step_loss=0.0645][RANK-0]: Step: [14020], local_loss=0.01711214892566204, train_loss=0.053419265896081924, time_cost=1.305546760559082
Steps:   1%|▏         | 14020/1000000 [2:36:24<2227:30:52,  8.13s/it, lr=1e-5, step_loss=0.0171]Steps:   1%|▏         | 14021/1000000 [2:36:38<2679:49:19,  9.78s/it, lr=1e-5, step_loss=0.0171][RANK-0]: Step: [14021], local_loss=0.5394738912582397, train_loss=0.1360926479101181, time_cost=4.419754505157471
Steps:   1%|▏         | 14021/1000000 [2:36:38<2679:49:19,  9.78s/it, lr=1e-5, step_loss=0.539] Steps:   1%|▏         | 14022/1000000 [2:36:47<2660:28:32,  9.71s/it, lr=1e-5, step_loss=0.539][RANK-0]: Step: [14022], local_loss=0.022953148931264877, train_loss=0.02039181813597679, time_cost=1.377488613128662
Steps:   1%|▏         | 14022/1000000 [2:36:47<2660:28:32,  9.71s/it, lr=1e-5, step_loss=0.023]Steps:   1%|▏         | 14023/1000000 [2:37:00<2900:07:48, 10.59s/it, lr=1e-5, step_loss=0.023][RANK-0]: Step: [14023], local_loss=0.036654189229011536, train_loss=0.03481290489435196, time_cost=6.483529090881348
Steps:   1%|▏         | 14023/1000000 [2:37:00<2900:07:48, 10.59s/it, lr=1e-5, step_loss=0.0367]Steps:   1%|▏         | 14024/1000000 [2:37:11<2952:46:01, 10.78s/it, lr=1e-5, step_loss=0.0367][RANK-0]: Step: [14024], local_loss=0.011803166940808296, train_loss=0.1473097801208496, time_cost=6.499017000198364
Steps:   1%|▏         | 14024/1000000 [2:37:11<2952:46:01, 10.78s/it, lr=1e-5, step_loss=0.0118]Steps:   1%|▏         | 14025/1000000 [2:37:19<2717:09:31,  9.92s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [14025], local_loss=0.28522181510925293, train_loss=0.08613809943199158, time_cost=2.0926058292388916
Steps:   1%|▏         | 14025/1000000 [2:37:19<2717:09:31,  9.92s/it, lr=1e-5, step_loss=0.285] Steps:   1%|▏         | 14026/1000000 [2:37:33<3037:43:46, 11.09s/it, lr=1e-5, step_loss=0.285][RANK-0]: Step: [14026], local_loss=0.027110302820801735, train_loss=0.028254196047782898, time_cost=4.1821911334991455
Steps:   1%|▏         | 14026/1000000 [2:37:33<3037:43:46, 11.09s/it, lr=1e-5, step_loss=0.0271]Steps:   1%|▏         | 14027/1000000 [2:37:38<2544:52:07,  9.29s/it, lr=1e-5, step_loss=0.0271][RANK-0]: Step: [14027], local_loss=0.015118220821022987, train_loss=0.015319110825657845, time_cost=4.0414721965789795
Steps:   1%|▏         | 14027/1000000 [2:37:38<2544:52:07,  9.29s/it, lr=1e-5, step_loss=0.0151]Steps:   1%|▏         | 14028/1000000 [2:37:50<2754:37:25, 10.06s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [14028], local_loss=0.027839994058012962, train_loss=0.025797121226787567, time_cost=3.2062525749206543
Steps:   1%|▏         | 14028/1000000 [2:37:50<2754:37:25, 10.06s/it, lr=1e-5, step_loss=0.0278]Steps:   1%|▏         | 14029/1000000 [2:37:55<2337:54:15,  8.54s/it, lr=1e-5, step_loss=0.0278][RANK-0]: Step: [14029], local_loss=0.022660836577415466, train_loss=0.04211156442761421, time_cost=2.1045644283294678
Steps:   1%|▏         | 14029/1000000 [2:37:55<2337:54:15,  8.54s/it, lr=1e-5, step_loss=0.0227]Steps:   1%|▏         | 14030/1000000 [2:38:06<2583:14:05,  9.43s/it, lr=1e-5, step_loss=0.0227][RANK-0]: Step: [14030], local_loss=0.012722771614789963, train_loss=0.16212311387062073, time_cost=1.229731559753418
Steps:   1%|▏         | 14030/1000000 [2:38:06<2583:14:05,  9.43s/it, lr=1e-5, step_loss=0.0127]Steps:   1%|▏         | 14031/1000000 [2:38:12<2306:54:49,  8.42s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [14031], local_loss=0.0162070132791996, train_loss=19.1119384765625, time_cost=1.966433048248291
Steps:   1%|▏         | 14031/1000000 [2:38:12<2306:54:49,  8.42s/it, lr=1e-5, step_loss=0.0162]Steps:   1%|▏         | 14032/1000000 [2:38:21<2334:47:51,  8.52s/it, lr=1e-5, step_loss=0.0162][RANK-0]: Step: [14032], local_loss=0.02677997387945652, train_loss=0.05192364379763603, time_cost=2.949047565460205
Steps:   1%|▏         | 14032/1000000 [2:38:21<2334:47:51,  8.52s/it, lr=1e-5, step_loss=0.0268]Steps:   1%|▏         | 14033/1000000 [2:38:31<2427:25:45,  8.86s/it, lr=1e-5, step_loss=0.0268][RANK-0]: Step: [14033], local_loss=0.05085736885666847, train_loss=0.040403373539447784, time_cost=1.3593332767486572
Steps:   1%|▏         | 14033/1000000 [2:38:31<2427:25:45,  8.86s/it, lr=1e-5, step_loss=0.0509]Steps:   1%|▏         | 14034/1000000 [2:38:43<2688:46:50,  9.82s/it, lr=1e-5, step_loss=0.0509][RANK-0]: Step: [14034], local_loss=0.006639894563704729, train_loss=0.1438673734664917, time_cost=4.35160493850708
Steps:   1%|▏         | 14034/1000000 [2:38:43<2688:46:50,  9.82s/it, lr=1e-5, step_loss=0.00664]Steps:   1%|▏         | 14035/1000000 [2:38:51<2545:03:37,  9.29s/it, lr=1e-5, step_loss=0.00664][RANK-0]: Step: [14035], local_loss=0.021933663636446, train_loss=0.0817335769534111, time_cost=3.6977057456970215
Steps:   1%|▏         | 14035/1000000 [2:38:51<2545:03:37,  9.29s/it, lr=1e-5, step_loss=0.0219] Steps:   1%|▏         | 14036/1000000 [2:39:04<2890:43:24, 10.55s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [14036], local_loss=0.04699994623661041, train_loss=0.02715536393225193, time_cost=3.8864123821258545
Steps:   1%|▏         | 14036/1000000 [2:39:04<2890:43:24, 10.55s/it, lr=1e-5, step_loss=0.047] Steps:   1%|▏         | 14037/1000000 [2:39:11<2526:40:19,  9.23s/it, lr=1e-5, step_loss=0.047][RANK-0]: Step: [14037], local_loss=0.021937694400548935, train_loss=0.060842398554086685, time_cost=1.6954700946807861
Steps:   1%|▏         | 14037/1000000 [2:39:11<2526:40:19,  9.23s/it, lr=1e-5, step_loss=0.0219]Steps:   1%|▏         | 14038/1000000 [2:39:22<2732:58:58,  9.98s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [14038], local_loss=0.0561930350959301, train_loss=0.06336580216884613, time_cost=8.82506012916565
Steps:   1%|▏         | 14038/1000000 [2:39:22<2732:58:58,  9.98s/it, lr=1e-5, step_loss=0.0562]Steps:   1%|▏         | 14039/1000000 [2:39:34<2844:43:16, 10.39s/it, lr=1e-5, step_loss=0.0562][RANK-0]: Step: [14039], local_loss=0.035090796649456024, train_loss=0.18764320015907288, time_cost=1.2475621700286865
Steps:   1%|▏         | 14039/1000000 [2:39:34<2844:43:16, 10.39s/it, lr=1e-5, step_loss=0.0351]Steps:   1%|▏         | 14040/1000000 [2:39:47<3116:35:21, 11.38s/it, lr=1e-5, step_loss=0.0351][RANK-0]: Step: [14040], local_loss=0.01517495233565569, train_loss=0.04814764857292175, time_cost=4.356549263000488
Steps:   1%|▏         | 14040/1000000 [2:39:47<3116:35:21, 11.38s/it, lr=1e-5, step_loss=0.0152]Steps:   1%|▏         | 14041/1000000 [2:39:58<3064:27:57, 11.19s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [14041], local_loss=0.013575262390077114, train_loss=0.01800113543868065, time_cost=3.137204647064209
Steps:   1%|▏         | 14041/1000000 [2:39:58<3064:27:57, 11.19s/it, lr=1e-5, step_loss=0.0136]Steps:   1%|▏         | 14042/1000000 [2:40:07<2895:51:06, 10.57s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [14042], local_loss=0.1411902755498886, train_loss=0.10819433629512787, time_cost=1.4095261096954346
Steps:   1%|▏         | 14042/1000000 [2:40:07<2895:51:06, 10.57s/it, lr=1e-5, step_loss=0.141] Steps:   1%|▏         | 14043/1000000 [2:40:18<2943:01:49, 10.75s/it, lr=1e-5, step_loss=0.141][RANK-0]: Step: [14043], local_loss=0.03349537029862404, train_loss=0.019998548552393913, time_cost=3.601322889328003
Steps:   1%|▏         | 14043/1000000 [2:40:18<2943:01:49, 10.75s/it, lr=1e-5, step_loss=0.0335]Steps:   1%|▏         | 14044/1000000 [2:40:24<2544:11:15,  9.29s/it, lr=1e-5, step_loss=0.0335][RANK-0]: Step: [14044], local_loss=0.011988474056124687, train_loss=0.07022624462842941, time_cost=1.664180040359497
Steps:   1%|▏         | 14044/1000000 [2:40:24<2544:11:15,  9.29s/it, lr=1e-5, step_loss=0.012] Steps:   1%|▏         | 14045/1000000 [2:40:33<2510:17:54,  9.17s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [14045], local_loss=0.048561908304691315, train_loss=0.043857090175151825, time_cost=2.9202966690063477
Steps:   1%|▏         | 14045/1000000 [2:40:33<2510:17:54,  9.17s/it, lr=1e-5, step_loss=0.0486]Steps:   1%|▏         | 14046/1000000 [2:40:40<2322:00:29,  8.48s/it, lr=1e-5, step_loss=0.0486][RANK-0]: Step: [14046], local_loss=0.052870914340019226, train_loss=0.04225607216358185, time_cost=2.2570745944976807
Steps:   1%|▏         | 14046/1000000 [2:40:40<2322:00:29,  8.48s/it, lr=1e-5, step_loss=0.0529]Steps:   1%|▏         | 14047/1000000 [2:40:45<2055:11:41,  7.50s/it, lr=1e-5, step_loss=0.0529][RANK-0]: Step: [14047], local_loss=0.007093056105077267, train_loss=0.014929141849279404, time_cost=1.9012904167175293
Steps:   1%|▏         | 14047/1000000 [2:40:45<2055:11:41,  7.50s/it, lr=1e-5, step_loss=0.00709]Steps:   1%|▏         | 14048/1000000 [2:40:52<2014:48:03,  7.36s/it, lr=1e-5, step_loss=0.00709][RANK-0]: Step: [14048], local_loss=0.008712833747267723, train_loss=0.03215838223695755, time_cost=2.2253451347351074
Steps:   1%|▏         | 14048/1000000 [2:40:52<2014:48:03,  7.36s/it, lr=1e-5, step_loss=0.00871]Steps:   1%|▏         | 14049/1000000 [2:41:04<2335:01:37,  8.53s/it, lr=1e-5, step_loss=0.00871][RANK-0]: Step: [14049], local_loss=0.02205101028084755, train_loss=44.584808349609375, time_cost=4.485236406326294
Steps:   1%|▏         | 14049/1000000 [2:41:04<2335:01:37,  8.53s/it, lr=1e-5, step_loss=0.0221] Steps:   1%|▏         | 14050/1000000 [2:41:09<2043:37:29,  7.46s/it, lr=1e-5, step_loss=0.0221][RANK-0]: Step: [14050], local_loss=0.016664160415530205, train_loss=0.06924927234649658, time_cost=1.2380449771881104
Steps:   1%|▏         | 14050/1000000 [2:41:09<2043:37:29,  7.46s/it, lr=1e-5, step_loss=0.0167]Steps:   1%|▏         | 14051/1000000 [2:41:20<2344:37:24,  8.56s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [14051], local_loss=0.018069151788949966, train_loss=0.03253762796521187, time_cost=8.791326522827148
Steps:   1%|▏         | 14051/1000000 [2:41:20<2344:37:24,  8.56s/it, lr=1e-5, step_loss=0.0181]Steps:   1%|▏         | 14052/1000000 [2:41:25<2055:47:06,  7.51s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [14052], local_loss=0.06811610609292984, train_loss=0.1687486618757248, time_cost=1.9619901180267334
Steps:   1%|▏         | 14052/1000000 [2:41:25<2055:47:06,  7.51s/it, lr=1e-5, step_loss=0.0681]Steps:   1%|▏         | 14053/1000000 [2:41:30<1861:05:32,  6.80s/it, lr=1e-5, step_loss=0.0681][RANK-0]: Step: [14053], local_loss=0.007969269528985023, train_loss=0.025489002466201782, time_cost=3.966522216796875
Steps:   1%|▏         | 14053/1000000 [2:41:30<1861:05:32,  6.80s/it, lr=1e-5, step_loss=0.00797]Steps:   1%|▏         | 14054/1000000 [2:41:35<1719:59:25,  6.28s/it, lr=1e-5, step_loss=0.00797][RANK-0]: Step: [14054], local_loss=0.061330024152994156, train_loss=0.04125996679067612, time_cost=2.1941580772399902
Steps:   1%|▏         | 14054/1000000 [2:41:35<1719:59:25,  6.28s/it, lr=1e-5, step_loss=0.0613] Steps:   1%|▏         | 14055/1000000 [2:41:40<1617:33:51,  5.91s/it, lr=1e-5, step_loss=0.0613][RANK-0]: Step: [14055], local_loss=0.044623710215091705, train_loss=0.03701028972864151, time_cost=3.7663559913635254
Steps:   1%|▏         | 14055/1000000 [2:41:40<1617:33:51,  5.91s/it, lr=1e-5, step_loss=0.0446]Steps:   1%|▏         | 14056/1000000 [2:41:47<1747:03:23,  6.38s/it, lr=1e-5, step_loss=0.0446][RANK-0]: Step: [14056], local_loss=0.05088010057806969, train_loss=0.1518382579088211, time_cost=2.13071608543396
Steps:   1%|▏         | 14056/1000000 [2:41:47<1747:03:23,  6.38s/it, lr=1e-5, step_loss=0.0509]Steps:   1%|▏         | 14057/1000000 [2:41:58<2116:39:57,  7.73s/it, lr=1e-5, step_loss=0.0509][RANK-0]: Step: [14057], local_loss=0.014991370029747486, train_loss=0.07828874886035919, time_cost=1.2128651142120361
Steps:   1%|▏         | 14057/1000000 [2:41:58<2116:39:57,  7.73s/it, lr=1e-5, step_loss=0.015] Steps:   1%|▏         | 14058/1000000 [2:42:08<2311:07:52,  8.44s/it, lr=1e-5, step_loss=0.015][RANK-0]: Step: [14058], local_loss=0.01600675843656063, train_loss=0.07435775548219681, time_cost=4.6172308921813965
Steps:   1%|▏         | 14058/1000000 [2:42:08<2311:07:52,  8.44s/it, lr=1e-5, step_loss=0.016]Steps:   1%|▏         | 14059/1000000 [2:42:19<2480:47:34,  9.06s/it, lr=1e-5, step_loss=0.016][RANK-0]: Step: [14059], local_loss=0.497003436088562, train_loss=0.09003317356109619, time_cost=1.2264955043792725
Steps:   1%|▏         | 14059/1000000 [2:42:19<2480:47:34,  9.06s/it, lr=1e-5, step_loss=0.497]Steps:   1%|▏         | 14060/1000000 [2:42:24<2146:18:39,  7.84s/it, lr=1e-5, step_loss=0.497][RANK-0]: Step: [14060], local_loss=0.012610353529453278, train_loss=0.04217107594013214, time_cost=1.9750170707702637
Steps:   1%|▏         | 14060/1000000 [2:42:24<2146:18:39,  7.84s/it, lr=1e-5, step_loss=0.0126]Steps:   1%|▏         | 14061/1000000 [2:42:34<2301:13:00,  8.40s/it, lr=1e-5, step_loss=0.0126][RANK-0]: Step: [14061], local_loss=0.11634030938148499, train_loss=0.06867703795433044, time_cost=2.532048463821411
Steps:   1%|▏         | 14061/1000000 [2:42:34<2301:13:00,  8.40s/it, lr=1e-5, step_loss=0.116] Steps:   1%|▏         | 14062/1000000 [2:42:47<2696:05:33,  9.84s/it, lr=1e-5, step_loss=0.116][RANK-0]: Step: [14062], local_loss=0.4194430708885193, train_loss=0.13237765431404114, time_cost=4.5847718715667725
Steps:   1%|▏         | 14062/1000000 [2:42:47<2696:05:33,  9.84s/it, lr=1e-5, step_loss=0.419]Steps:   1%|▏         | 14063/1000000 [2:42:58<2779:24:34, 10.15s/it, lr=1e-5, step_loss=0.419][RANK-0]: Step: [14063], local_loss=0.017889738082885742, train_loss=0.14973416924476624, time_cost=1.7956888675689697
Steps:   1%|▏         | 14063/1000000 [2:42:58<2779:24:34, 10.15s/it, lr=1e-5, step_loss=0.0179]Steps:   1%|▏         | 14064/1000000 [2:43:02<2326:40:30,  8.50s/it, lr=1e-5, step_loss=0.0179][RANK-0]: Step: [14064], local_loss=0.010826480574905872, train_loss=0.04647243022918701, time_cost=2.2282633781433105
Steps:   1%|▏         | 14064/1000000 [2:43:02<2326:40:30,  8.50s/it, lr=1e-5, step_loss=0.0108]Steps:   1%|▏         | 14065/1000000 [2:43:08<2070:59:55,  7.56s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [14065], local_loss=0.03188912570476532, train_loss=0.07944238185882568, time_cost=3.765624761581421
Steps:   1%|▏         | 14065/1000000 [2:43:08<2070:59:55,  7.56s/it, lr=1e-5, step_loss=0.0319]Steps:   1%|▏         | 14066/1000000 [2:43:17<2194:06:12,  8.01s/it, lr=1e-5, step_loss=0.0319][RANK-0]: Step: [14066], local_loss=1.0165154933929443, train_loss=0.2809164524078369, time_cost=2.6925241947174072
Steps:   1%|▏         | 14066/1000000 [2:43:17<2194:06:12,  8.01s/it, lr=1e-5, step_loss=1.02]  Steps:   1%|▏         | 14067/1000000 [2:43:26<2291:21:49,  8.37s/it, lr=1e-5, step_loss=1.02][RANK-0]: Step: [14067], local_loss=0.34283262491226196, train_loss=0.0714634358882904, time_cost=6.2779381275177
Steps:   1%|▏         | 14067/1000000 [2:43:26<2291:21:49,  8.37s/it, lr=1e-5, step_loss=0.343]Steps:   1%|▏         | 14068/1000000 [2:43:31<2051:58:09,  7.49s/it, lr=1e-5, step_loss=0.343][RANK-0]: Step: [14068], local_loss=0.11953256279230118, train_loss=0.07155926525592804, time_cost=2.3058102130889893
Steps:   1%|▏         | 14068/1000000 [2:43:31<2051:58:09,  7.49s/it, lr=1e-5, step_loss=0.12] Steps:   1%|▏         | 14069/1000000 [2:43:36<1844:41:15,  6.74s/it, lr=1e-5, step_loss=0.12][RANK-0]: Step: [14069], local_loss=0.02674674242734909, train_loss=0.07187708467245102, time_cost=1.2884814739227295
Steps:   1%|▏         | 14069/1000000 [2:43:36<1844:41:15,  6.74s/it, lr=1e-5, step_loss=0.0267]Steps:   1%|▏         | 14070/1000000 [2:43:47<2170:00:41,  7.92s/it, lr=1e-5, step_loss=0.0267][RANK-0]: Step: [14070], local_loss=0.005926141981035471, train_loss=0.1620481014251709, time_cost=3.65474796295166
Steps:   1%|▏         | 14070/1000000 [2:43:47<2170:00:41,  7.92s/it, lr=1e-5, step_loss=0.00593]Steps:   1%|▏         | 14071/1000000 [2:43:59<2475:13:37,  9.04s/it, lr=1e-5, step_loss=0.00593][RANK-0]: Step: [14071], local_loss=0.012703249230980873, train_loss=0.031695615500211716, time_cost=3.0180695056915283
Steps:   1%|▏         | 14071/1000000 [2:43:59<2475:13:37,  9.04s/it, lr=1e-5, step_loss=0.0127] Steps:   1%|▏         | 14072/1000000 [2:44:04<2149:54:38,  7.85s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [14072], local_loss=0.01060360949486494, train_loss=0.02522560954093933, time_cost=1.9932732582092285
Steps:   1%|▏         | 14072/1000000 [2:44:04<2149:54:38,  7.85s/it, lr=1e-5, step_loss=0.0106]Steps:   1%|▏         | 14073/1000000 [2:44:08<1865:53:03,  6.81s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [14073], local_loss=0.034270212054252625, train_loss=0.058572784066200256, time_cost=1.6184871196746826
Steps:   1%|▏         | 14073/1000000 [2:44:08<1865:53:03,  6.81s/it, lr=1e-5, step_loss=0.0343]Steps:   1%|▏         | 14074/1000000 [2:44:21<2387:07:44,  8.72s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [14074], local_loss=0.023813404142856598, train_loss=0.023403242230415344, time_cost=3.9672248363494873
Steps:   1%|▏         | 14074/1000000 [2:44:21<2387:07:44,  8.72s/it, lr=1e-5, step_loss=0.0238]Steps:   1%|▏         | 14075/1000000 [2:44:27<2102:53:26,  7.68s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [14075], local_loss=0.00878902431577444, train_loss=0.02255713939666748, time_cost=2.40600848197937
Steps:   1%|▏         | 14075/1000000 [2:44:27<2102:53:26,  7.68s/it, lr=1e-5, step_loss=0.00879]Steps:   1%|▏         | 14076/1000000 [2:44:32<1905:49:50,  6.96s/it, lr=1e-5, step_loss=0.00879][RANK-0]: Step: [14076], local_loss=0.00932309776544571, train_loss=19.068279266357422, time_cost=1.212599754333496
Steps:   1%|▏         | 14076/1000000 [2:44:32<1905:49:50,  6.96s/it, lr=1e-5, step_loss=0.00932]Steps:   1%|▏         | 14077/1000000 [2:44:48<2637:46:44,  9.63s/it, lr=1e-5, step_loss=0.00932][RANK-0]: Step: [14077], local_loss=0.2994841933250427, train_loss=0.11145615577697754, time_cost=7.036192178726196
Steps:   1%|▏         | 14077/1000000 [2:44:48<2637:46:44,  9.63s/it, lr=1e-5, step_loss=0.299]  Steps:   1%|▏         | 14078/1000000 [2:44:58<2729:13:08,  9.97s/it, lr=1e-5, step_loss=0.299][RANK-0]: Step: [14078], local_loss=0.007493922486901283, train_loss=0.03158736974000931, time_cost=2.0070855617523193
Steps:   1%|▏         | 14078/1000000 [2:44:58<2729:13:08,  9.97s/it, lr=1e-5, step_loss=0.00749]Steps:   1%|▏         | 14079/1000000 [2:45:12<3041:00:08, 11.10s/it, lr=1e-5, step_loss=0.00749][RANK-0]: Step: [14079], local_loss=0.01614656299352646, train_loss=0.04452397674322128, time_cost=3.7721259593963623
Steps:   1%|▏         | 14079/1000000 [2:45:12<3041:00:08, 11.10s/it, lr=1e-5, step_loss=0.0161] Steps:   1%|▏         | 14080/1000000 [2:45:20<2736:51:16,  9.99s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [14080], local_loss=0.03295561298727989, train_loss=0.2069566249847412, time_cost=1.7104649543762207
Steps:   1%|▏         | 14080/1000000 [2:45:20<2736:51:16,  9.99s/it, lr=1e-5, step_loss=0.033] Steps:   1%|▏         | 14081/1000000 [2:45:31<2856:54:25, 10.43s/it, lr=1e-5, step_loss=0.033][RANK-0]: Step: [14081], local_loss=0.03130868822336197, train_loss=0.15989530086517334, time_cost=3.6730268001556396
Steps:   1%|▏         | 14081/1000000 [2:45:31<2856:54:25, 10.43s/it, lr=1e-5, step_loss=0.0313]Steps:   1%|▏         | 14082/1000000 [2:45:42<2894:55:39, 10.57s/it, lr=1e-5, step_loss=0.0313][RANK-0]: Step: [14082], local_loss=0.006017506588250399, train_loss=0.04424891248345375, time_cost=1.2377548217773438
Steps:   1%|▏         | 14082/1000000 [2:45:42<2894:55:39, 10.57s/it, lr=1e-5, step_loss=0.00602]Steps:   1%|▏         | 14083/1000000 [2:45:56<3187:58:34, 11.64s/it, lr=1e-5, step_loss=0.00602][RANK-0]: Step: [14083], local_loss=0.0070571633987128735, train_loss=0.06814493238925934, time_cost=2.2694637775421143
Steps:   1%|▏         | 14083/1000000 [2:45:56<3187:58:34, 11.64s/it, lr=1e-5, step_loss=0.00706]Steps:   1%|▏         | 14084/1000000 [2:46:09<3325:18:28, 12.14s/it, lr=1e-5, step_loss=0.00706][RANK-0]: Step: [14084], local_loss=0.153286874294281, train_loss=0.03344444930553436, time_cost=3.7602198123931885
Steps:   1%|▏         | 14084/1000000 [2:46:09<3325:18:28, 12.14s/it, lr=1e-5, step_loss=0.153]  Steps:   1%|▏         | 14085/1000000 [2:46:22<3338:39:38, 12.19s/it, lr=1e-5, step_loss=0.153][RANK-0]: Step: [14085], local_loss=0.02808741293847561, train_loss=0.04233179986476898, time_cost=6.66150689125061
Steps:   1%|▏         | 14085/1000000 [2:46:22<3338:39:38, 12.19s/it, lr=1e-5, step_loss=0.0281]Steps:   1%|▏         | 14086/1000000 [2:46:31<3106:26:15, 11.34s/it, lr=1e-5, step_loss=0.0281][RANK-0]: Step: [14086], local_loss=0.05462180823087692, train_loss=0.023917851969599724, time_cost=2.403998613357544
Steps:   1%|▏         | 14086/1000000 [2:46:31<3106:26:15, 11.34s/it, lr=1e-5, step_loss=0.0546]Steps:   1%|▏         | 14087/1000000 [2:46:40<2925:58:15, 10.68s/it, lr=1e-5, step_loss=0.0546][RANK-0]: Step: [14087], local_loss=0.015675000846385956, train_loss=0.022721223533153534, time_cost=3.9981422424316406
Steps:   1%|▏         | 14087/1000000 [2:46:40<2925:58:15, 10.68s/it, lr=1e-5, step_loss=0.0157]Steps:   1%|▏         | 14088/1000000 [2:46:45<2452:12:47,  8.95s/it, lr=1e-5, step_loss=0.0157][RANK-0]: Step: [14088], local_loss=0.04528316855430603, train_loss=0.03069119155406952, time_cost=2.3042454719543457
Steps:   1%|▏         | 14088/1000000 [2:46:45<2452:12:47,  8.95s/it, lr=1e-5, step_loss=0.0453]Steps:   1%|▏         | 14089/1000000 [2:46:56<2625:36:01,  9.59s/it, lr=1e-5, step_loss=0.0453][RANK-0]: Step: [14089], local_loss=0.1466013789176941, train_loss=0.04286142438650131, time_cost=1.2199280261993408
Steps:   1%|▏         | 14089/1000000 [2:46:56<2625:36:01,  9.59s/it, lr=1e-5, step_loss=0.147] Steps:   1%|▏         | 14090/1000000 [2:47:02<2316:01:29,  8.46s/it, lr=1e-5, step_loss=0.147][RANK-0]: Step: [14090], local_loss=0.022866852581501007, train_loss=0.032109398394823074, time_cost=2.7482070922851562
Steps:   1%|▏         | 14090/1000000 [2:47:02<2316:01:29,  8.46s/it, lr=1e-5, step_loss=0.0229]Steps:   1%|▏         | 14091/1000000 [2:47:08<2104:43:00,  7.69s/it, lr=1e-5, step_loss=0.0229][RANK-0]: Step: [14091], local_loss=0.05148199200630188, train_loss=0.07173651456832886, time_cost=4.715597152709961
Steps:   1%|▏         | 14091/1000000 [2:47:08<2104:43:00,  7.69s/it, lr=1e-5, step_loss=0.0515]Steps:   1%|▏         | 14092/1000000 [2:47:20<2466:56:16,  9.01s/it, lr=1e-5, step_loss=0.0515][RANK-0]: Step: [14092], local_loss=0.04115563631057739, train_loss=0.01882275938987732, time_cost=1.9932498931884766
Steps:   1%|▏         | 14092/1000000 [2:47:20<2466:56:16,  9.01s/it, lr=1e-5, step_loss=0.0412]Steps:   1%|▏         | 14093/1000000 [2:47:34<2875:32:03, 10.50s/it, lr=1e-5, step_loss=0.0412][RANK-0]: Step: [14093], local_loss=0.03586550056934357, train_loss=0.03027632087469101, time_cost=1.3715717792510986
Steps:   1%|▏         | 14093/1000000 [2:47:34<2875:32:03, 10.50s/it, lr=1e-5, step_loss=0.0359]Steps:   1%|▏         | 14094/1000000 [2:47:47<3096:02:53, 11.31s/it, lr=1e-5, step_loss=0.0359][RANK-0]: Step: [14094], local_loss=0.005887121427804232, train_loss=0.02442111447453499, time_cost=3.9685888290405273
Steps:   1%|▏         | 14094/1000000 [2:47:47<3096:02:53, 11.31s/it, lr=1e-5, step_loss=0.00589]Steps:   1%|▏         | 14095/1000000 [2:48:01<3291:09:50, 12.02s/it, lr=1e-5, step_loss=0.00589][RANK-0]: Step: [14095], local_loss=0.005491478368639946, train_loss=0.06354999542236328, time_cost=4.519543170928955
Steps:   1%|▏         | 14095/1000000 [2:48:01<3291:09:50, 12.02s/it, lr=1e-5, step_loss=0.00549]Steps:   1%|▏         | 14096/1000000 [2:48:06<2719:18:15,  9.93s/it, lr=1e-5, step_loss=0.00549][RANK-0]: Step: [14096], local_loss=0.02463737316429615, train_loss=0.056953247636556625, time_cost=2.229001760482788
Steps:   1%|▏         | 14096/1000000 [2:48:06<2719:18:15,  9.93s/it, lr=1e-5, step_loss=0.0246] Steps:   1%|▏         | 14097/1000000 [2:48:18<2913:43:09, 10.64s/it, lr=1e-5, step_loss=0.0246][RANK-0]: Step: [14097], local_loss=0.004565075039863586, train_loss=0.07424129545688629, time_cost=5.7546374797821045
Steps:   1%|▏         | 14097/1000000 [2:48:18<2913:43:09, 10.64s/it, lr=1e-5, step_loss=0.00457]Steps:   1%|▏         | 14098/1000000 [2:48:23<2395:01:50,  8.75s/it, lr=1e-5, step_loss=0.00457][RANK-0]: Step: [14098], local_loss=0.022795362398028374, train_loss=0.04025927186012268, time_cost=1.4083242416381836
Steps:   1%|▏         | 14098/1000000 [2:48:23<2395:01:50,  8.75s/it, lr=1e-5, step_loss=0.0228] Steps:   1%|▏         | 14099/1000000 [2:48:27<2050:24:23,  7.49s/it, lr=1e-5, step_loss=0.0228][RANK-0]: Step: [14099], local_loss=0.09445963054895401, train_loss=0.07256016880273819, time_cost=1.5489919185638428
Steps:   1%|▏         | 14099/1000000 [2:48:27<2050:24:23,  7.49s/it, lr=1e-5, step_loss=0.0945]Steps:   1%|▏         | 14100/1000000 [2:48:32<1798:24:53,  6.57s/it, lr=1e-5, step_loss=0.0945][RANK-0]: Step: [14100], local_loss=0.04909656196832657, train_loss=0.035115428268909454, time_cost=1.481372594833374
Steps:   1%|▏         | 14100/1000000 [2:48:32<1798:24:53,  6.57s/it, lr=1e-5, step_loss=0.0491]Steps:   1%|▏         | 14101/1000000 [2:48:42<2115:35:14,  7.73s/it, lr=1e-5, step_loss=0.0491][RANK-0]: Step: [14101], local_loss=0.03315350413322449, train_loss=0.237238809466362, time_cost=7.728400945663452
Steps:   1%|▏         | 14101/1000000 [2:48:42<2115:35:14,  7.73s/it, lr=1e-5, step_loss=0.0332]Steps:   1%|▏         | 14102/1000000 [2:48:51<2252:59:03,  8.23s/it, lr=1e-5, step_loss=0.0332][RANK-0]: Step: [14102], local_loss=0.036620818078517914, train_loss=0.038581427186727524, time_cost=3.3023159503936768
Steps:   1%|▏         | 14102/1000000 [2:48:51<2252:59:03,  8.23s/it, lr=1e-5, step_loss=0.0366]Steps:   1%|▏         | 14103/1000000 [2:49:00<2301:52:30,  8.41s/it, lr=1e-5, step_loss=0.0366][RANK-0]: Step: [14103], local_loss=0.008706015534698963, train_loss=0.0211858619004488, time_cost=3.073223114013672
Steps:   1%|▏         | 14103/1000000 [2:49:00<2301:52:30,  8.41s/it, lr=1e-5, step_loss=0.00871]Steps:   1%|▏         | 14104/1000000 [2:49:07<2185:16:38,  7.98s/it, lr=1e-5, step_loss=0.00871][RANK-0]: Step: [14104], local_loss=0.0208804439753294, train_loss=0.03318680450320244, time_cost=5.806704044342041
Steps:   1%|▏         | 14104/1000000 [2:49:07<2185:16:38,  7.98s/it, lr=1e-5, step_loss=0.0209] Steps:   1%|▏         | 14105/1000000 [2:49:21<2686:26:47,  9.81s/it, lr=1e-5, step_loss=0.0209][RANK-0]: Step: [14105], local_loss=0.01698031648993492, train_loss=0.01925818622112274, time_cost=4.668039083480835
Steps:   1%|▏         | 14105/1000000 [2:49:21<2686:26:47,  9.81s/it, lr=1e-5, step_loss=0.017] Steps:   1%|▏         | 14106/1000000 [2:49:26<2279:13:33,  8.32s/it, lr=1e-5, step_loss=0.017][RANK-0]: Step: [14106], local_loss=0.008246101438999176, train_loss=0.01639663055539131, time_cost=2.0016584396362305
Steps:   1%|▏         | 14106/1000000 [2:49:26<2279:13:33,  8.32s/it, lr=1e-5, step_loss=0.00825]Steps:   1%|▏         | 14107/1000000 [2:49:32<2070:24:22,  7.56s/it, lr=1e-5, step_loss=0.00825][RANK-0]: Step: [14107], local_loss=0.01095232367515564, train_loss=0.016023218631744385, time_cost=4.765251398086548
Steps:   1%|▏         | 14107/1000000 [2:49:32<2070:24:22,  7.56s/it, lr=1e-5, step_loss=0.011]  Steps:   1%|▏         | 14108/1000000 [2:49:46<2581:47:54,  9.43s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [14108], local_loss=0.05244730785489082, train_loss=0.036357581615448, time_cost=4.72025990486145
Steps:   1%|▏         | 14108/1000000 [2:49:46<2581:47:54,  9.43s/it, lr=1e-5, step_loss=0.0524]/home/image_data/hxy/Open-Sora-Plan/opensora/utils/utils.py:369: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.
  caption = BeautifulSoup(caption, features='html.parser').text
Steps:   1%|▏         | 14109/1000000 [2:49:57<2719:22:21,  9.93s/it, lr=1e-5, step_loss=0.0524][RANK-0]: Step: [14109], local_loss=0.015686238184571266, train_loss=0.045234315097332, time_cost=2.1816368103027344
Steps:   1%|▏         | 14109/1000000 [2:49:57<2719:22:21,  9.93s/it, lr=1e-5, step_loss=0.0157]Steps:   1%|▏         | 14110/1000000 [2:50:13<3253:51:27, 11.88s/it, lr=1e-5, step_loss=0.0157][RANK-0]: Step: [14110], local_loss=0.07125768810510635, train_loss=0.02389705367386341, time_cost=6.6047446727752686
Steps:   1%|▏         | 14110/1000000 [2:50:13<3253:51:27, 11.88s/it, lr=1e-5, step_loss=0.0713]Steps:   1%|▏         | 14111/1000000 [2:50:18<2709:56:17,  9.90s/it, lr=1e-5, step_loss=0.0713][RANK-0]: Step: [14111], local_loss=0.0337374284863472, train_loss=0.05782727897167206, time_cost=2.250950813293457
Steps:   1%|▏         | 14111/1000000 [2:50:18<2709:56:17,  9.90s/it, lr=1e-5, step_loss=0.0337]Steps:   1%|▏         | 14112/1000000 [2:50:26<2529:49:26,  9.24s/it, lr=1e-5, step_loss=0.0337][RANK-0]: Step: [14112], local_loss=0.03769417852163315, train_loss=0.09010843932628632, time_cost=1.2388103008270264
Steps:   1%|▏         | 14112/1000000 [2:50:26<2529:49:26,  9.24s/it, lr=1e-5, step_loss=0.0377]Steps:   1%|▏         | 14113/1000000 [2:50:36<2604:12:06,  9.51s/it, lr=1e-5, step_loss=0.0377][RANK-0]: Step: [14113], local_loss=0.03572603687644005, train_loss=0.0592273473739624, time_cost=3.531306743621826
Steps:   1%|▏         | 14113/1000000 [2:50:36<2604:12:06,  9.51s/it, lr=1e-5, step_loss=0.0357]Steps:   1%|▏         | 14114/1000000 [2:50:46<2583:12:00,  9.43s/it, lr=1e-5, step_loss=0.0357][RANK-0]: Step: [14114], local_loss=0.006115241441875696, train_loss=0.02093784138560295, time_cost=3.030874729156494
Steps:   1%|▏         | 14114/1000000 [2:50:46<2583:12:00,  9.43s/it, lr=1e-5, step_loss=0.00612]Steps:   1%|▏         | 14115/1000000 [2:50:59<2896:21:00, 10.58s/it, lr=1e-5, step_loss=0.00612][RANK-0]: Step: [14115], local_loss=0.05557464808225632, train_loss=0.030957352370023727, time_cost=4.896298170089722
Steps:   1%|▏         | 14115/1000000 [2:50:59<2896:21:00, 10.58s/it, lr=1e-5, step_loss=0.0556] Steps:   1%|▏         | 14116/1000000 [2:51:04<2443:29:37,  8.92s/it, lr=1e-5, step_loss=0.0556][RANK-0]: Step: [14116], local_loss=0.011051367968320847, train_loss=0.024453718215227127, time_cost=1.7850477695465088
Steps:   1%|▏         | 14116/1000000 [2:51:04<2443:29:37,  8.92s/it, lr=1e-5, step_loss=0.0111]Steps:   1%|▏         | 14117/1000000 [2:51:17<2793:27:00, 10.20s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [14117], local_loss=0.3789955675601959, train_loss=0.09758946299552917, time_cost=5.783368110656738
Steps:   1%|▏         | 14117/1000000 [2:51:17<2793:27:00, 10.20s/it, lr=1e-5, step_loss=0.379] Steps:   1%|▏         | 14118/1000000 [2:51:29<2906:50:17, 10.61s/it, lr=1e-5, step_loss=0.379][RANK-0]: Step: [14118], local_loss=0.011080065742135048, train_loss=13.82101058959961, time_cost=4.308382749557495
Steps:   1%|▏         | 14118/1000000 [2:51:29<2906:50:17, 10.61s/it, lr=1e-5, step_loss=0.0111]Steps:   1%|▏         | 14119/1000000 [2:51:35<2558:01:02,  9.34s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [14119], local_loss=0.050719887018203735, train_loss=0.07333126664161682, time_cost=2.64676570892334
Steps:   1%|▏         | 14119/1000000 [2:51:35<2558:01:02,  9.34s/it, lr=1e-5, step_loss=0.0507]Steps:   1%|▏         | 14120/1000000 [2:51:45<2591:27:00,  9.46s/it, lr=1e-5, step_loss=0.0507][RANK-0]: Step: [14120], local_loss=0.022091703489422798, train_loss=0.03272608295083046, time_cost=3.296748638153076
Steps:   1%|▏         | 14120/1000000 [2:51:45<2591:27:00,  9.46s/it, lr=1e-5, step_loss=0.0221]Steps:   1%|▏         | 14121/1000000 [2:51:59<3014:37:43, 11.01s/it, lr=1e-5, step_loss=0.0221][RANK-0]: Step: [14121], local_loss=0.008420866914093494, train_loss=0.08758720755577087, time_cost=3.0148189067840576
Steps:   1%|▏         | 14121/1000000 [2:51:59<3014:37:43, 11.01s/it, lr=1e-5, step_loss=0.00842]Steps:   1%|▏         | 14122/1000000 [2:52:07<2720:36:05,  9.93s/it, lr=1e-5, step_loss=0.00842][RANK-0]: Step: [14122], local_loss=0.08974206447601318, train_loss=0.028568383306264877, time_cost=1.218428134918213
Steps:   1%|▏         | 14122/1000000 [2:52:07<2720:36:05,  9.93s/it, lr=1e-5, step_loss=0.0897] Steps:   1%|▏         | 14123/1000000 [2:52:19<2875:10:46, 10.50s/it, lr=1e-5, step_loss=0.0897][RANK-0]: Step: [14123], local_loss=0.09348595142364502, train_loss=0.06972211599349976, time_cost=1.9926340579986572
Steps:   1%|▏         | 14123/1000000 [2:52:19<2875:10:46, 10.50s/it, lr=1e-5, step_loss=0.0935]Steps:   1%|▏         | 14124/1000000 [2:52:27<2710:18:13,  9.90s/it, lr=1e-5, step_loss=0.0935][RANK-0]: Step: [14124], local_loss=0.024926042184233665, train_loss=0.14346536993980408, time_cost=2.308030843734741
Steps:   1%|▏         | 14124/1000000 [2:52:27<2710:18:13,  9.90s/it, lr=1e-5, step_loss=0.0249]Steps:   1%|▏         | 14125/1000000 [2:52:39<2910:24:51, 10.63s/it, lr=1e-5, step_loss=0.0249][RANK-0]: Step: [14125], local_loss=0.010817108675837517, train_loss=0.0214517954736948, time_cost=4.599536418914795
Steps:   1%|▏         | 14125/1000000 [2:52:39<2910:24:51, 10.63s/it, lr=1e-5, step_loss=0.0108]Steps:   1%|▏         | 14126/1000000 [2:52:50<2932:07:44, 10.71s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [14126], local_loss=0.007611059118062258, train_loss=0.037624653428792953, time_cost=9.710602283477783
Steps:   1%|▏         | 14126/1000000 [2:52:50<2932:07:44, 10.71s/it, lr=1e-5, step_loss=0.00761]Steps:   1%|▏         | 14127/1000000 [2:53:02<3044:30:30, 11.12s/it, lr=1e-5, step_loss=0.00761][RANK-0]: Step: [14127], local_loss=0.040110718458890915, train_loss=0.05718247964978218, time_cost=4.775214433670044
Steps:   1%|▏         | 14127/1000000 [2:53:02<3044:30:30, 11.12s/it, lr=1e-5, step_loss=0.0401] Steps:   1%|▏         | 14128/1000000 [2:53:07<2503:58:31,  9.14s/it, lr=1e-5, step_loss=0.0401][RANK-0]: Step: [14128], local_loss=0.05497666075825691, train_loss=0.037103258073329926, time_cost=1.2748641967773438
Steps:   1%|▏         | 14128/1000000 [2:53:07<2503:58:31,  9.14s/it, lr=1e-5, step_loss=0.055] Steps:   1%|▏         | 14129/1000000 [2:53:17<2545:03:34,  9.29s/it, lr=1e-5, step_loss=0.055][RANK-0]: Step: [14129], local_loss=0.030135268345475197, train_loss=0.016796162351965904, time_cost=4.2159624099731445
Steps:   1%|▏         | 14129/1000000 [2:53:17<2545:03:34,  9.29s/it, lr=1e-5, step_loss=0.0301]Steps:   1%|▏         | 14130/1000000 [2:53:22<2215:40:34,  8.09s/it, lr=1e-5, step_loss=0.0301][RANK-0]: Step: [14130], local_loss=0.025585852563381195, train_loss=0.04185933247208595, time_cost=2.36430025100708
Steps:   1%|▏         | 14130/1000000 [2:53:22<2215:40:34,  8.09s/it, lr=1e-5, step_loss=0.0256]Steps:   1%|▏         | 14131/1000000 [2:53:33<2474:17:48,  9.04s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [14131], local_loss=0.007245277054607868, train_loss=0.08521269261837006, time_cost=1.7147305011749268
Steps:   1%|▏         | 14131/1000000 [2:53:33<2474:17:48,  9.04s/it, lr=1e-5, step_loss=0.00725]Steps:   1%|▏         | 14132/1000000 [2:53:38<2159:26:43,  7.89s/it, lr=1e-5, step_loss=0.00725][RANK-0]: Step: [14132], local_loss=0.012982345186173916, train_loss=0.0582147091627121, time_cost=1.4650030136108398
Steps:   1%|▏         | 14132/1000000 [2:53:38<2159:26:43,  7.89s/it, lr=1e-5, step_loss=0.013]  Steps:   1%|▏         | 14133/1000000 [2:53:49<2380:52:54,  8.69s/it, lr=1e-5, step_loss=0.013][RANK-0]: Step: [14133], local_loss=0.2823958992958069, train_loss=40.31014633178711, time_cost=1.3662972450256348
Steps:   1%|▏         | 14133/1000000 [2:53:49<2380:52:54,  8.69s/it, lr=1e-5, step_loss=0.282]Steps:   1%|▏         | 14134/1000000 [2:53:53<2034:46:30,  7.43s/it, lr=1e-5, step_loss=0.282][RANK-0]: Step: [14134], local_loss=1.0184166431427002, train_loss=0.16541500389575958, time_cost=1.744394302368164
Steps:   1%|▏         | 14134/1000000 [2:53:53<2034:46:30,  7.43s/it, lr=1e-5, step_loss=1.02] Steps:   1%|▏         | 14135/1000000 [2:54:07<2538:44:51,  9.27s/it, lr=1e-5, step_loss=1.02][RANK-0]: Step: [14135], local_loss=0.01704762876033783, train_loss=0.09402361512184143, time_cost=1.5890588760375977
Steps:   1%|▏         | 14135/1000000 [2:54:07<2538:44:51,  9.27s/it, lr=1e-5, step_loss=0.017]Steps:   1%|▏         | 14136/1000000 [2:54:15<2414:01:19,  8.82s/it, lr=1e-5, step_loss=0.017][RANK-0]: Step: [14136], local_loss=0.14764995872974396, train_loss=0.06398802995681763, time_cost=3.6270153522491455
Steps:   1%|▏         | 14136/1000000 [2:54:15<2414:01:19,  8.82s/it, lr=1e-5, step_loss=0.148]Steps:   1%|▏         | 14137/1000000 [2:54:23<2348:43:41,  8.58s/it, lr=1e-5, step_loss=0.148][RANK-0]: Step: [14137], local_loss=0.020228616893291473, train_loss=0.03128793090581894, time_cost=4.153419733047485
Steps:   1%|▏         | 14137/1000000 [2:54:23<2348:43:41,  8.58s/it, lr=1e-5, step_loss=0.0202]Steps:   1%|▏         | 14138/1000000 [2:54:30<2280:04:15,  8.33s/it, lr=1e-5, step_loss=0.0202][RANK-0]: Step: [14138], local_loss=0.02051497809588909, train_loss=0.03401477262377739, time_cost=2.1932806968688965
Steps:   1%|▏         | 14138/1000000 [2:54:30<2280:04:15,  8.33s/it, lr=1e-5, step_loss=0.0205]Steps:   1%|▏         | 14139/1000000 [2:54:47<2919:19:09, 10.66s/it, lr=1e-5, step_loss=0.0205][RANK-0]: Step: [14139], local_loss=0.005724884103983641, train_loss=0.08503367751836777, time_cost=7.735530853271484
Steps:   1%|▏         | 14139/1000000 [2:54:47<2919:19:09, 10.66s/it, lr=1e-5, step_loss=0.00572]Steps:   1%|▏         | 14140/1000000 [2:54:57<2862:12:52, 10.45s/it, lr=1e-5, step_loss=0.00572][RANK-0]: Step: [14140], local_loss=0.011341666802763939, train_loss=0.05004066228866577, time_cost=1.679084062576294
Steps:   1%|▏         | 14140/1000000 [2:54:57<2862:12:52, 10.45s/it, lr=1e-5, step_loss=0.0113] Steps:   1%|▏         | 14141/1000000 [2:55:10<3141:47:38, 11.47s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [14141], local_loss=0.027079638093709946, train_loss=0.0560702383518219, time_cost=4.7649617195129395
Steps:   1%|▏         | 14141/1000000 [2:55:10<3141:47:38, 11.47s/it, lr=1e-5, step_loss=0.0271]Steps:   1%|▏         | 14142/1000000 [2:55:18<2862:16:13, 10.45s/it, lr=1e-5, step_loss=0.0271][RANK-0]: Step: [14142], local_loss=0.024776548147201538, train_loss=0.08863172680139542, time_cost=1.2936735153198242
Steps:   1%|▏         | 14142/1000000 [2:55:18<2862:16:13, 10.45s/it, lr=1e-5, step_loss=0.0248]Steps:   1%|▏         | 14143/1000000 [2:55:29<2863:28:12, 10.46s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [14143], local_loss=0.010911722667515278, train_loss=0.04145995154976845, time_cost=1.336437702178955
Steps:   1%|▏         | 14143/1000000 [2:55:29<2863:28:12, 10.46s/it, lr=1e-5, step_loss=0.0109]Steps:   1%|▏         | 14144/1000000 [2:55:38<2732:06:35,  9.98s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [14144], local_loss=0.03855106607079506, train_loss=0.13717371225357056, time_cost=1.7492091655731201
Steps:   1%|▏         | 14144/1000000 [2:55:38<2732:06:35,  9.98s/it, lr=1e-5, step_loss=0.0386]Steps:   1%|▏         | 14145/1000000 [2:55:50<2906:38:38, 10.61s/it, lr=1e-5, step_loss=0.0386][RANK-0]: Step: [14145], local_loss=0.014106504619121552, train_loss=0.03371185064315796, time_cost=1.3195607662200928
Steps:   1%|▏         | 14145/1000000 [2:55:50<2906:38:38, 10.61s/it, lr=1e-5, step_loss=0.0141]Steps:   1%|▏         | 14146/1000000 [2:55:54<2407:34:37,  8.79s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [14146], local_loss=0.02777903713285923, train_loss=0.0411057211458683, time_cost=1.7838551998138428
Steps:   1%|▏         | 14146/1000000 [2:55:54<2407:34:37,  8.79s/it, lr=1e-5, step_loss=0.0278]Steps:   1%|▏         | 14147/1000000 [2:56:03<2407:18:50,  8.79s/it, lr=1e-5, step_loss=0.0278][RANK-0]: Step: [14147], local_loss=0.048855122178792953, train_loss=0.04150574281811714, time_cost=2.3908684253692627
Steps:   1%|▏         | 14147/1000000 [2:56:03<2407:18:50,  8.79s/it, lr=1e-5, step_loss=0.0489]Steps:   1%|▏         | 14148/1000000 [2:56:14<2554:03:46,  9.33s/it, lr=1e-5, step_loss=0.0489][RANK-0]: Step: [14148], local_loss=0.012060807086527348, train_loss=0.01906910352408886, time_cost=2.199415445327759
Steps:   1%|▏         | 14148/1000000 [2:56:14<2554:03:46,  9.33s/it, lr=1e-5, step_loss=0.0121]Steps:   1%|▏         | 14149/1000000 [2:56:19<2214:37:38,  8.09s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [14149], local_loss=0.008762115612626076, train_loss=0.030866684392094612, time_cost=1.337050199508667
Steps:   1%|▏         | 14149/1000000 [2:56:19<2214:37:38,  8.09s/it, lr=1e-5, step_loss=0.00876]Steps:   1%|▏         | 14150/1000000 [2:56:33<2665:07:52,  9.73s/it, lr=1e-5, step_loss=0.00876][RANK-0]: Step: [14150], local_loss=0.02200229838490486, train_loss=0.04484473168849945, time_cost=5.752737522125244
Steps:   1%|▏         | 14150/1000000 [2:56:33<2665:07:52,  9.73s/it, lr=1e-5, step_loss=0.022]  Steps:   1%|▏         | 14151/1000000 [2:56:38<2275:49:09,  8.31s/it, lr=1e-5, step_loss=0.022][RANK-0]: Step: [14151], local_loss=0.010751733556389809, train_loss=0.031775616109371185, time_cost=2.6156413555145264
Steps:   1%|▏         | 14151/1000000 [2:56:38<2275:49:09,  8.31s/it, lr=1e-5, step_loss=0.0108]Steps:   1%|▏         | 14152/1000000 [2:56:45<2198:01:07,  8.03s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [14152], local_loss=0.0072416202165186405, train_loss=0.03640257567167282, time_cost=1.3438537120819092
Steps:   1%|▏         | 14152/1000000 [2:56:45<2198:01:07,  8.03s/it, lr=1e-5, step_loss=0.00724]Steps:   1%|▏         | 14153/1000000 [2:56:56<2471:26:15,  9.02s/it, lr=1e-5, step_loss=0.00724][RANK-0]: Step: [14153], local_loss=0.04968538507819176, train_loss=0.056293342262506485, time_cost=3.9601006507873535
Steps:   1%|▏         | 14153/1000000 [2:56:56<2471:26:15,  9.02s/it, lr=1e-5, step_loss=0.0497] Steps:   1%|▏         | 14154/1000000 [2:57:01<2124:02:03,  7.76s/it, lr=1e-5, step_loss=0.0497][RANK-0]: Step: [14154], local_loss=0.04418323561549187, train_loss=0.02810712158679962, time_cost=1.6049714088439941
Steps:   1%|▏         | 14154/1000000 [2:57:01<2124:02:03,  7.76s/it, lr=1e-5, step_loss=0.0442]Steps:   1%|▏         | 14155/1000000 [2:57:11<2302:43:54,  8.41s/it, lr=1e-5, step_loss=0.0442][RANK-0]: Step: [14155], local_loss=0.014367579482495785, train_loss=0.029678871855139732, time_cost=1.5389108657836914
Steps:   1%|▏         | 14155/1000000 [2:57:11<2302:43:54,  8.41s/it, lr=1e-5, step_loss=0.0144]Steps:   1%|▏         | 14156/1000000 [2:57:20<2360:42:33,  8.62s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [14156], local_loss=0.03919296711683273, train_loss=0.05861368030309677, time_cost=1.2621383666992188
Steps:   1%|▏         | 14156/1000000 [2:57:20<2360:42:33,  8.62s/it, lr=1e-5, step_loss=0.0392]Steps:   1%|▏         | 14157/1000000 [2:57:28<2271:09:08,  8.29s/it, lr=1e-5, step_loss=0.0392][RANK-0]: Step: [14157], local_loss=0.029343217611312866, train_loss=0.03642585873603821, time_cost=3.171757936477661
Steps:   1%|▏         | 14157/1000000 [2:57:28<2271:09:08,  8.29s/it, lr=1e-5, step_loss=0.0293]Steps:   1%|▏         | 14158/1000000 [2:57:33<2036:10:50,  7.44s/it, lr=1e-5, step_loss=0.0293][RANK-0]: Step: [14158], local_loss=0.006807010620832443, train_loss=0.05438427999615669, time_cost=2.3955721855163574
Steps:   1%|▏         | 14158/1000000 [2:57:33<2036:10:50,  7.44s/it, lr=1e-5, step_loss=0.00681]Steps:   1%|▏         | 14159/1000000 [2:57:40<2034:43:58,  7.43s/it, lr=1e-5, step_loss=0.00681][RANK-0]: Step: [14159], local_loss=0.017742563039064407, train_loss=0.02213311567902565, time_cost=3.2014384269714355
Steps:   1%|▏         | 14159/1000000 [2:57:40<2034:43:58,  7.43s/it, lr=1e-5, step_loss=0.0177] Steps:   1%|▏         | 14160/1000000 [2:57:50<2180:28:30,  7.96s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [14160], local_loss=0.20263586938381195, train_loss=0.11618175357580185, time_cost=4.999837636947632
Steps:   1%|▏         | 14160/1000000 [2:57:50<2180:28:30,  7.96s/it, lr=1e-5, step_loss=0.203] Steps:   1%|▏         | 14161/1000000 [2:57:57<2124:45:34,  7.76s/it, lr=1e-5, step_loss=0.203][RANK-0]: Step: [14161], local_loss=0.023954998701810837, train_loss=0.030122868716716766, time_cost=3.329582452774048
Steps:   1%|▏         | 14161/1000000 [2:57:57<2124:45:34,  7.76s/it, lr=1e-5, step_loss=0.024]Steps:   1%|▏         | 14162/1000000 [2:58:04<2078:20:18,  7.59s/it, lr=1e-5, step_loss=0.024][RANK-0]: Step: [14162], local_loss=0.30068427324295044, train_loss=0.05564670264720917, time_cost=2.611293077468872
Steps:   1%|▏         | 14162/1000000 [2:58:04<2078:20:18,  7.59s/it, lr=1e-5, step_loss=0.301]Steps:   1%|▏         | 14163/1000000 [2:58:20<2728:01:37,  9.96s/it, lr=1e-5, step_loss=0.301][RANK-0]: Step: [14163], local_loss=0.02315622940659523, train_loss=0.07392385601997375, time_cost=7.147566080093384
Steps:   1%|▏         | 14163/1000000 [2:58:20<2728:01:37,  9.96s/it, lr=1e-5, step_loss=0.0232]Steps:   1%|▏         | 14164/1000000 [2:58:31<2819:39:22, 10.30s/it, lr=1e-5, step_loss=0.0232][RANK-0]: Step: [14164], local_loss=0.008663766086101532, train_loss=0.05575505271553993, time_cost=2.484142780303955
Steps:   1%|▏         | 14164/1000000 [2:58:31<2819:39:22, 10.30s/it, lr=1e-5, step_loss=0.00866]Steps:   1%|▏         | 14165/1000000 [2:58:36<2422:53:04,  8.85s/it, lr=1e-5, step_loss=0.00866][RANK-0]: Step: [14165], local_loss=0.007776789367198944, train_loss=0.015615341253578663, time_cost=2.4253196716308594
Steps:   1%|▏         | 14165/1000000 [2:58:36<2422:53:04,  8.85s/it, lr=1e-5, step_loss=0.00778]Steps:   1%|▏         | 14166/1000000 [2:58:40<2037:12:25,  7.44s/it, lr=1e-5, step_loss=0.00778][RANK-0]: Step: [14166], local_loss=0.022133274003863335, train_loss=0.03880394995212555, time_cost=1.2306325435638428
Steps:   1%|▏         | 14166/1000000 [2:58:40<2037:12:25,  7.44s/it, lr=1e-5, step_loss=0.0221] Steps:   1%|▏         | 14167/1000000 [2:58:46<1866:19:36,  6.82s/it, lr=1e-5, step_loss=0.0221][RANK-0]: Step: [14167], local_loss=0.009449400007724762, train_loss=0.030930733308196068, time_cost=1.9298255443572998
Steps:   1%|▏         | 14167/1000000 [2:58:46<1866:19:36,  6.82s/it, lr=1e-5, step_loss=0.00945]Steps:   1%|▏         | 14168/1000000 [2:58:55<2054:17:59,  7.50s/it, lr=1e-5, step_loss=0.00945][RANK-0]: Step: [14168], local_loss=0.015590517781674862, train_loss=0.036286793649196625, time_cost=3.602389097213745
Steps:   1%|▏         | 14168/1000000 [2:58:55<2054:17:59,  7.50s/it, lr=1e-5, step_loss=0.0156] Steps:   1%|▏         | 14169/1000000 [2:59:10<2657:29:58,  9.70s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [14169], local_loss=0.05948673188686371, train_loss=0.1517806202173233, time_cost=12.203734874725342
Steps:   1%|▏         | 14169/1000000 [2:59:10<2657:29:58,  9.70s/it, lr=1e-5, step_loss=0.0595]Steps:   1%|▏         | 14170/1000000 [2:59:19<2654:48:29,  9.69s/it, lr=1e-5, step_loss=0.0595][RANK-0]: Step: [14170], local_loss=0.011207311414182186, train_loss=0.02230597287416458, time_cost=3.0813872814178467
Steps:   1%|▏         | 14170/1000000 [2:59:19<2654:48:29,  9.69s/it, lr=1e-5, step_loss=0.0112]Steps:   1%|▏         | 14171/1000000 [2:59:26<2425:54:18,  8.86s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [14171], local_loss=0.17923541367053986, train_loss=0.039199575781822205, time_cost=5.266646146774292
Steps:   1%|▏         | 14171/1000000 [2:59:26<2425:54:18,  8.86s/it, lr=1e-5, step_loss=0.179] Steps:   1%|▏         | 14172/1000000 [2:59:31<2121:01:13,  7.75s/it, lr=1e-5, step_loss=0.179][RANK-0]: Step: [14172], local_loss=0.06513252854347229, train_loss=0.07647797465324402, time_cost=2.40734601020813
Steps:   1%|▏         | 14172/1000000 [2:59:31<2121:01:13,  7.75s/it, lr=1e-5, step_loss=0.0651]Steps:   1%|▏         | 14173/1000000 [2:59:36<1892:18:09,  6.91s/it, lr=1e-5, step_loss=0.0651][RANK-0]: Step: [14173], local_loss=0.005546243861317635, train_loss=0.01790960691869259, time_cost=1.9503533840179443
Steps:   1%|▏         | 14173/1000000 [2:59:36<1892:18:09,  6.91s/it, lr=1e-5, step_loss=0.00555]Steps:   1%|▏         | 14174/1000000 [2:59:44<1920:44:09,  7.01s/it, lr=1e-5, step_loss=0.00555][RANK-0]: Step: [14174], local_loss=0.034766796976327896, train_loss=0.04368966817855835, time_cost=1.2527039051055908
Steps:   1%|▏         | 14174/1000000 [2:59:44<1920:44:09,  7.01s/it, lr=1e-5, step_loss=0.0348] Steps:   1%|▏         | 14175/1000000 [2:59:55<2300:17:14,  8.40s/it, lr=1e-5, step_loss=0.0348][RANK-0]: Step: [14175], local_loss=0.007315529976040125, train_loss=0.0221133753657341, time_cost=2.7853150367736816
Steps:   1%|▏         | 14175/1000000 [2:59:55<2300:17:14,  8.40s/it, lr=1e-5, step_loss=0.00732]Steps:   1%|▏         | 14176/1000000 [3:00:03<2242:16:32,  8.19s/it, lr=1e-5, step_loss=0.00732][RANK-0]: Step: [14176], local_loss=0.005978078581392765, train_loss=0.02712392434477806, time_cost=1.6488773822784424
Steps:   1%|▏         | 14176/1000000 [3:00:03<2242:16:32,  8.19s/it, lr=1e-5, step_loss=0.00598]Steps:   1%|▏         | 14177/1000000 [3:00:16<2651:27:01,  9.68s/it, lr=1e-5, step_loss=0.00598][RANK-0]: Step: [14177], local_loss=0.041642170399427414, train_loss=0.035571854561567307, time_cost=3.875638484954834
Steps:   1%|▏         | 14177/1000000 [3:00:16<2651:27:01,  9.68s/it, lr=1e-5, step_loss=0.0416] Steps:   1%|▏         | 14178/1000000 [3:00:24<2477:54:37,  9.05s/it, lr=1e-5, step_loss=0.0416][RANK-0]: Step: [14178], local_loss=0.008167493157088757, train_loss=0.011533010751008987, time_cost=1.2297933101654053
Steps:   1%|▏         | 14178/1000000 [3:00:24<2477:54:37,  9.05s/it, lr=1e-5, step_loss=0.00817]Steps:   1%|▏         | 14179/1000000 [3:00:31<2334:43:41,  8.53s/it, lr=1e-5, step_loss=0.00817][RANK-0]: Step: [14179], local_loss=0.01167056430131197, train_loss=0.02434016764163971, time_cost=2.266944169998169
Steps:   1%|▏         | 14179/1000000 [3:00:31<2334:43:41,  8.53s/it, lr=1e-5, step_loss=0.0117] Steps:   1%|▏         | 14180/1000000 [3:00:46<2894:40:23, 10.57s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [14180], local_loss=0.03976839780807495, train_loss=0.031822264194488525, time_cost=5.615163803100586
Steps:   1%|▏         | 14180/1000000 [3:00:46<2894:40:23, 10.57s/it, lr=1e-5, step_loss=0.0398]Steps:   1%|▏         | 14181/1000000 [3:00:59<3082:41:03, 11.26s/it, lr=1e-5, step_loss=0.0398][RANK-0]: Step: [14181], local_loss=0.007264932617545128, train_loss=0.04702651873230934, time_cost=3.2569844722747803
Steps:   1%|▏         | 14181/1000000 [3:00:59<3082:41:03, 11.26s/it, lr=1e-5, step_loss=0.00726]Steps:   1%|▏         | 14182/1000000 [3:01:08<2850:22:38, 10.41s/it, lr=1e-5, step_loss=0.00726][RANK-0]: Step: [14182], local_loss=0.011749545112252235, train_loss=0.013943705707788467, time_cost=1.221555233001709
Steps:   1%|▏         | 14182/1000000 [3:01:08<2850:22:38, 10.41s/it, lr=1e-5, step_loss=0.0117] Steps:   1%|▏         | 14183/1000000 [3:01:15<2605:53:09,  9.52s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [14183], local_loss=0.06690683215856552, train_loss=0.03274692967534065, time_cost=1.271735429763794
Steps:   1%|▏         | 14183/1000000 [3:01:15<2605:53:09,  9.52s/it, lr=1e-5, step_loss=0.0669]Steps:   1%|▏         | 14184/1000000 [3:01:27<2793:01:20, 10.20s/it, lr=1e-5, step_loss=0.0669][RANK-0]: Step: [14184], local_loss=0.044560566544532776, train_loss=0.06228004768490791, time_cost=1.2311184406280518
Steps:   1%|▏         | 14184/1000000 [3:01:27<2793:01:20, 10.20s/it, lr=1e-5, step_loss=0.0446]Steps:   1%|▏         | 14185/1000000 [3:01:36<2731:39:28,  9.98s/it, lr=1e-5, step_loss=0.0446][RANK-0]: Step: [14185], local_loss=0.01746823638677597, train_loss=0.022810906171798706, time_cost=1.222362995147705
Steps:   1%|▏         | 14185/1000000 [3:01:36<2731:39:28,  9.98s/it, lr=1e-5, step_loss=0.0175]Steps:   1%|▏         | 14186/1000000 [3:01:42<2344:32:14,  8.56s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [14186], local_loss=0.03336598724126816, train_loss=0.04434457793831825, time_cost=2.5357131958007812
Steps:   1%|▏         | 14186/1000000 [3:01:42<2344:32:14,  8.56s/it, lr=1e-5, step_loss=0.0334]Steps:   1%|▏         | 14187/1000000 [3:01:52<2497:30:13,  9.12s/it, lr=1e-5, step_loss=0.0334][RANK-0]: Step: [14187], local_loss=0.10546097159385681, train_loss=0.05633331090211868, time_cost=1.8428199291229248
Steps:   1%|▏         | 14187/1000000 [3:01:52<2497:30:13,  9.12s/it, lr=1e-5, step_loss=0.105] Steps:   1%|▏         | 14188/1000000 [3:01:56<2119:16:08,  7.74s/it, lr=1e-5, step_loss=0.105][RANK-0]: Step: [14188], local_loss=0.021893801167607307, train_loss=0.019180355593562126, time_cost=1.7169125080108643
Steps:   1%|▏         | 14188/1000000 [3:01:56<2119:16:08,  7.74s/it, lr=1e-5, step_loss=0.0219]Steps:   1%|▏         | 14189/1000000 [3:02:09<2498:35:49,  9.12s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [14189], local_loss=0.039375584572553635, train_loss=0.0522807240486145, time_cost=3.625124931335449
Steps:   1%|▏         | 14189/1000000 [3:02:09<2498:35:49,  9.12s/it, lr=1e-5, step_loss=0.0394]Steps:   1%|▏         | 14190/1000000 [3:02:14<2204:12:28,  8.05s/it, lr=1e-5, step_loss=0.0394][RANK-0]: Step: [14190], local_loss=0.02018335834145546, train_loss=0.06472272425889969, time_cost=2.6966991424560547
Steps:   1%|▏         | 14190/1000000 [3:02:14<2204:12:28,  8.05s/it, lr=1e-5, step_loss=0.0202]Steps:   1%|▏         | 14191/1000000 [3:02:23<2258:50:01,  8.25s/it, lr=1e-5, step_loss=0.0202][RANK-0]: Step: [14191], local_loss=0.505343496799469, train_loss=0.21922165155410767, time_cost=2.711510419845581
Steps:   1%|▏         | 14191/1000000 [3:02:23<2258:50:01,  8.25s/it, lr=1e-5, step_loss=0.505] Steps:   1%|▏         | 14192/1000000 [3:02:35<2555:08:32,  9.33s/it, lr=1e-5, step_loss=0.505][RANK-0]: Step: [14192], local_loss=0.05031251162290573, train_loss=0.02783368155360222, time_cost=2.290926218032837
Steps:   1%|▏         | 14192/1000000 [3:02:35<2555:08:32,  9.33s/it, lr=1e-5, step_loss=0.0503]Steps:   1%|▏         | 14193/1000000 [3:02:40<2210:43:32,  8.07s/it, lr=1e-5, step_loss=0.0503][RANK-0]: Step: [14193], local_loss=0.006432280410081148, train_loss=0.06344927847385406, time_cost=1.391740322113037
Steps:   1%|▏         | 14193/1000000 [3:02:40<2210:43:32,  8.07s/it, lr=1e-5, step_loss=0.00643]Steps:   1%|▏         | 14194/1000000 [3:02:45<1910:17:47,  6.98s/it, lr=1e-5, step_loss=0.00643][RANK-0]: Step: [14194], local_loss=0.07309627532958984, train_loss=0.037407174706459045, time_cost=1.3796672821044922
Steps:   1%|▏         | 14194/1000000 [3:02:45<1910:17:47,  6.98s/it, lr=1e-5, step_loss=0.0731] Steps:   1%|▏         | 14195/1000000 [3:02:57<2381:58:52,  8.70s/it, lr=1e-5, step_loss=0.0731][RANK-0]: Step: [14195], local_loss=0.25981152057647705, train_loss=0.06310483068227768, time_cost=5.361659049987793
Steps:   1%|▏         | 14195/1000000 [3:02:57<2381:58:52,  8.70s/it, lr=1e-5, step_loss=0.26]  Steps:   1%|▏         | 14196/1000000 [3:03:02<2092:17:03,  7.64s/it, lr=1e-5, step_loss=0.26][RANK-0]: Step: [14196], local_loss=0.32370951771736145, train_loss=0.06376327574253082, time_cost=2.140223741531372
Steps:   1%|▏         | 14196/1000000 [3:03:02<2092:17:03,  7.64s/it, lr=1e-5, step_loss=0.324]Steps:   1%|▏         | 14197/1000000 [3:03:09<2029:41:06,  7.41s/it, lr=1e-5, step_loss=0.324][RANK-0]: Step: [14197], local_loss=0.02484043687582016, train_loss=0.014720860868692398, time_cost=5.748403787612915
Steps:   1%|▏         | 14197/1000000 [3:03:09<2029:41:06,  7.41s/it, lr=1e-5, step_loss=0.0248]Steps:   1%|▏         | 14198/1000000 [3:03:13<1750:14:55,  6.39s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [14198], local_loss=0.037659548223018646, train_loss=0.04927702993154526, time_cost=1.2320446968078613
Steps:   1%|▏         | 14198/1000000 [3:03:13<1750:14:55,  6.39s/it, lr=1e-5, step_loss=0.0377]Steps:   1%|▏         | 14199/1000000 [3:03:27<2342:26:16,  8.55s/it, lr=1e-5, step_loss=0.0377][RANK-0]: Step: [14199], local_loss=0.058172907680273056, train_loss=0.039062950760126114, time_cost=6.796860456466675
Steps:   1%|▏         | 14199/1000000 [3:03:27<2342:26:16,  8.55s/it, lr=1e-5, step_loss=0.0582]Steps:   1%|▏         | 14200/1000000 [3:03:40<2694:54:58,  9.84s/it, lr=1e-5, step_loss=0.0582][RANK-0]: Step: [14200], local_loss=0.0113739725202322, train_loss=0.026897847652435303, time_cost=4.9372172355651855
Steps:   1%|▏         | 14200/1000000 [3:03:40<2694:54:58,  9.84s/it, lr=1e-5, step_loss=0.0114]Steps:   1%|▏         | 14201/1000000 [3:03:44<2257:37:31,  8.24s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [14201], local_loss=0.013777822256088257, train_loss=0.015730030834674835, time_cost=1.2292375564575195
Steps:   1%|▏         | 14201/1000000 [3:03:44<2257:37:31,  8.24s/it, lr=1e-5, step_loss=0.0138]Steps:   1%|▏         | 14202/1000000 [3:03:57<2651:02:04,  9.68s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [14202], local_loss=0.008705931715667248, train_loss=0.0414327047765255, time_cost=5.197913885116577
Steps:   1%|▏         | 14202/1000000 [3:03:57<2651:02:04,  9.68s/it, lr=1e-5, step_loss=0.00871]Steps:   1%|▏         | 14203/1000000 [3:04:10<2912:14:23, 10.64s/it, lr=1e-5, step_loss=0.00871][RANK-0]: Step: [14203], local_loss=0.0323328897356987, train_loss=0.03281733766198158, time_cost=6.532404661178589
Steps:   1%|▏         | 14203/1000000 [3:04:10<2912:14:23, 10.64s/it, lr=1e-5, step_loss=0.0323] Steps:   1%|▏         | 14204/1000000 [3:04:23<3124:04:58, 11.41s/it, lr=1e-5, step_loss=0.0323][RANK-0]: Step: [14204], local_loss=0.25409919023513794, train_loss=0.09870263189077377, time_cost=1.2302892208099365
Steps:   1%|▏         | 14204/1000000 [3:04:23<3124:04:58, 11.41s/it, lr=1e-5, step_loss=0.254] Steps:   1%|▏         | 14205/1000000 [3:04:30<2719:50:09,  9.93s/it, lr=1e-5, step_loss=0.254][RANK-0]: Step: [14205], local_loss=0.004642660263925791, train_loss=0.026954559609293938, time_cost=2.208721160888672
Steps:   1%|▏         | 14205/1000000 [3:04:30<2719:50:09,  9.93s/it, lr=1e-5, step_loss=0.00464]Steps:   1%|▏         | 14206/1000000 [3:04:38<2612:32:35,  9.54s/it, lr=1e-5, step_loss=0.00464][RANK-0]: Step: [14206], local_loss=0.047591302543878555, train_loss=0.037845317274332047, time_cost=5.019023656845093
Steps:   1%|▏         | 14206/1000000 [3:04:38<2612:32:35,  9.54s/it, lr=1e-5, step_loss=0.0476] Steps:   1%|▏         | 14207/1000000 [3:04:47<2559:56:46,  9.35s/it, lr=1e-5, step_loss=0.0476][RANK-0]: Step: [14207], local_loss=0.1258510798215866, train_loss=0.07374389469623566, time_cost=1.3182919025421143
Steps:   1%|▏         | 14207/1000000 [3:04:47<2559:56:46,  9.35s/it, lr=1e-5, step_loss=0.126] Steps:   1%|▏         | 14208/1000000 [3:04:55<2386:22:46,  8.71s/it, lr=1e-5, step_loss=0.126][RANK-0]: Step: [14208], local_loss=0.08146557956933975, train_loss=0.02829558774828911, time_cost=2.824890375137329
Steps:   1%|▏         | 14208/1000000 [3:04:55<2386:22:46,  8.71s/it, lr=1e-5, step_loss=0.0815]Steps:   1%|▏         | 14209/1000000 [3:05:09<2860:14:37, 10.45s/it, lr=1e-5, step_loss=0.0815][RANK-0]: Step: [14209], local_loss=0.007339631672948599, train_loss=0.043147847056388855, time_cost=5.612383127212524
Steps:   1%|▏         | 14209/1000000 [3:05:09<2860:14:37, 10.45s/it, lr=1e-5, step_loss=0.00734]Steps:   1%|▏         | 14210/1000000 [3:05:15<2447:29:33,  8.94s/it, lr=1e-5, step_loss=0.00734][RANK-0]: Step: [14210], local_loss=0.015998784452676773, train_loss=0.02243446186184883, time_cost=2.3908450603485107
Steps:   1%|▏         | 14210/1000000 [3:05:15<2447:29:33,  8.94s/it, lr=1e-5, step_loss=0.016]  Steps:   1%|▏         | 14211/1000000 [3:05:20<2123:39:49,  7.76s/it, lr=1e-5, step_loss=0.016][RANK-0]: Step: [14211], local_loss=0.060096099972724915, train_loss=0.042189955711364746, time_cost=2.187305450439453
Steps:   1%|▏         | 14211/1000000 [3:05:20<2123:39:49,  7.76s/it, lr=1e-5, step_loss=0.0601]Steps:   1%|▏         | 14212/1000000 [3:05:31<2450:00:10,  8.95s/it, lr=1e-5, step_loss=0.0601][RANK-0]: Step: [14212], local_loss=0.03840181604027748, train_loss=0.055106114596128464, time_cost=3.799562692642212
Steps:   1%|▏         | 14212/1000000 [3:05:31<2450:00:10,  8.95s/it, lr=1e-5, step_loss=0.0384]Steps:   1%|▏         | 14213/1000000 [3:05:38<2258:11:57,  8.25s/it, lr=1e-5, step_loss=0.0384][RANK-0]: Step: [14213], local_loss=0.06338559091091156, train_loss=0.07167477905750275, time_cost=1.8689868450164795
Steps:   1%|▏         | 14213/1000000 [3:05:38<2258:11:57,  8.25s/it, lr=1e-5, step_loss=0.0634]Steps:   1%|▏         | 14214/1000000 [3:05:43<2001:24:44,  7.31s/it, lr=1e-5, step_loss=0.0634][RANK-0]: Step: [14214], local_loss=0.03524881973862648, train_loss=0.04651999473571777, time_cost=2.6228792667388916
Steps:   1%|▏         | 14214/1000000 [3:05:43<2001:24:44,  7.31s/it, lr=1e-5, step_loss=0.0352]Steps:   1%|▏         | 14215/1000000 [3:05:50<1943:43:12,  7.10s/it, lr=1e-5, step_loss=0.0352][RANK-0]: Step: [14215], local_loss=0.021540002897381783, train_loss=0.046710312366485596, time_cost=2.7769381999969482
Steps:   1%|▏         | 14215/1000000 [3:05:50<1943:43:12,  7.10s/it, lr=1e-5, step_loss=0.0215]Steps:   1%|▏         | 14216/1000000 [3:05:57<1952:17:54,  7.13s/it, lr=1e-5, step_loss=0.0215][RANK-0]: Step: [14216], local_loss=0.01676035113632679, train_loss=0.07157400995492935, time_cost=2.0898005962371826
Steps:   1%|▏         | 14216/1000000 [3:05:57<1952:17:54,  7.13s/it, lr=1e-5, step_loss=0.0168]Steps:   1%|▏         | 14217/1000000 [3:06:03<1868:30:18,  6.82s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [14217], local_loss=0.005143247079104185, train_loss=0.05456412583589554, time_cost=1.1999716758728027
Steps:   1%|▏         | 14217/1000000 [3:06:03<1868:30:18,  6.82s/it, lr=1e-5, step_loss=0.00514]Steps:   1%|▏         | 14218/1000000 [3:06:08<1712:54:47,  6.26s/it, lr=1e-5, step_loss=0.00514][RANK-0]: Step: [14218], local_loss=0.040835898369550705, train_loss=0.05573632940649986, time_cost=1.8649072647094727
Steps:   1%|▏         | 14218/1000000 [3:06:08<1712:54:47,  6.26s/it, lr=1e-5, step_loss=0.0408] Steps:   1%|▏         | 14219/1000000 [3:06:19<2111:36:58,  7.71s/it, lr=1e-5, step_loss=0.0408][RANK-0]: Step: [14219], local_loss=0.009573481976985931, train_loss=0.01648521237075329, time_cost=1.6732761859893799
Steps:   1%|▏         | 14219/1000000 [3:06:19<2111:36:58,  7.71s/it, lr=1e-5, step_loss=0.00957]Steps:   1%|▏         | 14220/1000000 [3:06:24<1895:17:23,  6.92s/it, lr=1e-5, step_loss=0.00957][RANK-0]: Step: [14220], local_loss=0.05459560081362724, train_loss=0.020926080644130707, time_cost=2.3493800163269043
Steps:   1%|▏         | 14220/1000000 [3:06:24<1895:17:23,  6.92s/it, lr=1e-5, step_loss=0.0546] Steps:   1%|▏         | 14221/1000000 [3:06:30<1788:36:34,  6.53s/it, lr=1e-5, step_loss=0.0546][RANK-0]: Step: [14221], local_loss=0.03190125897526741, train_loss=0.21699245274066925, time_cost=1.2180607318878174
Steps:   1%|▏         | 14221/1000000 [3:06:30<1788:36:34,  6.53s/it, lr=1e-5, step_loss=0.0319]Steps:   1%|▏         | 14222/1000000 [3:06:36<1742:24:50,  6.36s/it, lr=1e-5, step_loss=0.0319][RANK-0]: Step: [14222], local_loss=0.02407645620405674, train_loss=0.03173578158020973, time_cost=1.2728843688964844
Steps:   1%|▏         | 14222/1000000 [3:06:36<1742:24:50,  6.36s/it, lr=1e-5, step_loss=0.0241]Steps:   1%|▏         | 14223/1000000 [3:06:45<1990:55:29,  7.27s/it, lr=1e-5, step_loss=0.0241][RANK-0]: Step: [14223], local_loss=0.02719392441213131, train_loss=0.028092525899410248, time_cost=3.311084747314453
Steps:   1%|▏         | 14223/1000000 [3:06:45<1990:55:29,  7.27s/it, lr=1e-5, step_loss=0.0272]Steps:   1%|▏         | 14224/1000000 [3:06:55<2194:01:34,  8.01s/it, lr=1e-5, step_loss=0.0272][RANK-0]: Step: [14224], local_loss=0.008815249428153038, train_loss=0.36310917139053345, time_cost=2.1796679496765137
Steps:   1%|▏         | 14224/1000000 [3:06:55<2194:01:34,  8.01s/it, lr=1e-5, step_loss=0.00882]Steps:   1%|▏         | 14225/1000000 [3:07:08<2594:48:00,  9.48s/it, lr=1e-5, step_loss=0.00882][RANK-0]: Step: [14225], local_loss=0.07336925715208054, train_loss=0.045467786490917206, time_cost=4.714899063110352
Steps:   1%|▏         | 14225/1000000 [3:07:08<2594:48:00,  9.48s/it, lr=1e-5, step_loss=0.0734] Steps:   1%|▏         | 14226/1000000 [3:07:17<2597:13:19,  9.48s/it, lr=1e-5, step_loss=0.0734][RANK-0]: Step: [14226], local_loss=0.012552927248179913, train_loss=0.03780968114733696, time_cost=1.2449347972869873
Steps:   1%|▏         | 14226/1000000 [3:07:17<2597:13:19,  9.48s/it, lr=1e-5, step_loss=0.0126]Steps:   1%|▏         | 14227/1000000 [3:07:22<2245:26:24,  8.20s/it, lr=1e-5, step_loss=0.0126][RANK-0]: Step: [14227], local_loss=0.005729861091822386, train_loss=0.05532527342438698, time_cost=1.3285026550292969
Steps:   1%|▏         | 14227/1000000 [3:07:22<2245:26:24,  8.20s/it, lr=1e-5, step_loss=0.00573]Steps:   1%|▏         | 14228/1000000 [3:07:34<2542:06:15,  9.28s/it, lr=1e-5, step_loss=0.00573][RANK-0]: Step: [14228], local_loss=0.11245831847190857, train_loss=0.1221463680267334, time_cost=1.3104608058929443
Steps:   1%|▏         | 14228/1000000 [3:07:34<2542:06:15,  9.28s/it, lr=1e-5, step_loss=0.112]  Steps:   1%|▏         | 14229/1000000 [3:07:49<2993:25:48, 10.93s/it, lr=1e-5, step_loss=0.112][RANK-0]: Step: [14229], local_loss=0.02633909322321415, train_loss=0.028753414750099182, time_cost=6.860444784164429
Steps:   1%|▏         | 14229/1000000 [3:07:49<2993:25:48, 10.93s/it, lr=1e-5, step_loss=0.0263]Steps:   1%|▏         | 14230/1000000 [3:08:03<3290:48:07, 12.02s/it, lr=1e-5, step_loss=0.0263][RANK-0]: Step: [14230], local_loss=0.007172807585448027, train_loss=0.03015379048883915, time_cost=8.695467472076416
Steps:   1%|▏         | 14230/1000000 [3:08:03<3290:48:07, 12.02s/it, lr=1e-5, step_loss=0.00717]Steps:   1%|▏         | 14231/1000000 [3:08:15<3233:07:55, 11.81s/it, lr=1e-5, step_loss=0.00717][RANK-0]: Step: [14231], local_loss=0.019940154626965523, train_loss=0.0166607778519392, time_cost=3.0919203758239746
Steps:   1%|▏         | 14231/1000000 [3:08:15<3233:07:55, 11.81s/it, lr=1e-5, step_loss=0.0199] Steps:   1%|▏         | 14232/1000000 [3:08:29<3469:55:39, 12.67s/it, lr=1e-5, step_loss=0.0199][RANK-0]: Step: [14232], local_loss=0.05003245547413826, train_loss=0.19250354170799255, time_cost=10.911273717880249
Steps:   1%|▏         | 14232/1000000 [3:08:29<3469:55:39, 12.67s/it, lr=1e-5, step_loss=0.05]  Steps:   1%|▏         | 14233/1000000 [3:08:34<2834:57:54, 10.35s/it, lr=1e-5, step_loss=0.05][RANK-0]: Step: [14233], local_loss=0.011711026541888714, train_loss=0.04028692841529846, time_cost=3.6785099506378174
Steps:   1%|▏         | 14233/1000000 [3:08:34<2834:57:54, 10.35s/it, lr=1e-5, step_loss=0.0117]Steps:   1%|▏         | 14234/1000000 [3:08:44<2759:35:46, 10.08s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [14234], local_loss=0.011041651479899883, train_loss=0.020403781905770302, time_cost=4.4473490715026855
Steps:   1%|▏         | 14234/1000000 [3:08:44<2759:35:46, 10.08s/it, lr=1e-5, step_loss=0.011] Steps:   1%|▏         | 14235/1000000 [3:08:51<2494:11:05,  9.11s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [14235], local_loss=0.061000287532806396, train_loss=0.1106918528676033, time_cost=3.018048048019409
Steps:   1%|▏         | 14235/1000000 [3:08:51<2494:11:05,  9.11s/it, lr=1e-5, step_loss=0.061]Steps:   1%|▏         | 14236/1000000 [3:09:06<2988:23:24, 10.91s/it, lr=1e-5, step_loss=0.061][RANK-0]: Step: [14236], local_loss=0.025343868881464005, train_loss=0.04230586811900139, time_cost=6.549295663833618
Steps:   1%|▏         | 14236/1000000 [3:09:06<2988:23:24, 10.91s/it, lr=1e-5, step_loss=0.0253]Steps:   1%|▏         | 14237/1000000 [3:09:17<2988:38:57, 10.91s/it, lr=1e-5, step_loss=0.0253][RANK-0]: Step: [14237], local_loss=0.013758780434727669, train_loss=0.014310291036963463, time_cost=3.5718038082122803
Steps:   1%|▏         | 14237/1000000 [3:09:17<2988:38:57, 10.91s/it, lr=1e-5, step_loss=0.0138]Steps:   1%|▏         | 14238/1000000 [3:09:33<3426:39:48, 12.51s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [14238], local_loss=0.014241650700569153, train_loss=0.6546061635017395, time_cost=13.320338010787964
Steps:   1%|▏         | 14238/1000000 [3:09:33<3426:39:48, 12.51s/it, lr=1e-5, step_loss=0.0142]Steps:   1%|▏         | 14239/1000000 [3:09:37<2737:35:54, 10.00s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [14239], local_loss=0.014421593397855759, train_loss=0.01880832575261593, time_cost=1.6538276672363281
Steps:   1%|▏         | 14239/1000000 [3:09:37<2737:35:54, 10.00s/it, lr=1e-5, step_loss=0.0144]Steps:   1%|▏         | 14240/1000000 [3:09:47<2710:36:42,  9.90s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [14240], local_loss=0.09079799056053162, train_loss=0.08085522800683975, time_cost=2.327352523803711
Steps:   1%|▏         | 14240/1000000 [3:09:47<2710:36:42,  9.90s/it, lr=1e-5, step_loss=0.0908]Steps:   1%|▏         | 14241/1000000 [3:09:56<2638:33:44,  9.64s/it, lr=1e-5, step_loss=0.0908][RANK-0]: Step: [14241], local_loss=1.008179783821106, train_loss=0.17539694905281067, time_cost=3.6741068363189697
Steps:   1%|▏         | 14241/1000000 [3:09:56<2638:33:44,  9.64s/it, lr=1e-5, step_loss=1.01]  Steps:   1%|▏         | 14242/1000000 [3:10:04<2505:00:04,  9.15s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [14242], local_loss=0.017880354076623917, train_loss=0.11235956102609634, time_cost=4.802075386047363
Steps:   1%|▏         | 14242/1000000 [3:10:04<2505:00:04,  9.15s/it, lr=1e-5, step_loss=0.0179]Steps:   1%|▏         | 14243/1000000 [3:10:14<2562:24:15,  9.36s/it, lr=1e-5, step_loss=0.0179][RANK-0]: Step: [14243], local_loss=0.016484582796692848, train_loss=0.06273200362920761, time_cost=2.8819780349731445
Steps:   1%|▏         | 14243/1000000 [3:10:14<2562:24:15,  9.36s/it, lr=1e-5, step_loss=0.0165]Steps:   1%|▏         | 14244/1000000 [3:10:20<2293:15:11,  8.38s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [14244], local_loss=0.02358976937830448, train_loss=0.04574631154537201, time_cost=3.4673168659210205
Steps:   1%|▏         | 14244/1000000 [3:10:20<2293:15:11,  8.38s/it, lr=1e-5, step_loss=0.0236]Steps:   1%|▏         | 14245/1000000 [3:10:26<2107:02:17,  7.69s/it, lr=1e-5, step_loss=0.0236][RANK-0]: Step: [14245], local_loss=0.009068929590284824, train_loss=0.03050316497683525, time_cost=4.597217082977295
Steps:   1%|▏         | 14245/1000000 [3:10:26<2107:02:17,  7.69s/it, lr=1e-5, step_loss=0.00907]Steps:   1%|▏         | 14246/1000000 [3:10:37<2365:57:17,  8.64s/it, lr=1e-5, step_loss=0.00907][RANK-0]: Step: [14246], local_loss=0.065425343811512, train_loss=0.07899083197116852, time_cost=1.2950668334960938
Steps:   1%|▏         | 14246/1000000 [3:10:37<2365:57:17,  8.64s/it, lr=1e-5, step_loss=0.0654] Steps:   1%|▏         | 14247/1000000 [3:10:51<2791:31:02, 10.19s/it, lr=1e-5, step_loss=0.0654][RANK-0]: Step: [14247], local_loss=0.01650976575911045, train_loss=0.032604411244392395, time_cost=4.883599042892456
Steps:   1%|▏         | 14247/1000000 [3:10:51<2791:31:02, 10.19s/it, lr=1e-5, step_loss=0.0165]Steps:   1%|▏         | 14248/1000000 [3:10:56<2378:04:12,  8.68s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [14248], local_loss=0.03653625026345253, train_loss=0.03562779724597931, time_cost=1.279280185699463
Steps:   1%|▏         | 14248/1000000 [3:10:56<2378:04:12,  8.68s/it, lr=1e-5, step_loss=0.0365]Steps:   1%|▏         | 14249/1000000 [3:11:00<2032:09:10,  7.42s/it, lr=1e-5, step_loss=0.0365][RANK-0]: Step: [14249], local_loss=0.00822453759610653, train_loss=0.17034833133220673, time_cost=1.6513292789459229
Steps:   1%|▏         | 14249/1000000 [3:11:00<2032:09:10,  7.42s/it, lr=1e-5, step_loss=0.00822]Steps:   1%|▏         | 14250/1000000 [3:11:08<2079:47:51,  7.60s/it, lr=1e-5, step_loss=0.00822][RANK-0]: Step: [14250], local_loss=0.04577897489070892, train_loss=0.08050478994846344, time_cost=2.923978328704834
Steps:   1%|▏         | 14250/1000000 [3:11:08<2079:47:51,  7.60s/it, lr=1e-5, step_loss=0.0458] Steps:   1%|▏         | 14251/1000000 [3:11:14<1927:03:04,  7.04s/it, lr=1e-5, step_loss=0.0458][RANK-0]: Step: [14251], local_loss=0.02242211624979973, train_loss=0.09034682810306549, time_cost=1.483139991760254
Steps:   1%|▏         | 14251/1000000 [3:11:14<1927:03:04,  7.04s/it, lr=1e-5, step_loss=0.0224]Steps:   1%|▏         | 14252/1000000 [3:11:25<2250:24:16,  8.22s/it, lr=1e-5, step_loss=0.0224][RANK-0]: Step: [14252], local_loss=0.03799359127879143, train_loss=54.276039123535156, time_cost=1.3746063709259033
Steps:   1%|▏         | 14252/1000000 [3:11:25<2250:24:16,  8.22s/it, lr=1e-5, step_loss=0.038] Steps:   1%|▏         | 14253/1000000 [3:11:36<2504:53:00,  9.15s/it, lr=1e-5, step_loss=0.038][RANK-0]: Step: [14253], local_loss=0.053929828107357025, train_loss=0.023699695244431496, time_cost=2.523909568786621
Steps:   1%|▏         | 14253/1000000 [3:11:36<2504:53:00,  9.15s/it, lr=1e-5, step_loss=0.0539]Steps:   1%|▏         | 14254/1000000 [3:11:50<2896:49:39, 10.58s/it, lr=1e-5, step_loss=0.0539][RANK-0]: Step: [14254], local_loss=0.04684378579258919, train_loss=0.01957099512219429, time_cost=11.86349105834961
Steps:   1%|▏         | 14254/1000000 [3:11:50<2896:49:39, 10.58s/it, lr=1e-5, step_loss=0.0468]Steps:   1%|▏         | 14255/1000000 [3:11:57<2610:58:18,  9.54s/it, lr=1e-5, step_loss=0.0468][RANK-0]: Step: [14255], local_loss=0.013814290054142475, train_loss=0.012206792831420898, time_cost=2.1746015548706055
Steps:   1%|▏         | 14255/1000000 [3:11:57<2610:58:18,  9.54s/it, lr=1e-5, step_loss=0.0138]Steps:   1%|▏         | 14256/1000000 [3:12:04<2364:59:12,  8.64s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [14256], local_loss=0.02957945317029953, train_loss=0.03347868472337723, time_cost=1.2112791538238525
Steps:   1%|▏         | 14256/1000000 [3:12:04<2364:59:12,  8.64s/it, lr=1e-5, step_loss=0.0296]Steps:   1%|▏         | 14257/1000000 [3:12:12<2325:37:32,  8.49s/it, lr=1e-5, step_loss=0.0296][RANK-0]: Step: [14257], local_loss=0.01716180145740509, train_loss=0.06458087265491486, time_cost=4.092110633850098
Steps:   1%|▏         | 14257/1000000 [3:12:12<2325:37:32,  8.49s/it, lr=1e-5, step_loss=0.0172]Steps:   1%|▏         | 14258/1000000 [3:12:24<2583:44:25,  9.44s/it, lr=1e-5, step_loss=0.0172][RANK-0]: Step: [14258], local_loss=0.06533925235271454, train_loss=0.03301844000816345, time_cost=3.3851261138916016
Steps:   1%|▏         | 14258/1000000 [3:12:24<2583:44:25,  9.44s/it, lr=1e-5, step_loss=0.0653]Steps:   1%|▏         | 14259/1000000 [3:12:37<2912:55:59, 10.64s/it, lr=1e-5, step_loss=0.0653][RANK-0]: Step: [14259], local_loss=0.23943911492824554, train_loss=0.055802956223487854, time_cost=11.265611410140991
Steps:   1%|▏         | 14259/1000000 [3:12:37<2912:55:59, 10.64s/it, lr=1e-5, step_loss=0.239] Steps:   1%|▏         | 14260/1000000 [3:12:44<2622:21:00,  9.58s/it, lr=1e-5, step_loss=0.239][RANK-0]: Step: [14260], local_loss=0.06483659148216248, train_loss=0.027867164462804794, time_cost=1.2150604724884033
Steps:   1%|▏         | 14260/1000000 [3:12:44<2622:21:00,  9.58s/it, lr=1e-5, step_loss=0.0648]Steps:   1%|▏         | 14261/1000000 [3:12:53<2529:40:30,  9.24s/it, lr=1e-5, step_loss=0.0648][RANK-0]: Step: [14261], local_loss=0.02131643332540989, train_loss=0.0797962173819542, time_cost=6.120904207229614
Steps:   1%|▏         | 14261/1000000 [3:12:53<2529:40:30,  9.24s/it, lr=1e-5, step_loss=0.0213]Steps:   1%|▏         | 14262/1000000 [3:13:01<2460:47:40,  8.99s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [14262], local_loss=0.03551629185676575, train_loss=0.07206873595714569, time_cost=3.0642542839050293
Steps:   1%|▏         | 14262/1000000 [3:13:01<2460:47:40,  8.99s/it, lr=1e-5, step_loss=0.0355]Steps:   1%|▏         | 14263/1000000 [3:13:08<2299:30:54,  8.40s/it, lr=1e-5, step_loss=0.0355][RANK-0]: Step: [14263], local_loss=0.01736973226070404, train_loss=0.03500639647245407, time_cost=2.1670875549316406
Steps:   1%|▏         | 14263/1000000 [3:13:08<2299:30:54,  8.40s/it, lr=1e-5, step_loss=0.0174]Steps:   1%|▏         | 14264/1000000 [3:13:19<2509:39:33,  9.17s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [14264], local_loss=0.08140674978494644, train_loss=0.05040644109249115, time_cost=1.2751274108886719
Steps:   1%|▏         | 14264/1000000 [3:13:19<2509:39:33,  9.17s/it, lr=1e-5, step_loss=0.0814]Steps:   1%|▏         | 14265/1000000 [3:13:29<2613:08:21,  9.54s/it, lr=1e-5, step_loss=0.0814][RANK-0]: Step: [14265], local_loss=0.3581782877445221, train_loss=0.06020989269018173, time_cost=2.9135799407958984
Steps:   1%|▏         | 14265/1000000 [3:13:29<2613:08:21,  9.54s/it, lr=1e-5, step_loss=0.358] Steps:   1%|▏         | 14266/1000000 [3:13:42<2844:48:20, 10.39s/it, lr=1e-5, step_loss=0.358][RANK-0]: Step: [14266], local_loss=0.028340652585029602, train_loss=0.03167849779129028, time_cost=1.2467126846313477
Steps:   1%|▏         | 14266/1000000 [3:13:42<2844:48:20, 10.39s/it, lr=1e-5, step_loss=0.0283]Steps:   1%|▏         | 14267/1000000 [3:13:49<2579:19:37,  9.42s/it, lr=1e-5, step_loss=0.0283][RANK-0]: Step: [14267], local_loss=0.021725790575146675, train_loss=0.03148111701011658, time_cost=2.5889029502868652
Steps:   1%|▏         | 14267/1000000 [3:13:49<2579:19:37,  9.42s/it, lr=1e-5, step_loss=0.0217]Steps:   1%|▏         | 14268/1000000 [3:14:01<2803:58:19, 10.24s/it, lr=1e-5, step_loss=0.0217][RANK-0]: Step: [14268], local_loss=0.026620153337717056, train_loss=0.04285259172320366, time_cost=2.419443368911743
Steps:   1%|▏         | 14268/1000000 [3:14:01<2803:58:19, 10.24s/it, lr=1e-5, step_loss=0.0266]Steps:   1%|▏         | 14269/1000000 [3:14:14<3008:22:55, 10.99s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [14269], local_loss=0.011772267520427704, train_loss=0.04189257696270943, time_cost=1.2159273624420166
Steps:   1%|▏         | 14269/1000000 [3:14:14<3008:22:55, 10.99s/it, lr=1e-5, step_loss=0.0118]Steps:   1%|▏         | 14270/1000000 [3:14:19<2532:46:22,  9.25s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [14270], local_loss=0.015810158103704453, train_loss=0.02890663780272007, time_cost=1.8921008110046387
Steps:   1%|▏         | 14270/1000000 [3:14:19<2532:46:22,  9.25s/it, lr=1e-5, step_loss=0.0158]Steps:   1%|▏         | 14271/1000000 [3:14:28<2520:21:03,  9.20s/it, lr=1e-5, step_loss=0.0158][RANK-0]: Step: [14271], local_loss=0.05985049903392792, train_loss=0.03393708914518356, time_cost=2.9652814865112305
Steps:   1%|▏         | 14271/1000000 [3:14:28<2520:21:03,  9.20s/it, lr=1e-5, step_loss=0.0599]Steps:   1%|▏         | 14272/1000000 [3:14:35<2343:47:54,  8.56s/it, lr=1e-5, step_loss=0.0599][RANK-0]: Step: [14272], local_loss=0.008734343573451042, train_loss=0.026861805468797684, time_cost=6.112222909927368
Steps:   1%|▏         | 14272/1000000 [3:14:35<2343:47:54,  8.56s/it, lr=1e-5, step_loss=0.00873]Steps:   1%|▏         | 14273/1000000 [3:14:43<2267:51:08,  8.28s/it, lr=1e-5, step_loss=0.00873][RANK-0]: Step: [14273], local_loss=0.03347863256931305, train_loss=0.05579090863466263, time_cost=1.459542989730835
Steps:   1%|▏         | 14273/1000000 [3:14:43<2267:51:08,  8.28s/it, lr=1e-5, step_loss=0.0335] Steps:   1%|▏         | 14274/1000000 [3:14:54<2548:11:20,  9.31s/it, lr=1e-5, step_loss=0.0335][RANK-0]: Step: [14274], local_loss=0.01695733703672886, train_loss=0.07649138569831848, time_cost=1.2263109683990479
Steps:   1%|▏         | 14274/1000000 [3:14:54<2548:11:20,  9.31s/it, lr=1e-5, step_loss=0.017] Steps:   1%|▏         | 14275/1000000 [3:15:05<2640:31:14,  9.64s/it, lr=1e-5, step_loss=0.017][RANK-0]: Step: [14275], local_loss=0.03406922519207001, train_loss=0.02170989289879799, time_cost=3.080545425415039
Steps:   1%|▏         | 14275/1000000 [3:15:05<2640:31:14,  9.64s/it, lr=1e-5, step_loss=0.0341]Steps:   1%|▏         | 14276/1000000 [3:15:11<2339:56:44,  8.55s/it, lr=1e-5, step_loss=0.0341][RANK-0]: Step: [14276], local_loss=0.11041990667581558, train_loss=0.05789492651820183, time_cost=1.7299325466156006
Steps:   1%|▏         | 14276/1000000 [3:15:11<2339:56:44,  8.55s/it, lr=1e-5, step_loss=0.11]  Steps:   1%|▏         | 14277/1000000 [3:15:26<2892:19:25, 10.56s/it, lr=1e-5, step_loss=0.11][RANK-0]: Step: [14277], local_loss=0.015044893138110638, train_loss=0.028046974912285805, time_cost=13.138832807540894
Steps:   1%|▏         | 14277/1000000 [3:15:26<2892:19:25, 10.56s/it, lr=1e-5, step_loss=0.015]Steps:   1%|▏         | 14278/1000000 [3:15:31<2442:26:04,  8.92s/it, lr=1e-5, step_loss=0.015][RANK-0]: Step: [14278], local_loss=0.02556581422686577, train_loss=0.03527949005365372, time_cost=1.9605309963226318
Steps:   1%|▏         | 14278/1000000 [3:15:31<2442:26:04,  8.92s/it, lr=1e-5, step_loss=0.0256]Steps:   1%|▏         | 14279/1000000 [3:15:39<2333:57:39,  8.52s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [14279], local_loss=0.047801751643419266, train_loss=0.07747282087802887, time_cost=1.2264618873596191
Steps:   1%|▏         | 14279/1000000 [3:15:39<2333:57:39,  8.52s/it, lr=1e-5, step_loss=0.0478]Steps:   1%|▏         | 14280/1000000 [3:15:50<2562:16:56,  9.36s/it, lr=1e-5, step_loss=0.0478][RANK-0]: Step: [14280], local_loss=0.171421617269516, train_loss=0.048345714807510376, time_cost=3.892334222793579
Steps:   1%|▏         | 14280/1000000 [3:15:50<2562:16:56,  9.36s/it, lr=1e-5, step_loss=0.171] Steps:   1%|▏         | 14281/1000000 [3:15:58<2420:47:54,  8.84s/it, lr=1e-5, step_loss=0.171][RANK-0]: Step: [14281], local_loss=0.012148861773312092, train_loss=0.03229408711194992, time_cost=2.290172815322876
Steps:   1%|▏         | 14281/1000000 [3:15:58<2420:47:54,  8.84s/it, lr=1e-5, step_loss=0.0121]Steps:   1%|▏         | 14282/1000000 [3:16:03<2135:08:14,  7.80s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [14282], local_loss=0.05745472386479378, train_loss=0.019674990326166153, time_cost=2.024303913116455
Steps:   1%|▏         | 14282/1000000 [3:16:03<2135:08:14,  7.80s/it, lr=1e-5, step_loss=0.0575]Steps:   1%|▏         | 14283/1000000 [3:16:09<1978:17:57,  7.23s/it, lr=1e-5, step_loss=0.0575][RANK-0]: Step: [14283], local_loss=0.04113392531871796, train_loss=0.05485644191503525, time_cost=2.981437921524048
Steps:   1%|▏         | 14283/1000000 [3:16:09<1978:17:57,  7.23s/it, lr=1e-5, step_loss=0.0411]Steps:   1%|▏         | 14284/1000000 [3:16:18<2157:33:51,  7.88s/it, lr=1e-5, step_loss=0.0411][RANK-0]: Step: [14284], local_loss=0.018958406522870064, train_loss=0.03478927165269852, time_cost=2.495028018951416
Steps:   1%|▏         | 14284/1000000 [3:16:18<2157:33:51,  7.88s/it, lr=1e-5, step_loss=0.019] Steps:   1%|▏         | 14285/1000000 [3:16:25<2079:53:49,  7.60s/it, lr=1e-5, step_loss=0.019][RANK-0]: Step: [14285], local_loss=0.14542272686958313, train_loss=0.14927838742733002, time_cost=1.2607271671295166
Steps:   1%|▏         | 14285/1000000 [3:16:25<2079:53:49,  7.60s/it, lr=1e-5, step_loss=0.145]Steps:   1%|▏         | 14286/1000000 [3:16:37<2406:47:36,  8.79s/it, lr=1e-5, step_loss=0.145][RANK-0]: Step: [14286], local_loss=0.02777276746928692, train_loss=0.06040891259908676, time_cost=2.8695197105407715
Steps:   1%|▏         | 14286/1000000 [3:16:37<2406:47:36,  8.79s/it, lr=1e-5, step_loss=0.0278]Steps:   1%|▏         | 14287/1000000 [3:16:50<2765:27:43, 10.10s/it, lr=1e-5, step_loss=0.0278][RANK-0]: Step: [14287], local_loss=0.045159634202718735, train_loss=0.14794407784938812, time_cost=4.459010362625122
Steps:   1%|▏         | 14287/1000000 [3:16:50<2765:27:43, 10.10s/it, lr=1e-5, step_loss=0.0452]Steps:   1%|▏         | 14288/1000000 [3:16:56<2407:51:32,  8.79s/it, lr=1e-5, step_loss=0.0452][RANK-0]: Step: [14288], local_loss=0.007996127009391785, train_loss=0.02992672100663185, time_cost=2.748748540878296
Steps:   1%|▏         | 14288/1000000 [3:16:56<2407:51:32,  8.79s/it, lr=1e-5, step_loss=0.008] Steps:   1%|▏         | 14289/1000000 [3:17:03<2305:51:25,  8.42s/it, lr=1e-5, step_loss=0.008][RANK-0]: Step: [14289], local_loss=0.4817882478237152, train_loss=0.08074834942817688, time_cost=1.8665962219238281
Steps:   1%|▏         | 14289/1000000 [3:17:03<2305:51:25,  8.42s/it, lr=1e-5, step_loss=0.482]Steps:   1%|▏         | 14290/1000000 [3:17:19<2875:01:04, 10.50s/it, lr=1e-5, step_loss=0.482][RANK-0]: Step: [14290], local_loss=0.018902208656072617, train_loss=0.019764918833971024, time_cost=5.324578523635864
Steps:   1%|▏         | 14290/1000000 [3:17:19<2875:01:04, 10.50s/it, lr=1e-5, step_loss=0.0189]Steps:   1%|▏         | 14291/1000000 [3:17:31<3042:39:23, 11.11s/it, lr=1e-5, step_loss=0.0189][RANK-0]: Step: [14291], local_loss=0.03937944397330284, train_loss=0.021972741931676865, time_cost=1.2411465644836426
Steps:   1%|▏         | 14291/1000000 [3:17:31<3042:39:23, 11.11s/it, lr=1e-5, step_loss=0.0394]Steps:   1%|▏         | 14292/1000000 [3:17:37<2583:33:39,  9.44s/it, lr=1e-5, step_loss=0.0394][RANK-0]: Step: [14292], local_loss=0.03813054785132408, train_loss=0.020816141739487648, time_cost=2.7440569400787354
Steps:   1%|▏         | 14292/1000000 [3:17:37<2583:33:39,  9.44s/it, lr=1e-5, step_loss=0.0381]Steps:   1%|▏         | 14293/1000000 [3:17:42<2237:06:36,  8.17s/it, lr=1e-5, step_loss=0.0381][RANK-0]: Step: [14293], local_loss=0.038464564830064774, train_loss=0.03641171753406525, time_cost=2.2230374813079834
Steps:   1%|▏         | 14293/1000000 [3:17:42<2237:06:36,  8.17s/it, lr=1e-5, step_loss=0.0385]Steps:   1%|▏         | 14294/1000000 [3:17:56<2719:30:55,  9.93s/it, lr=1e-5, step_loss=0.0385][RANK-0]: Step: [14294], local_loss=0.028778212144970894, train_loss=0.0421404093503952, time_cost=2.309908151626587
Steps:   1%|▏         | 14294/1000000 [3:17:56<2719:30:55,  9.93s/it, lr=1e-5, step_loss=0.0288]Steps:   1%|▏         | 14295/1000000 [3:18:02<2355:11:32,  8.60s/it, lr=1e-5, step_loss=0.0288][RANK-0]: Step: [14295], local_loss=0.1571832150220871, train_loss=0.166886568069458, time_cost=1.653005838394165
Steps:   1%|▏         | 14295/1000000 [3:18:02<2355:11:32,  8.60s/it, lr=1e-5, step_loss=0.157] Steps:   1%|▏         | 14296/1000000 [3:18:16<2848:36:46, 10.40s/it, lr=1e-5, step_loss=0.157][RANK-0]: Step: [14296], local_loss=0.013931029476225376, train_loss=0.06251650303602219, time_cost=10.800114870071411
Steps:   1%|▏         | 14296/1000000 [3:18:16<2848:36:46, 10.40s/it, lr=1e-5, step_loss=0.0139]Steps:   1%|▏         | 14297/1000000 [3:18:28<2947:23:01, 10.76s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [14297], local_loss=0.03988822177052498, train_loss=0.013466423377394676, time_cost=1.2272896766662598
Steps:   1%|▏         | 14297/1000000 [3:18:28<2947:23:01, 10.76s/it, lr=1e-5, step_loss=0.0399]Steps:   1%|▏         | 14298/1000000 [3:18:32<2413:30:04,  8.81s/it, lr=1e-5, step_loss=0.0399][RANK-0]: Step: [14298], local_loss=0.0393458716571331, train_loss=0.05568639561533928, time_cost=1.5290305614471436
Steps:   1%|▏         | 14298/1000000 [3:18:32<2413:30:04,  8.81s/it, lr=1e-5, step_loss=0.0393]Steps:   1%|▏         | 14299/1000000 [3:18:39<2277:25:37,  8.32s/it, lr=1e-5, step_loss=0.0393][RANK-0]: Step: [14299], local_loss=0.00991123728454113, train_loss=0.049722958356142044, time_cost=2.62005877494812
Steps:   1%|▏         | 14299/1000000 [3:18:39<2277:25:37,  8.32s/it, lr=1e-5, step_loss=0.00991]Steps:   1%|▏         | 14300/1000000 [3:18:46<2177:24:46,  7.95s/it, lr=1e-5, step_loss=0.00991][RANK-0]: Step: [14300], local_loss=0.005859286990016699, train_loss=18.441606521606445, time_cost=4.078344821929932
Steps:   1%|▏         | 14300/1000000 [3:18:46<2177:24:46,  7.95s/it, lr=1e-5, step_loss=0.00586]Steps:   1%|▏         | 14301/1000000 [3:18:55<2228:11:38,  8.14s/it, lr=1e-5, step_loss=0.00586][RANK-0]: Step: [14301], local_loss=0.02151058241724968, train_loss=0.03786458820104599, time_cost=1.2209842205047607
Steps:   1%|▏         | 14301/1000000 [3:18:55<2228:11:38,  8.14s/it, lr=1e-5, step_loss=0.0215] Steps:   1%|▏         | 14302/1000000 [3:19:01<2029:15:36,  7.41s/it, lr=1e-5, step_loss=0.0215][RANK-0]: Step: [14302], local_loss=0.016379591077566147, train_loss=0.022290412336587906, time_cost=3.3087198734283447
Steps:   1%|▏         | 14302/1000000 [3:19:01<2029:15:36,  7.41s/it, lr=1e-5, step_loss=0.0164]Steps:   1%|▏         | 14303/1000000 [3:19:11<2259:02:25,  8.25s/it, lr=1e-5, step_loss=0.0164][RANK-0]: Step: [14303], local_loss=0.027287263423204422, train_loss=0.026034193113446236, time_cost=1.7598190307617188
Steps:   1%|▏         | 14303/1000000 [3:19:11<2259:02:25,  8.25s/it, lr=1e-5, step_loss=0.0273]Steps:   1%|▏         | 14304/1000000 [3:19:18<2152:24:14,  7.86s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [14304], local_loss=0.028788337484002113, train_loss=0.045235056430101395, time_cost=2.4268691539764404
Steps:   1%|▏         | 14304/1000000 [3:19:18<2152:24:14,  7.86s/it, lr=1e-5, step_loss=0.0288]Steps:   1%|▏         | 14305/1000000 [3:19:22<1866:33:28,  6.82s/it, lr=1e-5, step_loss=0.0288][RANK-0]: Step: [14305], local_loss=0.01361401379108429, train_loss=0.07362444698810577, time_cost=1.520453929901123
Steps:   1%|▏         | 14305/1000000 [3:19:22<1866:33:28,  6.82s/it, lr=1e-5, step_loss=0.0136]Steps:   1%|▏         | 14306/1000000 [3:19:38<2573:31:09,  9.40s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [14306], local_loss=0.01145892683416605, train_loss=0.15578316152095795, time_cost=1.579416275024414
Steps:   1%|▏         | 14306/1000000 [3:19:38<2573:31:09,  9.40s/it, lr=1e-5, step_loss=0.0115]Steps:   1%|▏         | 14307/1000000 [3:19:42<2198:14:44,  8.03s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [14307], local_loss=0.04909933730959892, train_loss=0.025152940303087234, time_cost=2.4335556030273438
Steps:   1%|▏         | 14307/1000000 [3:19:42<2198:14:44,  8.03s/it, lr=1e-5, step_loss=0.0491]Steps:   1%|▏         | 14308/1000000 [3:19:47<1958:34:52,  7.15s/it, lr=1e-5, step_loss=0.0491][RANK-0]: Step: [14308], local_loss=0.09083318710327148, train_loss=0.06602328270673752, time_cost=2.4192709922790527
Steps:   1%|▏         | 14308/1000000 [3:19:47<1958:34:52,  7.15s/it, lr=1e-5, step_loss=0.0908]Steps:   1%|▏         | 14309/1000000 [3:19:56<2067:04:31,  7.55s/it, lr=1e-5, step_loss=0.0908][RANK-0]: Step: [14309], local_loss=0.008074806071817875, train_loss=0.025669937953352928, time_cost=1.686422348022461
Steps:   1%|▏         | 14309/1000000 [3:19:56<2067:04:31,  7.55s/it, lr=1e-5, step_loss=0.00807]Steps:   1%|▏         | 14310/1000000 [3:20:03<2030:00:22,  7.41s/it, lr=1e-5, step_loss=0.00807][RANK-0]: Step: [14310], local_loss=0.008744632825255394, train_loss=0.07886673510074615, time_cost=1.7611174583435059
Steps:   1%|▏         | 14310/1000000 [3:20:03<2030:00:22,  7.41s/it, lr=1e-5, step_loss=0.00874]Steps:   1%|▏         | 14311/1000000 [3:20:16<2523:06:30,  9.22s/it, lr=1e-5, step_loss=0.00874][RANK-0]: Step: [14311], local_loss=0.019902130588889122, train_loss=0.018504036590456963, time_cost=4.070356607437134
Steps:   1%|▏         | 14311/1000000 [3:20:16<2523:06:30,  9.22s/it, lr=1e-5, step_loss=0.0199] Steps:   1%|▏         | 14312/1000000 [3:20:27<2630:05:32,  9.61s/it, lr=1e-5, step_loss=0.0199][RANK-0]: Step: [14312], local_loss=0.008336019702255726, train_loss=0.0151072908192873, time_cost=1.2094800472259521
Steps:   1%|▏         | 14312/1000000 [3:20:27<2630:05:32,  9.61s/it, lr=1e-5, step_loss=0.00834]Steps:   1%|▏         | 14313/1000000 [3:20:34<2440:51:33,  8.91s/it, lr=1e-5, step_loss=0.00834][RANK-0]: Step: [14313], local_loss=0.004275171086192131, train_loss=0.05253658816218376, time_cost=1.5796418190002441
Steps:   1%|▏         | 14313/1000000 [3:20:34<2440:51:33,  8.91s/it, lr=1e-5, step_loss=0.00428]Steps:   1%|▏         | 14314/1000000 [3:20:41<2298:22:45,  8.39s/it, lr=1e-5, step_loss=0.00428][RANK-0]: Step: [14314], local_loss=0.005450072232633829, train_loss=0.02826218493282795, time_cost=1.6633381843566895
Steps:   1%|▏         | 14314/1000000 [3:20:41<2298:22:45,  8.39s/it, lr=1e-5, step_loss=0.00545]Steps:   1%|▏         | 14315/1000000 [3:20:51<2352:47:15,  8.59s/it, lr=1e-5, step_loss=0.00545][RANK-0]: Step: [14315], local_loss=0.007649563252925873, train_loss=0.023819968104362488, time_cost=1.2296051979064941
Steps:   1%|▏         | 14315/1000000 [3:20:51<2352:47:15,  8.59s/it, lr=1e-5, step_loss=0.00765]Steps:   1%|▏         | 14316/1000000 [3:21:00<2417:23:53,  8.83s/it, lr=1e-5, step_loss=0.00765][RANK-0]: Step: [14316], local_loss=0.03791068494319916, train_loss=0.14950227737426758, time_cost=7.050447702407837
Steps:   1%|▏         | 14316/1000000 [3:21:00<2417:23:53,  8.83s/it, lr=1e-5, step_loss=0.0379] Steps:   1%|▏         | 14317/1000000 [3:21:12<2682:33:38,  9.80s/it, lr=1e-5, step_loss=0.0379][RANK-0]: Step: [14317], local_loss=0.006898154504597187, train_loss=0.1360742747783661, time_cost=3.6964385509490967
Steps:   1%|▏         | 14317/1000000 [3:21:12<2682:33:38,  9.80s/it, lr=1e-5, step_loss=0.0069]Steps:   1%|▏         | 14318/1000000 [3:21:20<2523:17:08,  9.22s/it, lr=1e-5, step_loss=0.0069][RANK-0]: Step: [14318], local_loss=0.004736484028398991, train_loss=0.01958061009645462, time_cost=3.765845537185669
Steps:   1%|▏         | 14318/1000000 [3:21:20<2523:17:08,  9.22s/it, lr=1e-5, step_loss=0.00474]Steps:   1%|▏         | 14319/1000000 [3:21:29<2543:50:07,  9.29s/it, lr=1e-5, step_loss=0.00474][RANK-0]: Step: [14319], local_loss=0.025537818670272827, train_loss=0.03216013312339783, time_cost=1.8985018730163574
Steps:   1%|▏         | 14319/1000000 [3:21:29<2543:50:07,  9.29s/it, lr=1e-5, step_loss=0.0255] Steps:   1%|▏         | 14320/1000000 [3:21:36<2342:19:52,  8.55s/it, lr=1e-5, step_loss=0.0255][RANK-0]: Step: [14320], local_loss=0.00720202224329114, train_loss=0.07914475351572037, time_cost=2.5005569458007812
Steps:   1%|▏         | 14320/1000000 [3:21:36<2342:19:52,  8.55s/it, lr=1e-5, step_loss=0.0072]Steps:   1%|▏         | 14321/1000000 [3:21:41<2039:52:34,  7.45s/it, lr=1e-5, step_loss=0.0072][RANK-0]: Step: [14321], local_loss=0.01352495327591896, train_loss=0.02279367670416832, time_cost=2.213189125061035
Steps:   1%|▏         | 14321/1000000 [3:21:41<2039:52:34,  7.45s/it, lr=1e-5, step_loss=0.0135]Steps:   1%|▏         | 14322/1000000 [3:21:45<1783:55:21,  6.52s/it, lr=1e-5, step_loss=0.0135][RANK-0]: Step: [14322], local_loss=0.009713314473628998, train_loss=0.08297790586948395, time_cost=1.4264283180236816
Steps:   1%|▏         | 14322/1000000 [3:21:45<1783:55:21,  6.52s/it, lr=1e-5, step_loss=0.00971]Steps:   1%|▏         | 14323/1000000 [3:21:50<1604:57:15,  5.86s/it, lr=1e-5, step_loss=0.00971][RANK-0]: Step: [14323], local_loss=0.008354231715202332, train_loss=0.020509198307991028, time_cost=1.7985835075378418
Steps:   1%|▏         | 14323/1000000 [3:21:50<1604:57:15,  5.86s/it, lr=1e-5, step_loss=0.00835]Steps:   1%|▏         | 14324/1000000 [3:22:00<1973:05:16,  7.21s/it, lr=1e-5, step_loss=0.00835][RANK-0]: Step: [14324], local_loss=0.11807968467473984, train_loss=0.03827411308884621, time_cost=1.2321336269378662
Steps:   1%|▏         | 14324/1000000 [3:22:00<1973:05:16,  7.21s/it, lr=1e-5, step_loss=0.118]  Steps:   1%|▏         | 14325/1000000 [3:22:13<2460:21:06,  8.99s/it, lr=1e-5, step_loss=0.118][RANK-0]: Step: [14325], local_loss=0.01691843569278717, train_loss=0.020218193531036377, time_cost=3.6383025646209717
Steps:   1%|▏         | 14325/1000000 [3:22:13<2460:21:06,  8.99s/it, lr=1e-5, step_loss=0.0169]Steps:   1%|▏         | 14326/1000000 [3:22:18<2100:45:19,  7.67s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [14326], local_loss=0.014083553105592728, train_loss=0.02566804736852646, time_cost=1.813035249710083
Steps:   1%|▏         | 14326/1000000 [3:22:18<2100:45:19,  7.67s/it, lr=1e-5, step_loss=0.0141]Steps:   1%|▏         | 14327/1000000 [3:22:28<2293:55:54,  8.38s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [14327], local_loss=0.02331496775150299, train_loss=37.360172271728516, time_cost=1.3205785751342773
Steps:   1%|▏         | 14327/1000000 [3:22:28<2293:55:54,  8.38s/it, lr=1e-5, step_loss=0.0233]Steps:   1%|▏         | 14328/1000000 [3:22:37<2373:18:23,  8.67s/it, lr=1e-5, step_loss=0.0233][RANK-0]: Step: [14328], local_loss=0.02035505883395672, train_loss=0.04029957577586174, time_cost=3.0515754222869873
Steps:   1%|▏         | 14328/1000000 [3:22:37<2373:18:23,  8.67s/it, lr=1e-5, step_loss=0.0204]Steps:   1%|▏         | 14329/1000000 [3:22:45<2308:13:19,  8.43s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [14329], local_loss=0.006816389970481396, train_loss=0.01917438954114914, time_cost=2.0510644912719727
Steps:   1%|▏         | 14329/1000000 [3:22:45<2308:13:19,  8.43s/it, lr=1e-5, step_loss=0.00682]Steps:   1%|▏         | 14330/1000000 [3:22:54<2395:41:07,  8.75s/it, lr=1e-5, step_loss=0.00682][RANK-0]: Step: [14330], local_loss=0.020794274285435677, train_loss=0.015188025310635567, time_cost=1.9843485355377197
Steps:   1%|▏         | 14330/1000000 [3:22:54<2395:41:07,  8.75s/it, lr=1e-5, step_loss=0.0208] Steps:   1%|▏         | 14331/1000000 [3:23:05<2516:05:37,  9.19s/it, lr=1e-5, step_loss=0.0208][RANK-0]: Step: [14331], local_loss=0.03038283996284008, train_loss=0.07247801870107651, time_cost=4.501598596572876
Steps:   1%|▏         | 14331/1000000 [3:23:05<2516:05:37,  9.19s/it, lr=1e-5, step_loss=0.0304]Steps:   1%|▏         | 14332/1000000 [3:23:11<2276:31:33,  8.31s/it, lr=1e-5, step_loss=0.0304][RANK-0]: Step: [14332], local_loss=0.10848940908908844, train_loss=0.028999043628573418, time_cost=4.061704158782959
Steps:   1%|▏         | 14332/1000000 [3:23:11<2276:31:33,  8.31s/it, lr=1e-5, step_loss=0.108] Steps:   1%|▏         | 14333/1000000 [3:23:15<1946:35:47,  7.11s/it, lr=1e-5, step_loss=0.108][RANK-0]: Step: [14333], local_loss=0.1263912469148636, train_loss=0.03619540110230446, time_cost=1.4632506370544434
Steps:   1%|▏         | 14333/1000000 [3:23:15<1946:35:47,  7.11s/it, lr=1e-5, step_loss=0.126]Steps:   1%|▏         | 14334/1000000 [3:23:23<2008:51:18,  7.34s/it, lr=1e-5, step_loss=0.126][RANK-0]: Step: [14334], local_loss=0.04290202260017395, train_loss=0.053460489958524704, time_cost=3.566885471343994
Steps:   1%|▏         | 14334/1000000 [3:23:23<2008:51:18,  7.34s/it, lr=1e-5, step_loss=0.0429]Steps:   1%|▏         | 14335/1000000 [3:23:32<2164:59:30,  7.91s/it, lr=1e-5, step_loss=0.0429][RANK-0]: Step: [14335], local_loss=0.04291331768035889, train_loss=0.04267922043800354, time_cost=3.959965467453003
Steps:   1%|▏         | 14335/1000000 [3:23:32<2164:59:30,  7.91s/it, lr=1e-5, step_loss=0.0429]Steps:   1%|▏         | 14336/1000000 [3:23:40<2145:21:19,  7.84s/it, lr=1e-5, step_loss=0.0429][RANK-0]: Step: [14336], local_loss=0.0875944048166275, train_loss=11.843962669372559, time_cost=4.976382255554199
Steps:   1%|▏         | 14336/1000000 [3:23:40<2145:21:19,  7.84s/it, lr=1e-5, step_loss=0.0876]Steps:   1%|▏         | 14337/1000000 [3:23:51<2390:38:04,  8.73s/it, lr=1e-5, step_loss=0.0876][RANK-0]: Step: [14337], local_loss=0.07180777192115784, train_loss=0.04222340136766434, time_cost=2.8254547119140625
Steps:   1%|▏         | 14337/1000000 [3:23:51<2390:38:04,  8.73s/it, lr=1e-5, step_loss=0.0718]Steps:   1%|▏         | 14338/1000000 [3:23:56<2122:35:26,  7.75s/it, lr=1e-5, step_loss=0.0718][RANK-0]: Step: [14338], local_loss=0.008235113695263863, train_loss=0.018507257103919983, time_cost=2.7281370162963867
Steps:   1%|▏         | 14338/1000000 [3:23:56<2122:35:26,  7.75s/it, lr=1e-5, step_loss=0.00824]Steps:   1%|▏         | 14339/1000000 [3:24:08<2406:16:33,  8.79s/it, lr=1e-5, step_loss=0.00824][RANK-0]: Step: [14339], local_loss=0.020419398322701454, train_loss=0.021611008793115616, time_cost=1.5136592388153076
Steps:   1%|▏         | 14339/1000000 [3:24:08<2406:16:33,  8.79s/it, lr=1e-5, step_loss=0.0204] Steps:   1%|▏         | 14340/1000000 [3:24:17<2432:09:19,  8.88s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [14340], local_loss=0.008692378178238869, train_loss=0.011100146919488907, time_cost=7.536011457443237
Steps:   1%|▏         | 14340/1000000 [3:24:17<2432:09:19,  8.88s/it, lr=1e-5, step_loss=0.00869]Steps:   1%|▏         | 14341/1000000 [3:24:32<2940:18:36, 10.74s/it, lr=1e-5, step_loss=0.00869][RANK-0]: Step: [14341], local_loss=0.011930703185498714, train_loss=0.046055130660533905, time_cost=3.649395227432251
Steps:   1%|▏         | 14341/1000000 [3:24:32<2940:18:36, 10.74s/it, lr=1e-5, step_loss=0.0119] Steps:   1%|▏         | 14342/1000000 [3:24:37<2464:12:44,  9.00s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [14342], local_loss=0.01672055758535862, train_loss=0.04346342012286186, time_cost=2.076040267944336
Steps:   1%|▏         | 14342/1000000 [3:24:37<2464:12:44,  9.00s/it, lr=1e-5, step_loss=0.0167]Steps:   1%|▏         | 14343/1000000 [3:24:42<2158:49:30,  7.88s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [14343], local_loss=0.03612305968999863, train_loss=0.03040395677089691, time_cost=2.3340930938720703
Steps:   1%|▏         | 14343/1000000 [3:24:42<2158:49:30,  7.88s/it, lr=1e-5, step_loss=0.0361]Steps:   1%|▏         | 14344/1000000 [3:24:51<2237:00:59,  8.17s/it, lr=1e-5, step_loss=0.0361][RANK-0]: Step: [14344], local_loss=0.021739711984992027, train_loss=0.02446732670068741, time_cost=5.862530946731567
Steps:   1%|▏         | 14344/1000000 [3:24:51<2237:00:59,  8.17s/it, lr=1e-5, step_loss=0.0217]Steps:   1%|▏         | 14345/1000000 [3:24:55<1913:34:02,  6.99s/it, lr=1e-5, step_loss=0.0217][RANK-0]: Step: [14345], local_loss=0.04483717307448387, train_loss=0.05737285315990448, time_cost=1.7075743675231934
Steps:   1%|▏         | 14345/1000000 [3:24:55<1913:34:02,  6.99s/it, lr=1e-5, step_loss=0.0448]Steps:   1%|▏         | 14346/1000000 [3:24:59<1683:33:28,  6.15s/it, lr=1e-5, step_loss=0.0448][RANK-0]: Step: [14346], local_loss=0.9883979558944702, train_loss=0.24511423707008362, time_cost=1.5021443367004395
Steps:   1%|▏         | 14346/1000000 [3:24:59<1683:33:28,  6.15s/it, lr=1e-5, step_loss=0.988] Steps:   1%|▏         | 14347/1000000 [3:25:15<2448:31:52,  8.94s/it, lr=1e-5, step_loss=0.988][RANK-0]: Step: [14347], local_loss=0.006653369404375553, train_loss=0.03870119899511337, time_cost=5.246936559677124
Steps:   1%|▏         | 14347/1000000 [3:25:15<2448:31:52,  8.94s/it, lr=1e-5, step_loss=0.00665]Steps:   1%|▏         | 14348/1000000 [3:25:20<2187:41:01,  7.99s/it, lr=1e-5, step_loss=0.00665][RANK-0]: Step: [14348], local_loss=0.035288646817207336, train_loss=0.14649274945259094, time_cost=3.256542205810547
Steps:   1%|▏         | 14348/1000000 [3:25:20<2187:41:01,  7.99s/it, lr=1e-5, step_loss=0.0353] Steps:   1%|▏         | 14349/1000000 [3:25:35<2689:30:05,  9.82s/it, lr=1e-5, step_loss=0.0353][RANK-0]: Step: [14349], local_loss=0.4393543004989624, train_loss=0.14515012502670288, time_cost=4.0300538539886475
Steps:   1%|▏         | 14349/1000000 [3:25:35<2689:30:05,  9.82s/it, lr=1e-5, step_loss=0.439] Steps:   1%|▏         | 14350/1000000 [3:25:40<2325:38:12,  8.49s/it, lr=1e-5, step_loss=0.439][RANK-0]: Step: [14350], local_loss=0.16316422820091248, train_loss=0.04247797280550003, time_cost=2.8130762577056885
Steps:   1%|▏         | 14350/1000000 [3:25:40<2325:38:12,  8.49s/it, lr=1e-5, step_loss=0.163]Steps:   1%|▏         | 14351/1000000 [3:25:47<2183:40:50,  7.98s/it, lr=1e-5, step_loss=0.163][RANK-0]: Step: [14351], local_loss=0.02561384066939354, train_loss=21.049179077148438, time_cost=1.9544785022735596
Steps:   1%|▏         | 14351/1000000 [3:25:47<2183:40:50,  7.98s/it, lr=1e-5, step_loss=0.0256]Steps:   1%|▏         | 14352/1000000 [3:26:00<2650:30:38,  9.68s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [14352], local_loss=0.25780755281448364, train_loss=0.0556553415954113, time_cost=5.757248401641846
Steps:   1%|▏         | 14352/1000000 [3:26:00<2650:30:38,  9.68s/it, lr=1e-5, step_loss=0.258] Steps:   1%|▏         | 14353/1000000 [3:26:06<2347:14:37,  8.57s/it, lr=1e-5, step_loss=0.258][RANK-0]: Step: [14353], local_loss=0.019259952008724213, train_loss=0.0179764237254858, time_cost=1.9264633655548096
Steps:   1%|▏         | 14353/1000000 [3:26:06<2347:14:37,  8.57s/it, lr=1e-5, step_loss=0.0193]Steps:   1%|▏         | 14354/1000000 [3:26:11<1989:32:48,  7.27s/it, lr=1e-5, step_loss=0.0193][RANK-0]: Step: [14354], local_loss=0.03430010750889778, train_loss=0.10076844692230225, time_cost=1.4987030029296875
Steps:   1%|▏         | 14354/1000000 [3:26:11<1989:32:48,  7.27s/it, lr=1e-5, step_loss=0.0343]Steps:   1%|▏         | 14355/1000000 [3:26:23<2452:56:21,  8.96s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [14355], local_loss=0.03460897132754326, train_loss=0.07775217294692993, time_cost=4.233229398727417
Steps:   1%|▏         | 14355/1000000 [3:26:23<2452:56:21,  8.96s/it, lr=1e-5, step_loss=0.0346]Steps:   1%|▏         | 14356/1000000 [3:26:32<2398:30:48,  8.76s/it, lr=1e-5, step_loss=0.0346][RANK-0]: Step: [14356], local_loss=0.015960143879055977, train_loss=0.019421255216002464, time_cost=6.549242258071899
Steps:   1%|▏         | 14356/1000000 [3:26:32<2398:30:48,  8.76s/it, lr=1e-5, step_loss=0.016] Steps:   1%|▏         | 14357/1000000 [3:26:46<2836:22:14, 10.36s/it, lr=1e-5, step_loss=0.016][RANK-0]: Step: [14357], local_loss=0.02479364164173603, train_loss=0.030105454847216606, time_cost=4.192545175552368
Steps:   1%|▏         | 14357/1000000 [3:26:46<2836:22:14, 10.36s/it, lr=1e-5, step_loss=0.0248]Steps:   1%|▏         | 14358/1000000 [3:26:50<2347:04:28,  8.57s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [14358], local_loss=0.016732018440961838, train_loss=0.02188676968216896, time_cost=1.5234320163726807
Steps:   1%|▏         | 14358/1000000 [3:26:50<2347:04:28,  8.57s/it, lr=1e-5, step_loss=0.0167]Steps:   1%|▏         | 14359/1000000 [3:27:03<2710:35:33,  9.90s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [14359], local_loss=0.004264086484909058, train_loss=0.06816677749156952, time_cost=4.452088832855225
Steps:   1%|▏         | 14359/1000000 [3:27:03<2710:35:33,  9.90s/it, lr=1e-5, step_loss=0.00426]Steps:   1%|▏         | 14360/1000000 [3:27:11<2506:54:21,  9.16s/it, lr=1e-5, step_loss=0.00426][RANK-0]: Step: [14360], local_loss=0.007853042334318161, train_loss=20.687179565429688, time_cost=2.734675884246826
Steps:   1%|▏         | 14360/1000000 [3:27:11<2506:54:21,  9.16s/it, lr=1e-5, step_loss=0.00785]Steps:   1%|▏         | 14361/1000000 [3:27:22<2672:19:09,  9.76s/it, lr=1e-5, step_loss=0.00785][RANK-0]: Step: [14361], local_loss=0.1977750062942505, train_loss=0.0836566910147667, time_cost=1.2098827362060547
Steps:   1%|▏         | 14361/1000000 [3:27:22<2672:19:09,  9.76s/it, lr=1e-5, step_loss=0.198]  Steps:   1%|▏         | 14362/1000000 [3:27:28<2365:22:12,  8.64s/it, lr=1e-5, step_loss=0.198][RANK-0]: Step: [14362], local_loss=0.024600956588983536, train_loss=0.021575521677732468, time_cost=3.3234682083129883
Steps:   1%|▏         | 14362/1000000 [3:27:28<2365:22:12,  8.64s/it, lr=1e-5, step_loss=0.0246]Steps:   1%|▏         | 14363/1000000 [3:27:42<2810:43:41, 10.27s/it, lr=1e-5, step_loss=0.0246][RANK-0]: Step: [14363], local_loss=0.0356779545545578, train_loss=0.03963273763656616, time_cost=4.839030742645264
Steps:   1%|▏         | 14363/1000000 [3:27:42<2810:43:41, 10.27s/it, lr=1e-5, step_loss=0.0357]Steps:   1%|▏         | 14364/1000000 [3:27:50<2614:45:35,  9.55s/it, lr=1e-5, step_loss=0.0357][RANK-0]: Step: [14364], local_loss=0.006500591523945332, train_loss=0.061030901968479156, time_cost=6.441577434539795
Steps:   1%|▏         | 14364/1000000 [3:27:50<2614:45:35,  9.55s/it, lr=1e-5, step_loss=0.0065]Steps:   1%|▏         | 14365/1000000 [3:27:54<2172:01:11,  7.93s/it, lr=1e-5, step_loss=0.0065][RANK-0]: Step: [14365], local_loss=0.04596655070781708, train_loss=0.2991465628147125, time_cost=1.258223056793213
Steps:   1%|▏         | 14365/1000000 [3:27:54<2172:01:11,  7.93s/it, lr=1e-5, step_loss=0.046] Steps:   1%|▏         | 14366/1000000 [3:27:59<1932:23:10,  7.06s/it, lr=1e-5, step_loss=0.046][RANK-0]: Step: [14366], local_loss=0.05702436715364456, train_loss=0.055179134011268616, time_cost=1.3673732280731201
Steps:   1%|▏         | 14366/1000000 [3:27:59<1932:23:10,  7.06s/it, lr=1e-5, step_loss=0.057]Steps:   1%|▏         | 14367/1000000 [3:28:13<2474:09:26,  9.04s/it, lr=1e-5, step_loss=0.057][RANK-0]: Step: [14367], local_loss=0.008656129240989685, train_loss=0.0349697470664978, time_cost=4.635830879211426
Steps:   1%|▏         | 14367/1000000 [3:28:13<2474:09:26,  9.04s/it, lr=1e-5, step_loss=0.00866]Steps:   1%|▏         | 14368/1000000 [3:28:18<2130:41:08,  7.78s/it, lr=1e-5, step_loss=0.00866][RANK-0]: Step: [14368], local_loss=0.01646897941827774, train_loss=0.021459437906742096, time_cost=2.030017614364624
Steps:   1%|▏         | 14368/1000000 [3:28:18<2130:41:08,  7.78s/it, lr=1e-5, step_loss=0.0165] Steps:   1%|▏         | 14369/1000000 [3:28:23<1974:17:29,  7.21s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [14369], local_loss=0.006748713552951813, train_loss=0.024097410961985588, time_cost=1.783585548400879
Steps:   1%|▏         | 14369/1000000 [3:28:23<1974:17:29,  7.21s/it, lr=1e-5, step_loss=0.00675]Steps:   1%|▏         | 14370/1000000 [3:28:34<2237:52:33,  8.17s/it, lr=1e-5, step_loss=0.00675][RANK-0]: Step: [14370], local_loss=0.011777265928685665, train_loss=0.15695522725582123, time_cost=2.470282554626465
Steps:   1%|▏         | 14370/1000000 [3:28:34<2237:52:33,  8.17s/it, lr=1e-5, step_loss=0.0118] Steps:   1%|▏         | 14371/1000000 [3:28:42<2218:08:59,  8.10s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [14371], local_loss=0.006779232062399387, train_loss=0.021289166063070297, time_cost=3.8253748416900635
Steps:   1%|▏         | 14371/1000000 [3:28:42<2218:08:59,  8.10s/it, lr=1e-5, step_loss=0.00678]Steps:   1%|▏         | 14372/1000000 [3:28:49<2137:20:59,  7.81s/it, lr=1e-5, step_loss=0.00678][RANK-0]: Step: [14372], local_loss=0.09971161931753159, train_loss=0.1884794384241104, time_cost=2.861685037612915
Steps:   1%|▏         | 14372/1000000 [3:28:49<2137:20:59,  7.81s/it, lr=1e-5, step_loss=0.0997] Steps:   1%|▏         | 14373/1000000 [3:28:55<1985:44:06,  7.25s/it, lr=1e-5, step_loss=0.0997][RANK-0]: Step: [14373], local_loss=0.02509070746600628, train_loss=0.024265389889478683, time_cost=1.2197842597961426
Steps:   1%|▏         | 14373/1000000 [3:28:55<1985:44:06,  7.25s/it, lr=1e-5, step_loss=0.0251]Steps:   1%|▏         | 14374/1000000 [3:29:05<2221:32:11,  8.11s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [14374], local_loss=0.006015895400196314, train_loss=0.06709441542625427, time_cost=2.1057844161987305
Steps:   1%|▏         | 14374/1000000 [3:29:05<2221:32:11,  8.11s/it, lr=1e-5, step_loss=0.00602]Steps:   1%|▏         | 14375/1000000 [3:29:09<1924:50:48,  7.03s/it, lr=1e-5, step_loss=0.00602][RANK-0]: Step: [14375], local_loss=0.42100876569747925, train_loss=0.08389833569526672, time_cost=1.6222412586212158
Steps:   1%|▏         | 14375/1000000 [3:29:09<1924:50:48,  7.03s/it, lr=1e-5, step_loss=0.421]  Steps:   1%|▏         | 14376/1000000 [3:29:19<2119:57:17,  7.74s/it, lr=1e-5, step_loss=0.421][RANK-0]: Step: [14376], local_loss=0.08851013332605362, train_loss=0.12781095504760742, time_cost=1.2305750846862793
Steps:   1%|▏         | 14376/1000000 [3:29:19<2119:57:17,  7.74s/it, lr=1e-5, step_loss=0.0885]Steps:   1%|▏         | 14377/1000000 [3:29:23<1839:05:18,  6.72s/it, lr=1e-5, step_loss=0.0885][RANK-0]: Step: [14377], local_loss=0.07358845323324203, train_loss=0.04480855166912079, time_cost=1.5339057445526123
Steps:   1%|▏         | 14377/1000000 [3:29:23<1839:05:18,  6.72s/it, lr=1e-5, step_loss=0.0736]Steps:   1%|▏         | 14378/1000000 [3:29:33<2083:25:04,  7.61s/it, lr=1e-5, step_loss=0.0736][RANK-0]: Step: [14378], local_loss=0.01321801170706749, train_loss=0.02872757613658905, time_cost=2.232032537460327
Steps:   1%|▏         | 14378/1000000 [3:29:33<2083:25:04,  7.61s/it, lr=1e-5, step_loss=0.0132]Steps:   1%|▏         | 14379/1000000 [3:29:41<2164:00:38,  7.90s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [14379], local_loss=0.05228010192513466, train_loss=0.054965388029813766, time_cost=3.2460408210754395
Steps:   1%|▏         | 14379/1000000 [3:29:41<2164:00:38,  7.90s/it, lr=1e-5, step_loss=0.0523]Steps:   1%|▏         | 14380/1000000 [3:29:49<2139:35:30,  7.81s/it, lr=1e-5, step_loss=0.0523][RANK-0]: Step: [14380], local_loss=0.005420318339020014, train_loss=0.016847850754857063, time_cost=2.8507184982299805
Steps:   1%|▏         | 14380/1000000 [3:29:49<2139:35:30,  7.81s/it, lr=1e-5, step_loss=0.00542]Steps:   1%|▏         | 14381/1000000 [3:30:02<2524:22:10,  9.22s/it, lr=1e-5, step_loss=0.00542][RANK-0]: Step: [14381], local_loss=0.006001242436468601, train_loss=0.09470468014478683, time_cost=5.459389686584473
Steps:   1%|▏         | 14381/1000000 [3:30:02<2524:22:10,  9.22s/it, lr=1e-5, step_loss=0.006]  Steps:   1%|▏         | 14382/1000000 [3:30:11<2565:46:17,  9.37s/it, lr=1e-5, step_loss=0.006][RANK-0]: Step: [14382], local_loss=0.010567022487521172, train_loss=0.11799097806215286, time_cost=3.439460039138794
Steps:   1%|▏         | 14382/1000000 [3:30:11<2565:46:17,  9.37s/it, lr=1e-5, step_loss=0.0106]Steps:   1%|▏         | 14383/1000000 [3:30:25<2889:25:35, 10.55s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [14383], local_loss=0.0660909041762352, train_loss=37.501686096191406, time_cost=2.9995076656341553
Steps:   1%|▏         | 14383/1000000 [3:30:25<2889:25:35, 10.55s/it, lr=1e-5, step_loss=0.0661]Steps:   1%|▏         | 14384/1000000 [3:30:36<2935:44:04, 10.72s/it, lr=1e-5, step_loss=0.0661][RANK-0]: Step: [14384], local_loss=0.03344650939106941, train_loss=0.023628417402505875, time_cost=8.09201955795288
Steps:   1%|▏         | 14384/1000000 [3:30:36<2935:44:04, 10.72s/it, lr=1e-5, step_loss=0.0334]Steps:   1%|▏         | 14385/1000000 [3:30:42<2545:25:50,  9.30s/it, lr=1e-5, step_loss=0.0334][RANK-0]: Step: [14385], local_loss=0.06342516839504242, train_loss=0.03581395372748375, time_cost=1.7684423923492432
Steps:   1%|▏         | 14385/1000000 [3:30:42<2545:25:50,  9.30s/it, lr=1e-5, step_loss=0.0634]Steps:   1%|▏         | 14386/1000000 [3:30:46<2132:13:51,  7.79s/it, lr=1e-5, step_loss=0.0634][RANK-0]: Step: [14386], local_loss=0.014420334249734879, train_loss=0.06825320422649384, time_cost=1.3615999221801758
Steps:   1%|▏         | 14386/1000000 [3:30:46<2132:13:51,  7.79s/it, lr=1e-5, step_loss=0.0144]Steps:   1%|▏         | 14387/1000000 [3:30:52<2000:40:04,  7.31s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [14387], local_loss=0.056319206953048706, train_loss=0.04410405457019806, time_cost=1.2300686836242676
Steps:   1%|▏         | 14387/1000000 [3:30:52<2000:40:04,  7.31s/it, lr=1e-5, step_loss=0.0563]Steps:   1%|▏         | 14388/1000000 [3:31:03<2281:48:29,  8.33s/it, lr=1e-5, step_loss=0.0563][RANK-0]: Step: [14388], local_loss=0.14073075354099274, train_loss=0.0566241517663002, time_cost=3.666351079940796
Steps:   1%|▏         | 14388/1000000 [3:31:03<2281:48:29,  8.33s/it, lr=1e-5, step_loss=0.141] Steps:   1%|▏         | 14389/1000000 [3:31:16<2711:14:01,  9.90s/it, lr=1e-5, step_loss=0.141][RANK-0]: Step: [14389], local_loss=0.01241995394229889, train_loss=0.020035801455378532, time_cost=11.368299007415771
Steps:   1%|▏         | 14389/1000000 [3:31:16<2711:14:01,  9.90s/it, lr=1e-5, step_loss=0.0124]Steps:   1%|▏         | 14390/1000000 [3:31:24<2493:58:29,  9.11s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [14390], local_loss=0.030919570475816727, train_loss=0.022342609241604805, time_cost=2.6666364669799805
Steps:   1%|▏         | 14390/1000000 [3:31:24<2493:58:29,  9.11s/it, lr=1e-5, step_loss=0.0309]Steps:   1%|▏         | 14391/1000000 [3:31:29<2209:53:36,  8.07s/it, lr=1e-5, step_loss=0.0309][RANK-0]: Step: [14391], local_loss=0.016654370352625847, train_loss=0.04208843410015106, time_cost=1.2600266933441162
Steps:   1%|▏         | 14391/1000000 [3:31:29<2209:53:36,  8.07s/it, lr=1e-5, step_loss=0.0167]Steps:   1%|▏         | 14392/1000000 [3:31:43<2654:26:49,  9.70s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [14392], local_loss=0.06275907903909683, train_loss=0.026073800399899483, time_cost=3.3627209663391113
Steps:   1%|▏         | 14392/1000000 [3:31:43<2654:26:49,  9.70s/it, lr=1e-5, step_loss=0.0628]Steps:   1%|▏         | 14393/1000000 [3:31:49<2332:29:40,  8.52s/it, lr=1e-5, step_loss=0.0628][RANK-0]: Step: [14393], local_loss=0.021285109221935272, train_loss=0.021779995411634445, time_cost=2.9868221282958984
Steps:   1%|▏         | 14393/1000000 [3:31:49<2332:29:40,  8.52s/it, lr=1e-5, step_loss=0.0213]Steps:   1%|▏         | 14394/1000000 [3:32:00<2539:34:49,  9.28s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [14394], local_loss=0.010060042142868042, train_loss=0.05791587382555008, time_cost=1.5977039337158203
Steps:   1%|▏         | 14394/1000000 [3:32:00<2539:34:49,  9.28s/it, lr=1e-5, step_loss=0.0101]Steps:   1%|▏         | 14395/1000000 [3:32:13<2871:43:15, 10.49s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [14395], local_loss=0.008680988103151321, train_loss=0.047839198261499405, time_cost=11.220980644226074
Steps:   1%|▏         | 14395/1000000 [3:32:13<2871:43:15, 10.49s/it, lr=1e-5, step_loss=0.00868]Steps:   1%|▏         | 14396/1000000 [3:32:20<2572:08:20,  9.39s/it, lr=1e-5, step_loss=0.00868][RANK-0]: Step: [14396], local_loss=0.05632779747247696, train_loss=33.19349670410156, time_cost=1.8449015617370605
Steps:   1%|▏         | 14396/1000000 [3:32:20<2572:08:20,  9.39s/it, lr=1e-5, step_loss=0.0563] Steps:   1%|▏         | 14397/1000000 [3:32:31<2687:21:46,  9.82s/it, lr=1e-5, step_loss=0.0563][RANK-0]: Step: [14397], local_loss=0.024847202003002167, train_loss=0.06632300466299057, time_cost=4.535000324249268
Steps:   1%|▏         | 14397/1000000 [3:32:31<2687:21:46,  9.82s/it, lr=1e-5, step_loss=0.0248]Steps:   1%|▏         | 14398/1000000 [3:32:42<2851:37:14, 10.42s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [14398], local_loss=0.023195581510663033, train_loss=0.032945238053798676, time_cost=2.455749034881592
Steps:   1%|▏         | 14398/1000000 [3:32:42<2851:37:14, 10.42s/it, lr=1e-5, step_loss=0.0232]Steps:   1%|▏         | 14399/1000000 [3:32:50<2634:06:27,  9.62s/it, lr=1e-5, step_loss=0.0232][RANK-0]: Step: [14399], local_loss=0.02045447751879692, train_loss=0.12837257981300354, time_cost=2.785898208618164
Steps:   1%|▏         | 14399/1000000 [3:32:50<2634:06:27,  9.62s/it, lr=1e-5, step_loss=0.0205]Steps:   1%|▏         | 14400/1000000 [3:33:00<2651:18:38,  9.68s/it, lr=1e-5, step_loss=0.0205][RANK-0]: Step: [14400], local_loss=0.016658635810017586, train_loss=0.028561165556311607, time_cost=2.3355700969696045
Steps:   1%|▏         | 14400/1000000 [3:33:00<2651:18:38,  9.68s/it, lr=1e-5, step_loss=0.0167]Steps:   1%|▏         | 14401/1000000 [3:33:09<2627:19:46,  9.60s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [14401], local_loss=0.03807790204882622, train_loss=0.08395595848560333, time_cost=2.330284833908081
Steps:   1%|▏         | 14401/1000000 [3:33:09<2627:19:46,  9.60s/it, lr=1e-5, step_loss=0.0381]Steps:   1%|▏         | 14402/1000000 [3:33:21<2807:01:13, 10.25s/it, lr=1e-5, step_loss=0.0381][RANK-0]: Step: [14402], local_loss=0.028805403038859367, train_loss=0.046159401535987854, time_cost=1.204965353012085
Steps:   1%|▏         | 14402/1000000 [3:33:21<2807:01:13, 10.25s/it, lr=1e-5, step_loss=0.0288]Steps:   1%|▏         | 14403/1000000 [3:33:28<2542:07:10,  9.29s/it, lr=1e-5, step_loss=0.0288][RANK-0]: Step: [14403], local_loss=0.011038660071790218, train_loss=0.018477316945791245, time_cost=2.680417060852051
Steps:   1%|▏         | 14403/1000000 [3:33:28<2542:07:10,  9.29s/it, lr=1e-5, step_loss=0.011] Steps:   1%|▏         | 14404/1000000 [3:33:40<2714:57:11,  9.92s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [14404], local_loss=0.44242382049560547, train_loss=0.21692350506782532, time_cost=3.0335516929626465
Steps:   1%|▏         | 14404/1000000 [3:33:40<2714:57:11,  9.92s/it, lr=1e-5, step_loss=0.442]Steps:   1%|▏         | 14405/1000000 [3:33:46<2445:30:28,  8.93s/it, lr=1e-5, step_loss=0.442][RANK-0]: Step: [14405], local_loss=0.01746067777276039, train_loss=0.027154475450515747, time_cost=1.7012546062469482
Steps:   1%|▏         | 14405/1000000 [3:33:46<2445:30:28,  8.93s/it, lr=1e-5, step_loss=0.0175]Steps:   1%|▏         | 14406/1000000 [3:33:51<2139:47:01,  7.82s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [14406], local_loss=0.04886331409215927, train_loss=0.0761779397726059, time_cost=2.124696731567383
Steps:   1%|▏         | 14406/1000000 [3:33:51<2139:47:01,  7.82s/it, lr=1e-5, step_loss=0.0489]Steps:   1%|▏         | 14407/1000000 [3:34:02<2372:54:55,  8.67s/it, lr=1e-5, step_loss=0.0489][RANK-0]: Step: [14407], local_loss=0.2457868754863739, train_loss=0.12829241156578064, time_cost=4.190356492996216
Steps:   1%|▏         | 14407/1000000 [3:34:02<2372:54:55,  8.67s/it, lr=1e-5, step_loss=0.246] Steps:   1%|▏         | 14408/1000000 [3:34:09<2217:09:49,  8.10s/it, lr=1e-5, step_loss=0.246][RANK-0]: Step: [14408], local_loss=0.024463549256324768, train_loss=0.022950705140829086, time_cost=2.3616631031036377
Steps:   1%|▏         | 14408/1000000 [3:34:09<2217:09:49,  8.10s/it, lr=1e-5, step_loss=0.0245]Steps:   1%|▏         | 14409/1000000 [3:34:13<1910:21:47,  6.98s/it, lr=1e-5, step_loss=0.0245][RANK-0]: Step: [14409], local_loss=0.008445079438388348, train_loss=0.018080320209264755, time_cost=1.231144905090332
Steps:   1%|▏         | 14409/1000000 [3:34:13<1910:21:47,  6.98s/it, lr=1e-5, step_loss=0.00845]Steps:   1%|▏         | 14410/1000000 [3:34:24<2248:50:41,  8.21s/it, lr=1e-5, step_loss=0.00845][RANK-0]: Step: [14410], local_loss=0.05509783327579498, train_loss=0.035214632749557495, time_cost=1.209012508392334
Steps:   1%|▏         | 14410/1000000 [3:34:24<2248:50:41,  8.21s/it, lr=1e-5, step_loss=0.0551] Steps:   1%|▏         | 14411/1000000 [3:34:36<2562:30:33,  9.36s/it, lr=1e-5, step_loss=0.0551][RANK-0]: Step: [14411], local_loss=0.13095402717590332, train_loss=0.04853587597608566, time_cost=5.081682205200195
Steps:   1%|▏         | 14411/1000000 [3:34:36<2562:30:33,  9.36s/it, lr=1e-5, step_loss=0.131] /Steps:   1%|▏         | 14412/1000000 [3:34:47<2680:23:58,  9.79s/it, lr=1e-5, step_loss=0.131][RANK-0]: Step: [14412], local_loss=0.025012439116835594, train_loss=0.0632084310054779, time_cost=5.355118751525879
Steps:   1%|▏         | 14412/1000000 [3:34:47<2680:23:58,  9.79s/it, lr=1e-5, step_loss=0.025]Steps:   1%|▏         | 14413/1000000 [3:34:53<2336:33:11,  8.53s/it, lr=1e-5, step_loss=0.025][RANK-0]: Step: [14413], local_loss=0.049060944467782974, train_loss=0.041570618748664856, time_cost=2.5981390476226807
Steps:   1%|▏         | 14413/1000000 [3:34:53<2336:33:11,  8.53s/it, lr=1e-5, step_loss=0.0491]Steps:   1%|▏         | 14414/1000000 [3:35:05<2679:04:39,  9.79s/it, lr=1e-5, step_loss=0.0491][RANK-0]: Step: [14414], local_loss=0.012881595641374588, train_loss=0.20966145396232605, time_cost=3.1530635356903076
Steps:   1%|▏         | 14414/1000000 [3:35:05<2679:04:39,  9.79s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 14415/1000000 [3:35:16<2740:20:57, 10.01s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [14415], local_loss=86.87480926513672, train_loss=10.872732162475586, time_cost=1.2141430377960205
Steps:   1%|▏         | 14415/1000000 [3:35:16<2740:20:57, 10.01s/it, lr=1e-5, step_loss=86.9]  Steps:   1%|▏         | 14416/1000000 [3:35:28<2928:12:52, 10.70s/it, lr=1e-5, step_loss=86.9][RANK-0]: Step: [14416], local_loss=0.023202965036034584, train_loss=0.027738498523831367, time_cost=1.2003061771392822
Steps:   1%|▏         | 14416/1000000 [3:35:28<2928:12:52, 10.70s/it, lr=1e-5, step_loss=0.0232]Steps:   1%|▏         | 14417/1000000 [3:35:35<2561:26:41,  9.36s/it, lr=1e-5, step_loss=0.0232][RANK-0]: Step: [14417], local_loss=0.01790759339928627, train_loss=0.042559560388326645, time_cost=1.2107009887695312
Steps:   1%|▏         | 14417/1000000 [3:35:35<2561:26:41,  9.36s/it, lr=1e-5, step_loss=0.0179]Steps:   1%|▏         | 14418/1000000 [3:35:44<2532:26:55,  9.25s/it, lr=1e-5, step_loss=0.0179][RANK-0]: Step: [14418], local_loss=0.03649088740348816, train_loss=35.24381637573242, time_cost=3.4648568630218506
Steps:   1%|▏         | 14418/1000000 [3:35:44<2532:26:55,  9.25s/it, lr=1e-5, step_loss=0.0365]Steps:   1%|▏         | 14419/1000000 [3:35:50<2344:12:30,  8.56s/it, lr=1e-5, step_loss=0.0365][RANK-0]: Step: [14419], local_loss=0.01575232297182083, train_loss=0.07797049731016159, time_cost=1.2052156925201416
Steps:   1%|▏         | 14419/1000000 [3:35:50<2344:12:30,  8.56s/it, lr=1e-5, step_loss=0.0158]Steps:   1%|▏         | 14420/1000000 [3:36:00<2382:21:05,  8.70s/it, lr=1e-5, step_loss=0.0158][RANK-0]: Step: [14420], local_loss=0.04952258616685867, train_loss=0.04114647954702377, time_cost=2.806825637817383
Steps:   1%|▏         | 14420/1000000 [3:36:00<2382:21:05,  8.70s/it, lr=1e-5, step_loss=0.0495]Steps:   1%|▏         | 14421/1000000 [3:36:16<2997:32:00, 10.95s/it, lr=1e-5, step_loss=0.0495][RANK-0]: Step: [14421], local_loss=0.34415730834007263, train_loss=0.07902133464813232, time_cost=7.9980628490448
Steps:   1%|▏         | 14421/1000000 [3:36:16<2997:32:00, 10.95s/it, lr=1e-5, step_loss=0.344] Steps:   1%|▏         | 14422/1000000 [3:36:23<2728:55:15,  9.97s/it, lr=1e-5, step_loss=0.344][RANK-0]: Step: [14422], local_loss=0.049998100847005844, train_loss=0.04338904842734337, time_cost=1.9167354106903076
Steps:   1%|▏         | 14422/1000000 [3:36:23<2728:55:15,  9.97s/it, lr=1e-5, step_loss=0.05] Steps:   1%|▏         | 14423/1000000 [3:36:29<2334:15:35,  8.53s/it, lr=1e-5, step_loss=0.05][RANK-0]: Step: [14423], local_loss=0.01545712724328041, train_loss=0.04096248000860214, time_cost=2.044922113418579
Steps:   1%|▏         | 14423/1000000 [3:36:29<2334:15:35,  8.53s/it, lr=1e-5, step_loss=0.0155]Steps:   1%|▏         | 14424/1000000 [3:36:36<2245:12:23,  8.20s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [14424], local_loss=0.03447433188557625, train_loss=0.04374413564801216, time_cost=2.3298451900482178
Steps:   1%|▏         | 14424/1000000 [3:36:36<2245:12:23,  8.20s/it, lr=1e-5, step_loss=0.0345]Steps:   1%|▏         | 14425/1000000 [3:36:51<2772:20:51, 10.13s/it, lr=1e-5, step_loss=0.0345][RANK-0]: Step: [14425], local_loss=0.007167281117290258, train_loss=0.019674701616168022, time_cost=2.3186867237091064
Steps:   1%|▏         | 14425/1000000 [3:36:51<2772:20:51, 10.13s/it, lr=1e-5, step_loss=0.00717]Steps:   1%|▏         | 14426/1000000 [3:36:56<2349:15:56,  8.58s/it, lr=1e-5, step_loss=0.00717][RANK-0]: Step: [14426], local_loss=0.3122768700122833, train_loss=0.06084060296416283, time_cost=1.2677662372589111
Steps:   1%|▏         | 14426/1000000 [3:36:56<2349:15:56,  8.58s/it, lr=1e-5, step_loss=0.312]  Steps:   1%|▏         | 14427/1000000 [3:37:01<2049:35:31,  7.49s/it, lr=1e-5, step_loss=0.312][RANK-0]: Step: [14427], local_loss=0.012075209990143776, train_loss=0.06314098834991455, time_cost=2.3320343494415283
Steps:   1%|▏         | 14427/1000000 [3:37:01<2049:35:31,  7.49s/it, lr=1e-5, step_loss=0.0121]Steps:   1%|▏         | 14428/1000000 [3:37:08<2088:20:42,  7.63s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [14428], local_loss=0.012903792783617973, train_loss=0.039749667048454285, time_cost=4.068902969360352
Steps:   1%|▏         | 14428/1000000 [3:37:08<2088:20:42,  7.63s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 14429/1000000 [3:37:21<2476:23:15,  9.05s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [14429], local_loss=0.030690133571624756, train_loss=0.07023641467094421, time_cost=1.21335768699646
Steps:   1%|▏         | 14429/1000000 [3:37:21<2476:23:15,  9.05s/it, lr=1e-5, step_loss=0.0307]Steps:   1%|▏         | 14430/1000000 [3:37:27<2259:44:26,  8.25s/it, lr=1e-5, step_loss=0.0307][RANK-0]: Step: [14430], local_loss=0.006653104443103075, train_loss=0.020818952471017838, time_cost=1.197901725769043
Steps:   1%|▏         | 14430/1000000 [3:37:27<2259:44:26,  8.25s/it, lr=1e-5, step_loss=0.00665]Steps:   1%|▏         | 14431/1000000 [3:37:40<2626:05:26,  9.59s/it, lr=1e-5, step_loss=0.00665][RANK-0]: Step: [14431], local_loss=0.19352151453495026, train_loss=0.11235924065113068, time_cost=1.1900649070739746
Steps:   1%|▏         | 14431/1000000 [3:37:40<2626:05:26,  9.59s/it, lr=1e-5, step_loss=0.194]  Steps:   1%|▏         | 14432/1000000 [3:37:49<2576:17:52,  9.41s/it, lr=1e-5, step_loss=0.194][RANK-0]: Step: [14432], local_loss=0.009968176484107971, train_loss=0.039430562406778336, time_cost=3.657980442047119
Steps:   1%|▏         | 14432/1000000 [3:37:49<2576:17:52,  9.41s/it, lr=1e-5, step_loss=0.00997]Steps:   1%|▏         | 14433/1000000 [3:37:56<2418:31:35,  8.83s/it, lr=1e-5, step_loss=0.00997][RANK-0]: Step: [14433], local_loss=0.015127342194318771, train_loss=0.04947135969996452, time_cost=5.5560877323150635
Steps:   1%|▏         | 14433/1000000 [3:37:56<2418:31:35,  8.83s/it, lr=1e-5, step_loss=0.0151] Steps:   1%|▏         | 14434/1000000 [3:38:06<2476:39:44,  9.05s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [14434], local_loss=0.05065513029694557, train_loss=0.16097700595855713, time_cost=1.2827348709106445
Steps:   1%|▏         | 14434/1000000 [3:38:06<2476:39:44,  9.05s/it, lr=1e-5, step_loss=0.0507]Steps:   1%|▏         | 14435/1000000 [3:38:13<2299:27:26,  8.40s/it, lr=1e-5, step_loss=0.0507][RANK-0]: Step: [14435], local_loss=0.07792268693447113, train_loss=0.13954579830169678, time_cost=2.206876754760742
Steps:   1%|▏         | 14435/1000000 [3:38:13<2299:27:26,  8.40s/it, lr=1e-5, step_loss=0.0779]Steps:   1%|▏         | 14436/1000000 [3:38:25<2636:11:50,  9.63s/it, lr=1e-5, step_loss=0.0779][RANK-0]: Step: [14436], local_loss=0.051829252392053604, train_loss=0.07385776937007904, time_cost=5.349815607070923
Steps:   1%|▏         | 14436/1000000 [3:38:25<2636:11:50,  9.63s/it, lr=1e-5, step_loss=0.0518]Steps:   1%|▏         | 14437/1000000 [3:38:40<3042:13:08, 11.11s/it, lr=1e-5, step_loss=0.0518][RANK-0]: Step: [14437], local_loss=0.028809037059545517, train_loss=0.06465186923742294, time_cost=11.422505140304565
Steps:   1%|▏         | 14437/1000000 [3:38:40<3042:13:08, 11.11s/it, lr=1e-5, step_loss=0.0288]Steps:   1%|▏         | 14438/1000000 [3:38:47<2724:25:19,  9.95s/it, lr=1e-5, step_loss=0.0288][RANK-0]: Step: [14438], local_loss=0.02617528662085533, train_loss=0.03396850824356079, time_cost=2.4967076778411865
Steps:   1%|▏         | 14438/1000000 [3:38:47<2724:25:19,  9.95s/it, lr=1e-5, step_loss=0.0262]Steps:   1%|▏         | 14439/1000000 [3:39:00<2957:32:32, 10.80s/it, lr=1e-5, step_loss=0.0262][RANK-0]: Step: [14439], local_loss=0.017187947407364845, train_loss=0.1075659692287445, time_cost=5.088781356811523
Steps:   1%|▏         | 14439/1000000 [3:39:00<2957:32:32, 10.80s/it, lr=1e-5, step_loss=0.0172]Steps:   1%|▏         | 14440/1000000 [3:39:09<2800:35:05, 10.23s/it, lr=1e-5, step_loss=0.0172][RANK-0]: Step: [14440], local_loss=0.039138346910476685, train_loss=0.04237692058086395, time_cost=3.133746385574341
Steps:   1%|▏         | 14440/1000000 [3:39:09<2800:35:05, 10.23s/it, lr=1e-5, step_loss=0.0391]Steps:   1%|▏         | 14441/1000000 [3:39:25<3271:15:49, 11.95s/it, lr=1e-5, step_loss=0.0391][RANK-0]: Step: [14441], local_loss=0.0076507446356117725, train_loss=15.204437255859375, time_cost=7.044513702392578
Steps:   1%|▏         | 14441/1000000 [3:39:25<3271:15:49, 11.95s/it, lr=1e-5, step_loss=0.00765]Steps:   1%|▏         | 14442/1000000 [3:39:34<3041:00:48, 11.11s/it, lr=1e-5, step_loss=0.00765][RANK-0]: Step: [14442], local_loss=0.007281155325472355, train_loss=0.06270384788513184, time_cost=2.1826674938201904
Steps:   1%|▏         | 14442/1000000 [3:39:34<3041:00:48, 11.11s/it, lr=1e-5, step_loss=0.00728]Steps:   1%|▏         | 14443/1000000 [3:39:42<2755:10:46, 10.06s/it, lr=1e-5, step_loss=0.00728][RANK-0]: Step: [14443], local_loss=0.047335848212242126, train_loss=0.029386574402451515, time_cost=1.2151753902435303
Steps:   1%|▏         | 14443/1000000 [3:39:42<2755:10:46, 10.06s/it, lr=1e-5, step_loss=0.0473] Steps:   1%|▏         | 14444/1000000 [3:39:48<2429:35:08,  8.87s/it, lr=1e-5, step_loss=0.0473][RANK-0]: Step: [14444], local_loss=0.007418538443744183, train_loss=0.03324032947421074, time_cost=2.365175247192383
Steps:   1%|▏         | 14444/1000000 [3:39:48<2429:35:08,  8.87s/it, lr=1e-5, step_loss=0.00742]Steps:   1%|▏         | 14445/1000000 [3:39:54<2204:58:30,  8.05s/it, lr=1e-5, step_loss=0.00742][RANK-0]: Step: [14445], local_loss=0.3085310459136963, train_loss=0.1028166115283966, time_cost=2.008277416229248
Steps:   1%|▏         | 14445/1000000 [3:39:54<2204:58:30,  8.05s/it, lr=1e-5, step_loss=0.309]  Steps:   1%|▏         | 14446/1000000 [3:40:01<2109:38:55,  7.71s/it, lr=1e-5, step_loss=0.309][RANK-0]: Step: [14446], local_loss=0.005726412869989872, train_loss=0.030109163373708725, time_cost=2.402430295944214
Steps:   1%|▏         | 14446/1000000 [3:40:01<2109:38:55,  7.71s/it, lr=1e-5, step_loss=0.00573]Steps:   1%|▏         | 14447/1000000 [3:40:13<2510:15:59,  9.17s/it, lr=1e-5, step_loss=0.00573][RANK-0]: Step: [14447], local_loss=0.15130400657653809, train_loss=0.031564194709062576, time_cost=6.425499439239502
Steps:   1%|▏         | 14447/1000000 [3:40:13<2510:15:59,  9.17s/it, lr=1e-5, step_loss=0.151]  Steps:   1%|▏         | 14448/1000000 [3:40:26<2798:03:29, 10.22s/it, lr=1e-5, step_loss=0.151][RANK-0]: Step: [14448], local_loss=0.009691567160189152, train_loss=0.013142944313585758, time_cost=3.9502577781677246
Steps:   1%|▏         | 14448/1000000 [3:40:26<2798:03:29, 10.22s/it, lr=1e-5, step_loss=0.00969]Steps:   1%|▏         | 14449/1000000 [3:40:33<2497:00:54,  9.12s/it, lr=1e-5, step_loss=0.00969][RANK-0]: Step: [14449], local_loss=0.11722463369369507, train_loss=0.15659299492835999, time_cost=1.397400140762329
Steps:   1%|▏         | 14449/1000000 [3:40:33<2497:00:54,  9.12s/it, lr=1e-5, step_loss=0.117]  Steps:   1%|▏         | 14450/1000000 [3:40:43<2640:51:04,  9.65s/it, lr=1e-5, step_loss=0.117][RANK-0]: Step: [14450], local_loss=0.013820176012814045, train_loss=0.024901360273361206, time_cost=7.863779306411743
Steps:   1%|▏         | 14450/1000000 [3:40:43<2640:51:04,  9.65s/it, lr=1e-5, step_loss=0.0138]Steps:   1%|▏         | 14451/1000000 [3:40:53<2607:13:51,  9.52s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [14451], local_loss=0.010906873270869255, train_loss=0.14712923765182495, time_cost=1.7107875347137451
Steps:   1%|▏         | 14451/1000000 [3:40:53<2607:13:51,  9.52s/it, lr=1e-5, step_loss=0.0109]Steps:   1%|▏         | 14452/1000000 [3:40:59<2367:10:56,  8.65s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [14452], local_loss=0.03171927109360695, train_loss=0.013483557850122452, time_cost=2.4950602054595947
Steps:   1%|▏         | 14452/1000000 [3:40:59<2367:10:56,  8.65s/it, lr=1e-5, step_loss=0.0317]Steps:   1%|▏         | 14453/1000000 [3:41:08<2396:22:41,  8.75s/it, lr=1e-5, step_loss=0.0317][RANK-0]: Step: [14453], local_loss=0.00979459285736084, train_loss=0.017066016793251038, time_cost=4.171120643615723
Steps:   1%|▏         | 14453/1000000 [3:41:08<2396:22:41,  8.75s/it, lr=1e-5, step_loss=0.00979]Steps:   1%|▏         | 14454/1000000 [3:41:14<2165:10:38,  7.91s/it, lr=1e-5, step_loss=0.00979][RANK-0]: Step: [14454], local_loss=0.031656038016080856, train_loss=0.12533296644687653, time_cost=3.048931360244751
Steps:   1%|▏         | 14454/1000000 [3:41:14<2165:10:38,  7.91s/it, lr=1e-5, step_loss=0.0317] Steps:   1%|▏         | 14455/1000000 [3:41:19<1916:25:51,  7.00s/it, lr=1e-5, step_loss=0.0317][RANK-0]: Step: [14455], local_loss=0.010331735946238041, train_loss=0.02839791215956211, time_cost=2.3858325481414795
Steps:   1%|▏         | 14455/1000000 [3:41:19<1916:25:51,  7.00s/it, lr=1e-5, step_loss=0.0103]Steps:   1%|▏         | 14456/1000000 [3:41:26<1925:22:51,  7.03s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [14456], local_loss=0.056610457599163055, train_loss=0.1555284559726715, time_cost=2.7841804027557373
Steps:   1%|▏         | 14456/1000000 [3:41:26<1925:22:51,  7.03s/it, lr=1e-5, step_loss=0.0566]Steps:   1%|▏         | 14457/1000000 [3:41:31<1733:48:08,  6.33s/it, lr=1e-5, step_loss=0.0566][RANK-0]: Step: [14457], local_loss=0.009901770390570164, train_loss=0.026155617088079453, time_cost=1.9461009502410889
Steps:   1%|▏         | 14457/1000000 [3:41:31<1733:48:08,  6.33s/it, lr=1e-5, step_loss=0.0099]Steps:   1%|▏         | 14458/1000000 [3:41:38<1798:39:32,  6.57s/it, lr=1e-5, step_loss=0.0099][RANK-0]: Step: [14458], local_loss=0.17369000613689423, train_loss=0.0968814343214035, time_cost=2.494429349899292
Steps:   1%|▏         | 14458/1000000 [3:41:38<1798:39:32,  6.57s/it, lr=1e-5, step_loss=0.174] Steps:   1%|▏         | 14459/1000000 [3:41:52<2400:18:43,  8.77s/it, lr=1e-5, step_loss=0.174][RANK-0]: Step: [14459], local_loss=0.03210507333278656, train_loss=0.0378967821598053, time_cost=5.511459112167358
Steps:   1%|▏         | 14459/1000000 [3:41:52<2400:18:43,  8.77s/it, lr=1e-5, step_loss=0.0321]Steps:   1%|▏         | 14460/1000000 [3:42:08<3020:26:50, 11.03s/it, lr=1e-5, step_loss=0.0321][RANK-0]: Step: [14460], local_loss=0.024914881214499474, train_loss=0.04046633467078209, time_cost=12.07249927520752
Steps:   1%|▏         | 14460/1000000 [3:42:08<3020:26:50, 11.03s/it, lr=1e-5, step_loss=0.0249]Steps:   1%|▏         | 14461/1000000 [3:42:20<3048:57:18, 11.14s/it, lr=1e-5, step_loss=0.0249][RANK-0]: Step: [14461], local_loss=0.016388585790991783, train_loss=0.05076517537236214, time_cost=2.3590614795684814
Steps:   1%|▏         | 14461/1000000 [3:42:20<3048:57:18, 11.14s/it, lr=1e-5, step_loss=0.0164]Steps:   1%|▏         | 14462/1000000 [3:42:31<3041:25:12, 11.11s/it, lr=1e-5, step_loss=0.0164][RANK-0]: Step: [14462], local_loss=0.01169670931994915, train_loss=0.021358102560043335, time_cost=3.4442412853240967
Steps:   1%|▏         | 14462/1000000 [3:42:31<3041:25:12, 11.11s/it, lr=1e-5, step_loss=0.0117]Steps:   1%|▏         | 14463/1000000 [3:42:35<2517:27:34,  9.20s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [14463], local_loss=0.015108789317309856, train_loss=0.059160731732845306, time_cost=1.7452549934387207
Steps:   1%|▏         | 14463/1000000 [3:42:35<2517:27:34,  9.20s/it, lr=1e-5, step_loss=0.0151]Steps:   1%|▏         | 14464/1000000 [3:42:50<2991:20:52, 10.93s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [14464], local_loss=0.06165404990315437, train_loss=0.041531600058078766, time_cost=6.735465049743652
Steps:   1%|▏         | 14464/1000000 [3:42:50<2991:20:52, 10.93s/it, lr=1e-5, step_loss=0.0617]Steps:   1%|▏         | 14465/1000000 [3:42:58<2714:34:15,  9.92s/it, lr=1e-5, step_loss=0.0617][RANK-0]: Step: [14465], local_loss=0.019417526200413704, train_loss=0.02901039831340313, time_cost=4.494375467300415
Steps:   1%|▏         | 14465/1000000 [3:42:58<2714:34:15,  9.92s/it, lr=1e-5, step_loss=0.0194]Steps:   1%|▏         | 14466/1000000 [3:43:04<2365:54:12,  8.64s/it, lr=1e-5, step_loss=0.0194][RANK-0]: Step: [14466], local_loss=0.007411320228129625, train_loss=0.09344395995140076, time_cost=2.882761240005493
Steps:   1%|▏         | 14466/1000000 [3:43:04<2365:54:12,  8.64s/it, lr=1e-5, step_loss=0.00741]Steps:   1%|▏         | 14467/1000000 [3:43:11<2225:04:17,  8.13s/it, lr=1e-5, step_loss=0.00741][RANK-0]: Step: [14467], local_loss=0.38487064838409424, train_loss=0.08580903708934784, time_cost=1.854731559753418
Steps:   1%|▏         | 14467/1000000 [3:43:11<2225:04:17,  8.13s/it, lr=1e-5, step_loss=0.385]  Steps:   1%|▏         | 14468/1000000 [3:43:22<2468:47:48,  9.02s/it, lr=1e-5, step_loss=0.385][RANK-0]: Step: [14468], local_loss=0.013997159898281097, train_loss=0.05088870972394943, time_cost=2.1179726123809814
Steps:   1%|▏         | 14468/1000000 [3:43:22<2468:47:48,  9.02s/it, lr=1e-5, step_loss=0.014]Steps:   1%|▏         | 14469/1000000 [3:43:28<2272:14:46,  8.30s/it, lr=1e-5, step_loss=0.014][RANK-0]: Step: [14469], local_loss=0.012943558394908905, train_loss=0.01403967384248972, time_cost=1.2198827266693115
Steps:   1%|▏         | 14469/1000000 [3:43:28<2272:14:46,  8.30s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 14470/1000000 [3:43:43<2824:37:23, 10.32s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [14470], local_loss=0.010174525901675224, train_loss=0.09242096543312073, time_cost=2.2263050079345703
Steps:   1%|▏         | 14470/1000000 [3:43:43<2824:37:23, 10.32s/it, lr=1e-5, step_loss=0.0102]Steps:   1%|▏         | 14471/1000000 [3:43:48<2392:47:56,  8.74s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [14471], local_loss=0.016527554020285606, train_loss=0.025096029043197632, time_cost=1.2027606964111328
Steps:   1%|▏         | 14471/1000000 [3:43:48<2392:47:56,  8.74s/it, lr=1e-5, step_loss=0.0165]Steps:   1%|▏         | 14472/1000000 [3:44:00<2640:23:23,  9.64s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [14472], local_loss=0.11410535126924515, train_loss=0.03957274556159973, time_cost=4.950367450714111
Steps:   1%|▏         | 14472/1000000 [3:44:00<2640:23:23,  9.64s/it, lr=1e-5, step_loss=0.114] Steps:   1%|▏         | 14473/1000000 [3:44:06<2324:38:49,  8.49s/it, lr=1e-5, step_loss=0.114][RANK-0]: Step: [14473], local_loss=0.030566100031137466, train_loss=0.03395284339785576, time_cost=1.7121403217315674
Steps:   1%|▏         | 14473/1000000 [3:44:06<2324:38:49,  8.49s/it, lr=1e-5, step_loss=0.0306]Steps:   1%|▏         | 14474/1000000 [3:44:15<2377:41:42,  8.69s/it, lr=1e-5, step_loss=0.0306][RANK-0]: Step: [14474], local_loss=0.02888292819261551, train_loss=0.09712720662355423, time_cost=2.397289991378784
Steps:   1%|▏         | 14474/1000000 [3:44:15<2377:41:42,  8.69s/it, lr=1e-5, step_loss=0.0289]Steps:   1%|▏         | 14475/1000000 [3:44:26<2599:41:12,  9.50s/it, lr=1e-5, step_loss=0.0289][RANK-0]: Step: [14475], local_loss=0.025035254657268524, train_loss=0.12715336680412292, time_cost=6.0310118198394775
Steps:   1%|▏         | 14475/1000000 [3:44:26<2599:41:12,  9.50s/it, lr=1e-5, step_loss=0.025] Steps:   1%|▏         | 14476/1000000 [3:44:34<2407:16:39,  8.79s/it, lr=1e-5, step_loss=0.025][RANK-0]: Step: [14476], local_loss=0.021194884553551674, train_loss=0.028997762128710747, time_cost=2.748044490814209
Steps:   1%|▏         | 14476/1000000 [3:44:34<2407:16:39,  8.79s/it, lr=1e-5, step_loss=0.0212]Steps:   1%|▏         | 14477/1000000 [3:44:38<2064:58:15,  7.54s/it, lr=1e-5, step_loss=0.0212][RANK-0]: Step: [14477], local_loss=0.033867478370666504, train_loss=0.2020861804485321, time_cost=2.3328378200531006
Steps:   1%|▏         | 14477/1000000 [3:44:38<2064:58:15,  7.54s/it, lr=1e-5, step_loss=0.0339]Steps:   1%|▏         | 14478/1000000 [3:44:47<2164:31:23,  7.91s/it, lr=1e-5, step_loss=0.0339][RANK-0]: Step: [14478], local_loss=0.0585506409406662, train_loss=0.03749625012278557, time_cost=1.921830415725708
Steps:   1%|▏         | 14478/1000000 [3:44:47<2164:31:23,  7.91s/it, lr=1e-5, step_loss=0.0586]Steps:   1%|▏         | 14479/1000000 [3:44:56<2254:05:21,  8.23s/it, lr=1e-5, step_loss=0.0586][RANK-0]: Step: [14479], local_loss=0.08872917294502258, train_loss=0.04154708981513977, time_cost=1.2517240047454834
Steps:   1%|▏         | 14479/1000000 [3:44:56<2254:05:21,  8.23s/it, lr=1e-5, step_loss=0.0887]Steps:   1%|▏         | 14480/1000000 [3:45:04<2209:23:48,  8.07s/it, lr=1e-5, step_loss=0.0887][RANK-0]: Step: [14480], local_loss=0.021753137931227684, train_loss=0.02329101413488388, time_cost=1.228205919265747
Steps:   1%|▏         | 14480/1000000 [3:45:04<2209:23:48,  8.07s/it, lr=1e-5, step_loss=0.0218]Steps:   1%|▏         | 14481/1000000 [3:45:09<2014:49:21,  7.36s/it, lr=1e-5, step_loss=0.0218][RANK-0]: Step: [14481], local_loss=0.005075419787317514, train_loss=0.14980313181877136, time_cost=1.4146289825439453
Steps:   1%|▏         | 14481/1000000 [3:45:09<2014:49:21,  7.36s/it, lr=1e-5, step_loss=0.00508]Steps:   1%|▏         | 14482/1000000 [3:45:18<2123:31:08,  7.76s/it, lr=1e-5, step_loss=0.00508][RANK-0]: Step: [14482], local_loss=0.07455328106880188, train_loss=0.033686526119709015, time_cost=2.941002130508423
Steps:   1%|▏         | 14482/1000000 [3:45:18<2123:31:08,  7.76s/it, lr=1e-5, step_loss=0.0746] Steps:   1%|▏         | 14483/1000000 [3:45:31<2570:14:58,  9.39s/it, lr=1e-5, step_loss=0.0746][RANK-0]: Step: [14483], local_loss=0.04440584033727646, train_loss=0.021548792719841003, time_cost=6.924813985824585
Steps:   1%|▏         | 14483/1000000 [3:45:31<2570:14:58,  9.39s/it, lr=1e-5, step_loss=0.0444]Steps:   1%|▏         | 14484/1000000 [3:45:42<2719:48:14,  9.94s/it, lr=1e-5, step_loss=0.0444][RANK-0]: Step: [14484], local_loss=0.023078221827745438, train_loss=0.016061585396528244, time_cost=2.59590220451355
Steps:   1%|▏         | 14484/1000000 [3:45:42<2719:48:14,  9.94s/it, lr=1e-5, step_loss=0.0231]Steps:   1%|▏         | 14485/1000000 [3:45:56<2997:44:46, 10.95s/it, lr=1e-5, step_loss=0.0231][RANK-0]: Step: [14485], local_loss=0.016963325440883636, train_loss=0.05026848614215851, time_cost=9.836309909820557
Steps:   1%|▏         | 14485/1000000 [3:45:56<2997:44:46, 10.95s/it, lr=1e-5, step_loss=0.017] Steps:   1%|▏         | 14486/1000000 [3:46:09<3215:22:50, 11.75s/it, lr=1e-5, step_loss=0.017][RANK-0]: Step: [14486], local_loss=0.07616055756807327, train_loss=0.02991982363164425, time_cost=4.291054010391235
Steps:   1%|▏         | 14486/1000000 [3:46:09<3215:22:50, 11.75s/it, lr=1e-5, step_loss=0.0762]Steps:   1%|▏         | 14487/1000000 [3:46:18<3003:55:29, 10.97s/it, lr=1e-5, step_loss=0.0762][RANK-0]: Step: [14487], local_loss=0.011303117498755455, train_loss=0.05277293920516968, time_cost=3.318760395050049
Steps:   1%|▏         | 14487/1000000 [3:46:18<3003:55:29, 10.97s/it, lr=1e-5, step_loss=0.0113]Steps:   1%|▏         | 14488/1000000 [3:46:25<2670:26:11,  9.75s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [14488], local_loss=0.00865038949996233, train_loss=0.15919162333011627, time_cost=1.2914915084838867
Steps:   1%|▏         | 14488/1000000 [3:46:25<2670:26:11,  9.75s/it, lr=1e-5, step_loss=0.00865]Steps:   1%|▏         | 14489/1000000 [3:46:32<2448:59:45,  8.95s/it, lr=1e-5, step_loss=0.00865][RANK-0]: Step: [14489], local_loss=0.008890163153409958, train_loss=0.026256747543811798, time_cost=2.6903929710388184
Steps:   1%|▏         | 14489/1000000 [3:46:32<2448:59:45,  8.95s/it, lr=1e-5, step_loss=0.00889]Steps:   1%|▏         | 14490/1000000 [3:46:38<2182:28:11,  7.97s/it, lr=1e-5, step_loss=0.00889][RANK-0]: Step: [14490], local_loss=0.033381715416908264, train_loss=0.04688158631324768, time_cost=2.700066566467285
Steps:   1%|▏         | 14490/1000000 [3:46:38<2182:28:11,  7.97s/it, lr=1e-5, step_loss=0.0334] Steps:   1%|▏         | 14491/1000000 [3:46:47<2224:28:23,  8.13s/it, lr=1e-5, step_loss=0.0334][RANK-0]: Step: [14491], local_loss=0.12101853638887405, train_loss=0.03315998986363411, time_cost=1.8535137176513672
Steps:   1%|▏         | 14491/1000000 [3:46:47<2224:28:23,  8.13s/it, lr=1e-5, step_loss=0.121] Steps:   1%|▏         | 14492/1000000 [3:47:01<2703:48:22,  9.88s/it, lr=1e-5, step_loss=0.121][RANK-0]: Step: [14492], local_loss=0.099565789103508, train_loss=0.02385936677455902, time_cost=4.642866373062134
Steps:   1%|▏         | 14492/1000000 [3:47:01<2703:48:22,  9.88s/it, lr=1e-5, step_loss=0.0996]Steps:   1%|▏         | 14493/1000000 [3:47:06<2304:53:10,  8.42s/it, lr=1e-5, step_loss=0.0996][RANK-0]: Step: [14493], local_loss=0.010058498941361904, train_loss=0.01563584804534912, time_cost=2.3895862102508545
Steps:   1%|▏         | 14493/1000000 [3:47:06<2304:53:10,  8.42s/it, lr=1e-5, step_loss=0.0101]Steps:   1%|▏         | 14494/1000000 [3:47:14<2332:35:22,  8.52s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [14494], local_loss=0.19010503590106964, train_loss=0.03998648747801781, time_cost=1.9590284824371338
Steps:   1%|▏         | 14494/1000000 [3:47:14<2332:35:22,  8.52s/it, lr=1e-5, step_loss=0.19]  Steps:   1%|▏         | 14495/1000000 [3:47:24<2462:18:43,  8.99s/it, lr=1e-5, step_loss=0.19][RANK-0]: Step: [14495], local_loss=0.0676659494638443, train_loss=0.16917265951633453, time_cost=8.451897144317627
Steps:   1%|▏         | 14495/1000000 [3:47:24<2462:18:43,  8.99s/it, lr=1e-5, step_loss=0.0677]Steps:   1%|▏         | 14496/1000000 [3:47:38<2850:20:33, 10.41s/it, lr=1e-5, step_loss=0.0677][RANK-0]: Step: [14496], local_loss=0.07478578388690948, train_loss=0.0798829197883606, time_cost=2.092539072036743
Steps:   1%|▏         | 14496/1000000 [3:47:38<2850:20:33, 10.41s/it, lr=1e-5, step_loss=0.0748]Steps:   1%|▏         | 14497/1000000 [3:47:44<2479:30:19,  9.06s/it, lr=1e-5, step_loss=0.0748][RANK-0]: Step: [14497], local_loss=0.03840508684515953, train_loss=0.03669435530900955, time_cost=1.2533035278320312
Steps:   1%|▏         | 14497/1000000 [3:47:44<2479:30:19,  9.06s/it, lr=1e-5, step_loss=0.0384]Steps:   1%|▏         | 14498/1000000 [3:47:50<2201:34:39,  8.04s/it, lr=1e-5, step_loss=0.0384][RANK-0]: Step: [14498], local_loss=115.14026641845703, train_loss=14.425862312316895, time_cost=2.918111801147461
Steps:   1%|▏         | 14498/1000000 [3:47:50<2201:34:39,  8.04s/it, lr=1e-5, step_loss=115]   Steps:   1%|▏         | 14499/1000000 [3:48:01<2432:36:36,  8.89s/it, lr=1e-5, step_loss=115][RANK-0]: Step: [14499], local_loss=0.012200030498206615, train_loss=0.05510815232992172, time_cost=3.555874824523926
Steps:   1%|▏         | 14499/1000000 [3:48:01<2432:36:36,  8.89s/it, lr=1e-5, step_loss=0.0122]Steps:   1%|▏         | 14500/1000000 [3:48:10<2446:05:13,  8.94s/it, lr=1e-5, step_loss=0.0122][RANK-0]: Step: [14500], local_loss=0.011135173961520195, train_loss=0.015330446884036064, time_cost=6.7711381912231445
Steps:   1%|▏         | 14500/1000000 [3:48:10<2446:05:13,  8.94s/it, lr=1e-5, step_loss=0.0111]Steps:   1%|▏         | 14501/1000000 [3:48:16<2218:08:09,  8.10s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [14501], local_loss=0.06508985161781311, train_loss=0.1691705584526062, time_cost=1.8780755996704102
Steps:   1%|▏         | 14501/1000000 [3:48:16<2218:08:09,  8.10s/it, lr=1e-5, step_loss=0.0651]Steps:   1%|▏         | 14502/1000000 [3:48:21<1968:16:22,  7.19s/it, lr=1e-5, step_loss=0.0651][RANK-0]: Step: [14502], local_loss=0.012432838790118694, train_loss=0.020867425948381424, time_cost=2.532747268676758
Steps:   1%|▏         | 14502/1000000 [3:48:21<1968:16:22,  7.19s/it, lr=1e-5, step_loss=0.0124]Steps:   1%|▏         | 14503/1000000 [3:48:35<2511:07:47,  9.17s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [14503], local_loss=0.006309265270829201, train_loss=0.03688867390155792, time_cost=4.484621524810791
Steps:   1%|▏         | 14503/1000000 [3:48:35<2511:07:47,  9.17s/it, lr=1e-5, step_loss=0.00631]Steps:   1%|▏         | 14504/1000000 [3:48:49<2902:36:21, 10.60s/it, lr=1e-5, step_loss=0.00631][RANK-0]: Step: [14504], local_loss=0.014597420580685139, train_loss=0.044498808681964874, time_cost=4.57879114151001
Steps:   1%|▏         | 14504/1000000 [3:48:49<2902:36:21, 10.60s/it, lr=1e-5, step_loss=0.0146] Steps:   1%|▏         | 14505/1000000 [3:49:03<3210:13:42, 11.73s/it, lr=1e-5, step_loss=0.0146][RANK-0]: Step: [14505], local_loss=0.06952168047428131, train_loss=0.02137484773993492, time_cost=5.131584644317627
Steps:   1%|▏         | 14505/1000000 [3:49:03<3210:13:42, 11.73s/it, lr=1e-5, step_loss=0.0695]Steps:   1%|▏         | 14506/1000000 [3:49:12<2975:49:19, 10.87s/it, lr=1e-5, step_loss=0.0695][RANK-0]: Step: [14506], local_loss=0.1404329538345337, train_loss=0.0397762656211853, time_cost=3.578799247741699
Steps:   1%|▏         | 14506/1000000 [3:49:12<2975:49:19, 10.87s/it, lr=1e-5, step_loss=0.14]  Steps:   1%|▏         | 14507/1000000 [3:49:21<2796:21:11, 10.22s/it, lr=1e-5, step_loss=0.14][RANK-0]: Step: [14507], local_loss=0.037639256566762924, train_loss=0.04192159324884415, time_cost=6.323858737945557
Steps:   1%|▏         | 14507/1000000 [3:49:21<2796:21:11, 10.22s/it, lr=1e-5, step_loss=0.0376]Steps:   1%|▏         | 14508/1000000 [3:49:28<2597:01:00,  9.49s/it, lr=1e-5, step_loss=0.0376][RANK-0]: Step: [14508], local_loss=0.04171661660075188, train_loss=0.036872848868370056, time_cost=1.8537507057189941
Steps:   1%|▏         | 14508/1000000 [3:49:28<2597:01:00,  9.49s/it, lr=1e-5, step_loss=0.0417]Steps:   1%|▏         | 14509/1000000 [3:49:34<2244:18:10,  8.20s/it, lr=1e-5, step_loss=0.0417][RANK-0]: Step: [14509], local_loss=0.02130265347659588, train_loss=0.0625562071800232, time_cost=1.2245399951934814
Steps:   1%|▏         | 14509/1000000 [3:49:34<2244:18:10,  8.20s/it, lr=1e-5, step_loss=0.0213]Steps:   1%|▏         | 14510/1000000 [3:49:38<1927:03:22,  7.04s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [14510], local_loss=0.03716004639863968, train_loss=0.04088392108678818, time_cost=1.605456829071045
Steps:   1%|▏         | 14510/1000000 [3:49:38<1927:03:22,  7.04s/it, lr=1e-5, step_loss=0.0372]Steps:   1%|▏         | 14511/1000000 [3:49:44<1847:51:17,  6.75s/it, lr=1e-5, step_loss=0.0372][RANK-0]: Step: [14511], local_loss=0.01206298265606165, train_loss=0.028948193415999413, time_cost=1.3266572952270508
Steps:   1%|▏         | 14511/1000000 [3:49:44<1847:51:17,  6.75s/it, lr=1e-5, step_loss=0.0121]Steps:   1%|▏         | 14512/1000000 [3:49:58<2447:25:06,  8.94s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [14512], local_loss=0.41046643257141113, train_loss=0.2142925262451172, time_cost=2.8464927673339844
Steps:   1%|▏         | 14512/1000000 [3:49:58<2447:25:06,  8.94s/it, lr=1e-5, step_loss=0.41]  Steps:   1%|▏         | 14513/1000000 [3:50:13<2960:47:34, 10.82s/it, lr=1e-5, step_loss=0.41][RANK-0]: Step: [14513], local_loss=0.013874107971787453, train_loss=0.025695910677313805, time_cost=6.777476787567139
Steps:   1%|▏         | 14513/1000000 [3:50:13<2960:47:34, 10.82s/it, lr=1e-5, step_loss=0.0139]Steps:   1%|▏         | 14514/1000000 [3:50:29<3368:10:44, 12.30s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [14514], local_loss=0.006544442381709814, train_loss=0.01668558642268181, time_cost=5.98080587387085
Steps:   1%|▏         | 14514/1000000 [3:50:29<3368:10:44, 12.30s/it, lr=1e-5, step_loss=0.00654]Steps:   1%|▏         | 14515/1000000 [3:50:40<3285:37:02, 12.00s/it, lr=1e-5, step_loss=0.00654][RANK-0]: Step: [14515], local_loss=0.02006658911705017, train_loss=0.030159123241901398, time_cost=1.4825036525726318
Steps:   1%|▏         | 14515/1000000 [3:50:40<3285:37:02, 12.00s/it, lr=1e-5, step_loss=0.0201] Steps:   1%|▏         | 14516/1000000 [3:50:47<2815:53:53, 10.29s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [14516], local_loss=0.017342640087008476, train_loss=0.049203060567379, time_cost=2.030318021774292
Steps:   1%|▏         | 14516/1000000 [3:50:47<2815:53:53, 10.29s/it, lr=1e-5, step_loss=0.0173]Steps:   1%|▏         | 14517/1000000 [3:50:54<2601:03:21,  9.50s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [14517], local_loss=0.036085695028305054, train_loss=0.02773282490670681, time_cost=3.6061198711395264
Steps:   1%|▏         | 14517/1000000 [3:50:54<2601:03:21,  9.50s/it, lr=1e-5, step_loss=0.0361]Steps:   1%|▏         | 14518/1000000 [3:51:01<2381:01:35,  8.70s/it, lr=1e-5, step_loss=0.0361][RANK-0]: Step: [14518], local_loss=0.01550372689962387, train_loss=0.17862282693386078, time_cost=3.0659165382385254
Steps:   1%|▏         | 14518/1000000 [3:51:01<2381:01:35,  8.70s/it, lr=1e-5, step_loss=0.0155]Steps:   1%|▏         | 14519/1000000 [3:51:08<2263:46:15,  8.27s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [14519], local_loss=0.020292378962039948, train_loss=0.011715201660990715, time_cost=3.1731021404266357
Steps:   1%|▏         | 14519/1000000 [3:51:08<2263:46:15,  8.27s/it, lr=1e-5, step_loss=0.0203]Steps:   1%|▏         | 14520/1000000 [3:51:21<2667:36:52,  9.74s/it, lr=1e-5, step_loss=0.0203][RANK-0]: Step: [14520], local_loss=0.0524701327085495, train_loss=0.10011225938796997, time_cost=4.329916477203369
Steps:   1%|▏         | 14520/1000000 [3:51:21<2667:36:52,  9.74s/it, lr=1e-5, step_loss=0.0525]Steps:   1%|▏         | 14521/1000000 [3:51:30<2570:53:49,  9.39s/it, lr=1e-5, step_loss=0.0525][RANK-0]: Step: [14521], local_loss=0.007469822186976671, train_loss=0.024075832217931747, time_cost=1.6852688789367676
Steps:   1%|▏         | 14521/1000000 [3:51:30<2570:53:49,  9.39s/it, lr=1e-5, step_loss=0.00747]Steps:   1%|▏         | 14522/1000000 [3:51:37<2389:26:22,  8.73s/it, lr=1e-5, step_loss=0.00747][RANK-0]: Step: [14522], local_loss=0.01898360252380371, train_loss=0.042131371796131134, time_cost=1.7153856754302979
Steps:   1%|▏         | 14522/1000000 [3:51:37<2389:26:22,  8.73s/it, lr=1e-5, step_loss=0.019]  Steps:   1%|▏         | 14523/1000000 [3:51:42<2092:08:07,  7.64s/it, lr=1e-5, step_loss=0.019][RANK-0]: Step: [14523], local_loss=0.014238793402910233, train_loss=0.0453624352812767, time_cost=2.2692763805389404
Steps:   1%|▏         | 14523/1000000 [3:51:42<2092:08:07,  7.64s/it, lr=1e-5, step_loss=0.0142]Steps:   1%|▏         | 14524/1000000 [3:51:54<2398:54:27,  8.76s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [14524], local_loss=0.007050089072436094, train_loss=0.030864417552947998, time_cost=3.327563762664795
Steps:   1%|▏         | 14524/1000000 [3:51:54<2398:54:27,  8.76s/it, lr=1e-5, step_loss=0.00705]Steps:   1%|▏         | 14525/1000000 [3:52:02<2397:58:27,  8.76s/it, lr=1e-5, step_loss=0.00705][RANK-0]: Step: [14525], local_loss=0.11337967216968536, train_loss=0.06182107329368591, time_cost=2.5459771156311035
Steps:   1%|▏         | 14525/1000000 [3:52:02<2397:58:27,  8.76s/it, lr=1e-5, step_loss=0.113]  Steps:   1%|▏         | 14526/1000000 [3:52:09<2178:43:09,  7.96s/it, lr=1e-5, step_loss=0.113][RANK-0]: Step: [14526], local_loss=0.014748765155673027, train_loss=0.03647053241729736, time_cost=1.5746619701385498
Steps:   1%|▏         | 14526/1000000 [3:52:09<2178:43:09,  7.96s/it, lr=1e-5, step_loss=0.0147]Steps:   1%|▏         | 14527/1000000 [3:52:19<2403:24:43,  8.78s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [14527], local_loss=0.14281338453292847, train_loss=0.033225078135728836, time_cost=1.6412138938903809
Steps:   1%|▏         | 14527/1000000 [3:52:19<2403:24:43,  8.78s/it, lr=1e-5, step_loss=0.143] Steps:   1%|▏         | 14528/1000000 [3:52:24<2036:16:37,  7.44s/it, lr=1e-5, step_loss=0.143][RANK-0]: Step: [14528], local_loss=0.0250526275485754, train_loss=0.1434258371591568, time_cost=1.2237651348114014
Steps:   1%|▏         | 14528/1000000 [3:52:24<2036:16:37,  7.44s/it, lr=1e-5, step_loss=0.0251]Steps:   1%|▏         | 14529/1000000 [3:52:31<2008:48:02,  7.34s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [14529], local_loss=0.007927000522613525, train_loss=0.030990513041615486, time_cost=1.4157345294952393
Steps:   1%|▏         | 14529/1000000 [3:52:31<2008:48:02,  7.34s/it, lr=1e-5, step_loss=0.00793]Steps:   1%|▏         | 14530/1000000 [3:52:44<2512:52:55,  9.18s/it, lr=1e-5, step_loss=0.00793][RANK-0]: Step: [14530], local_loss=0.04001782462000847, train_loss=0.0916774570941925, time_cost=1.3815476894378662
Steps:   1%|▏         | 14530/1000000 [3:52:44<2512:52:55,  9.18s/it, lr=1e-5, step_loss=0.04]   Steps:   1%|▏         | 14531/1000000 [3:52:49<2184:40:36,  7.98s/it, lr=1e-5, step_loss=0.04][RANK-0]: Step: [14531], local_loss=0.2677679657936096, train_loss=0.06205632537603378, time_cost=4.339561700820923
Steps:   1%|▏         | 14531/1000000 [3:52:49<2184:40:36,  7.98s/it, lr=1e-5, step_loss=0.268]Steps:   1%|▏         | 14532/1000000 [3:53:06<2932:00:11, 10.71s/it, lr=1e-5, step_loss=0.268][RANK-0]: Step: [14532], local_loss=0.02259828709065914, train_loss=15.275247573852539, time_cost=4.4436585903167725
Steps:   1%|▏         | 14532/1000000 [3:53:06<2932:00:11, 10.71s/it, lr=1e-5, step_loss=0.0226]Steps:   1%|▏         | 14533/1000000 [3:53:13<2594:04:07,  9.48s/it, lr=1e-5, step_loss=0.0226][RANK-0]: Step: [14533], local_loss=0.02396424487233162, train_loss=0.04367504268884659, time_cost=2.4622185230255127
Steps:   1%|▏         | 14533/1000000 [3:53:13<2594:04:07,  9.48s/it, lr=1e-5, step_loss=0.024] Steps:   1%|▏         | 14534/1000000 [3:53:26<2911:28:11, 10.64s/it, lr=1e-5, step_loss=0.024][RANK-0]: Step: [14534], local_loss=0.03404005244374275, train_loss=0.04316100850701332, time_cost=1.2306742668151855
Steps:   1%|▏         | 14534/1000000 [3:53:26<2911:28:11, 10.64s/it, lr=1e-5, step_loss=0.034]Steps:   1%|▏         | 14535/1000000 [3:53:42<3309:20:44, 12.09s/it, lr=1e-5, step_loss=0.034][RANK-0]: Step: [14535], local_loss=0.07987777888774872, train_loss=0.02779197134077549, time_cost=7.384159803390503
Steps:   1%|▏         | 14535/1000000 [3:53:42<3309:20:44, 12.09s/it, lr=1e-5, step_loss=0.0799]Steps:   1%|▏         | 14536/1000000 [3:53:53<3255:51:02, 11.89s/it, lr=1e-5, step_loss=0.0799][RANK-0]: Step: [14536], local_loss=0.038858331739902496, train_loss=0.02131474018096924, time_cost=4.495136499404907
Steps:   1%|▏         | 14536/1000000 [3:53:53<3255:51:02, 11.89s/it, lr=1e-5, step_loss=0.0389]Steps:   1%|▏         | 14537/1000000 [3:54:00<2798:37:46, 10.22s/it, lr=1e-5, step_loss=0.0389][RANK-0]: Step: [14537], local_loss=0.004973786883056164, train_loss=0.031613051891326904, time_cost=1.6716771125793457
Steps:   1%|▏         | 14537/1000000 [3:54:00<2798:37:46, 10.22s/it, lr=1e-5, step_loss=0.00497]Steps:   1%|▏         | 14538/1000000 [3:54:12<2997:47:38, 10.95s/it, lr=1e-5, step_loss=0.00497][RANK-0]: Step: [14538], local_loss=0.010008150711655617, train_loss=0.059680625796318054, time_cost=2.927312135696411
Steps:   1%|▏         | 14538/1000000 [3:54:12<2997:47:38, 10.95s/it, lr=1e-5, step_loss=0.01]   Steps:   1%|▏         | 14539/1000000 [3:54:22<2914:58:16, 10.65s/it, lr=1e-5, step_loss=0.01][RANK-0]: Step: [14539], local_loss=0.22467803955078125, train_loss=0.0369531624019146, time_cost=2.149521827697754
Steps:   1%|▏         | 14539/1000000 [3:54:22<2914:58:16, 10.65s/it, lr=1e-5, step_loss=0.225]Steps:   1%|▏         | 14540/1000000 [3:54:29<2637:14:41,  9.63s/it, lr=1e-5, step_loss=0.225][RANK-0]: Step: [14540], local_loss=0.0058050905354321, train_loss=0.032553065568208694, time_cost=2.6096031665802
Steps:   1%|▏         | 14540/1000000 [3:54:29<2637:14:41,  9.63s/it, lr=1e-5, step_loss=0.00581]Steps:   1%|▏         | 14541/1000000 [3:54:40<2717:20:17,  9.93s/it, lr=1e-5, step_loss=0.00581][RANK-0]: Step: [14541], local_loss=0.01592911034822464, train_loss=0.21892960369586945, time_cost=3.3879637718200684
Steps:   1%|▏         | 14541/1000000 [3:54:40<2717:20:17,  9.93s/it, lr=1e-5, step_loss=0.0159] Steps:   1%|▏         | 14542/1000000 [3:54:52<2870:14:12, 10.49s/it, lr=1e-5, step_loss=0.0159][RANK-0]: Step: [14542], local_loss=0.05357716977596283, train_loss=0.03106033243238926, time_cost=1.2163538932800293
Steps:   1%|▏         | 14542/1000000 [3:54:52<2870:14:12, 10.49s/it, lr=1e-5, step_loss=0.0536]Steps:   1%|▏         | 14543/1000000 [3:55:06<3193:32:23, 11.67s/it, lr=1e-5, step_loss=0.0536][RANK-0]: Step: [14543], local_loss=0.06294271349906921, train_loss=0.049327053129673004, time_cost=4.711332321166992
Steps:   1%|▏         | 14543/1000000 [3:55:06<3193:32:23, 11.67s/it, lr=1e-5, step_loss=0.0629]Steps:   1%|▏         | 14544/1000000 [3:55:13<2791:00:24, 10.20s/it, lr=1e-5, step_loss=0.0629][RANK-0]: Step: [14544], local_loss=0.0364326648414135, train_loss=0.1097848117351532, time_cost=3.2159371376037598
Steps:   1%|▏         | 14544/1000000 [3:55:13<2791:00:24, 10.20s/it, lr=1e-5, step_loss=0.0364]Steps:   1%|▏         | 14545/1000000 [3:55:24<2862:57:43, 10.46s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [14545], local_loss=0.007372621446847916, train_loss=0.05557575821876526, time_cost=1.9095299243927002
Steps:   1%|▏         | 14545/1000000 [3:55:24<2862:57:43, 10.46s/it, lr=1e-5, step_loss=0.00737]Steps:   1%|▏         | 14546/1000000 [3:55:38<3147:31:28, 11.50s/it, lr=1e-5, step_loss=0.00737][RANK-0]: Step: [14546], local_loss=0.010273181833326817, train_loss=0.04357389733195305, time_cost=1.2438583374023438
Steps:   1%|▏         | 14546/1000000 [3:55:38<3147:31:28, 11.50s/it, lr=1e-5, step_loss=0.0103] Steps:   1%|▏         | 14547/1000000 [3:55:43<2599:37:31,  9.50s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [14547], local_loss=0.007088837679475546, train_loss=0.01994231902062893, time_cost=1.6441254615783691
Steps:   1%|▏         | 14547/1000000 [3:55:43<2599:37:31,  9.50s/it, lr=1e-5, step_loss=0.00709]Steps:   1%|▏         | 14548/1000000 [3:55:47<2194:35:15,  8.02s/it, lr=1e-5, step_loss=0.00709][RANK-0]: Step: [14548], local_loss=0.026674456894397736, train_loss=0.024350445717573166, time_cost=1.2262563705444336
Steps:   1%|▏         | 14548/1000000 [3:55:47<2194:35:15,  8.02s/it, lr=1e-5, step_loss=0.0267] Steps:   1%|▏         | 14549/1000000 [3:55:55<2178:27:52,  7.96s/it, lr=1e-5, step_loss=0.0267][RANK-0]: Step: [14549], local_loss=0.04003457725048065, train_loss=0.03604993224143982, time_cost=1.1922566890716553
Steps:   1%|▏         | 14549/1000000 [3:55:55<2178:27:52,  7.96s/it, lr=1e-5, step_loss=0.04]  Steps:   1%|▏         | 14550/1000000 [3:56:00<1908:34:41,  6.97s/it, lr=1e-5, step_loss=0.04][RANK-0]: Step: [14550], local_loss=0.0037952959537506104, train_loss=0.022357895970344543, time_cost=1.2084429264068604
Steps:   1%|▏         | 14550/1000000 [3:56:00<1908:34:41,  6.97s/it, lr=1e-5, step_loss=0.0038]Steps:   1%|▏         | 14551/1000000 [3:56:06<1808:36:47,  6.61s/it, lr=1e-5, step_loss=0.0038][RANK-0]: Step: [14551], local_loss=0.027481714263558388, train_loss=0.025180399417877197, time_cost=2.8805670738220215
Steps:   1%|▏         | 14551/1000000 [3:56:06<1808:36:47,  6.61s/it, lr=1e-5, step_loss=0.0275]Steps:   1%|▏         | 14552/1000000 [3:56:11<1714:15:34,  6.26s/it, lr=1e-5, step_loss=0.0275][RANK-0]: Step: [14552], local_loss=0.037195995450019836, train_loss=0.09169454872608185, time_cost=1.451070785522461
Steps:   1%|▏         | 14552/1000000 [3:56:11<1714:15:34,  6.26s/it, lr=1e-5, step_loss=0.0372]Steps:   1%|▏         | 14553/1000000 [3:56:18<1800:07:53,  6.58s/it, lr=1e-5, step_loss=0.0372][RANK-0]: Step: [14553], local_loss=0.011751738376915455, train_loss=0.020394600927829742, time_cost=2.5312044620513916
Steps:   1%|▏         | 14553/1000000 [3:56:18<1800:07:53,  6.58s/it, lr=1e-5, step_loss=0.0118]Steps:   1%|▏         | 14554/1000000 [3:56:29<2164:26:40,  7.91s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [14554], local_loss=0.04990339279174805, train_loss=0.030074546113610268, time_cost=7.989263296127319
Steps:   1%|▏         | 14554/1000000 [3:56:29<2164:26:40,  7.91s/it, lr=1e-5, step_loss=0.0499]Steps:   1%|▏         | 14555/1000000 [3:56:39<2322:37:17,  8.48s/it, lr=1e-5, step_loss=0.0499][RANK-0]: Step: [14555], local_loss=0.0472852885723114, train_loss=0.04917284846305847, time_cost=1.8040149211883545
Steps:   1%|▏         | 14555/1000000 [3:56:39<2322:37:17,  8.48s/it, lr=1e-5, step_loss=0.0473]Steps:   1%|▏         | 14556/1000000 [3:56:45<2077:21:21,  7.59s/it, lr=1e-5, step_loss=0.0473][RANK-0]: Step: [14556], local_loss=0.01873146742582321, train_loss=0.035420238971710205, time_cost=1.554931402206421
Steps:   1%|▏         | 14556/1000000 [3:56:45<2077:21:21,  7.59s/it, lr=1e-5, step_loss=0.0187]Steps:   1%|▏         | 14557/1000000 [3:56:49<1807:54:47,  6.60s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [14557], local_loss=0.005776859354227781, train_loss=0.07825543731451035, time_cost=1.3873083591461182
Steps:   1%|▏         | 14557/1000000 [3:56:49<1807:54:47,  6.60s/it, lr=1e-5, step_loss=0.00578]Steps:   1%|▏         | 14558/1000000 [3:57:00<2199:44:56,  8.04s/it, lr=1e-5, step_loss=0.00578][RANK-0]: Step: [14558], local_loss=0.049111876636743546, train_loss=0.08200894296169281, time_cost=1.8816092014312744
Steps:   1%|▏         | 14558/1000000 [3:57:00<2199:44:56,  8.04s/it, lr=1e-5, step_loss=0.0491] Steps:   1%|▏         | 14559/1000000 [3:57:14<2618:16:43,  9.57s/it, lr=1e-5, step_loss=0.0491][RANK-0]: Step: [14559], local_loss=0.03178580105304718, train_loss=0.02168979123234749, time_cost=11.024041414260864
Steps:   1%|▏         | 14559/1000000 [3:57:14<2618:16:43,  9.57s/it, lr=1e-5, step_loss=0.0318]Steps:   1%|▏         | 14560/1000000 [3:57:20<2366:25:39,  8.65s/it, lr=1e-5, step_loss=0.0318][RANK-0]: Step: [14560], local_loss=0.03565547987818718, train_loss=0.02984839677810669, time_cost=2.1647324562072754
Steps:   1%|▏         | 14560/1000000 [3:57:20<2366:25:39,  8.65s/it, lr=1e-5, step_loss=0.0357]Steps:   1%|▏         | 14561/1000000 [3:57:31<2579:41:01,  9.42s/it, lr=1e-5, step_loss=0.0357][RANK-0]: Step: [14561], local_loss=0.00817162450402975, train_loss=0.03457563742995262, time_cost=3.9859044551849365
Steps:   1%|▏         | 14561/1000000 [3:57:31<2579:41:01,  9.42s/it, lr=1e-5, step_loss=0.00817]Steps:   1%|▏         | 14562/1000000 [3:57:36<2225:10:17,  8.13s/it, lr=1e-5, step_loss=0.00817][RANK-0]: Step: [14562], local_loss=0.012689180672168732, train_loss=0.011359324678778648, time_cost=2.638629674911499
Steps:   1%|▏         | 14562/1000000 [3:57:36<2225:10:17,  8.13s/it, lr=1e-5, step_loss=0.0127] Steps:   1%|▏         | 14563/1000000 [3:57:46<2306:05:24,  8.42s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [14563], local_loss=1.0044530630111694, train_loss=0.1499565988779068, time_cost=3.266735553741455
Steps:   1%|▏         | 14563/1000000 [3:57:46<2306:05:24,  8.42s/it, lr=1e-5, step_loss=1]     Steps:   1%|▏         | 14564/1000000 [3:57:59<2684:36:04,  9.81s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [14564], local_loss=0.015472833067178726, train_loss=0.01941712573170662, time_cost=1.3414204120635986
Steps:   1%|▏         | 14564/1000000 [3:57:59<2684:36:04,  9.81s/it, lr=1e-5, step_loss=0.0155]Steps:   1%|▏         | 14565/1000000 [3:58:05<2424:42:40,  8.86s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [14565], local_loss=0.028310419991612434, train_loss=0.02249854989349842, time_cost=3.030341148376465
Steps:   1%|▏         | 14565/1000000 [3:58:05<2424:42:40,  8.86s/it, lr=1e-5, step_loss=0.0283]Steps:   1%|▏         | 14566/1000000 [3:58:10<2115:10:42,  7.73s/it, lr=1e-5, step_loss=0.0283][RANK-0]: Step: [14566], local_loss=0.05402405560016632, train_loss=0.03150000050663948, time_cost=2.273684024810791
Steps:   1%|▏         | 14566/1000000 [3:58:10<2115:10:42,  7.73s/it, lr=1e-5, step_loss=0.054] Steps:   1%|▏         | 14567/1000000 [3:58:15<1841:23:58,  6.73s/it, lr=1e-5, step_loss=0.054][RANK-0]: Step: [14567], local_loss=0.0077075110748410225, train_loss=0.041615720838308334, time_cost=1.6503562927246094
Steps:   1%|▏         | 14567/1000000 [3:58:15<1841:23:58,  6.73s/it, lr=1e-5, step_loss=0.00771]Steps:   1%|▏         | 14568/1000000 [3:58:28<2338:23:18,  8.54s/it, lr=1e-5, step_loss=0.00771][RANK-0]: Step: [14568], local_loss=0.005754211451858282, train_loss=0.030002128332853317, time_cost=5.255432605743408
Steps:   1%|▏         | 14568/1000000 [3:58:28<2338:23:18,  8.54s/it, lr=1e-5, step_loss=0.00575]Steps:   1%|▏         | 14569/1000000 [3:58:39<2547:28:40,  9.31s/it, lr=1e-5, step_loss=0.00575][RANK-0]: Step: [14569], local_loss=0.016405535861849785, train_loss=0.014719583094120026, time_cost=1.9897127151489258
Steps:   1%|▏         | 14569/1000000 [3:58:39<2547:28:40,  9.31s/it, lr=1e-5, step_loss=0.0164] Steps:   1%|▏         | 14570/1000000 [3:58:55<3100:30:39, 11.33s/it, lr=1e-5, step_loss=0.0164][RANK-0]: Step: [14570], local_loss=0.008842509239912033, train_loss=0.017207764089107513, time_cost=8.504846572875977
Steps:   1%|▏         | 14570/1000000 [3:58:55<3100:30:39, 11.33s/it, lr=1e-5, step_loss=0.00884]Steps:   1%|▏         | 14571/1000000 [3:59:07<3181:02:10, 11.62s/it, lr=1e-5, step_loss=0.00884][RANK-0]: Step: [14571], local_loss=0.026484625414013863, train_loss=0.1431855410337448, time_cost=2.937407970428467
Steps:   1%|▏         | 14571/1000000 [3:59:07<3181:02:10, 11.62s/it, lr=1e-5, step_loss=0.0265] Steps:   1%|▏         | 14572/1000000 [3:59:16<2966:33:16, 10.84s/it, lr=1e-5, step_loss=0.0265][RANK-0]: Step: [14572], local_loss=0.004690936300903559, train_loss=0.10834961384534836, time_cost=2.9169795513153076
Steps:   1%|▏         | 14572/1000000 [3:59:16<2966:33:16, 10.84s/it, lr=1e-5, step_loss=0.00469]Steps:   1%|▏         | 14573/1000000 [3:59:21<2502:09:41,  9.14s/it, lr=1e-5, step_loss=0.00469][RANK-0]: Step: [14573], local_loss=0.007938600145280361, train_loss=0.0496477372944355, time_cost=1.387364387512207
Steps:   1%|▏         | 14573/1000000 [3:59:21<2502:09:41,  9.14s/it, lr=1e-5, step_loss=0.00794]Steps:   1%|▏         | 14574/1000000 [3:59:34<2802:34:14, 10.24s/it, lr=1e-5, step_loss=0.00794][RANK-0]: Step: [14574], local_loss=0.0034821818117052317, train_loss=0.02677168883383274, time_cost=10.82869029045105
Steps:   1%|▏         | 14574/1000000 [3:59:34<2802:34:14, 10.24s/it, lr=1e-5, step_loss=0.00348]Steps:   1%|▏         | 14575/1000000 [3:59:46<2928:09:47, 10.70s/it, lr=1e-5, step_loss=0.00348][RANK-0]: Step: [14575], local_loss=0.06916476786136627, train_loss=0.023198433220386505, time_cost=2.733978509902954
Steps:   1%|▏         | 14575/1000000 [3:59:46<2928:09:47, 10.70s/it, lr=1e-5, step_loss=0.0692] Steps:   1%|▏         | 14576/1000000 [3:59:55<2853:49:41, 10.43s/it, lr=1e-5, step_loss=0.0692][RANK-0]: Step: [14576], local_loss=0.020051956176757812, train_loss=0.014243845827877522, time_cost=1.2859492301940918
Steps:   1%|▏         | 14576/1000000 [3:59:55<2853:49:41, 10.43s/it, lr=1e-5, step_loss=0.0201]Steps:   1%|▏         | 14577/1000000 [4:00:04<2657:07:38,  9.71s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [14577], local_loss=0.2018847018480301, train_loss=0.06483262777328491, time_cost=1.2433116436004639
Steps:   1%|▏         | 14577/1000000 [4:00:04<2657:07:38,  9.71s/it, lr=1e-5, step_loss=0.202] Steps:   1%|▏         | 14578/1000000 [4:00:10<2363:38:28,  8.63s/it, lr=1e-5, step_loss=0.202][RANK-0]: Step: [14578], local_loss=0.009312245063483715, train_loss=0.015071390196681023, time_cost=1.6716516017913818
Steps:   1%|▏         | 14578/1000000 [4:00:10<2363:38:28,  8.63s/it, lr=1e-5, step_loss=0.00931]Steps:   1%|▏         | 14579/1000000 [4:00:19<2381:56:30,  8.70s/it, lr=1e-5, step_loss=0.00931][RANK-0]: Step: [14579], local_loss=0.017521964386105537, train_loss=0.06762316077947617, time_cost=3.186119318008423
Steps:   1%|▏         | 14579/1000000 [4:00:19<2381:56:30,  8.70s/it, lr=1e-5, step_loss=0.0175] Steps:   1%|▏         | 14580/1000000 [4:00:23<2023:23:24,  7.39s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [14580], local_loss=0.016263600438833237, train_loss=0.024779070168733597, time_cost=1.3358182907104492
Steps:   1%|▏         | 14580/1000000 [4:00:23<2023:23:24,  7.39s/it, lr=1e-5, step_loss=0.0163]Steps:   1%|▏         | 14581/1000000 [4:00:28<1828:23:00,  6.68s/it, lr=1e-5, step_loss=0.0163][RANK-0]: Step: [14581], local_loss=0.02482488751411438, train_loss=0.03687184303998947, time_cost=2.5093729496002197
Steps:   1%|▏         | 14581/1000000 [4:00:28<1828:23:00,  6.68s/it, lr=1e-5, step_loss=0.0248]Steps:   1%|▏         | 14582/1000000 [4:00:33<1729:04:13,  6.32s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [14582], local_loss=0.11325957626104355, train_loss=0.05506373941898346, time_cost=2.8532748222351074
Steps:   1%|▏         | 14582/1000000 [4:00:33<1729:04:13,  6.32s/it, lr=1e-5, step_loss=0.113] Steps:   1%|▏         | 14583/1000000 [4:00:45<2173:51:41,  7.94s/it, lr=1e-5, step_loss=0.113][RANK-0]: Step: [14583], local_loss=0.024808941408991814, train_loss=0.048561859875917435, time_cost=4.240293741226196
Steps:   1%|▏         | 14583/1000000 [4:00:45<2173:51:41,  7.94s/it, lr=1e-5, step_loss=0.0248]Steps:   1%|▏         | 14584/1000000 [4:00:49<1877:05:19,  6.86s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [14584], local_loss=0.017580056563019753, train_loss=0.0292240958660841, time_cost=1.325117588043213
Steps:   1%|▏         | 14584/1000000 [4:00:49<1877:05:19,  6.86s/it, lr=1e-5, step_loss=0.0176]Steps:   1%|▏         | 14585/1000000 [4:00:55<1790:04:16,  6.54s/it, lr=1e-5, step_loss=0.0176][RANK-0]: Step: [14585], local_loss=0.012362116947770119, train_loss=0.019932949915528297, time_cost=4.367323398590088
Steps:   1%|▏         | 14585/1000000 [4:00:55<1790:04:16,  6.54s/it, lr=1e-5, step_loss=0.0124]Steps:   1%|▏         | 14586/1000000 [4:01:01<1755:28:41,  6.41s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [14586], local_loss=0.04323829710483551, train_loss=0.02955932728946209, time_cost=1.579688310623169
Steps:   1%|▏         | 14586/1000000 [4:01:01<1755:28:41,  6.41s/it, lr=1e-5, step_loss=0.0432]Steps:   1%|▏         | 14587/1000000 [4:01:06<1650:25:47,  6.03s/it, lr=1e-5, step_loss=0.0432][RANK-0]: Step: [14587], local_loss=0.07889463752508163, train_loss=0.04772890359163284, time_cost=2.189601421356201
Steps:   1%|▏         | 14587/1000000 [4:01:06<1650:25:47,  6.03s/it, lr=1e-5, step_loss=0.0789]Steps:   1%|▏         | 14588/1000000 [4:01:13<1710:05:54,  6.25s/it, lr=1e-5, step_loss=0.0789][RANK-0]: Step: [14588], local_loss=0.08318459242582321, train_loss=0.027237223461270332, time_cost=5.367211818695068
Steps:   1%|▏         | 14588/1000000 [4:01:13<1710:05:54,  6.25s/it, lr=1e-5, step_loss=0.0832]Steps:   1%|▏         | 14589/1000000 [4:01:22<1923:06:39,  7.03s/it, lr=1e-5, step_loss=0.0832][RANK-0]: Step: [14589], local_loss=0.0470159649848938, train_loss=0.04665350168943405, time_cost=1.203963041305542
Steps:   1%|▏         | 14589/1000000 [4:01:22<1923:06:39,  7.03s/it, lr=1e-5, step_loss=0.047] Steps:   1%|▏         | 14590/1000000 [4:01:28<1853:55:12,  6.77s/it, lr=1e-5, step_loss=0.047][RANK-0]: Step: [14590], local_loss=0.3620862066745758, train_loss=0.0622769258916378, time_cost=2.6650173664093018
Steps:   1%|▏         | 14590/1000000 [4:01:28<1853:55:12,  6.77s/it, lr=1e-5, step_loss=0.362]Steps:   1%|▏         | 14591/1000000 [4:01:41<2386:15:08,  8.72s/it, lr=1e-5, step_loss=0.362][RANK-0]: Step: [14591], local_loss=0.06574119627475739, train_loss=0.07113084942102432, time_cost=3.7236361503601074
Steps:   1%|▏         | 14591/1000000 [4:01:41<2386:15:08,  8.72s/it, lr=1e-5, step_loss=0.0657]Steps:   1%|▏         | 14592/1000000 [4:01:50<2395:16:53,  8.75s/it, lr=1e-5, step_loss=0.0657][RANK-0]: Step: [14592], local_loss=0.007393618114292622, train_loss=0.014779283665120602, time_cost=3.6867787837982178
Steps:   1%|▏         | 14592/1000000 [4:01:50<2395:16:53,  8.75s/it, lr=1e-5, step_loss=0.00739]Steps:   1%|▏         | 14593/1000000 [4:02:02<2648:35:50,  9.68s/it, lr=1e-5, step_loss=0.00739][RANK-0]: Step: [14593], local_loss=0.047356005758047104, train_loss=0.07180820405483246, time_cost=2.4189045429229736
Steps:   1%|▏         | 14593/1000000 [4:02:02<2648:35:50,  9.68s/it, lr=1e-5, step_loss=0.0474] Steps:   1%|▏         | 14594/1000000 [4:02:13<2769:45:22, 10.12s/it, lr=1e-5, step_loss=0.0474][RANK-0]: Step: [14594], local_loss=0.0031223283149302006, train_loss=0.012759413570165634, time_cost=2.0188236236572266
Steps:   1%|▏         | 14594/1000000 [4:02:13<2769:45:22, 10.12s/it, lr=1e-5, step_loss=0.00312]Steps:   1%|▏         | 14595/1000000 [4:02:24<2779:48:19, 10.16s/it, lr=1e-5, step_loss=0.00312][RANK-0]: Step: [14595], local_loss=0.005321408621966839, train_loss=0.01426822692155838, time_cost=5.4837164878845215
Steps:   1%|▏         | 14595/1000000 [4:02:24<2779:48:19, 10.16s/it, lr=1e-5, step_loss=0.00532]Steps:   1%|▏         | 14596/1000000 [4:02:28<2292:41:11,  8.38s/it, lr=1e-5, step_loss=0.00532][RANK-0]: Step: [14596], local_loss=0.04917968809604645, train_loss=0.04222787916660309, time_cost=1.4241943359375
Steps:   1%|▏         | 14596/1000000 [4:02:28<2292:41:11,  8.38s/it, lr=1e-5, step_loss=0.0492] Steps:   1%|▏         | 14597/1000000 [4:02:35<2219:03:10,  8.11s/it, lr=1e-5, step_loss=0.0492][RANK-0]: Step: [14597], local_loss=0.01429453119635582, train_loss=0.04820859432220459, time_cost=5.4445860385894775
Steps:   1%|▏         | 14597/1000000 [4:02:35<2219:03:10,  8.11s/it, lr=1e-5, step_loss=0.0143]Steps:   1%|▏         | 14598/1000000 [4:02:49<2644:44:04,  9.66s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [14598], local_loss=0.16503500938415527, train_loss=0.07727568596601486, time_cost=5.390451669692993
Steps:   1%|▏         | 14598/1000000 [4:02:49<2644:44:04,  9.66s/it, lr=1e-5, step_loss=0.165] Steps:   1%|▏         | 14599/1000000 [4:02:56<2442:58:36,  8.93s/it, lr=1e-5, step_loss=0.165][RANK-0]: Step: [14599], local_loss=0.045446865260601044, train_loss=0.025208603590726852, time_cost=1.5798521041870117
Steps:   1%|▏         | 14599/1000000 [4:02:56<2442:58:36,  8.93s/it, lr=1e-5, step_loss=0.0454]Steps:   1%|▏         | 14600/1000000 [4:03:06<2524:59:52,  9.22s/it, lr=1e-5, step_loss=0.0454][RANK-0]: Step: [14600], local_loss=0.011925159022212029, train_loss=0.023425791412591934, time_cost=4.9566943645477295
Steps:   1%|▏         | 14600/1000000 [4:03:06<2524:59:52,  9.22s/it, lr=1e-5, step_loss=0.0119]Steps:   1%|▏         | 14601/1000000 [4:03:10<2120:53:08,  7.75s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [14601], local_loss=0.010447436943650246, train_loss=0.0231336560100317, time_cost=1.2193799018859863
Steps:   1%|▏         | 14601/1000000 [4:03:10<2120:53:08,  7.75s/it, lr=1e-5, step_loss=0.0104]Steps:   1%|▏         | 14602/1000000 [4:03:26<2772:14:16, 10.13s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [14602], local_loss=0.6486324071884155, train_loss=0.24942579865455627, time_cost=6.04773736000061
Steps:   1%|▏         | 14602/1000000 [4:03:26<2772:14:16, 10.13s/it, lr=1e-5, step_loss=0.649] Steps:   1%|▏         | 14603/1000000 [4:03:34<2636:49:18,  9.63s/it, lr=1e-5, step_loss=0.649][RANK-0]: Step: [14603], local_loss=0.006415564566850662, train_loss=0.08421044051647186, time_cost=2.072007179260254
Steps:   1%|▏         | 14603/1000000 [4:03:34<2636:49:18,  9.63s/it, lr=1e-5, step_loss=0.00642]Steps:   1%|▏         | 14604/1000000 [4:03:42<2465:39:46,  9.01s/it, lr=1e-5, step_loss=0.00642][RANK-0]: Step: [14604], local_loss=0.007689613848924637, train_loss=0.029908189550042152, time_cost=1.2334480285644531
Steps:   1%|▏         | 14604/1000000 [4:03:42<2465:39:46,  9.01s/it, lr=1e-5, step_loss=0.00769]Steps:   1%|▏         | 14605/1000000 [4:03:46<2079:13:19,  7.60s/it, lr=1e-5, step_loss=0.00769][RANK-0]: Step: [14605], local_loss=0.15014880895614624, train_loss=0.05160528048872948, time_cost=1.5495820045471191
Steps:   1%|▏         | 14605/1000000 [4:03:46<2079:13:19,  7.60s/it, lr=1e-5, step_loss=0.15]   Steps:   1%|▏         | 14606/1000000 [4:04:00<2633:58:53,  9.62s/it, lr=1e-5, step_loss=0.15][RANK-0]: Step: [14606], local_loss=0.03662360459566116, train_loss=0.04492183402180672, time_cost=7.064941167831421
Steps:   1%|▏         | 14606/1000000 [4:04:00<2633:58:53,  9.62s/it, lr=1e-5, step_loss=0.0366]Steps:   1%|▏         | 14607/1000000 [4:04:05<2213:47:51,  8.09s/it, lr=1e-5, step_loss=0.0366][RANK-0]: Step: [14607], local_loss=0.011054310016334057, train_loss=0.04973388463258743, time_cost=1.332331657409668
Steps:   1%|▏         | 14607/1000000 [4:04:05<2213:47:51,  8.09s/it, lr=1e-5, step_loss=0.0111]Steps:   1%|▏         | 14608/1000000 [4:04:17<2562:40:46,  9.36s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [14608], local_loss=0.0525914691388607, train_loss=0.09820406138896942, time_cost=4.205674171447754
Steps:   1%|▏         | 14608/1000000 [4:04:17<2562:40:46,  9.36s/it, lr=1e-5, step_loss=0.0526]Steps:   1%|▏         | 14609/1000000 [4:04:27<2623:10:20,  9.58s/it, lr=1e-5, step_loss=0.0526][RANK-0]: Step: [14609], local_loss=0.019735433161258698, train_loss=0.14157865941524506, time_cost=1.2115349769592285
Steps:   1%|▏         | 14609/1000000 [4:04:27<2623:10:20,  9.58s/it, lr=1e-5, step_loss=0.0197]Steps:   1%|▏         | 14610/1000000 [4:04:32<2248:03:06,  8.21s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [14610], local_loss=0.014544444158673286, train_loss=0.15605299174785614, time_cost=1.213435411453247
Steps:   1%|▏         | 14610/1000000 [4:04:32<2248:03:06,  8.21s/it, lr=1e-5, step_loss=0.0145]Steps:   1%|▏         | 14611/1000000 [4:04:48<2886:56:13, 10.55s/it, lr=1e-5, step_loss=0.0145][RANK-0]: Step: [14611], local_loss=0.0635690987110138, train_loss=0.16304326057434082, time_cost=1.5827834606170654
Steps:   1%|▏         | 14611/1000000 [4:04:48<2886:56:13, 10.55s/it, lr=1e-5, step_loss=0.0636]Steps:   1%|▏         | 14612/1000000 [4:05:02<3123:26:48, 11.41s/it, lr=1e-5, step_loss=0.0636][RANK-0]: Step: [14612], local_loss=0.13699790835380554, train_loss=0.04681918025016785, time_cost=5.346842527389526
Steps:   1%|▏         | 14612/1000000 [4:05:02<3123:26:48, 11.41s/it, lr=1e-5, step_loss=0.137] Steps:   1%|▏         | 14613/1000000 [4:05:13<3108:25:00, 11.36s/it, lr=1e-5, step_loss=0.137][RANK-0]: Step: [14613], local_loss=0.00714306253939867, train_loss=0.01088312640786171, time_cost=2.0475268363952637
Steps:   1%|▏         | 14613/1000000 [4:05:13<3108:25:00, 11.36s/it, lr=1e-5, step_loss=0.00714]Steps:   1%|▏         | 14614/1000000 [4:05:19<2672:46:07,  9.76s/it, lr=1e-5, step_loss=0.00714][RANK-0]: Step: [14614], local_loss=0.018242528662085533, train_loss=0.06687669456005096, time_cost=1.5077264308929443
Steps:   1%|▏         | 14614/1000000 [4:05:19<2672:46:07,  9.76s/it, lr=1e-5, step_loss=0.0182] Steps:   1%|▏         | 14615/1000000 [4:05:25<2364:48:23,  8.64s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [14615], local_loss=0.04698414355516434, train_loss=0.06471319496631622, time_cost=1.3699862957000732
Steps:   1%|▏         | 14615/1000000 [4:05:25<2364:48:23,  8.64s/it, lr=1e-5, step_loss=0.047] Steps:   1%|▏         | 14616/1000000 [4:05:40<2918:42:26, 10.66s/it, lr=1e-5, step_loss=0.047][RANK-0]: Step: [14616], local_loss=0.011065797880291939, train_loss=0.022258898243308067, time_cost=1.2128396034240723
Steps:   1%|▏         | 14616/1000000 [4:05:40<2918:42:26, 10.66s/it, lr=1e-5, step_loss=0.0111]Steps:   1%|▏         | 14617/1000000 [4:05:54<3150:36:24, 11.51s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [14617], local_loss=0.045923955738544464, train_loss=10.797355651855469, time_cost=4.654610872268677
Steps:   1%|▏         | 14617/1000000 [4:05:54<3150:36:24, 11.51s/it, lr=1e-5, step_loss=0.0459]Steps:   1%|▏         | 14618/1000000 [4:06:00<2719:26:10,  9.94s/it, lr=1e-5, step_loss=0.0459][RANK-0]: Step: [14618], local_loss=0.026851266622543335, train_loss=0.02233867719769478, time_cost=2.683739185333252
Steps:   1%|▏         | 14618/1000000 [4:06:00<2719:26:10,  9.94s/it, lr=1e-5, step_loss=0.0269]Steps:   1%|▏         | 14619/1000000 [4:06:13<2964:05:39, 10.83s/it, lr=1e-5, step_loss=0.0269][RANK-0]: Step: [14619], local_loss=0.01221193466335535, train_loss=0.0568045899271965, time_cost=9.286746501922607
Steps:   1%|▏         | 14619/1000000 [4:06:13<2964:05:39, 10.83s/it, lr=1e-5, step_loss=0.0122]Steps:   1%|▏         | 14620/1000000 [4:06:18<2460:48:40,  8.99s/it, lr=1e-5, step_loss=0.0122][RANK-0]: Step: [14620], local_loss=0.03159601613879204, train_loss=0.15955762565135956, time_cost=2.340930223464966
Steps:   1%|▏         | 14620/1000000 [4:06:18<2460:48:40,  8.99s/it, lr=1e-5, step_loss=0.0316]Steps:   1%|▏         | 14621/1000000 [4:06:30<2730:51:35,  9.98s/it, lr=1e-5, step_loss=0.0316][RANK-0]: Step: [14621], local_loss=1.000211238861084, train_loss=0.18523985147476196, time_cost=3.5054943561553955
Steps:   1%|▏         | 14621/1000000 [4:06:30<2730:51:35,  9.98s/it, lr=1e-5, step_loss=1]     Steps:   1%|▏         | 14622/1000000 [4:06:40<2705:58:57,  9.89s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [14622], local_loss=0.05526687949895859, train_loss=0.058067213743925095, time_cost=7.943739891052246
Steps:   1%|▏         | 14622/1000000 [4:06:40<2705:58:57,  9.89s/it, lr=1e-5, step_loss=0.0553]Steps:   1%|▏         | 14623/1000000 [4:06:48<2612:31:04,  9.54s/it, lr=1e-5, step_loss=0.0553][RANK-0]: Step: [14623], local_loss=0.012151745148003101, train_loss=0.030072450637817383, time_cost=1.9783411026000977
Steps:   1%|▏         | 14623/1000000 [4:06:48<2612:31:04,  9.54s/it, lr=1e-5, step_loss=0.0122]Steps:   1%|▏         | 14624/1000000 [4:06:55<2389:19:22,  8.73s/it, lr=1e-5, step_loss=0.0122][RANK-0]: Step: [14624], local_loss=0.05533691868185997, train_loss=0.12070900201797485, time_cost=1.2060489654541016
Steps:   1%|▏         | 14624/1000000 [4:06:55<2389:19:22,  8.73s/it, lr=1e-5, step_loss=0.0553]Steps:   1%|▏         | 14625/1000000 [4:07:00<2087:28:25,  7.63s/it, lr=1e-5, step_loss=0.0553][RANK-0]: Step: [14625], local_loss=0.13900598883628845, train_loss=0.037307851016521454, time_cost=1.2582499980926514
Steps:   1%|▏         | 14625/1000000 [4:07:00<2087:28:25,  7.63s/it, lr=1e-5, step_loss=0.139] Steps:   1%|▏         | 14626/1000000 [4:07:12<2401:05:57,  8.77s/it, lr=1e-5, step_loss=0.139][RANK-0]: Step: [14626], local_loss=0.010476316325366497, train_loss=0.04554560035467148, time_cost=2.2537052631378174
Steps:   1%|▏         | 14626/1000000 [4:07:12<2401:05:57,  8.77s/it, lr=1e-5, step_loss=0.0105]Steps:   1%|▏         | 14627/1000000 [4:07:25<2776:02:18, 10.14s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [14627], local_loss=0.00781419686973095, train_loss=0.0205075703561306, time_cost=1.2178022861480713
Steps:   1%|▏         | 14627/1000000 [4:07:25<2776:02:18, 10.14s/it, lr=1e-5, step_loss=0.00781]Steps:   1%|▏         | 14628/1000000 [4:07:34<2670:42:25,  9.76s/it, lr=1e-5, step_loss=0.00781][RANK-0]: Step: [14628], local_loss=0.036636389791965485, train_loss=0.039618995040655136, time_cost=1.3373146057128906
Steps:   1%|▏         | 14628/1000000 [4:07:34<2670:42:25,  9.76s/it, lr=1e-5, step_loss=0.0366] Steps:   1%|▏         | 14629/1000000 [4:07:47<2919:06:43, 10.66s/it, lr=1e-5, step_loss=0.0366][RANK-0]: Step: [14629], local_loss=0.005587401799857616, train_loss=29.99433135986328, time_cost=5.383854389190674
Steps:   1%|▏         | 14629/1000000 [4:07:47<2919:06:43, 10.66s/it, lr=1e-5, step_loss=0.00559]Steps:   1%|▏         | 14630/1000000 [4:07:57<2889:07:30, 10.56s/it, lr=1e-5, step_loss=0.00559][RANK-0]: Step: [14630], local_loss=0.015453105792403221, train_loss=0.03490758687257767, time_cost=1.9113142490386963
Steps:   1%|▏         | 14630/1000000 [4:07:57<2889:07:30, 10.56s/it, lr=1e-5, step_loss=0.0155] Steps:   1%|▏         | 14631/1000000 [4:08:08<2882:55:19, 10.53s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [14631], local_loss=0.01981058157980442, train_loss=0.05597744882106781, time_cost=2.7339155673980713
Steps:   1%|▏         | 14631/1000000 [4:08:08<2882:55:19, 10.53s/it, lr=1e-5, step_loss=0.0198]Steps:   1%|▏         | 14632/1000000 [4:08:17<2804:53:02, 10.25s/it, lr=1e-5, step_loss=0.0198][RANK-0]: Step: [14632], local_loss=0.011867637746036053, train_loss=0.13442592322826385, time_cost=3.662262439727783
Steps:   1%|▏         | 14632/1000000 [4:08:17<2804:53:02, 10.25s/it, lr=1e-5, step_loss=0.0119]Steps:   1%|▏         | 14633/1000000 [4:08:25<2603:25:29,  9.51s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [14633], local_loss=0.07809003442525864, train_loss=0.059613004326820374, time_cost=1.2105305194854736
Steps:   1%|▏         | 14633/1000000 [4:08:25<2603:25:29,  9.51s/it, lr=1e-5, step_loss=0.0781]Steps:   1%|▏         | 14634/1000000 [4:08:34<2546:39:18,  9.30s/it, lr=1e-5, step_loss=0.0781][RANK-0]: Step: [14634], local_loss=0.012205451726913452, train_loss=0.031301189213991165, time_cost=3.8786702156066895
Steps:   1%|▏         | 14634/1000000 [4:08:34<2546:39:18,  9.30s/it, lr=1e-5, step_loss=0.0122]Steps:   1%|▏         | 14635/1000000 [4:08:46<2800:15:43, 10.23s/it, lr=1e-5, step_loss=0.0122][RANK-0]: Step: [14635], local_loss=0.006689855828881264, train_loss=0.030309412628412247, time_cost=6.756704568862915
Steps:   1%|▏         | 14635/1000000 [4:08:46<2800:15:43, 10.23s/it, lr=1e-5, step_loss=0.00669]Steps:   1%|▏         | 14636/1000000 [4:08:51<2376:15:44,  8.68s/it, lr=1e-5, step_loss=0.00669][RANK-0]: Step: [14636], local_loss=0.10386546701192856, train_loss=0.3205249607563019, time_cost=2.5002975463867188
Steps:   1%|▏         | 14636/1000000 [4:08:51<2376:15:44,  8.68s/it, lr=1e-5, step_loss=0.104]  Steps:   1%|▏         | 14637/1000000 [4:09:03<2637:49:47,  9.64s/it, lr=1e-5, step_loss=0.104][RANK-0]: Step: [14637], local_loss=0.0072660124860703945, train_loss=0.07524718344211578, time_cost=2.8816721439361572
Steps:   1%|▏         | 14637/1000000 [4:09:03<2637:49:47,  9.64s/it, lr=1e-5, step_loss=0.00727]Steps:   1%|▏         | 14638/1000000 [4:09:07<2207:14:32,  8.06s/it, lr=1e-5, step_loss=0.00727][RANK-0]: Step: [14638], local_loss=0.01060991920530796, train_loss=0.07222678512334824, time_cost=1.5962271690368652
Steps:   1%|▏         | 14638/1000000 [4:09:07<2207:14:32,  8.06s/it, lr=1e-5, step_loss=0.0106] Steps:   1%|▏         | 14639/1000000 [4:09:15<2158:37:09,  7.89s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [14639], local_loss=0.09760930389165878, train_loss=0.08279021829366684, time_cost=1.9501044750213623
Steps:   1%|▏         | 14639/1000000 [4:09:15<2158:37:09,  7.89s/it, lr=1e-5, step_loss=0.0976]Steps:   1%|▏         | 14640/1000000 [4:09:27<2468:32:03,  9.02s/it, lr=1e-5, step_loss=0.0976][RANK-0]: Step: [14640], local_loss=0.9884605407714844, train_loss=0.15037192404270172, time_cost=3.1915085315704346
Steps:   1%|▏         | 14640/1000000 [4:09:27<2468:32:03,  9.02s/it, lr=1e-5, step_loss=0.988] Steps:   1%|▏         | 14641/1000000 [4:09:31<2080:12:51,  7.60s/it, lr=1e-5, step_loss=0.988][RANK-0]: Step: [14641], local_loss=0.034823525696992874, train_loss=0.01942039653658867, time_cost=1.6103692054748535
Steps:   1%|▏         | 14641/1000000 [4:09:31<2080:12:51,  7.60s/it, lr=1e-5, step_loss=0.0348]Steps:   1%|▏         | 14642/1000000 [4:09:43<2420:47:42,  8.84s/it, lr=1e-5, step_loss=0.0348][RANK-0]: Step: [14642], local_loss=0.004597719758749008, train_loss=0.05209633708000183, time_cost=4.094258546829224
Steps:   1%|▏         | 14642/1000000 [4:09:43<2420:47:42,  8.84s/it, lr=1e-5, step_loss=0.0046]Steps:   1%|▏         | 14643/1000000 [4:09:50<2273:37:30,  8.31s/it, lr=1e-5, step_loss=0.0046][RANK-0]: Step: [14643], local_loss=0.013863603584468365, train_loss=0.019230453297495842, time_cost=2.240412473678589
Steps:   1%|▏         | 14643/1000000 [4:09:50<2273:37:30,  8.31s/it, lr=1e-5, step_loss=0.0139]Steps:   1%|▏         | 14644/1000000 [4:09:55<2069:08:49,  7.56s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [14644], local_loss=0.08735578507184982, train_loss=0.021805236116051674, time_cost=1.967777967453003
Steps:   1%|▏         | 14644/1000000 [4:09:55<2069:08:49,  7.56s/it, lr=1e-5, step_loss=0.0874]Steps:   1%|▏         | 14645/1000000 [4:10:01<1926:35:40,  7.04s/it, lr=1e-5, step_loss=0.0874][RANK-0]: Step: [14645], local_loss=0.04499240592122078, train_loss=0.019352776929736137, time_cost=1.528977870941162
Steps:   1%|▏         | 14645/1000000 [4:10:01<1926:35:40,  7.04s/it, lr=1e-5, step_loss=0.045] Steps:   1%|▏         | 14646/1000000 [4:10:08<1887:35:00,  6.90s/it, lr=1e-5, step_loss=0.045][RANK-0]: Step: [14646], local_loss=0.05741938576102257, train_loss=0.14595386385917664, time_cost=2.7831757068634033
Steps:   1%|▏         | 14646/1000000 [4:10:08<1887:35:00,  6.90s/it, lr=1e-5, step_loss=0.0574]Steps:   1%|▏         | 14647/1000000 [4:10:19<2232:44:59,  8.16s/it, lr=1e-5, step_loss=0.0574][RANK-0]: Step: [14647], local_loss=0.22486276924610138, train_loss=0.07370555400848389, time_cost=4.236080169677734
Steps:   1%|▏         | 14647/1000000 [4:10:19<2232:44:59,  8.16s/it, lr=1e-5, step_loss=0.225] Steps:   1%|▏         | 14648/1000000 [4:10:30<2469:46:58,  9.02s/it, lr=1e-5, step_loss=0.225][RANK-0]: Step: [14648], local_loss=0.03757099807262421, train_loss=0.06651546061038971, time_cost=3.8736684322357178
Steps:   1%|▏         | 14648/1000000 [4:10:30<2469:46:58,  9.02s/it, lr=1e-5, step_loss=0.0376]Steps:   1%|▏         | 14649/1000000 [4:10:35<2138:38:15,  7.81s/it, lr=1e-5, step_loss=0.0376][RANK-0]: Step: [14649], local_loss=0.006745805032551289, train_loss=0.013475120067596436, time_cost=3.7694268226623535
Steps:   1%|▏         | 14649/1000000 [4:10:35<2138:38:15,  7.81s/it, lr=1e-5, step_loss=0.00675]Steps:   1%|▏         | 14650/1000000 [4:10:43<2125:47:20,  7.77s/it, lr=1e-5, step_loss=0.00675][RANK-0]: Step: [14650], local_loss=0.011467870324850082, train_loss=0.03492097929120064, time_cost=5.223607540130615
Steps:   1%|▏         | 14650/1000000 [4:10:43<2125:47:20,  7.77s/it, lr=1e-5, step_loss=0.0115] Steps:   1%|▏         | 14651/1000000 [4:10:53<2335:31:05,  8.53s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [14651], local_loss=0.034635864198207855, train_loss=0.04407453536987305, time_cost=4.693748950958252
Steps:   1%|▏         | 14651/1000000 [4:10:53<2335:31:05,  8.53s/it, lr=1e-5, step_loss=0.0346]Steps:   1%|▏         | 14652/1000000 [4:11:05<2587:55:34,  9.46s/it, lr=1e-5, step_loss=0.0346][RANK-0]: Step: [14652], local_loss=0.0487428717315197, train_loss=0.13077029585838318, time_cost=4.620225667953491
Steps:   1%|▏         | 14652/1000000 [4:11:05<2587:55:34,  9.46s/it, lr=1e-5, step_loss=0.0487]Steps:   1%|▏         | 14653/1000000 [4:11:20<3082:56:21, 11.26s/it, lr=1e-5, step_loss=0.0487][RANK-0]: Step: [14653], local_loss=0.024212198331952095, train_loss=0.15147916972637177, time_cost=4.26161003112793
Steps:   1%|▏         | 14653/1000000 [4:11:20<3082:56:21, 11.26s/it, lr=1e-5, step_loss=0.0242]Steps:   1%|▏         | 14654/1000000 [4:11:32<3162:44:13, 11.56s/it, lr=1e-5, step_loss=0.0242][RANK-0]: Step: [14654], local_loss=0.01690785586833954, train_loss=0.02770863100886345, time_cost=1.320815086364746
Steps:   1%|▏         | 14654/1000000 [4:11:32<3162:44:13, 11.56s/it, lr=1e-5, step_loss=0.0169]Steps:   1%|▏         | 14655/1000000 [4:11:43<3075:01:49, 11.23s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [14655], local_loss=0.010459840297698975, train_loss=0.10140855610370636, time_cost=1.316533088684082
Steps:   1%|▏         | 14655/1000000 [4:11:43<3075:01:49, 11.23s/it, lr=1e-5, step_loss=0.0105]Steps:   1%|▏         | 14656/1000000 [4:11:54<3104:38:40, 11.34s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [14656], local_loss=0.030347373336553574, train_loss=0.046999234706163406, time_cost=6.479245901107788
Steps:   1%|▏         | 14656/1000000 [4:11:54<3104:38:40, 11.34s/it, lr=1e-5, step_loss=0.0303]Steps:   1%|▏         | 14657/1000000 [4:12:03<2883:14:44, 10.53s/it, lr=1e-5, step_loss=0.0303][RANK-0]: Step: [14657], local_loss=0.029923900961875916, train_loss=0.1659267246723175, time_cost=2.258388042449951
Steps:   1%|▏         | 14657/1000000 [4:12:03<2883:14:44, 10.53s/it, lr=1e-5, step_loss=0.0299]Steps:   1%|▏         | 14658/1000000 [4:12:15<2980:07:51, 10.89s/it, lr=1e-5, step_loss=0.0299][RANK-0]: Step: [14658], local_loss=0.016727862879633904, train_loss=0.041753362864255905, time_cost=2.456427574157715
Steps:   1%|▏         | 14658/1000000 [4:12:15<2980:07:51, 10.89s/it, lr=1e-5, step_loss=0.0167]Steps:   1%|▏         | 14659/1000000 [4:12:23<2771:05:49, 10.12s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [14659], local_loss=0.029675781726837158, train_loss=0.04193774238228798, time_cost=4.277524948120117
Steps:   1%|▏         | 14659/1000000 [4:12:23<2771:05:49, 10.12s/it, lr=1e-5, step_loss=0.0297]Steps:   1%|▏         | 14660/1000000 [4:12:32<2692:28:25,  9.84s/it, lr=1e-5, step_loss=0.0297][RANK-0]: Step: [14660], local_loss=0.03367901220917702, train_loss=0.027537669986486435, time_cost=1.2994263172149658
Steps:   1%|▏         | 14660/1000000 [4:12:32<2692:28:25,  9.84s/it, lr=1e-5, step_loss=0.0337]Steps:   1%|▏         | 14661/1000000 [4:12:42<2674:02:44,  9.77s/it, lr=1e-5, step_loss=0.0337][RANK-0]: Step: [14661], local_loss=0.012608525343239307, train_loss=0.030773350968956947, time_cost=2.0860791206359863
Steps:   1%|▏         | 14661/1000000 [4:12:42<2674:02:44,  9.77s/it, lr=1e-5, step_loss=0.0126]Steps:   1%|▏         | 14662/1000000 [4:12:49<2475:18:19,  9.04s/it, lr=1e-5, step_loss=0.0126][RANK-0]: Step: [14662], local_loss=0.013774355873465538, train_loss=0.02171763777732849, time_cost=2.479266405105591
Steps:   1%|▏         | 14662/1000000 [4:12:49<2475:18:19,  9.04s/it, lr=1e-5, step_loss=0.0138]Steps:   1%|▏         | 14663/1000000 [4:13:02<2770:35:46, 10.12s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [14663], local_loss=0.041670504957437515, train_loss=0.04560825973749161, time_cost=8.927667140960693
Steps:   1%|▏         | 14663/1000000 [4:13:02<2770:35:46, 10.12s/it, lr=1e-5, step_loss=0.0417]Steps:   1%|▏         | 14664/1000000 [4:13:06<2283:51:56,  8.34s/it, lr=1e-5, step_loss=0.0417][RANK-0]: Step: [14664], local_loss=0.06967793405056, train_loss=0.14024938642978668, time_cost=1.5504729747772217
Steps:   1%|▏         | 14664/1000000 [4:13:06<2283:51:56,  8.34s/it, lr=1e-5, step_loss=0.0697]Steps:   1%|▏         | 14665/1000000 [4:13:10<1957:02:33,  7.15s/it, lr=1e-5, step_loss=0.0697][RANK-0]: Step: [14665], local_loss=0.02603054977953434, train_loss=0.15593864023685455, time_cost=1.8883411884307861
Steps:   1%|▏         | 14665/1000000 [4:13:10<1957:02:33,  7.15s/it, lr=1e-5, step_loss=0.026] Steps:   1%|▏         | 14666/1000000 [4:13:23<2431:57:30,  8.89s/it, lr=1e-5, step_loss=0.026][RANK-0]: Step: [14666], local_loss=0.03315962105989456, train_loss=16.642147064208984, time_cost=4.747227907180786
Steps:   1%|▏         | 14666/1000000 [4:13:23<2431:57:30,  8.89s/it, lr=1e-5, step_loss=0.0332]Steps:   1%|▏         | 14667/1000000 [4:13:36<2766:17:56, 10.11s/it, lr=1e-5, step_loss=0.0332][RANK-0]: Step: [14667], local_loss=0.05100315064191818, train_loss=0.1560850441455841, time_cost=3.229203462600708
Steps:   1%|▏         | 14667/1000000 [4:13:36<2766:17:56, 10.11s/it, lr=1e-5, step_loss=0.051] Steps:   1%|▏         | 14668/1000000 [4:13:44<2530:20:21,  9.24s/it, lr=1e-5, step_loss=0.051][RANK-0]: Step: [14668], local_loss=0.00665643997490406, train_loss=0.015772230923175812, time_cost=2.8561909198760986
Steps:   1%|▏         | 14668/1000000 [4:13:44<2530:20:21,  9.24s/it, lr=1e-5, step_loss=0.00666]Steps:   1%|▏         | 14669/1000000 [4:13:48<2122:57:21,  7.76s/it, lr=1e-5, step_loss=0.00666][RANK-0]: Step: [14669], local_loss=0.00904964841902256, train_loss=0.022358674556016922, time_cost=1.4446923732757568
Steps:   1%|▏         | 14669/1000000 [4:13:48<2122:57:21,  7.76s/it, lr=1e-5, step_loss=0.00905]Steps:   1%|▏         | 14670/1000000 [4:13:54<1971:27:00,  7.20s/it, lr=1e-5, step_loss=0.00905][RANK-0]: Step: [14670], local_loss=0.023012438789010048, train_loss=0.09013821184635162, time_cost=1.4564476013183594
Steps:   1%|▏         | 14670/1000000 [4:13:54<1971:27:00,  7.20s/it, lr=1e-5, step_loss=0.023]  Steps:   1%|▏         | 14671/1000000 [4:14:02<2064:47:33,  7.54s/it, lr=1e-5, step_loss=0.023][RANK-0]: Step: [14671], local_loss=0.03994528204202652, train_loss=0.03136814758181572, time_cost=4.696420192718506
Steps:   1%|▏         | 14671/1000000 [4:14:02<2064:47:33,  7.54s/it, lr=1e-5, step_loss=0.0399]Steps:   1%|▏         | 14672/1000000 [4:14:07<1869:47:26,  6.83s/it, lr=1e-5, step_loss=0.0399][RANK-0]: Step: [14672], local_loss=0.05449312925338745, train_loss=0.14480780065059662, time_cost=1.2247977256774902
Steps:   1%|▏         | 14672/1000000 [4:14:07<1869:47:26,  6.83s/it, lr=1e-5, step_loss=0.0545]Steps:   1%|▏         | 14673/1000000 [4:14:18<2209:41:12,  8.07s/it, lr=1e-5, step_loss=0.0545][RANK-0]: Step: [14673], local_loss=0.0067075761035084724, train_loss=0.03779635205864906, time_cost=5.008602857589722
Steps:   1%|▏         | 14673/1000000 [4:14:18<2209:41:12,  8.07s/it, lr=1e-5, step_loss=0.00671]Steps:   1%|▏         | 14674/1000000 [4:14:29<2456:45:39,  8.98s/it, lr=1e-5, step_loss=0.00671][RANK-0]: Step: [14674], local_loss=0.007118198089301586, train_loss=0.02661346271634102, time_cost=3.2537682056427
Steps:   1%|▏         | 14674/1000000 [4:14:29<2456:45:39,  8.98s/it, lr=1e-5, step_loss=0.00712]Steps:   1%|▏         | 14675/1000000 [4:14:45<3012:54:02, 11.01s/it, lr=1e-5, step_loss=0.00712][RANK-0]: Step: [14675], local_loss=0.019374193623661995, train_loss=0.013129780068993568, time_cost=13.008808374404907
Steps:   1%|▏         | 14675/1000000 [4:14:45<3012:54:02, 11.01s/it, lr=1e-5, step_loss=0.0194] Steps:   1%|▏         | 14676/1000000 [4:14:51<2568:07:38,  9.38s/it, lr=1e-5, step_loss=0.0194][RANK-0]: Step: [14676], local_loss=0.02061731368303299, train_loss=0.02225489914417267, time_cost=1.5205073356628418
Steps:   1%|▏         | 14676/1000000 [4:14:51<2568:07:38,  9.38s/it, lr=1e-5, step_loss=0.0206]Steps:   1%|▏         | 14677/1000000 [4:15:04<2902:00:34, 10.60s/it, lr=1e-5, step_loss=0.0206][RANK-0]: Step: [14677], local_loss=0.008456965908408165, train_loss=0.028937583789229393, time_cost=1.8495733737945557
Steps:   1%|▏         | 14677/1000000 [4:15:04<2902:00:34, 10.60s/it, lr=1e-5, step_loss=0.00846]Steps:   1%|▏         | 14678/1000000 [4:15:18<3161:43:42, 11.55s/it, lr=1e-5, step_loss=0.00846][RANK-0]: Step: [14678], local_loss=0.018700847402215004, train_loss=0.03970469534397125, time_cost=5.397881746292114
Steps:   1%|▏         | 14678/1000000 [4:15:18<3161:43:42, 11.55s/it, lr=1e-5, step_loss=0.0187] Steps:   1%|▏         | 14679/1000000 [4:15:24<2749:22:42, 10.05s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [14679], local_loss=0.2933834493160248, train_loss=0.09658661484718323, time_cost=2.2415273189544678
Steps:   1%|▏         | 14679/1000000 [4:15:24<2749:22:42, 10.05s/it, lr=1e-5, step_loss=0.293] Steps:   1%|▏         | 14680/1000000 [4:15:32<2509:18:57,  9.17s/it, lr=1e-5, step_loss=0.293][RANK-0]: Step: [14680], local_loss=0.01043972373008728, train_loss=0.04361501336097717, time_cost=1.2326467037200928
Steps:   1%|▏         | 14680/1000000 [4:15:32<2509:18:57,  9.17s/it, lr=1e-5, step_loss=0.0104]Steps:   1%|▏         | 14681/1000000 [4:15:37<2165:56:07,  7.91s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [14681], local_loss=0.015951506793498993, train_loss=0.07343346625566483, time_cost=4.10580587387085
Steps:   1%|▏         | 14681/1000000 [4:15:37<2165:56:07,  7.91s/it, lr=1e-5, step_loss=0.016] Steps:   1%|▏         | 14682/1000000 [4:15:50<2651:59:58,  9.69s/it, lr=1e-5, step_loss=0.016][RANK-0]: Step: [14682], local_loss=0.009479801170527935, train_loss=0.04519259184598923, time_cost=1.216456413269043
Steps:   1%|▏         | 14682/1000000 [4:15:50<2651:59:58,  9.69s/it, lr=1e-5, step_loss=0.00948]Steps:   1%|▏         | 14683/1000000 [4:15:55<2229:40:04,  8.15s/it, lr=1e-5, step_loss=0.00948][RANK-0]: Step: [14683], local_loss=0.013201999478042126, train_loss=0.020105700939893723, time_cost=1.7810404300689697
Steps:   1%|▏         | 14683/1000000 [4:15:55<2229:40:04,  8.15s/it, lr=1e-5, step_loss=0.0132] Steps:   1%|▏         | 14684/1000000 [4:16:05<2380:25:15,  8.70s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [14684], local_loss=0.014688118360936642, train_loss=0.04033602029085159, time_cost=1.6896491050720215
Steps:   1%|▏         | 14684/1000000 [4:16:05<2380:25:15,  8.70s/it, lr=1e-5, step_loss=0.0147]Steps:   1%|▏         | 14685/1000000 [4:16:13<2327:43:38,  8.50s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [14685], local_loss=0.004252323880791664, train_loss=0.04579472541809082, time_cost=7.147128582000732
Steps:   1%|▏         | 14685/1000000 [4:16:13<2327:43:38,  8.50s/it, lr=1e-5, step_loss=0.00425]Steps:   1%|▏         | 14686/1000000 [4:16:26<2691:18:13,  9.83s/it, lr=1e-5, step_loss=0.00425][RANK-0]: Step: [14686], local_loss=0.036682650446891785, train_loss=0.05462517589330673, time_cost=1.2116577625274658
Steps:   1%|▏         | 14686/1000000 [4:16:26<2691:18:13,  9.83s/it, lr=1e-5, step_loss=0.0367] Steps:   1%|▏         | 14687/1000000 [4:16:35<2602:59:14,  9.51s/it, lr=1e-5, step_loss=0.0367][RANK-0]: Step: [14687], local_loss=0.04279659688472748, train_loss=0.01321333460509777, time_cost=2.410400152206421
Steps:   1%|▏         | 14687/1000000 [4:16:35<2602:59:14,  9.51s/it, lr=1e-5, step_loss=0.0428]Steps:   1%|▏         | 14688/1000000 [4:16:42<2401:20:58,  8.77s/it, lr=1e-5, step_loss=0.0428][RANK-0]: Step: [14688], local_loss=0.01973021775484085, train_loss=0.022813551127910614, time_cost=2.575984477996826
Steps:   1%|▏         | 14688/1000000 [4:16:42<2401:20:58,  8.77s/it, lr=1e-5, step_loss=0.0197]Steps:   1%|▏         | 14689/1000000 [4:16:50<2355:45:26,  8.61s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [14689], local_loss=0.011218957602977753, train_loss=0.05575517192482948, time_cost=1.2106106281280518
Steps:   1%|▏         | 14689/1000000 [4:16:50<2355:45:26,  8.61s/it, lr=1e-5, step_loss=0.0112]Steps:   1%|▏         | 14690/1000000 [4:17:04<2810:11:09, 10.27s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [14690], local_loss=0.08993136137723923, train_loss=0.19618883728981018, time_cost=5.50937819480896
Steps:   1%|▏         | 14690/1000000 [4:17:04<2810:11:09, 10.27s/it, lr=1e-5, step_loss=0.0899]Steps:   1%|▏         | 14691/1000000 [4:17:09<2353:24:29,  8.60s/it, lr=1e-5, step_loss=0.0899][RANK-0]: Step: [14691], local_loss=0.012896453961730003, train_loss=0.01084536500275135, time_cost=1.904770851135254
Steps:   1%|▏         | 14691/1000000 [4:17:09<2353:24:29,  8.60s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 14692/1000000 [4:17:16<2211:38:13,  8.08s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [14692], local_loss=0.014731056988239288, train_loss=0.035565510392189026, time_cost=2.245335340499878
Steps:   1%|▏         | 14692/1000000 [4:17:16<2211:38:13,  8.08s/it, lr=1e-5, step_loss=0.0147]Steps:   1%|▏         | 14693/1000000 [4:17:31<2809:50:44, 10.27s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [14693], local_loss=0.12480141967535019, train_loss=0.06034925580024719, time_cost=11.657625436782837
Steps:   1%|▏         | 14693/1000000 [4:17:31<2809:50:44, 10.27s/it, lr=1e-5, step_loss=0.125] Steps:   1%|▏         | 14694/1000000 [4:17:42<2862:39:36, 10.46s/it, lr=1e-5, step_loss=0.125][RANK-0]: Step: [14694], local_loss=0.07062393426895142, train_loss=0.03577963262796402, time_cost=2.530029058456421
Steps:   1%|▏         | 14694/1000000 [4:17:42<2862:39:36, 10.46s/it, lr=1e-5, step_loss=0.0706]Steps:   1%|▏         | 14695/1000000 [4:17:54<2980:14:56, 10.89s/it, lr=1e-5, step_loss=0.0706][RANK-0]: Step: [14695], local_loss=0.013449020683765411, train_loss=0.0174548476934433, time_cost=2.9132802486419678
Steps:   1%|▏         | 14695/1000000 [4:17:54<2980:14:56, 10.89s/it, lr=1e-5, step_loss=0.0134]Steps:   1%|▏         | 14696/1000000 [4:18:00<2627:45:48,  9.60s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [14696], local_loss=0.012743824161589146, train_loss=0.030202604830265045, time_cost=2.538081169128418
Steps:   1%|▏         | 14696/1000000 [4:18:00<2627:45:48,  9.60s/it, lr=1e-5, step_loss=0.0127]Steps:   1%|▏         | 14697/1000000 [4:18:06<2339:20:49,  8.55s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [14697], local_loss=0.1346888393163681, train_loss=0.037418290972709656, time_cost=2.090273857116699
Steps:   1%|▏         | 14697/1000000 [4:18:06<2339:20:49,  8.55s/it, lr=1e-5, step_loss=0.135] Steps:   1%|▏         | 14698/1000000 [4:18:18<2555:40:15,  9.34s/it, lr=1e-5, step_loss=0.135][RANK-0]: Step: [14698], local_loss=0.033116042613983154, train_loss=0.06770898401737213, time_cost=1.8584625720977783
Steps:   1%|▏         | 14698/1000000 [4:18:18<2555:40:15,  9.34s/it, lr=1e-5, step_loss=0.0331]Steps:   1%|▏         | 14699/1000000 [4:18:22<2137:46:21,  7.81s/it, lr=1e-5, step_loss=0.0331][RANK-0]: Step: [14699], local_loss=1.0140783786773682, train_loss=0.1526990532875061, time_cost=1.3580305576324463
Steps:   1%|▏         | 14699/1000000 [4:18:22<2137:46:21,  7.81s/it, lr=1e-5, step_loss=1.01]  Steps:   1%|▏         | 14700/1000000 [4:18:26<1865:38:20,  6.82s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [14700], local_loss=0.060536306351423264, train_loss=0.05989828705787659, time_cost=1.7722680568695068
Steps:   1%|▏         | 14700/1000000 [4:18:26<1865:38:20,  6.82s/it, lr=1e-5, step_loss=0.0605]Steps:   1%|▏         | 14701/1000000 [4:18:38<2220:50:37,  8.11s/it, lr=1e-5, step_loss=0.0605][RANK-0]: Step: [14701], local_loss=0.006368828006088734, train_loss=0.11250264942646027, time_cost=3.1074962615966797
Steps:   1%|▏         | 14701/1000000 [4:18:38<2220:50:37,  8.11s/it, lr=1e-5, step_loss=0.00637]Steps:   1%|▏         | 14702/1000000 [4:18:45<2188:28:28,  8.00s/it, lr=1e-5, step_loss=0.00637][RANK-0]: Step: [14702], local_loss=0.008616430684924126, train_loss=0.012555585242807865, time_cost=2.972393035888672
Steps:   1%|▏         | 14702/1000000 [4:18:45<2188:28:28,  8.00s/it, lr=1e-5, step_loss=0.00862]Steps:   1%|▏         | 14703/1000000 [4:18:50<1959:08:52,  7.16s/it, lr=1e-5, step_loss=0.00862][RANK-0]: Step: [14703], local_loss=0.03501215949654579, train_loss=0.0896555483341217, time_cost=1.9108788967132568
Steps:   1%|▏         | 14703/1000000 [4:18:50<1959:08:52,  7.16s/it, lr=1e-5, step_loss=0.035]  Steps:   1%|▏         | 14704/1000000 [4:19:01<2220:39:54,  8.11s/it, lr=1e-5, step_loss=0.035][RANK-0]: Step: [14704], local_loss=0.0046443757601082325, train_loss=0.023621059954166412, time_cost=1.4807963371276855
Steps:   1%|▏         | 14704/1000000 [4:19:01<2220:39:54,  8.11s/it, lr=1e-5, step_loss=0.00464]Steps:   1%|▏         | 14705/1000000 [4:19:05<1907:07:36,  6.97s/it, lr=1e-5, step_loss=0.00464][RANK-0]: Step: [14705], local_loss=0.019473567605018616, train_loss=0.027768343687057495, time_cost=1.2315361499786377
Steps:   1%|▏         | 14705/1000000 [4:19:05<1907:07:36,  6.97s/it, lr=1e-5, step_loss=0.0195] Steps:   1%|▏         | 14706/1000000 [4:19:20<2528:11:15,  9.24s/it, lr=1e-5, step_loss=0.0195][RANK-0]: Step: [14706], local_loss=0.022238856181502342, train_loss=0.0715840756893158, time_cost=5.931665420532227
Steps:   1%|▏         | 14706/1000000 [4:19:20<2528:11:15,  9.24s/it, lr=1e-5, step_loss=0.0222]Steps:   1%|▏         | 14707/1000000 [4:19:30<2646:10:33,  9.67s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [14707], local_loss=0.008103846572339535, train_loss=0.020859399810433388, time_cost=2.1177561283111572
Steps:   1%|▏         | 14707/1000000 [4:19:30<2646:10:33,  9.67s/it, lr=1e-5, step_loss=0.0081]Steps:   1%|▏         | 14708/1000000 [4:19:37<2427:47:09,  8.87s/it, lr=1e-5, step_loss=0.0081][RANK-0]: Step: [14708], local_loss=0.04074040427803993, train_loss=0.05517875775694847, time_cost=3.1593050956726074
Steps:   1%|▏         | 14708/1000000 [4:19:37<2427:47:09,  8.87s/it, lr=1e-5, step_loss=0.0407]Steps:   1%|▏         | 14709/1000000 [4:19:43<2159:42:21,  7.89s/it, lr=1e-5, step_loss=0.0407][RANK-0]: Step: [14709], local_loss=0.31085333228111267, train_loss=0.060867805033922195, time_cost=2.291849374771118
Steps:   1%|▏         | 14709/1000000 [4:19:43<2159:42:21,  7.89s/it, lr=1e-5, step_loss=0.311] Steps:   1%|▏         | 14710/1000000 [4:19:52<2241:12:12,  8.19s/it, lr=1e-5, step_loss=0.311][RANK-0]: Step: [14710], local_loss=0.016805298626422882, train_loss=0.042318589985370636, time_cost=2.6097726821899414
Steps:   1%|▏         | 14710/1000000 [4:19:52<2241:12:12,  8.19s/it, lr=1e-5, step_loss=0.0168]Steps:   1%|▏         | 14711/1000000 [4:20:04<2548:45:44,  9.31s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [14711], local_loss=0.012807956896722317, train_loss=0.13061562180519104, time_cost=4.615823984146118
Steps:   1%|▏         | 14711/1000000 [4:20:04<2548:45:44,  9.31s/it, lr=1e-5, step_loss=0.0128]Steps:   1%|▏         | 14712/1000000 [4:20:20<3086:16:33, 11.28s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [14712], local_loss=0.0067066471092402935, train_loss=0.018618889153003693, time_cost=1.196645975112915
Steps:   1%|▏         | 14712/1000000 [4:20:20<3086:16:33, 11.28s/it, lr=1e-5, step_loss=0.00671]Steps:   1%|▏         | 14713/1000000 [4:20:35<3451:30:38, 12.61s/it, lr=1e-5, step_loss=0.00671][RANK-0]: Step: [14713], local_loss=0.008092278614640236, train_loss=0.019206978380680084, time_cost=6.926741361618042
Steps:   1%|▏         | 14713/1000000 [4:20:35<3451:30:38, 12.61s/it, lr=1e-5, step_loss=0.00809]Steps:   1%|▏         | 14714/1000000 [4:20:40<2831:09:19, 10.34s/it, lr=1e-5, step_loss=0.00809][RANK-0]: Step: [14714], local_loss=0.007643518038094044, train_loss=0.05313144624233246, time_cost=2.1770784854888916
Steps:   1%|▏         | 14714/1000000 [4:20:40<2831:09:19, 10.34s/it, lr=1e-5, step_loss=0.00764]Steps:   1%|▏         | 14715/1000000 [4:20:46<2483:58:48,  9.08s/it, lr=1e-5, step_loss=0.00764][RANK-0]: Step: [14715], local_loss=0.007377718575298786, train_loss=0.027723072096705437, time_cost=1.9326410293579102
Steps:   1%|▏         | 14715/1000000 [4:20:46<2483:58:48,  9.08s/it, lr=1e-5, step_loss=0.00738]Steps:   1%|▏         | 14716/1000000 [4:21:01<2912:38:38, 10.64s/it, lr=1e-5, step_loss=0.00738][RANK-0]: Step: [14716], local_loss=0.007171782199293375, train_loss=0.07929309457540512, time_cost=2.4410157203674316
Steps:   1%|▏         | 14716/1000000 [4:21:01<2912:38:38, 10.64s/it, lr=1e-5, step_loss=0.00717]Steps:   1%|▏         | 14717/1000000 [4:21:08<2613:47:23,  9.55s/it, lr=1e-5, step_loss=0.00717][RANK-0]: Step: [14717], local_loss=0.011380704119801521, train_loss=17.937610626220703, time_cost=1.5942082405090332
Steps:   1%|▏         | 14717/1000000 [4:21:08<2613:47:23,  9.55s/it, lr=1e-5, step_loss=0.0114] Steps:   1%|▏         | 14718/1000000 [4:21:14<2315:08:03,  8.46s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [14718], local_loss=0.01372694130986929, train_loss=0.037289105355739594, time_cost=1.3264992237091064
Steps:   1%|▏         | 14718/1000000 [4:21:14<2315:08:03,  8.46s/it, lr=1e-5, step_loss=0.0137]Steps:   1%|▏         | 14719/1000000 [4:21:28<2803:04:16, 10.24s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [14719], local_loss=0.3315747380256653, train_loss=0.07087769359350204, time_cost=2.6644623279571533
Steps:   1%|▏         | 14719/1000000 [4:21:28<2803:04:16, 10.24s/it, lr=1e-5, step_loss=0.332] Steps:   1%|▏         | 14720/1000000 [4:21:35<2519:19:14,  9.21s/it, lr=1e-5, step_loss=0.332][RANK-0]: Step: [14720], local_loss=0.011948846280574799, train_loss=0.012041466310620308, time_cost=1.2257258892059326
Steps:   1%|▏         | 14720/1000000 [4:21:35<2519:19:14,  9.21s/it, lr=1e-5, step_loss=0.0119]Steps:   1%|▏         | 14721/1000000 [4:21:49<2893:50:34, 10.57s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [14721], local_loss=0.006196950096637011, train_loss=0.01943599432706833, time_cost=4.599635362625122
Steps:   1%|▏         | 14721/1000000 [4:21:49<2893:50:34, 10.57s/it, lr=1e-5, step_loss=0.0062]Steps:   1%|▏         | 14722/1000000 [4:21:53<2377:17:07,  8.69s/it, lr=1e-5, step_loss=0.0062][RANK-0]: Step: [14722], local_loss=0.019143303856253624, train_loss=0.028703469783067703, time_cost=1.4418199062347412
Steps:   1%|▏         | 14722/1000000 [4:21:53<2377:17:07,  8.69s/it, lr=1e-5, step_loss=0.0191]Steps:   1%|▏         | 14723/1000000 [4:22:09<2954:41:47, 10.80s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [14723], local_loss=0.052869364619255066, train_loss=0.04422840476036072, time_cost=7.0427086353302
Steps:   1%|▏         | 14723/1000000 [4:22:09<2954:41:47, 10.80s/it, lr=1e-5, step_loss=0.0529]Steps:   1%|▏         | 14724/1000000 [4:22:18<2804:05:24, 10.25s/it, lr=1e-5, step_loss=0.0529][RANK-0]: Step: [14724], local_loss=0.3453312814235687, train_loss=0.07253323495388031, time_cost=3.080416679382324
Steps:   1%|▏         | 14724/1000000 [4:22:18<2804:05:24, 10.25s/it, lr=1e-5, step_loss=0.345] Steps:   1%|▏         | 14725/1000000 [4:22:22<2334:23:43,  8.53s/it, lr=1e-5, step_loss=0.345][RANK-0]: Step: [14725], local_loss=0.0645306408405304, train_loss=0.037890076637268066, time_cost=1.4964184761047363
Steps:   1%|▏         | 14725/1000000 [4:22:22<2334:23:43,  8.53s/it, lr=1e-5, step_loss=0.0645]Steps:   1%|▏         | 14726/1000000 [4:22:32<2462:14:33,  9.00s/it, lr=1e-5, step_loss=0.0645][RANK-0]: Step: [14726], local_loss=0.06530415266752243, train_loss=0.22863152623176575, time_cost=8.215357780456543
Steps:   1%|▏         | 14726/1000000 [4:22:32<2462:14:33,  9.00s/it, lr=1e-5, step_loss=0.0653]Steps:   1%|▏         | 14727/1000000 [4:22:45<2782:04:36, 10.17s/it, lr=1e-5, step_loss=0.0653][RANK-0]: Step: [14727], local_loss=0.05102715641260147, train_loss=0.07572601735591888, time_cost=4.617207288742065
Steps:   1%|▏         | 14727/1000000 [4:22:45<2782:04:36, 10.17s/it, lr=1e-5, step_loss=0.051] Steps:   1%|▏         | 14728/1000000 [4:22:50<2360:36:08,  8.63s/it, lr=1e-5, step_loss=0.051][RANK-0]: Step: [14728], local_loss=0.018326934427022934, train_loss=0.024676915258169174, time_cost=2.3060617446899414
Steps:   1%|▏         | 14728/1000000 [4:22:50<2360:36:08,  8.63s/it, lr=1e-5, step_loss=0.0183]Steps:   1%|▏         | 14729/1000000 [4:23:01<2558:01:27,  9.35s/it, lr=1e-5, step_loss=0.0183][RANK-0]: Step: [14729], local_loss=0.006772896274924278, train_loss=0.09560677409172058, time_cost=3.519225835800171
Steps:   1%|▏         | 14729/1000000 [4:23:01<2558:01:27,  9.35s/it, lr=1e-5, step_loss=0.00677]Steps:   1%|▏         | 14730/1000000 [4:23:09<2410:01:24,  8.81s/it, lr=1e-5, step_loss=0.00677][RANK-0]: Step: [14730], local_loss=0.02275172248482704, train_loss=0.011686909943819046, time_cost=2.393359899520874
Steps:   1%|▏         | 14730/1000000 [4:23:09<2410:01:24,  8.81s/it, lr=1e-5, step_loss=0.0228] Steps:   1%|▏         | 14731/1000000 [4:23:14<2101:37:07,  7.68s/it, lr=1e-5, step_loss=0.0228][RANK-0]: Step: [14731], local_loss=0.023799583315849304, train_loss=0.02675991877913475, time_cost=2.536607027053833
Steps:   1%|▏         | 14731/1000000 [4:23:14<2101:37:07,  7.68s/it, lr=1e-5, step_loss=0.0238]Steps:   1%|▏         | 14732/1000000 [4:23:21<2081:44:29,  7.61s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [14732], local_loss=0.040172889828681946, train_loss=0.04837510734796524, time_cost=2.9944920539855957
Steps:   1%|▏         | 14732/1000000 [4:23:21<2081:44:29,  7.61s/it, lr=1e-5, step_loss=0.0402]Steps:   1%|▏         | 14733/1000000 [4:23:28<2005:50:47,  7.33s/it, lr=1e-5, step_loss=0.0402][RANK-0]: Step: [14733], local_loss=0.06477022171020508, train_loss=0.05368828773498535, time_cost=2.5676004886627197
Steps:   1%|▏         | 14733/1000000 [4:23:28<2005:50:47,  7.33s/it, lr=1e-5, step_loss=0.0648]Steps:   1%|▏         | 14734/1000000 [4:23:33<1847:48:05,  6.75s/it, lr=1e-5, step_loss=0.0648][RANK-0]: Step: [14734], local_loss=0.011593511328101158, train_loss=0.08908215910196304, time_cost=2.337218999862671
Steps:   1%|▏         | 14734/1000000 [4:23:33<1847:48:05,  6.75s/it, lr=1e-5, step_loss=0.0116]Steps:   1%|▏         | 14735/1000000 [4:23:38<1690:35:48,  6.18s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [14735], local_loss=0.05721653997898102, train_loss=0.0359342023730278, time_cost=1.8034489154815674
Steps:   1%|▏         | 14735/1000000 [4:23:38<1690:35:48,  6.18s/it, lr=1e-5, step_loss=0.0572]Steps:   1%|▏         | 14736/1000000 [4:23:51<2273:35:08,  8.31s/it, lr=1e-5, step_loss=0.0572][RANK-0]: Step: [14736], local_loss=0.04444913938641548, train_loss=0.05178293213248253, time_cost=3.646395444869995
Steps:   1%|▏         | 14736/1000000 [4:23:51<2273:35:08,  8.31s/it, lr=1e-5, step_loss=0.0444]Steps:   1%|▏         | 14737/1000000 [4:23:59<2238:32:45,  8.18s/it, lr=1e-5, step_loss=0.0444][RANK-0]: Step: [14737], local_loss=0.006248354911804199, train_loss=0.0403190553188324, time_cost=5.130163669586182
Steps:   1%|▏         | 14737/1000000 [4:23:59<2238:32:45,  8.18s/it, lr=1e-5, step_loss=0.00625]Steps:   1%|▏         | 14738/1000000 [4:24:10<2432:27:13,  8.89s/it, lr=1e-5, step_loss=0.00625][RANK-0]: Step: [14738], local_loss=0.18905027210712433, train_loss=0.09211963415145874, time_cost=1.301830768585205
Steps:   1%|▏         | 14738/1000000 [4:24:10<2432:27:13,  8.89s/it, lr=1e-5, step_loss=0.189]  Steps:   1%|▏         | 14739/1000000 [4:24:16<2195:36:26,  8.02s/it, lr=1e-5, step_loss=0.189][RANK-0]: Step: [14739], local_loss=0.009104305878281593, train_loss=0.02324623614549637, time_cost=3.1777141094207764
Steps:   1%|▏         | 14739/1000000 [4:24:16<2195:36:26,  8.02s/it, lr=1e-5, step_loss=0.0091]Steps:   1%|▏         | 14740/1000000 [4:24:29<2583:53:43,  9.44s/it, lr=1e-5, step_loss=0.0091][RANK-0]: Step: [14740], local_loss=0.017236433923244476, train_loss=0.018276847898960114, time_cost=2.9021553993225098
Steps:   1%|▏         | 14740/1000000 [4:24:29<2583:53:43,  9.44s/it, lr=1e-5, step_loss=0.0172]Steps:   1%|▏         | 14741/1000000 [4:24:37<2479:09:58,  9.06s/it, lr=1e-5, step_loss=0.0172][RANK-0]: Step: [14741], local_loss=0.024645961821079254, train_loss=0.026179920881986618, time_cost=1.2180664539337158
Steps:   1%|▏         | 14741/1000000 [4:24:37<2479:09:58,  9.06s/it, lr=1e-5, step_loss=0.0246]Steps:   1%|▏         | 14742/1000000 [4:24:49<2766:11:55, 10.11s/it, lr=1e-5, step_loss=0.0246][RANK-0]: Step: [14742], local_loss=0.5124877691268921, train_loss=0.09734906256198883, time_cost=5.534940958023071
Steps:   1%|▏         | 14742/1000000 [4:24:49<2766:11:55, 10.11s/it, lr=1e-5, step_loss=0.512] Steps:   1%|▏         | 14743/1000000 [4:25:06<3308:03:33, 12.09s/it, lr=1e-5, step_loss=0.512][RANK-0]: Step: [14743], local_loss=0.031570885330438614, train_loss=0.0648689717054367, time_cost=9.71142292022705
Steps:   1%|▏         | 14743/1000000 [4:25:06<3308:03:33, 12.09s/it, lr=1e-5, step_loss=0.0316]Steps:   1%|▏         | 14744/1000000 [4:25:19<3387:56:36, 12.38s/it, lr=1e-5, step_loss=0.0316][RANK-0]: Step: [14744], local_loss=0.02015490084886551, train_loss=0.020533312112092972, time_cost=1.2298436164855957
Steps:   1%|▏         | 14744/1000000 [4:25:19<3387:56:36, 12.38s/it, lr=1e-5, step_loss=0.0202]Steps:   1%|▏         | 14745/1000000 [4:25:30<3253:08:11, 11.89s/it, lr=1e-5, step_loss=0.0202][RANK-0]: Step: [14745], local_loss=0.01922481134533882, train_loss=0.01325689535588026, time_cost=5.503614664077759
Steps:   1%|▏         | 14745/1000000 [4:25:30<3253:08:11, 11.89s/it, lr=1e-5, step_loss=0.0192]Steps:   1%|▏         | 14746/1000000 [4:25:43<3335:44:21, 12.19s/it, lr=1e-5, step_loss=0.0192][RANK-0]: Step: [14746], local_loss=0.017090486362576485, train_loss=0.19434700906276703, time_cost=4.369600772857666
Steps:   1%|▏         | 14746/1000000 [4:25:43<3335:44:21, 12.19s/it, lr=1e-5, step_loss=0.0171]Steps:   1%|▏         | 14747/1000000 [4:25:58<3587:13:54, 13.11s/it, lr=1e-5, step_loss=0.0171][RANK-0]: Step: [14747], local_loss=0.008012808859348297, train_loss=0.016194578260183334, time_cost=6.8438568115234375
Steps:   1%|▏         | 14747/1000000 [4:25:58<3587:13:54, 13.11s/it, lr=1e-5, step_loss=0.00801]Steps:   1%|▏         | 14748/1000000 [4:26:07<3273:11:23, 11.96s/it, lr=1e-5, step_loss=0.00801][RANK-0]: Step: [14748], local_loss=0.011242726817727089, train_loss=0.08539408445358276, time_cost=1.260352373123169
Steps:   1%|▏         | 14748/1000000 [4:26:07<3273:11:23, 11.96s/it, lr=1e-5, step_loss=0.0112] Steps:   1%|▏         | 14749/1000000 [4:26:17<3129:36:06, 11.44s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [14749], local_loss=0.41824159026145935, train_loss=0.15514610707759857, time_cost=3.1133220195770264
Steps:   1%|▏         | 14749/1000000 [4:26:17<3129:36:06, 11.44s/it, lr=1e-5, step_loss=0.418] Steps:   1%|▏         | 14750/1000000 [4:26:25<2809:08:27, 10.26s/it, lr=1e-5, step_loss=0.418][RANK-0]: Step: [14750], local_loss=0.0099679846316576, train_loss=0.033337242901325226, time_cost=1.6044728755950928
Steps:   1%|▏         | 14750/1000000 [4:26:25<2809:08:27, 10.26s/it, lr=1e-5, step_loss=0.00997]Steps:   1%|▏         | 14751/1000000 [4:26:30<2370:40:01,  8.66s/it, lr=1e-5, step_loss=0.00997][RANK-0]: Step: [14751], local_loss=0.007220172323286533, train_loss=0.05234305560588837, time_cost=1.2077817916870117
Steps:   1%|▏         | 14751/1000000 [4:26:30<2370:40:01,  8.66s/it, lr=1e-5, step_loss=0.00722]Steps:   1%|▏         | 14752/1000000 [4:26:37<2259:58:05,  8.26s/it, lr=1e-5, step_loss=0.00722][RANK-0]: Step: [14752], local_loss=0.06638146936893463, train_loss=0.14995577931404114, time_cost=3.1686830520629883
Steps:   1%|▏         | 14752/1000000 [4:26:37<2259:58:05,  8.26s/it, lr=1e-5, step_loss=0.0664] Steps:   1%|▏         | 14753/1000000 [4:26:47<2402:18:46,  8.78s/it, lr=1e-5, step_loss=0.0664][RANK-0]: Step: [14753], local_loss=0.010871435515582561, train_loss=0.04185755178332329, time_cost=1.9342014789581299
Steps:   1%|▏         | 14753/1000000 [4:26:47<2402:18:46,  8.78s/it, lr=1e-5, step_loss=0.0109]Steps:   1%|▏         | 14754/1000000 [4:26:58<2595:57:24,  9.49s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [14754], local_loss=0.038641925901174545, train_loss=0.07719317078590393, time_cost=3.724165439605713
Steps:   1%|▏         | 14754/1000000 [4:26:58<2595:57:24,  9.49s/it, lr=1e-5, step_loss=0.0386]Steps:   1%|▏         | 14755/1000000 [4:27:09<2695:20:16,  9.85s/it, lr=1e-5, step_loss=0.0386][RANK-0]: Step: [14755], local_loss=0.2588414251804352, train_loss=0.061907801777124405, time_cost=1.6758460998535156
Steps:   1%|▏         | 14755/1000000 [4:27:09<2695:20:16,  9.85s/it, lr=1e-5, step_loss=0.259] Steps:   1%|▏         | 14756/1000000 [4:27:15<2346:25:36,  8.57s/it, lr=1e-5, step_loss=0.259][RANK-0]: Step: [14756], local_loss=0.007079081144183874, train_loss=0.17632406949996948, time_cost=4.526883363723755
Steps:   1%|▏         | 14756/1000000 [4:27:15<2346:25:36,  8.57s/it, lr=1e-5, step_loss=0.00708]Steps:   1%|▏         | 14757/1000000 [4:27:25<2529:05:57,  9.24s/it, lr=1e-5, step_loss=0.00708][RANK-0]: Step: [14757], local_loss=0.054147519171237946, train_loss=0.03315373882651329, time_cost=2.2659389972686768
Steps:   1%|▏         | 14757/1000000 [4:27:25<2529:05:57,  9.24s/it, lr=1e-5, step_loss=0.0541] Steps:   1%|▏         | 14758/1000000 [4:27:35<2585:46:09,  9.45s/it, lr=1e-5, step_loss=0.0541][RANK-0]: Step: [14758], local_loss=0.027234073728322983, train_loss=0.059967316687107086, time_cost=4.172126054763794
Steps:   1%|▏         | 14758/1000000 [4:27:35<2585:46:09,  9.45s/it, lr=1e-5, step_loss=0.0272]Steps:   1%|▏         | 14759/1000000 [4:27:40<2175:49:39,  7.95s/it, lr=1e-5, step_loss=0.0272][RANK-0]: Step: [14759], local_loss=0.023570094257593155, train_loss=0.028712430968880653, time_cost=1.5836458206176758
Steps:   1%|▏         | 14759/1000000 [4:27:40<2175:49:39,  7.95s/it, lr=1e-5, step_loss=0.0236]Steps:   1%|▏         | 14760/1000000 [4:27:44<1871:56:53,  6.84s/it, lr=1e-5, step_loss=0.0236][RANK-0]: Step: [14760], local_loss=0.03781456500291824, train_loss=0.02861412800848484, time_cost=1.2435178756713867
Steps:   1%|▏         | 14760/1000000 [4:27:44<1871:56:53,  6.84s/it, lr=1e-5, step_loss=0.0378]Steps:   1%|▏         | 14761/1000000 [4:27:49<1719:48:49,  6.28s/it, lr=1e-5, step_loss=0.0378][RANK-0]: Step: [14761], local_loss=0.006679291371256113, train_loss=0.034931331872940063, time_cost=1.878692388534546
Steps:   1%|▏         | 14761/1000000 [4:27:49<1719:48:49,  6.28s/it, lr=1e-5, step_loss=0.00668]Steps:   1%|▏         | 14762/1000000 [4:27:56<1786:15:30,  6.53s/it, lr=1e-5, step_loss=0.00668][RANK-0]: Step: [14762], local_loss=0.016587339341640472, train_loss=0.03809472918510437, time_cost=1.5256938934326172
Steps:   1%|▏         | 14762/1000000 [4:27:56<1786:15:30,  6.53s/it, lr=1e-5, step_loss=0.0166] Steps:   1%|▏         | 14763/1000000 [4:28:04<1886:59:54,  6.89s/it, lr=1e-5, step_loss=0.0166][RANK-0]: Step: [14763], local_loss=0.03556475788354874, train_loss=0.04630544036626816, time_cost=3.685504913330078
Steps:   1%|▏         | 14763/1000000 [4:28:04<1886:59:54,  6.89s/it, lr=1e-5, step_loss=0.0356]Steps:   1%|▏         | 14764/1000000 [4:28:17<2413:38:18,  8.82s/it, lr=1e-5, step_loss=0.0356][RANK-0]: Step: [14764], local_loss=0.02948298305273056, train_loss=0.15300095081329346, time_cost=3.920696973800659
Steps:   1%|▏         | 14764/1000000 [4:28:17<2413:38:18,  8.82s/it, lr=1e-5, step_loss=0.0295]Steps:   1%|▏         | 14765/1000000 [4:28:30<2715:30:08,  9.92s/it, lr=1e-5, step_loss=0.0295][RANK-0]: Step: [14765], local_loss=0.012526502832770348, train_loss=0.01674320548772812, time_cost=2.968496561050415
Steps:   1%|▏         | 14765/1000000 [4:28:30<2715:30:08,  9.92s/it, lr=1e-5, step_loss=0.0125]Steps:   1%|▏         | 14766/1000000 [4:28:39<2679:11:04,  9.79s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [14766], local_loss=0.0484674833714962, train_loss=0.0439952090382576, time_cost=6.355089902877808
Steps:   1%|▏         | 14766/1000000 [4:28:39<2679:11:04,  9.79s/it, lr=1e-5, step_loss=0.0485]Steps:   1%|▏         | 14767/1000000 [4:28:47<2556:09:48,  9.34s/it, lr=1e-5, step_loss=0.0485][RANK-0]: Step: [14767], local_loss=0.0194169282913208, train_loss=0.03641030937433243, time_cost=1.214000940322876
Steps:   1%|▏         | 14767/1000000 [4:28:47<2556:09:48,  9.34s/it, lr=1e-5, step_loss=0.0194]Steps:   1%|▏         | 14768/1000000 [4:28:52<2154:31:59,  7.87s/it, lr=1e-5, step_loss=0.0194][RANK-0]: Step: [14768], local_loss=0.008644084446132183, train_loss=7.058232307434082, time_cost=1.331955909729004
Steps:   1%|▏         | 14768/1000000 [4:28:52<2154:31:59,  7.87s/it, lr=1e-5, step_loss=0.00864]Steps:   1%|▏         | 14769/1000000 [4:29:01<2267:48:22,  8.29s/it, lr=1e-5, step_loss=0.00864][RANK-0]: Step: [14769], local_loss=0.07727541029453278, train_loss=0.035246506333351135, time_cost=3.452263116836548
Steps:   1%|▏         | 14769/1000000 [4:29:01<2267:48:22,  8.29s/it, lr=1e-5, step_loss=0.0773] Steps:   1%|▏         | 14770/1000000 [4:29:17<2861:35:03, 10.46s/it, lr=1e-5, step_loss=0.0773][RANK-0]: Step: [14770], local_loss=0.06920063495635986, train_loss=0.04885569587349892, time_cost=6.952779293060303
Steps:   1%|▏         | 14770/1000000 [4:29:17<2861:35:03, 10.46s/it, lr=1e-5, step_loss=0.0692]Steps:   1%|▏         | 14771/1000000 [4:29:30<3117:10:31, 11.39s/it, lr=1e-5, step_loss=0.0692][RANK-0]: Step: [14771], local_loss=0.007162939291447401, train_loss=0.016770139336586, time_cost=3.999751329421997
Steps:   1%|▏         | 14771/1000000 [4:29:30<3117:10:31, 11.39s/it, lr=1e-5, step_loss=0.00716]Steps:   1%|▏         | 14772/1000000 [4:29:37<2740:05:45, 10.01s/it, lr=1e-5, step_loss=0.00716][RANK-0]: Step: [14772], local_loss=0.008420668542385101, train_loss=8.098228454589844, time_cost=2.69419264793396
Steps:   1%|▏         | 14772/1000000 [4:29:37<2740:05:45, 10.01s/it, lr=1e-5, step_loss=0.00842]Steps:   1%|▏         | 14773/1000000 [4:29:42<2330:32:18,  8.52s/it, lr=1e-5, step_loss=0.00842][RANK-0]: Step: [14773], local_loss=0.00513613922521472, train_loss=0.017110681161284447, time_cost=2.0475590229034424
Steps:   1%|▏         | 14773/1000000 [4:29:42<2330:32:18,  8.52s/it, lr=1e-5, step_loss=0.00514]Steps:   1%|▏         | 14774/1000000 [4:29:53<2527:18:28,  9.23s/it, lr=1e-5, step_loss=0.00514][RANK-0]: Step: [14774], local_loss=0.037232983857393265, train_loss=0.14993226528167725, time_cost=1.2119042873382568
Steps:   1%|▏         | 14774/1000000 [4:29:53<2527:18:28,  9.23s/it, lr=1e-5, step_loss=0.0372] Steps:   1%|▏         | 14775/1000000 [4:30:06<2858:58:02, 10.45s/it, lr=1e-5, step_loss=0.0372][RANK-0]: Step: [14775], local_loss=0.038351304829120636, train_loss=0.028034694492816925, time_cost=1.2315614223480225
Steps:   1%|▏         | 14775/1000000 [4:30:06<2858:58:02, 10.45s/it, lr=1e-5, step_loss=0.0384]Steps:   1%|▏         | 14776/1000000 [4:30:12<2488:34:27,  9.09s/it, lr=1e-5, step_loss=0.0384][RANK-0]: Step: [14776], local_loss=0.010765165090560913, train_loss=0.01721728779375553, time_cost=1.9841575622558594
Steps:   1%|▏         | 14776/1000000 [4:30:12<2488:34:27,  9.09s/it, lr=1e-5, step_loss=0.0108]Steps:   1%|▏         | 14777/1000000 [4:30:28<3036:31:29, 11.10s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [14777], local_loss=0.033903785049915314, train_loss=0.029913734644651413, time_cost=8.550203323364258
Steps:   1%|▏         | 14777/1000000 [4:30:28<3036:31:29, 11.10s/it, lr=1e-5, step_loss=0.0339]Steps:   1%|▏         | 14778/1000000 [4:30:44<3413:04:22, 12.47s/it, lr=1e-5, step_loss=0.0339][RANK-0]: Step: [14778], local_loss=0.010332545265555382, train_loss=0.12545551359653473, time_cost=4.693894147872925
Steps:   1%|▏         | 14778/1000000 [4:30:44<3413:04:22, 12.47s/it, lr=1e-5, step_loss=0.0103]Steps:   1%|▏         | 14779/1000000 [4:30:49<2801:28:58, 10.24s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [14779], local_loss=0.022868186235427856, train_loss=0.018375590443611145, time_cost=1.8281707763671875
Steps:   1%|▏         | 14779/1000000 [4:30:49<2801:28:58, 10.24s/it, lr=1e-5, step_loss=0.0229]Steps:   1%|▏         | 14780/1000000 [4:30:55<2456:13:33,  8.98s/it, lr=1e-5, step_loss=0.0229][RANK-0]: Step: [14780], local_loss=0.008868050761520863, train_loss=0.0421130396425724, time_cost=1.9158589839935303
Steps:   1%|▏         | 14780/1000000 [4:30:55<2456:13:33,  8.98s/it, lr=1e-5, step_loss=0.00887]Steps:   1%|▏         | 14781/1000000 [4:31:07<2721:24:15,  9.94s/it, lr=1e-5, step_loss=0.00887][RANK-0]: Step: [14781], local_loss=0.008531318977475166, train_loss=0.04000496864318848, time_cost=4.0945892333984375
Steps:   1%|▏         | 14781/1000000 [4:31:07<2721:24:15,  9.94s/it, lr=1e-5, step_loss=0.00853]Steps:   1%|▏         | 14782/1000000 [4:31:15<2549:14:21,  9.31s/it, lr=1e-5, step_loss=0.00853][RANK-0]: Step: [14782], local_loss=0.03146262466907501, train_loss=0.03291485458612442, time_cost=1.5769782066345215
Steps:   1%|▏         | 14782/1000000 [4:31:15<2549:14:21,  9.31s/it, lr=1e-5, step_loss=0.0315] Steps:   1%|▏         | 14783/1000000 [4:31:21<2324:13:41,  8.49s/it, lr=1e-5, step_loss=0.0315][RANK-0]: Step: [14783], local_loss=0.006524811964482069, train_loss=0.049108412116765976, time_cost=1.6601858139038086
Steps:   1%|▏         | 14783/1000000 [4:31:21<2324:13:41,  8.49s/it, lr=1e-5, step_loss=0.00652]Steps:   1%|▏         | 14784/1000000 [4:31:36<2789:10:12, 10.19s/it, lr=1e-5, step_loss=0.00652][RANK-0]: Step: [14784], local_loss=0.06674962490797043, train_loss=0.029498636722564697, time_cost=1.9537417888641357
Steps:   1%|▏         | 14784/1000000 [4:31:36<2789:10:12, 10.19s/it, lr=1e-5, step_loss=0.0667] Steps:   1%|▏         | 14785/1000000 [4:31:52<3301:07:20, 12.06s/it, lr=1e-5, step_loss=0.0667][RANK-0]: Step: [14785], local_loss=0.004551581107079983, train_loss=0.07398337870836258, time_cost=8.131178617477417
Steps:   1%|▏         | 14785/1000000 [4:31:52<3301:07:20, 12.06s/it, lr=1e-5, step_loss=0.00455]Steps:   1%|▏         | 14786/1000000 [4:31:57<2742:55:45, 10.02s/it, lr=1e-5, step_loss=0.00455][RANK-0]: Step: [14786], local_loss=0.004014684818685055, train_loss=0.029241304844617844, time_cost=2.417013168334961
Steps:   1%|▏         | 14786/1000000 [4:31:57<2742:55:45, 10.02s/it, lr=1e-5, step_loss=0.00401]Steps:   1%|▏         | 14787/1000000 [4:32:08<2799:22:30, 10.23s/it, lr=1e-5, step_loss=0.00401][RANK-0]: Step: [14787], local_loss=0.01321581844240427, train_loss=0.1387391835451126, time_cost=3.033693313598633
Steps:   1%|▏         | 14787/1000000 [4:32:08<2799:22:30, 10.23s/it, lr=1e-5, step_loss=0.0132] Steps:   1%|▏         | 14788/1000000 [4:32:19<2862:21:12, 10.46s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [14788], local_loss=0.022436074912548065, train_loss=0.06224597245454788, time_cost=1.5777034759521484
Steps:   1%|▏         | 14788/1000000 [4:32:19<2862:21:12, 10.46s/it, lr=1e-5, step_loss=0.0224]Steps:   1%|▏         | 14789/1000000 [4:32:34<3256:01:24, 11.90s/it, lr=1e-5, step_loss=0.0224][RANK-0]: Step: [14789], local_loss=0.020938629284501076, train_loss=0.06824871152639389, time_cost=1.9491233825683594
Steps:   1%|▏         | 14789/1000000 [4:32:34<3256:01:24, 11.90s/it, lr=1e-5, step_loss=0.0209]Steps:   1%|▏         | 14790/1000000 [4:32:45<3147:49:56, 11.50s/it, lr=1e-5, step_loss=0.0209][RANK-0]: Step: [14790], local_loss=0.04382288083434105, train_loss=0.03874736651778221, time_cost=1.2349133491516113
Steps:   1%|▏         | 14790/1000000 [4:32:45<3147:49:56, 11.50s/it, lr=1e-5, step_loss=0.0438]Steps:   1%|▏         | 14791/1000000 [4:32:53<2859:10:09, 10.45s/it, lr=1e-5, step_loss=0.0438][RANK-0]: Step: [14791], local_loss=0.014927122741937637, train_loss=0.023195164278149605, time_cost=6.880376815795898
Steps:   1%|▏         | 14791/1000000 [4:32:53<2859:10:09, 10.45s/it, lr=1e-5, step_loss=0.0149]Steps:   1%|▏         | 14792/1000000 [4:32:59<2511:15:24,  9.18s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [14792], local_loss=0.05654202774167061, train_loss=0.028914660215377808, time_cost=1.8314435482025146
Steps:   1%|▏         | 14792/1000000 [4:32:59<2511:15:24,  9.18s/it, lr=1e-5, step_loss=0.0565]Steps:   1%|▏         | 14793/1000000 [4:33:04<2192:11:41,  8.01s/it, lr=1e-5, step_loss=0.0565][RANK-0]: Step: [14793], local_loss=0.20125256478786469, train_loss=0.12844346463680267, time_cost=1.2321248054504395
Steps:   1%|▏         | 14793/1000000 [4:33:04<2192:11:41,  8.01s/it, lr=1e-5, step_loss=0.201] Steps:   1%|▏         | 14794/1000000 [4:33:09<1953:29:50,  7.14s/it, lr=1e-5, step_loss=0.201][RANK-0]: Step: [14794], local_loss=0.012855418026447296, train_loss=0.02728576585650444, time_cost=2.3032679557800293
Steps:   1%|▏         | 14794/1000000 [4:33:09<1953:29:50,  7.14s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 14795/1000000 [4:33:14<1724:18:38,  6.30s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [14795], local_loss=0.014855224639177322, train_loss=0.19601213932037354, time_cost=1.7855050563812256
Steps:   1%|▏         | 14795/1000000 [4:33:14<1724:18:38,  6.30s/it, lr=1e-5, step_loss=0.0149]Steps:   1%|▏         | 14796/1000000 [4:33:22<1913:31:55,  6.99s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [14796], local_loss=0.01272561214864254, train_loss=0.0710512101650238, time_cost=1.443211317062378
Steps:   1%|▏         | 14796/1000000 [4:33:22<1913:31:55,  6.99s/it, lr=1e-5, step_loss=0.0127]Steps:   1%|▏         | 14797/1000000 [4:33:29<1930:37:37,  7.05s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [14797], local_loss=0.007273312192410231, train_loss=0.016218282282352448, time_cost=1.5101521015167236
Steps:   1%|▏         | 14797/1000000 [4:33:29<1930:37:37,  7.05s/it, lr=1e-5, step_loss=0.00727]Steps:   1%|▏         | 14798/1000000 [4:33:35<1775:30:34,  6.49s/it, lr=1e-5, step_loss=0.00727][RANK-0]: Step: [14798], local_loss=0.011823873966932297, train_loss=0.04968133568763733, time_cost=1.8631386756896973
Steps:   1%|▏         | 14798/1000000 [4:33:35<1775:30:34,  6.49s/it, lr=1e-5, step_loss=0.0118] Steps:   1%|▏         | 14799/1000000 [4:33:47<2276:18:15,  8.32s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [14799], local_loss=0.04705583676695824, train_loss=0.05561906099319458, time_cost=2.690302610397339
Steps:   1%|▏         | 14799/1000000 [4:33:47<2276:18:15,  8.32s/it, lr=1e-5, step_loss=0.0471]Steps:   1%|▏         | 14800/1000000 [4:34:05<3039:49:34, 11.11s/it, lr=1e-5, step_loss=0.0471][RANK-0]: Step: [14800], local_loss=0.022454898804426193, train_loss=0.0459202378988266, time_cost=8.98517394065857
Steps:   1%|▏         | 14800/1000000 [4:34:05<3039:49:34, 11.11s/it, lr=1e-5, step_loss=0.0225]Steps:   1%|▏         | 14801/1000000 [4:34:21<3417:51:05, 12.49s/it, lr=1e-5, step_loss=0.0225][RANK-0]: Step: [14801], local_loss=0.00830603577196598, train_loss=0.09358292073011398, time_cost=7.7917492389678955
Steps:   1%|▏         | 14801/1000000 [4:34:21<3417:51:05, 12.49s/it, lr=1e-5, step_loss=0.00831]Steps:   1%|▏         | 14802/1000000 [4:34:28<2970:11:05, 10.85s/it, lr=1e-5, step_loss=0.00831][RANK-0]: Step: [14802], local_loss=0.0058510443195700645, train_loss=0.033347517251968384, time_cost=5.732261657714844
Steps:   1%|▏         | 14802/1000000 [4:34:28<2970:11:05, 10.85s/it, lr=1e-5, step_loss=0.00585]Steps:   1%|▏         | 14803/1000000 [4:34:37<2834:09:28, 10.36s/it, lr=1e-5, step_loss=0.00585][RANK-0]: Step: [14803], local_loss=0.03989694267511368, train_loss=0.05242391303181648, time_cost=3.2324094772338867
Steps:   1%|▏         | 14803/1000000 [4:34:37<2834:09:28, 10.36s/it, lr=1e-5, step_loss=0.0399] Steps:   1%|▏         | 14804/1000000 [4:34:43<2476:51:24,  9.05s/it, lr=1e-5, step_loss=0.0399][RANK-0]: Step: [14804], local_loss=0.006602143403142691, train_loss=0.08661015331745148, time_cost=2.260833740234375
Steps:   1%|▏         | 14804/1000000 [4:34:43<2476:51:24,  9.05s/it, lr=1e-5, step_loss=0.0066]Steps:   1%|▏         | 14805/1000000 [4:34:48<2128:55:38,  7.78s/it, lr=1e-5, step_loss=0.0066][RANK-0]: Step: [14805], local_loss=0.01906452514231205, train_loss=0.06989328563213348, time_cost=1.6746571063995361
Steps:   1%|▏         | 14805/1000000 [4:34:48<2128:55:38,  7.78s/it, lr=1e-5, step_loss=0.0191]Steps:   1%|▏         | 14806/1000000 [4:34:55<2121:18:38,  7.75s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [14806], local_loss=0.026610292494297028, train_loss=0.07962582260370255, time_cost=1.9909813404083252
Steps:   1%|▏         | 14806/1000000 [4:34:55<2121:18:38,  7.75s/it, lr=1e-5, step_loss=0.0266]Steps:   1%|▏         | 14807/1000000 [4:35:11<2734:29:25,  9.99s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [14807], local_loss=0.03085925243794918, train_loss=0.09881483018398285, time_cost=1.2211668491363525
Steps:   1%|▏         | 14807/1000000 [4:35:11<2734:29:25,  9.99s/it, lr=1e-5, step_loss=0.0309]Steps:   1%|▏         | 14808/1000000 [4:35:18<2544:55:28,  9.30s/it, lr=1e-5, step_loss=0.0309][RANK-0]: Step: [14808], local_loss=0.013425284996628761, train_loss=0.031245749443769455, time_cost=3.4435243606567383
Steps:   1%|▏         | 14808/1000000 [4:35:18<2544:55:28,  9.30s/it, lr=1e-5, step_loss=0.0134]Steps:   1%|▏         | 14809/1000000 [4:35:30<2710:46:55,  9.91s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [14809], local_loss=0.07911606132984161, train_loss=0.05628331005573273, time_cost=8.751146078109741
Steps:   1%|▏         | 14809/1000000 [4:35:30<2710:46:55,  9.91s/it, lr=1e-5, step_loss=0.0791]Steps:   1%|▏         | 14810/1000000 [4:35:46<3213:24:12, 11.74s/it, lr=1e-5, step_loss=0.0791][RANK-0]: Step: [14810], local_loss=0.389151394367218, train_loss=0.11878819018602371, time_cost=4.353291034698486
Steps:   1%|▏         | 14810/1000000 [4:35:46<3213:24:12, 11.74s/it, lr=1e-5, step_loss=0.389] Steps:   1%|▏         | 14811/1000000 [4:35:50<2603:41:30,  9.51s/it, lr=1e-5, step_loss=0.389][RANK-0]: Step: [14811], local_loss=0.004962211009114981, train_loss=0.023937920108437538, time_cost=1.2239768505096436
Steps:   1%|▏         | 14811/1000000 [4:35:50<2603:41:30,  9.51s/it, lr=1e-5, step_loss=0.00496]Steps:   1%|▏         | 14812/1000000 [4:35:54<2191:42:25,  8.01s/it, lr=1e-5, step_loss=0.00496][RANK-0]: Step: [14812], local_loss=0.005521959159523249, train_loss=0.05101299285888672, time_cost=1.259460687637329
Steps:   1%|▏         | 14812/1000000 [4:35:54<2191:42:25,  8.01s/it, lr=1e-5, step_loss=0.00552]Steps:   1%|▏         | 14813/1000000 [4:36:05<2405:45:08,  8.79s/it, lr=1e-5, step_loss=0.00552][RANK-0]: Step: [14813], local_loss=0.04479566216468811, train_loss=0.023201484233140945, time_cost=1.563767910003662
Steps:   1%|▏         | 14813/1000000 [4:36:05<2405:45:08,  8.79s/it, lr=1e-5, step_loss=0.0448] Steps:   1%|▏         | 14814/1000000 [4:36:18<2790:14:09, 10.20s/it, lr=1e-5, step_loss=0.0448][RANK-0]: Step: [14814], local_loss=0.024646004661917686, train_loss=0.028846604749560356, time_cost=4.551395654678345
Steps:   1%|▏         | 14814/1000000 [4:36:18<2790:14:09, 10.20s/it, lr=1e-5, step_loss=0.0246]Steps:   1%|▏         | 14815/1000000 [4:36:33<3108:01:23, 11.36s/it, lr=1e-5, step_loss=0.0246][RANK-0]: Step: [14815], local_loss=0.016155889257788658, train_loss=0.03301559388637543, time_cost=4.212308406829834
Steps:   1%|▏         | 14815/1000000 [4:36:33<3108:01:23, 11.36s/it, lr=1e-5, step_loss=0.0162]Steps:   1%|▏         | 14816/1000000 [4:36:42<2990:40:58, 10.93s/it, lr=1e-5, step_loss=0.0162][RANK-0]: Step: [14816], local_loss=0.011028851382434368, train_loss=0.009879467077553272, time_cost=1.232269048690796
Steps:   1%|▏         | 14816/1000000 [4:36:42<2990:40:58, 10.93s/it, lr=1e-5, step_loss=0.011] Steps:   1%|▏         | 14817/1000000 [4:36:56<3181:10:25, 11.62s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [14817], local_loss=0.011789103038609028, train_loss=0.17564740777015686, time_cost=3.7086598873138428
Steps:   1%|▏         | 14817/1000000 [4:36:56<3181:10:25, 11.62s/it, lr=1e-5, step_loss=0.0118]Steps:   1%|▏         | 14818/1000000 [4:37:03<2804:21:02, 10.25s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [14818], local_loss=0.005012230481952429, train_loss=7.963468074798584, time_cost=2.623952627182007
Steps:   1%|▏         | 14818/1000000 [4:37:03<2804:21:02, 10.25s/it, lr=1e-5, step_loss=0.00501]Steps:   1%|▏         | 14819/1000000 [4:37:08<2394:58:15,  8.75s/it, lr=1e-5, step_loss=0.00501][RANK-0]: Step: [14819], local_loss=0.017702795565128326, train_loss=0.05346386879682541, time_cost=2.484811544418335
Steps:   1%|▏         | 14819/1000000 [4:37:08<2394:58:15,  8.75s/it, lr=1e-5, step_loss=0.0177] Steps:   1%|▏         | 14820/1000000 [4:37:21<2749:10:07, 10.05s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [14820], local_loss=0.012014608830213547, train_loss=0.022114213556051254, time_cost=4.284900188446045
Steps:   1%|▏         | 14820/1000000 [4:37:21<2749:10:07, 10.05s/it, lr=1e-5, step_loss=0.012] Steps:   1%|▏         | 14821/1000000 [4:37:35<3053:13:54, 11.16s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [14821], local_loss=0.023724708706140518, train_loss=0.02087450958788395, time_cost=1.22501540184021
Steps:   1%|▏         | 14821/1000000 [4:37:35<3053:13:54, 11.16s/it, lr=1e-5, step_loss=0.0237]Steps:   1%|▏         | 14822/1000000 [4:37:45<2940:44:44, 10.75s/it, lr=1e-5, step_loss=0.0237][RANK-0]: Step: [14822], local_loss=0.007905077189207077, train_loss=0.023478591814637184, time_cost=3.8023836612701416
Steps:   1%|▏         | 14822/1000000 [4:37:45<2940:44:44, 10.75s/it, lr=1e-5, step_loss=0.00791]Steps:   1%|▏         | 14823/1000000 [4:38:01<3393:20:51, 12.40s/it, lr=1e-5, step_loss=0.00791][RANK-0]: Step: [14823], local_loss=0.033159732818603516, train_loss=0.08190475404262543, time_cost=6.152115345001221
Steps:   1%|▏         | 14823/1000000 [4:38:01<3393:20:51, 12.40s/it, lr=1e-5, step_loss=0.0332] Steps:   1%|▏         | 14824/1000000 [4:38:05<2737:03:25, 10.00s/it, lr=1e-5, step_loss=0.0332][RANK-0]: Step: [14824], local_loss=0.005802393425256014, train_loss=0.022196782752871513, time_cost=3.2853963375091553
Steps:   1%|▏         | 14824/1000000 [4:38:05<2737:03:25, 10.00s/it, lr=1e-5, step_loss=0.0058]Steps:   1%|▏         | 14825/1000000 [4:38:15<2753:54:05, 10.06s/it, lr=1e-5, step_loss=0.0058][RANK-0]: Step: [14825], local_loss=0.06451235711574554, train_loss=0.04599297419190407, time_cost=4.047606706619263
Steps:   1%|▏         | 14825/1000000 [4:38:15<2753:54:05, 10.06s/it, lr=1e-5, step_loss=0.0645]Steps:   1%|▏         | 14826/1000000 [4:38:27<2904:38:05, 10.61s/it, lr=1e-5, step_loss=0.0645][RANK-0]: Step: [14826], local_loss=0.00855304580181837, train_loss=0.0285965483635664, time_cost=1.2130327224731445
Steps:   1%|▏         | 14826/1000000 [4:38:27<2904:38:05, 10.61s/it, lr=1e-5, step_loss=0.00855]Steps:   1%|▏         | 14827/1000000 [4:38:33<2508:51:37,  9.17s/it, lr=1e-5, step_loss=0.00855][RANK-0]: Step: [14827], local_loss=0.005043285898864269, train_loss=0.015779532492160797, time_cost=1.4831554889678955
Steps:   1%|▏         | 14827/1000000 [4:38:33<2508:51:37,  9.17s/it, lr=1e-5, step_loss=0.00504]Steps:   1%|▏         | 14828/1000000 [4:38:45<2689:34:33,  9.83s/it, lr=1e-5, step_loss=0.00504][RANK-0]: Step: [14828], local_loss=0.00866618100553751, train_loss=0.06484987586736679, time_cost=2.7751071453094482
Steps:   1%|▏         | 14828/1000000 [4:38:45<2689:34:33,  9.83s/it, lr=1e-5, step_loss=0.00867]Steps:   1%|▏         | 14829/1000000 [4:38:50<2297:48:11,  8.40s/it, lr=1e-5, step_loss=0.00867][RANK-0]: Step: [14829], local_loss=0.006524417549371719, train_loss=0.025813501328229904, time_cost=2.2193331718444824
Steps:   1%|▏         | 14829/1000000 [4:38:50<2297:48:11,  8.40s/it, lr=1e-5, step_loss=0.00652]Steps:   1%|▏         | 14830/1000000 [4:39:03<2724:54:00,  9.96s/it, lr=1e-5, step_loss=0.00652][RANK-0]: Step: [14830], local_loss=0.05991845205426216, train_loss=0.02402748540043831, time_cost=2.2206180095672607
Steps:   1%|▏         | 14830/1000000 [4:39:03<2724:54:00,  9.96s/it, lr=1e-5, step_loss=0.0599] Steps:   1%|▏         | 14831/1000000 [4:39:10<2482:55:19,  9.07s/it, lr=1e-5, step_loss=0.0599][RANK-0]: Step: [14831], local_loss=0.013099508360028267, train_loss=5.575165271759033, time_cost=2.61555814743042
Steps:   1%|▏         | 14831/1000000 [4:39:10<2482:55:19,  9.07s/it, lr=1e-5, step_loss=0.0131]Steps:   1%|▏         | 14832/1000000 [4:39:17<2301:57:18,  8.41s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [14832], local_loss=0.006344515364617109, train_loss=0.029359815642237663, time_cost=3.0772736072540283
Steps:   1%|▏         | 14832/1000000 [4:39:17<2301:57:18,  8.41s/it, lr=1e-5, step_loss=0.00634]Steps:   1%|▏         | 14833/1000000 [4:39:31<2797:04:00, 10.22s/it, lr=1e-5, step_loss=0.00634][RANK-0]: Step: [14833], local_loss=0.008183229714632034, train_loss=0.032412074506282806, time_cost=5.297165870666504
Steps:   1%|▏         | 14833/1000000 [4:39:32<2797:04:00, 10.22s/it, lr=1e-5, step_loss=0.00818]Steps:   1%|▏         | 14834/1000000 [4:39:37<2444:30:35,  8.93s/it, lr=1e-5, step_loss=0.00818][RANK-0]: Step: [14834], local_loss=0.013165713287889957, train_loss=0.014291333965957165, time_cost=1.666050910949707
Steps:   1%|▏         | 14834/1000000 [4:39:37<2444:30:35,  8.93s/it, lr=1e-5, step_loss=0.0132] Steps:   1%|▏         | 14835/1000000 [4:39:51<2852:04:29, 10.42s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [14835], local_loss=0.05431947857141495, train_loss=0.029154865071177483, time_cost=4.6055755615234375
Steps:   1%|▏         | 14835/1000000 [4:39:51<2852:04:29, 10.42s/it, lr=1e-5, step_loss=0.0543]Steps:   1%|▏         | 14836/1000000 [4:40:04<3048:08:48, 11.14s/it, lr=1e-5, step_loss=0.0543][RANK-0]: Step: [14836], local_loss=0.009044593200087547, train_loss=0.05978616327047348, time_cost=5.127327919006348
Steps:   1%|▏         | 14836/1000000 [4:40:04<3048:08:48, 11.14s/it, lr=1e-5, step_loss=0.00904]Steps:   1%|▏         | 14837/1000000 [4:40:19<3357:18:08, 12.27s/it, lr=1e-5, step_loss=0.00904][RANK-0]: Step: [14837], local_loss=0.036407601088285446, train_loss=0.09661763906478882, time_cost=5.8117735385894775
Steps:   1%|▏         | 14837/1000000 [4:40:19<3357:18:08, 12.27s/it, lr=1e-5, step_loss=0.0364] Steps:   1%|▏         | 14838/1000000 [4:40:27<2964:39:31, 10.83s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [14838], local_loss=0.026945089921355247, train_loss=0.018328092992305756, time_cost=3.2910406589508057
Steps:   1%|▏         | 14838/1000000 [4:40:27<2964:39:31, 10.83s/it, lr=1e-5, step_loss=0.0269]Steps:   1%|▏         | 14839/1000000 [4:40:41<3257:04:37, 11.90s/it, lr=1e-5, step_loss=0.0269][RANK-0]: Step: [14839], local_loss=0.09669850021600723, train_loss=8.161358833312988, time_cost=2.2960116863250732
Steps:   1%|▏         | 14839/1000000 [4:40:41<3257:04:37, 11.90s/it, lr=1e-5, step_loss=0.0967]Steps:   1%|▏         | 14840/1000000 [4:40:46<2683:38:29,  9.81s/it, lr=1e-5, step_loss=0.0967][RANK-0]: Step: [14840], local_loss=0.0648893415927887, train_loss=0.017864849418401718, time_cost=1.319504737854004
Steps:   1%|▏         | 14840/1000000 [4:40:46<2683:38:29,  9.81s/it, lr=1e-5, step_loss=0.0649]Steps:   1%|▏         | 14841/1000000 [4:40:59<2924:16:13, 10.69s/it, lr=1e-5, step_loss=0.0649][RANK-0]: Step: [14841], local_loss=0.02936621569097042, train_loss=0.037061143666505814, time_cost=1.268625020980835
Steps:   1%|▏         | 14841/1000000 [4:40:59<2924:16:13, 10.69s/it, lr=1e-5, step_loss=0.0294]Steps:   1%|▏         | 14842/1000000 [4:41:03<2411:50:40,  8.81s/it, lr=1e-5, step_loss=0.0294][RANK-0]: Step: [14842], local_loss=0.05391436070203781, train_loss=0.05640628933906555, time_cost=1.3912291526794434
Steps:   1%|▏         | 14842/1000000 [4:41:03<2411:50:40,  8.81s/it, lr=1e-5, step_loss=0.0539]Steps:   1%|▏         | 14843/1000000 [4:41:09<2162:17:56,  7.90s/it, lr=1e-5, step_loss=0.0539][RANK-0]: Step: [14843], local_loss=0.9915362000465393, train_loss=0.14502274990081787, time_cost=1.3004136085510254
Steps:   1%|▏         | 14843/1000000 [4:41:09<2162:17:56,  7.90s/it, lr=1e-5, step_loss=0.992] Steps:   1%|▏         | 14844/1000000 [4:41:26<2932:05:45, 10.71s/it, lr=1e-5, step_loss=0.992][RANK-0]: Step: [14844], local_loss=0.01064026728272438, train_loss=0.0230155810713768, time_cost=5.1924803256988525
Steps:   1%|▏         | 14844/1000000 [4:41:26<2932:05:45, 10.71s/it, lr=1e-5, step_loss=0.0106]Steps:   1%|▏         | 14845/1000000 [4:41:34<2701:13:13,  9.87s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [14845], local_loss=0.004120511468499899, train_loss=0.02271994575858116, time_cost=3.84908127784729
Steps:   1%|▏         | 14845/1000000 [4:41:34<2701:13:13,  9.87s/it, lr=1e-5, step_loss=0.00412]Steps:   1%|▏         | 14846/1000000 [4:41:40<2420:47:04,  8.85s/it, lr=1e-5, step_loss=0.00412][RANK-0]: Step: [14846], local_loss=0.10944651067256927, train_loss=0.10224325954914093, time_cost=2.684401512145996
Steps:   1%|▏         | 14846/1000000 [4:41:40<2420:47:04,  8.85s/it, lr=1e-5, step_loss=0.109]  Steps:   1%|▏         | 14847/1000000 [4:41:51<2533:45:28,  9.26s/it, lr=1e-5, step_loss=0.109][RANK-0]: Step: [14847], local_loss=0.009811503812670708, train_loss=0.05238841846585274, time_cost=2.2114155292510986
Steps:   1%|▏         | 14847/1000000 [4:41:51<2533:45:28,  9.26s/it, lr=1e-5, step_loss=0.00981]Steps:   1%|▏         | 14848/1000000 [4:42:01<2656:19:53,  9.71s/it, lr=1e-5, step_loss=0.00981][RANK-0]: Step: [14848], local_loss=0.008690925315022469, train_loss=0.1441684365272522, time_cost=3.019426107406616
Steps:   1%|▏         | 14848/1000000 [4:42:01<2656:19:53,  9.71s/it, lr=1e-5, step_loss=0.00869]Steps:   1%|▏         | 14849/1000000 [4:42:12<2692:50:00,  9.84s/it, lr=1e-5, step_loss=0.00869][RANK-0]: Step: [14849], local_loss=0.004557411652058363, train_loss=0.054172225296497345, time_cost=3.872861385345459
Steps:   1%|▏         | 14849/1000000 [4:42:12<2692:50:00,  9.84s/it, lr=1e-5, step_loss=0.00456]Steps:   1%|▏         | 14850/1000000 [4:42:24<2917:13:33, 10.66s/it, lr=1e-5, step_loss=0.00456][RANK-0]: Step: [14850], local_loss=0.020394615828990936, train_loss=0.039784468710422516, time_cost=8.588949918746948
Steps:   1%|▏         | 14850/1000000 [4:42:24<2917:13:33, 10.66s/it, lr=1e-5, step_loss=0.0204] Steps:   1%|▏         | 14851/1000000 [4:42:29<2435:52:46,  8.90s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [14851], local_loss=0.029995985329151154, train_loss=0.0241068247705698, time_cost=2.3414998054504395
Steps:   1%|▏         | 14851/1000000 [4:42:29<2435:52:46,  8.90s/it, lr=1e-5, step_loss=0.03]  Steps:   1%|▏         | 14852/1000000 [4:42:46<3105:40:13, 11.35s/it, lr=1e-5, step_loss=0.03][RANK-0]: Step: [14852], local_loss=0.03151186555624008, train_loss=0.02915005013346672, time_cost=9.544118404388428
Steps:   1%|▏         | 14852/1000000 [4:42:46<3105:40:13, 11.35s/it, lr=1e-5, step_loss=0.0315]Steps:   1%|▏         | 14853/1000000 [4:42:50<2525:11:39,  9.23s/it, lr=1e-5, step_loss=0.0315][RANK-0]: Step: [14853], local_loss=0.01286035031080246, train_loss=0.03426756337285042, time_cost=1.4227573871612549
Steps:   1%|▏         | 14853/1000000 [4:42:50<2525:11:39,  9.23s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 14854/1000000 [4:42:55<2135:35:50,  7.80s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [14854], local_loss=0.04536835104227066, train_loss=0.03085096925497055, time_cost=1.5889694690704346
Steps:   1%|▏         | 14854/1000000 [4:42:55<2135:35:50,  7.80s/it, lr=1e-5, step_loss=0.0454]Steps:   1%|▏         | 14855/1000000 [4:43:03<2163:01:27,  7.90s/it, lr=1e-5, step_loss=0.0454][RANK-0]: Step: [14855], local_loss=0.018957801163196564, train_loss=0.060819678008556366, time_cost=4.62339186668396
Steps:   1%|▏         | 14855/1000000 [4:43:03<2163:01:27,  7.90s/it, lr=1e-5, step_loss=0.019] Steps:   1%|▏         | 14856/1000000 [4:43:13<2374:34:44,  8.68s/it, lr=1e-5, step_loss=0.019][RANK-0]: Step: [14856], local_loss=0.3215089738368988, train_loss=0.07736272364854813, time_cost=1.8554739952087402
Steps:   1%|▏         | 14856/1000000 [4:43:13<2374:34:44,  8.68s/it, lr=1e-5, step_loss=0.322]Steps:   1%|▏         | 14857/1000000 [4:43:19<2085:54:59,  7.62s/it, lr=1e-5, step_loss=0.322][RANK-0]: Step: [14857], local_loss=0.010412374511361122, train_loss=0.026415303349494934, time_cost=2.189988136291504
Steps:   1%|▏         | 14857/1000000 [4:43:19<2085:54:59,  7.62s/it, lr=1e-5, step_loss=0.0104]Steps:   1%|▏         | 14858/1000000 [4:43:27<2187:26:42,  7.99s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [14858], local_loss=0.0193818099796772, train_loss=0.05466897785663605, time_cost=2.930114269256592
Steps:   1%|▏         | 14858/1000000 [4:43:27<2187:26:42,  7.99s/it, lr=1e-5, step_loss=0.0194]Steps:   1%|▏         | 14859/1000000 [4:43:38<2437:12:17,  8.91s/it, lr=1e-5, step_loss=0.0194][RANK-0]: Step: [14859], local_loss=0.011665517464280128, train_loss=0.02344628795981407, time_cost=1.72764253616333
Steps:   1%|▏         | 14859/1000000 [4:43:38<2437:12:17,  8.91s/it, lr=1e-5, step_loss=0.0117]Steps:   1%|▏         | 14860/1000000 [4:43:43<2056:13:13,  7.51s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [14860], local_loss=0.014888815581798553, train_loss=0.05460862070322037, time_cost=1.2703399658203125
Steps:   1%|▏         | 14860/1000000 [4:43:43<2056:13:13,  7.51s/it, lr=1e-5, step_loss=0.0149]Steps:   1%|▏         | 14861/1000000 [4:43:51<2083:24:32,  7.61s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [14861], local_loss=0.02450750209391117, train_loss=0.16053202748298645, time_cost=2.1387102603912354
Steps:   1%|▏         | 14861/1000000 [4:43:51<2083:24:32,  7.61s/it, lr=1e-5, step_loss=0.0245]Steps:   1%|▏         | 14862/1000000 [4:43:59<2167:38:38,  7.92s/it, lr=1e-5, step_loss=0.0245][RANK-0]: Step: [14862], local_loss=0.03185471147298813, train_loss=0.147830992937088, time_cost=1.2181892395019531
Steps:   1%|▏         | 14862/1000000 [4:43:59<2167:38:38,  7.92s/it, lr=1e-5, step_loss=0.0319]Steps:   1%|▏         | 14863/1000000 [4:44:05<1978:17:14,  7.23s/it, lr=1e-5, step_loss=0.0319][RANK-0]: Step: [14863], local_loss=0.01168286893516779, train_loss=0.1738828718662262, time_cost=2.9378087520599365
Steps:   1%|▏         | 14863/1000000 [4:44:05<1978:17:14,  7.23s/it, lr=1e-5, step_loss=0.0117]Steps:   1%|▏         | 14864/1000000 [4:44:12<1950:37:36,  7.13s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [14864], local_loss=0.23220379650592804, train_loss=0.06015945225954056, time_cost=2.933713674545288
Steps:   1%|▏         | 14864/1000000 [4:44:12<1950:37:36,  7.13s/it, lr=1e-5, step_loss=0.232] Steps:   1%|▏         | 14865/1000000 [4:44:24<2395:07:43,  8.75s/it, lr=1e-5, step_loss=0.232][RANK-0]: Step: [14865], local_loss=0.018582938238978386, train_loss=0.031575486063957214, time_cost=4.049297571182251
Steps:   1%|▏         | 14865/1000000 [4:44:24<2395:07:43,  8.75s/it, lr=1e-5, step_loss=0.0186]Steps:   1%|▏         | 14866/1000000 [4:44:31<2234:56:27,  8.17s/it, lr=1e-5, step_loss=0.0186][RANK-0]: Step: [14866], local_loss=0.010844404809176922, train_loss=0.01850321516394615, time_cost=1.991137981414795
Steps:   1%|▏         | 14866/1000000 [4:44:31<2234:56:27,  8.17s/it, lr=1e-5, step_loss=0.0108]Steps:   1%|▏         | 14867/1000000 [4:44:36<1984:46:09,  7.25s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [14867], local_loss=0.09466363489627838, train_loss=0.038755107671022415, time_cost=2.0824391841888428
Steps:   1%|▏         | 14867/1000000 [4:44:36<1984:46:09,  7.25s/it, lr=1e-5, step_loss=0.0947]Steps:   1%|▏         | 14868/1000000 [4:44:47<2313:11:28,  8.45s/it, lr=1e-5, step_loss=0.0947][RANK-0]: Step: [14868], local_loss=0.07670803368091583, train_loss=0.05899801850318909, time_cost=3.045818567276001
Steps:   1%|▏         | 14868/1000000 [4:44:47<2313:11:28,  8.45s/it, lr=1e-5, step_loss=0.0767]Steps:   1%|▏         | 14869/1000000 [4:45:02<2815:00:41, 10.29s/it, lr=1e-5, step_loss=0.0767][RANK-0]: Step: [14869], local_loss=0.014161542989313602, train_loss=0.012871958315372467, time_cost=6.033977031707764
Steps:   1%|▏         | 14869/1000000 [4:45:02<2815:00:41, 10.29s/it, lr=1e-5, step_loss=0.0142]Steps:   1%|▏         | 14870/1000000 [4:45:07<2395:00:50,  8.75s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [14870], local_loss=0.008356627076864243, train_loss=31.253324508666992, time_cost=2.3718066215515137
Steps:   1%|▏         | 14870/1000000 [4:45:07<2395:00:50,  8.75s/it, lr=1e-5, step_loss=0.00836]Steps:   1%|▏         | 14871/1000000 [4:45:18<2540:08:13,  9.28s/it, lr=1e-5, step_loss=0.00836][RANK-0]: Step: [14871], local_loss=0.01099596917629242, train_loss=43.17817306518555, time_cost=2.065843105316162
Steps:   1%|▏         | 14871/1000000 [4:45:18<2540:08:13,  9.28s/it, lr=1e-5, step_loss=0.011]  Steps:   1%|▏         | 14872/1000000 [4:45:22<2152:45:23,  7.87s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [14872], local_loss=0.011485685594379902, train_loss=0.07860848307609558, time_cost=2.1320953369140625
Steps:   1%|▏         | 14872/1000000 [4:45:22<2152:45:23,  7.87s/it, lr=1e-5, step_loss=0.0115]Steps:   1%|▏         | 14873/1000000 [4:45:33<2359:03:36,  8.62s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [14873], local_loss=0.00956951268017292, train_loss=0.059486325830221176, time_cost=3.9265198707580566
Steps:   1%|▏         | 14873/1000000 [4:45:33<2359:03:36,  8.62s/it, lr=1e-5, step_loss=0.00957]Steps:   1%|▏         | 14874/1000000 [4:45:44<2586:00:45,  9.45s/it, lr=1e-5, step_loss=0.00957][RANK-0]: Step: [14874], local_loss=0.09483054280281067, train_loss=0.032478779554367065, time_cost=1.213463306427002
Steps:   1%|▏         | 14874/1000000 [4:45:44<2586:00:45,  9.45s/it, lr=1e-5, step_loss=0.0948] Steps:   1%|▏         | 14875/1000000 [4:45:57<2868:36:33, 10.48s/it, lr=1e-5, step_loss=0.0948][RANK-0]: Step: [14875], local_loss=0.004477085545659065, train_loss=0.029415035620331764, time_cost=1.2315211296081543
Steps:   1%|▏         | 14875/1000000 [4:45:57<2868:36:33, 10.48s/it, lr=1e-5, step_loss=0.00448]Steps:   1%|▏         | 14876/1000000 [4:46:04<2630:25:03,  9.61s/it, lr=1e-5, step_loss=0.00448][RANK-0]: Step: [14876], local_loss=0.2974267303943634, train_loss=0.06547889858484268, time_cost=2.129624128341675
Steps:   1%|▏         | 14876/1000000 [4:46:04<2630:25:03,  9.61s/it, lr=1e-5, step_loss=0.297]  Steps:   1%|▏         | 14877/1000000 [4:46:09<2255:21:02,  8.24s/it, lr=1e-5, step_loss=0.297][RANK-0]: Step: [14877], local_loss=0.006797281093895435, train_loss=0.08902861922979355, time_cost=2.277390718460083
Steps:   1%|▏         | 14877/1000000 [4:46:10<2255:21:02,  8.24s/it, lr=1e-5, step_loss=0.0068]Steps:   1%|▏         | 14878/1000000 [4:46:24<2783:56:21, 10.17s/it, lr=1e-5, step_loss=0.0068][RANK-0]: Step: [14878], local_loss=0.008729508146643639, train_loss=0.03729673847556114, time_cost=6.384620904922485
Steps:   1%|▏         | 14878/1000000 [4:46:24<2783:56:21, 10.17s/it, lr=1e-5, step_loss=0.00873]Steps:   1%|▏         | 14879/1000000 [4:46:38<3113:17:46, 11.38s/it, lr=1e-5, step_loss=0.00873][RANK-0]: Step: [14879], local_loss=0.003822814440354705, train_loss=0.07443229854106903, time_cost=5.392857313156128
Steps:   1%|▏         | 14879/1000000 [4:46:38<3113:17:46, 11.38s/it, lr=1e-5, step_loss=0.00382]Steps:   1%|▏         | 14880/1000000 [4:46:51<3244:08:25, 11.86s/it, lr=1e-5, step_loss=0.00382][RANK-0]: Step: [14880], local_loss=0.023162072524428368, train_loss=0.07429881393909454, time_cost=1.8364183902740479
Steps:   1%|▏         | 14880/1000000 [4:46:51<3244:08:25, 11.86s/it, lr=1e-5, step_loss=0.0232] Steps:   1%|▏         | 14881/1000000 [4:46:57<2775:57:32, 10.14s/it, lr=1e-5, step_loss=0.0232][RANK-0]: Step: [14881], local_loss=0.0033265589736402035, train_loss=0.045768268406391144, time_cost=2.000793695449829
Steps:   1%|▏         | 14881/1000000 [4:46:57<2775:57:32, 10.14s/it, lr=1e-5, step_loss=0.00333]Steps:   1%|▏         | 14882/1000000 [4:47:12<3161:07:09, 11.55s/it, lr=1e-5, step_loss=0.00333][RANK-0]: Step: [14882], local_loss=0.20817150175571442, train_loss=0.058191344141960144, time_cost=5.534129619598389
Steps:   1%|▏         | 14882/1000000 [4:47:12<3161:07:09, 11.55s/it, lr=1e-5, step_loss=0.208]  Steps:   1%|▏         | 14883/1000000 [4:47:22<3025:14:58, 11.06s/it, lr=1e-5, step_loss=0.208][RANK-0]: Step: [14883], local_loss=0.004683848936110735, train_loss=0.016470635309815407, time_cost=8.400119304656982
Steps:   1%|▏         | 14883/1000000 [4:47:22<3025:14:58, 11.06s/it, lr=1e-5, step_loss=0.00468]Steps:   1%|▏         | 14884/1000000 [4:47:27<2471:32:35,  9.03s/it, lr=1e-5, step_loss=0.00468][RANK-0]: Step: [14884], local_loss=0.0325736328959465, train_loss=0.03558166325092316, time_cost=1.3867528438568115
Steps:   1%|▏         | 14884/1000000 [4:47:27<2471:32:35,  9.03s/it, lr=1e-5, step_loss=0.0326] Steps:   1%|▏         | 14885/1000000 [4:47:31<2082:57:43,  7.61s/it, lr=1e-5, step_loss=0.0326][RANK-0]: Step: [14885], local_loss=0.06649735569953918, train_loss=0.02406466379761696, time_cost=1.2034509181976318
Steps:   1%|▏         | 14885/1000000 [4:47:31<2082:57:43,  7.61s/it, lr=1e-5, step_loss=0.0665]Steps:   1%|▏         | 14886/1000000 [4:47:35<1802:04:12,  6.59s/it, lr=1e-5, step_loss=0.0665][RANK-0]: Step: [14886], local_loss=0.012897252105176449, train_loss=0.019658301025629044, time_cost=1.5552630424499512
Steps:   1%|▏         | 14886/1000000 [4:47:35<1802:04:12,  6.59s/it, lr=1e-5, step_loss=0.0129]Steps:   1%|▏         | 14887/1000000 [4:47:41<1739:37:22,  6.36s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [14887], local_loss=0.035976752638816833, train_loss=0.03292878717184067, time_cost=2.5460376739501953
Steps:   1%|▏         | 14887/1000000 [4:47:41<1739:37:22,  6.36s/it, lr=1e-5, step_loss=0.036] Steps:   1%|▏         | 14888/1000000 [4:47:52<2131:11:20,  7.79s/it, lr=1e-5, step_loss=0.036][RANK-0]: Step: [14888], local_loss=0.03590158745646477, train_loss=0.039994653314352036, time_cost=2.4313416481018066
Steps:   1%|▏         | 14888/1000000 [4:47:52<2131:11:20,  7.79s/it, lr=1e-5, step_loss=0.0359]Steps:   1%|▏         | 14889/1000000 [4:48:05<2583:21:46,  9.44s/it, lr=1e-5, step_loss=0.0359][RANK-0]: Step: [14889], local_loss=0.07831653952598572, train_loss=0.07773766666650772, time_cost=4.103408336639404
Steps:   1%|▏         | 14889/1000000 [4:48:05<2583:21:46,  9.44s/it, lr=1e-5, step_loss=0.0783]Steps:   1%|▏         | 14890/1000000 [4:48:13<2454:40:28,  8.97s/it, lr=1e-5, step_loss=0.0783][RANK-0]: Step: [14890], local_loss=0.011599493212997913, train_loss=0.1914181113243103, time_cost=2.2278833389282227
Steps:   1%|▏         | 14890/1000000 [4:48:13<2454:40:28,  8.97s/it, lr=1e-5, step_loss=0.0116]Steps:   1%|▏         | 14891/1000000 [4:48:18<2136:16:04,  7.81s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [14891], local_loss=0.03936706855893135, train_loss=0.04050739109516144, time_cost=2.1330044269561768
Steps:   1%|▏         | 14891/1000000 [4:48:18<2136:16:04,  7.81s/it, lr=1e-5, step_loss=0.0394]Steps:   1%|▏         | 14892/1000000 [4:48:24<1964:44:22,  7.18s/it, lr=1e-5, step_loss=0.0394][RANK-0]: Step: [14892], local_loss=0.010369147174060345, train_loss=15.301007270812988, time_cost=2.7393319606781006
Steps:   1%|▏         | 14892/1000000 [4:48:24<1964:44:22,  7.18s/it, lr=1e-5, step_loss=0.0104]Steps:   1%|▏         | 14893/1000000 [4:48:38<2526:15:54,  9.23s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [14893], local_loss=0.03423941880464554, train_loss=0.08997899293899536, time_cost=5.656130313873291
Steps:   1%|▏         | 14893/1000000 [4:48:38<2526:15:54,  9.23s/it, lr=1e-5, step_loss=0.0342]Steps:   1%|▏         | 14894/1000000 [4:48:50<2719:09:53,  9.94s/it, lr=1e-5, step_loss=0.0342][RANK-0]: Step: [14894], local_loss=0.007291649002581835, train_loss=0.020896239206194878, time_cost=3.0508487224578857
Steps:   1%|▏         | 14894/1000000 [4:48:50<2719:09:53,  9.94s/it, lr=1e-5, step_loss=0.00729]Steps:   1%|▏         | 14895/1000000 [4:49:00<2776:04:17, 10.14s/it, lr=1e-5, step_loss=0.00729][RANK-0]: Step: [14895], local_loss=0.010838943533599377, train_loss=0.020304029807448387, time_cost=1.2332305908203125
Steps:   1%|▏         | 14895/1000000 [4:49:00<2776:04:17, 10.14s/it, lr=1e-5, step_loss=0.0108] Steps:   1%|▏         | 14896/1000000 [4:49:11<2866:01:10, 10.47s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [14896], local_loss=0.008966566063463688, train_loss=0.01889868453145027, time_cost=1.9922287464141846
Steps:   1%|▏         | 14896/1000000 [4:49:11<2866:01:10, 10.47s/it, lr=1e-5, step_loss=0.00897]Steps:   1%|▏         | 14897/1000000 [4:49:18<2553:52:27,  9.33s/it, lr=1e-5, step_loss=0.00897][RANK-0]: Step: [14897], local_loss=0.012420487590134144, train_loss=0.01929599791765213, time_cost=1.9348959922790527
Steps:   1%|▏         | 14897/1000000 [4:49:18<2553:52:27,  9.33s/it, lr=1e-5, step_loss=0.0124] Steps:   1%|▏         | 14898/1000000 [4:49:24<2231:18:45,  8.15s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [14898], local_loss=0.07140347361564636, train_loss=0.03905991464853287, time_cost=1.2125623226165771
Steps:   1%|▏         | 14898/1000000 [4:49:24<2231:18:45,  8.15s/it, lr=1e-5, step_loss=0.0714]Steps:   1%|▏         | 14899/1000000 [4:49:28<1908:27:10,  6.97s/it, lr=1e-5, step_loss=0.0714][RANK-0]: Step: [14899], local_loss=0.08165682107210159, train_loss=0.030667323619127274, time_cost=1.5373280048370361
Steps:   1%|▏         | 14899/1000000 [4:49:28<1908:27:10,  6.97s/it, lr=1e-5, step_loss=0.0817]Steps:   1%|▏         | 14900/1000000 [4:49:44<2638:58:39,  9.64s/it, lr=1e-5, step_loss=0.0817][RANK-0]: Step: [14900], local_loss=0.19004124402999878, train_loss=0.09126138687133789, time_cost=9.005156517028809
Steps:   1%|▏         | 14900/1000000 [4:49:44<2638:58:39,  9.64s/it, lr=1e-5, step_loss=0.19]  Steps:   1%|▏         | 14901/1000000 [4:49:51<2486:10:20,  9.09s/it, lr=1e-5, step_loss=0.19][RANK-0]: Step: [14901], local_loss=0.009863552637398243, train_loss=0.02184509113430977, time_cost=4.028268098831177
Steps:   1%|▏         | 14901/1000000 [4:49:51<2486:10:20,  9.09s/it, lr=1e-5, step_loss=0.00986]Steps:   1%|▏         | 14902/1000000 [4:50:05<2821:20:05, 10.31s/it, lr=1e-5, step_loss=0.00986][RANK-0]: Step: [14902], local_loss=0.044554226100444794, train_loss=0.05196381360292435, time_cost=4.623145341873169
Steps:   1%|▏         | 14902/1000000 [4:50:05<2821:20:05, 10.31s/it, lr=1e-5, step_loss=0.0446] Steps:   1%|▏         | 14903/1000000 [4:50:19<3159:11:46, 11.55s/it, lr=1e-5, step_loss=0.0446][RANK-0]: Step: [14903], local_loss=0.014319363050162792, train_loss=0.0698741152882576, time_cost=4.879827976226807
Steps:   1%|▏         | 14903/1000000 [4:50:19<3159:11:46, 11.55s/it, lr=1e-5, step_loss=0.0143]Steps:   1%|▏         | 14904/1000000 [4:50:25<2693:16:46,  9.84s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [14904], local_loss=0.004913366865366697, train_loss=0.015425808727741241, time_cost=1.9921445846557617
Steps:   1%|▏         | 14904/1000000 [4:50:25<2693:16:46,  9.84s/it, lr=1e-5, step_loss=0.00491]Steps:   1%|▏         | 14905/1000000 [4:50:33<2574:00:25,  9.41s/it, lr=1e-5, step_loss=0.00491][RANK-0]: Step: [14905], local_loss=0.011673720553517342, train_loss=0.04447215795516968, time_cost=2.658564805984497
Steps:   1%|▏         | 14905/1000000 [4:50:33<2574:00:25,  9.41s/it, lr=1e-5, step_loss=0.0117] Steps:   1%|▏         | 14906/1000000 [4:50:41<2452:43:21,  8.96s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [14906], local_loss=0.007256001699715853, train_loss=0.05185055732727051, time_cost=6.359926462173462
Steps:   1%|▏         | 14906/1000000 [4:50:41<2452:43:21,  8.96s/it, lr=1e-5, step_loss=0.00726]Steps:   1%|▏         | 14907/1000000 [4:50:54<2749:47:28, 10.05s/it, lr=1e-5, step_loss=0.00726][RANK-0]: Step: [14907], local_loss=0.025612955912947655, train_loss=0.029528824612498283, time_cost=3.260500431060791
Steps:   1%|▏         | 14907/1000000 [4:50:54<2749:47:28, 10.05s/it, lr=1e-5, step_loss=0.0256] Steps:   1%|▏         | 14908/1000000 [4:51:08<3068:12:25, 11.21s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [14908], local_loss=0.009396294131875038, train_loss=0.01834207773208618, time_cost=1.266603708267212
Steps:   1%|▏         | 14908/1000000 [4:51:08<3068:12:25, 11.21s/it, lr=1e-5, step_loss=0.0094]Steps:   1%|▏         | 14909/1000000 [4:51:14<2700:12:26,  9.87s/it, lr=1e-5, step_loss=0.0094][RANK-0]: Step: [14909], local_loss=0.0065124304965138435, train_loss=0.03529401123523712, time_cost=2.8514115810394287
Steps:   1%|▏         | 14909/1000000 [4:51:14<2700:12:26,  9.87s/it, lr=1e-5, step_loss=0.00651]Steps:   1%|▏         | 14910/1000000 [4:51:23<2620:38:36,  9.58s/it, lr=1e-5, step_loss=0.00651][RANK-0]: Step: [14910], local_loss=0.03219713270664215, train_loss=0.057958174496889114, time_cost=2.807530164718628
Steps:   1%|▏         | 14910/1000000 [4:51:23<2620:38:36,  9.58s/it, lr=1e-5, step_loss=0.0322] Steps:   1%|▏         | 14911/1000000 [4:51:30<2405:32:38,  8.79s/it, lr=1e-5, step_loss=0.0322][RANK-0]: Step: [14911], local_loss=0.008725691586732864, train_loss=0.04367058724164963, time_cost=1.4010860919952393
Steps:   1%|▏         | 14911/1000000 [4:51:30<2405:32:38,  8.79s/it, lr=1e-5, step_loss=0.00873]Steps:   1%|▏         | 14912/1000000 [4:51:36<2119:30:23,  7.75s/it, lr=1e-5, step_loss=0.00873][RANK-0]: Step: [14912], local_loss=0.029493872076272964, train_loss=0.03331279754638672, time_cost=2.188317060470581
Steps:   1%|▏         | 14912/1000000 [4:51:36<2119:30:23,  7.75s/it, lr=1e-5, step_loss=0.0295] Steps:   1%|▏         | 14913/1000000 [4:51:51<2749:19:03, 10.05s/it, lr=1e-5, step_loss=0.0295][RANK-0]: Step: [14913], local_loss=0.0455271378159523, train_loss=0.022016607224941254, time_cost=3.363168954849243
Steps:   1%|▏         | 14913/1000000 [4:51:51<2749:19:03, 10.05s/it, lr=1e-5, step_loss=0.0455]Steps:   1%|▏         | 14914/1000000 [4:52:02<2793:59:48, 10.21s/it, lr=1e-5, step_loss=0.0455][RANK-0]: Step: [14914], local_loss=0.017495330423116684, train_loss=0.013129323720932007, time_cost=4.987297534942627
Steps:   1%|▏         | 14914/1000000 [4:52:02<2793:59:48, 10.21s/it, lr=1e-5, step_loss=0.0175]Steps:   1%|▏         | 14915/1000000 [4:52:12<2770:56:06, 10.13s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [14915], local_loss=0.01388215646147728, train_loss=0.05900370329618454, time_cost=4.380313158035278
Steps:   1%|▏         | 14915/1000000 [4:52:12<2770:56:06, 10.13s/it, lr=1e-5, step_loss=0.0139]Steps:   1%|▏         | 14916/1000000 [4:52:26<3151:05:09, 11.52s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [14916], local_loss=0.009191063232719898, train_loss=0.05086424946784973, time_cost=11.204217433929443
Steps:   1%|▏         | 14916/1000000 [4:52:26<3151:05:09, 11.52s/it, lr=1e-5, step_loss=0.00919]Steps:   1%|▏         | 14917/1000000 [4:52:32<2648:13:40,  9.68s/it, lr=1e-5, step_loss=0.00919][RANK-0]: Step: [14917], local_loss=0.06794412434101105, train_loss=0.021165715530514717, time_cost=1.9440968036651611
Steps:   1%|▏         | 14917/1000000 [4:52:32<2648:13:40,  9.68s/it, lr=1e-5, step_loss=0.0679] Steps:   1%|▏         | 14918/1000000 [4:52:41<2651:57:33,  9.69s/it, lr=1e-5, step_loss=0.0679][RANK-0]: Step: [14918], local_loss=0.009100977331399918, train_loss=0.09711330384016037, time_cost=1.200270414352417
Steps:   1%|▏         | 14918/1000000 [4:52:41<2651:57:33,  9.69s/it, lr=1e-5, step_loss=0.0091]Steps:   1%|▏         | 14919/1000000 [4:52:46<2268:12:22,  8.29s/it, lr=1e-5, step_loss=0.0091][RANK-0]: Step: [14919], local_loss=0.13404610753059387, train_loss=0.040609899908304214, time_cost=2.076732873916626
Steps:   1%|▏         | 14919/1000000 [4:52:46<2268:12:22,  8.29s/it, lr=1e-5, step_loss=0.134] Steps:   1%|▏         | 14920/1000000 [4:52:53<2163:25:09,  7.91s/it, lr=1e-5, step_loss=0.134][RANK-0]: Step: [14920], local_loss=0.017527960240840912, train_loss=0.01893514394760132, time_cost=3.3025062084198
Steps:   1%|▏         | 14920/1000000 [4:52:53<2163:25:09,  7.91s/it, lr=1e-5, step_loss=0.0175]Steps:   1%|▏         | 14921/1000000 [4:53:07<2635:42:57,  9.63s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [14921], local_loss=0.989104688167572, train_loss=0.25178465247154236, time_cost=3.6236562728881836
Steps:   1%|▏         | 14921/1000000 [4:53:07<2635:42:57,  9.63s/it, lr=1e-5, step_loss=0.989] Steps:   1%|▏         | 14922/1000000 [4:53:12<2263:40:09,  8.27s/it, lr=1e-5, step_loss=0.989][RANK-0]: Step: [14922], local_loss=0.005381550639867783, train_loss=0.03906988352537155, time_cost=2.274428129196167
Steps:   1%|▏         | 14922/1000000 [4:53:12<2263:40:09,  8.27s/it, lr=1e-5, step_loss=0.00538]Steps:   1%|▏         | 14923/1000000 [4:53:20<2241:50:00,  8.19s/it, lr=1e-5, step_loss=0.00538][RANK-0]: Step: [14923], local_loss=0.06275425851345062, train_loss=0.07923828065395355, time_cost=2.518515110015869
Steps:   1%|▏         | 14923/1000000 [4:53:20<2241:50:00,  8.19s/it, lr=1e-5, step_loss=0.0628] Steps:   1%|▏         | 14924/1000000 [4:53:31<2475:14:00,  9.05s/it, lr=1e-5, step_loss=0.0628][RANK-0]: Step: [14924], local_loss=0.022150453180074692, train_loss=0.03947938233613968, time_cost=1.2339355945587158
Steps:   1%|▏         | 14924/1000000 [4:53:31<2475:14:00,  9.05s/it, lr=1e-5, step_loss=0.0222]Steps:   1%|▏         | 14925/1000000 [4:53:42<2628:14:40,  9.61s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [14925], local_loss=0.05998176336288452, train_loss=0.031015988439321518, time_cost=1.931788682937622
Steps:   1%|▏         | 14925/1000000 [4:53:42<2628:14:40,  9.61s/it, lr=1e-5, step_loss=0.06]  Steps:   1%|▏         | 14926/1000000 [4:53:47<2201:53:16,  8.05s/it, lr=1e-5, step_loss=0.06][RANK-0]: Step: [14926], local_loss=0.008434812538325787, train_loss=0.056858599185943604, time_cost=1.7905807495117188
Steps:   1%|▏         | 14926/1000000 [4:53:47<2201:53:16,  8.05s/it, lr=1e-5, step_loss=0.00843]Steps:   1%|▏         | 14927/1000000 [4:54:02<2830:13:38, 10.34s/it, lr=1e-5, step_loss=0.00843][RANK-0]: Step: [14927], local_loss=0.07816984504461288, train_loss=35.160770416259766, time_cost=4.850481033325195
Steps:   1%|▏         | 14927/1000000 [4:54:02<2830:13:38, 10.34s/it, lr=1e-5, step_loss=0.0782] Steps:   1%|▏         | 14928/1000000 [4:54:10<2618:14:20,  9.57s/it, lr=1e-5, step_loss=0.0782][RANK-0]: Step: [14928], local_loss=0.014941250905394554, train_loss=0.020625313743948936, time_cost=1.1936264038085938
Steps:   1%|▏         | 14928/1000000 [4:54:10<2618:14:20,  9.57s/it, lr=1e-5, step_loss=0.0149]Steps:   1%|▏         | 14929/1000000 [4:54:17<2396:11:43,  8.76s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [14929], local_loss=0.5079153776168823, train_loss=0.14052200317382812, time_cost=1.2382590770721436
Steps:   1%|▏         | 14929/1000000 [4:54:17<2396:11:43,  8.76s/it, lr=1e-5, step_loss=0.508] Steps:   1%|▏         | 14930/1000000 [4:54:27<2545:23:16,  9.30s/it, lr=1e-5, step_loss=0.508][RANK-0]: Step: [14930], local_loss=0.01729588769376278, train_loss=0.023306023329496384, time_cost=2.6332755088806152
Steps:   1%|▏         | 14930/1000000 [4:54:27<2545:23:16,  9.30s/it, lr=1e-5, step_loss=0.0173]Steps:   1%|▏         | 14931/1000000 [4:54:35<2415:18:37,  8.83s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [14931], local_loss=0.00836565438657999, train_loss=0.01968005858361721, time_cost=3.4842073917388916
Steps:   1%|▏         | 14931/1000000 [4:54:35<2415:18:37,  8.83s/it, lr=1e-5, step_loss=0.00837]Steps:   1%|▏         | 14932/1000000 [4:54:41<2181:55:25,  7.97s/it, lr=1e-5, step_loss=0.00837][RANK-0]: Step: [14932], local_loss=0.06856310367584229, train_loss=0.032497040927410126, time_cost=4.563480615615845
Steps:   1%|▏         | 14932/1000000 [4:54:41<2181:55:25,  7.97s/it, lr=1e-5, step_loss=0.0686] Steps:   1%|▏         | 14933/1000000 [4:54:46<1949:15:21,  7.12s/it, lr=1e-5, step_loss=0.0686][RANK-0]: Step: [14933], local_loss=0.04252425208687782, train_loss=0.027926165610551834, time_cost=2.0531885623931885
Steps:   1%|▏         | 14933/1000000 [4:54:46<1949:15:21,  7.12s/it, lr=1e-5, step_loss=0.0425]Steps:   1%|▏         | 14934/1000000 [4:54:54<2018:46:24,  7.38s/it, lr=1e-5, step_loss=0.0425][RANK-0]: Step: [14934], local_loss=0.012267474085092545, train_loss=0.015946129336953163, time_cost=6.782374143600464
Steps:   1%|▏         | 14934/1000000 [4:54:54<2018:46:24,  7.38s/it, lr=1e-5, step_loss=0.0123]Steps:   1%|▏         | 14935/1000000 [4:54:59<1827:20:35,  6.68s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [14935], local_loss=0.036382049322128296, train_loss=0.041997164487838745, time_cost=3.8158047199249268
Steps:   1%|▏         | 14935/1000000 [4:54:59<1827:20:35,  6.68s/it, lr=1e-5, step_loss=0.0364]Steps:   1%|▏         | 14936/1000000 [4:55:04<1706:02:30,  6.23s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [14936], local_loss=0.020432639867067337, train_loss=0.013049746863543987, time_cost=4.370388746261597
Steps:   1%|▏         | 14936/1000000 [4:55:04<1706:02:30,  6.23s/it, lr=1e-5, step_loss=0.0204]Steps:   1%|▏         | 14937/1000000 [4:55:13<1872:46:34,  6.84s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [14937], local_loss=0.12094493210315704, train_loss=0.05454851686954498, time_cost=4.454131364822388
Steps:   1%|▏         | 14937/1000000 [4:55:13<1872:46:34,  6.84s/it, lr=1e-5, step_loss=0.121] Steps:   1%|▏         | 14938/1000000 [4:55:25<2331:25:48,  8.52s/it, lr=1e-5, step_loss=0.121][RANK-0]: Step: [14938], local_loss=0.24203114211559296, train_loss=0.04931742697954178, time_cost=1.9732308387756348
Steps:   1%|▏         | 14938/1000000 [4:55:25<2331:25:48,  8.52s/it, lr=1e-5, step_loss=0.242]Steps:   1%|▏         | 14939/1000000 [4:55:33<2288:57:22,  8.37s/it, lr=1e-5, step_loss=0.242][RANK-0]: Step: [14939], local_loss=0.006249512080103159, train_loss=0.15129759907722473, time_cost=3.748800754547119
Steps:   1%|▏         | 14939/1000000 [4:55:33<2288:57:22,  8.37s/it, lr=1e-5, step_loss=0.00625]Steps:   1%|▏         | 14940/1000000 [4:55:46<2686:38:39,  9.82s/it, lr=1e-5, step_loss=0.00625][RANK-0]: Step: [14940], local_loss=0.016809917986392975, train_loss=0.04817280173301697, time_cost=1.2977352142333984
Steps:   1%|▏         | 14940/1000000 [4:55:46<2686:38:39,  9.82s/it, lr=1e-5, step_loss=0.0168] Steps:   1%|▏         | 14941/1000000 [4:55:58<2813:22:42, 10.28s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [14941], local_loss=0.008415818214416504, train_loss=0.016546715050935745, time_cost=3.2643468379974365
Steps:   1%|▏         | 14941/1000000 [4:55:58<2813:22:42, 10.28s/it, lr=1e-5, step_loss=0.00842]Steps:   1%|▏         | 14942/1000000 [4:56:04<2507:07:51,  9.16s/it, lr=1e-5, step_loss=0.00842][RANK-0]: Step: [14942], local_loss=0.027566513046622276, train_loss=0.030062297359108925, time_cost=2.958451747894287
Steps:   1%|▏         | 14942/1000000 [4:56:04<2507:07:51,  9.16s/it, lr=1e-5, step_loss=0.0276] Steps:   1%|▏         | 14943/1000000 [4:56:16<2746:30:43, 10.04s/it, lr=1e-5, step_loss=0.0276][RANK-0]: Step: [14943], local_loss=0.009646369144320488, train_loss=0.14589770138263702, time_cost=4.544978618621826
Steps:   1%|▏         | 14943/1000000 [4:56:16<2746:30:43, 10.04s/it, lr=1e-5, step_loss=0.00965]Steps:   1%|▏         | 14944/1000000 [4:56:22<2353:33:36,  8.60s/it, lr=1e-5, step_loss=0.00965][RANK-0]: Step: [14944], local_loss=0.005416546948254108, train_loss=0.09972669184207916, time_cost=2.234903335571289
Steps:   1%|▏         | 14944/1000000 [4:56:22<2353:33:36,  8.60s/it, lr=1e-5, step_loss=0.00542]Steps:   1%|▏         | 14945/1000000 [4:56:27<2076:35:09,  7.59s/it, lr=1e-5, step_loss=0.00542][RANK-0]: Step: [14945], local_loss=0.08491826802492142, train_loss=0.06360266357660294, time_cost=2.6016452312469482
Steps:   1%|▏         | 14945/1000000 [4:56:27<2076:35:09,  7.59s/it, lr=1e-5, step_loss=0.0849] Steps:   1%|▏         | 14946/1000000 [4:56:40<2551:49:47,  9.33s/it, lr=1e-5, step_loss=0.0849][RANK-0]: Step: [14946], local_loss=0.02817263826727867, train_loss=0.06260805577039719, time_cost=1.2272987365722656
Steps:   1%|▏         | 14946/1000000 [4:56:40<2551:49:47,  9.33s/it, lr=1e-5, step_loss=0.0282]Steps:   1%|▏         | 14947/1000000 [4:56:51<2672:32:28,  9.77s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [14947], local_loss=0.00894880574196577, train_loss=0.023342406377196312, time_cost=3.4099974632263184
Steps:   1%|▏         | 14947/1000000 [4:56:51<2672:32:28,  9.77s/it, lr=1e-5, step_loss=0.00895]Steps:   1%|▏         | 14948/1000000 [4:57:05<3042:50:21, 11.12s/it, lr=1e-5, step_loss=0.00895][RANK-0]: Step: [14948], local_loss=0.04030827432870865, train_loss=0.04945296049118042, time_cost=4.3191444873809814
Steps:   1%|▏         | 14948/1000000 [4:57:05<3042:50:21, 11.12s/it, lr=1e-5, step_loss=0.0403] Steps:   1%|▏         | 14949/1000000 [4:57:18<3186:09:02, 11.64s/it, lr=1e-5, step_loss=0.0403][RANK-0]: Step: [14949], local_loss=0.007608009502291679, train_loss=0.08632191270589828, time_cost=3.775759220123291
Steps:   1%|▏         | 14949/1000000 [4:57:18<3186:09:02, 11.64s/it, lr=1e-5, step_loss=0.00761]Steps:   1%|▏         | 14950/1000000 [4:57:31<3267:10:24, 11.94s/it, lr=1e-5, step_loss=0.00761][RANK-0]: Step: [14950], local_loss=0.03574813902378082, train_loss=0.030340904369950294, time_cost=3.2026710510253906
Steps:   1%|▏         | 14950/1000000 [4:57:31<3267:10:24, 11.94s/it, lr=1e-5, step_loss=0.0357] Steps:   1%|▏         | 14951/1000000 [4:57:38<2880:29:44, 10.53s/it, lr=1e-5, step_loss=0.0357][RANK-0]: Step: [14951], local_loss=0.02318013831973076, train_loss=0.018386226147413254, time_cost=6.159324407577515
Steps:   1%|▏         | 14951/1000000 [4:57:38<2880:29:44, 10.53s/it, lr=1e-5, step_loss=0.0232]Steps:   1%|▏         | 14952/1000000 [4:57:44<2498:59:50,  9.13s/it, lr=1e-5, step_loss=0.0232][RANK-0]: Step: [14952], local_loss=0.01058135461062193, train_loss=15.130525588989258, time_cost=3.077847957611084
Steps:   1%|▏         | 14952/1000000 [4:57:44<2498:59:50,  9.13s/it, lr=1e-5, step_loss=0.0106]Steps:   1%|▏         | 14953/1000000 [4:57:51<2336:38:14,  8.54s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [14953], local_loss=0.1592450588941574, train_loss=0.10258179157972336, time_cost=2.5939691066741943
Steps:   1%|▏         | 14953/1000000 [4:57:51<2336:38:14,  8.54s/it, lr=1e-5, step_loss=0.159] Steps:   1%|▏         | 14954/1000000 [4:57:55<1979:58:28,  7.24s/it, lr=1e-5, step_loss=0.159][RANK-0]: Step: [14954], local_loss=0.045372866094112396, train_loss=0.02127995528280735, time_cost=1.2246425151824951
Steps:   1%|▏         | 14954/1000000 [4:57:55<1979:58:28,  7.24s/it, lr=1e-5, step_loss=0.0454]Steps:   1%|▏         | 14955/1000000 [4:58:06<2276:15:11,  8.32s/it, lr=1e-5, step_loss=0.0454][RANK-0]: Step: [14955], local_loss=0.027692899107933044, train_loss=0.021026823669672012, time_cost=3.3313424587249756
Steps:   1%|▏         | 14955/1000000 [4:58:06<2276:15:11,  8.32s/it, lr=1e-5, step_loss=0.0277]Steps:   1%|▏         | 14956/1000000 [4:58:18<2546:54:36,  9.31s/it, lr=1e-5, step_loss=0.0277][RANK-0]: Step: [14956], local_loss=0.008913141675293446, train_loss=0.045163676142692566, time_cost=8.511451482772827
Steps:   1%|▏         | 14956/1000000 [4:58:18<2546:54:36,  9.31s/it, lr=1e-5, step_loss=0.00891]Steps:   1%|▏         | 14957/1000000 [4:58:31<2890:34:35, 10.56s/it, lr=1e-5, step_loss=0.00891][RANK-0]: Step: [14957], local_loss=0.3675192594528198, train_loss=0.21551942825317383, time_cost=5.136701345443726
Steps:   1%|▏         | 14957/1000000 [4:58:31<2890:34:35, 10.56s/it, lr=1e-5, step_loss=0.368]  Steps:   1%|▏         | 14958/1000000 [4:58:37<2459:15:26,  8.99s/it, lr=1e-5, step_loss=0.368][RANK-0]: Step: [14958], local_loss=0.0027796360664069653, train_loss=0.01196802593767643, time_cost=1.7749042510986328
Steps:   1%|▏         | 14958/1000000 [4:58:37<2459:15:26,  8.99s/it, lr=1e-5, step_loss=0.00278]Steps:   1%|▏         | 14959/1000000 [4:58:48<2651:08:09,  9.69s/it, lr=1e-5, step_loss=0.00278][RANK-0]: Step: [14959], local_loss=0.006381568964570761, train_loss=0.10289501398801804, time_cost=2.1055212020874023
Steps:   1%|▏         | 14959/1000000 [4:58:48<2651:08:09,  9.69s/it, lr=1e-5, step_loss=0.00638]Steps:   1%|▏         | 14960/1000000 [4:58:54<2371:02:58,  8.67s/it, lr=1e-5, step_loss=0.00638][RANK-0]: Step: [14960], local_loss=0.09144099801778793, train_loss=8.827804565429688, time_cost=1.2809526920318604
Steps:   1%|▏         | 14960/1000000 [4:58:54<2371:02:58,  8.67s/it, lr=1e-5, step_loss=0.0914] Steps:   1%|▏         | 14961/1000000 [4:59:05<2552:45:48,  9.33s/it, lr=1e-5, step_loss=0.0914][RANK-0]: Step: [14961], local_loss=0.01751765049993992, train_loss=0.03839963674545288, time_cost=1.2013821601867676
Steps:   1%|▏         | 14961/1000000 [4:59:05<2552:45:48,  9.33s/it, lr=1e-5, step_loss=0.0175]Steps:   1%|▏         | 14962/1000000 [4:59:14<2548:30:02,  9.31s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [14962], local_loss=0.005634406581521034, train_loss=0.010674634017050266, time_cost=1.778726577758789
Steps:   1%|▏         | 14962/1000000 [4:59:14<2548:30:02,  9.31s/it, lr=1e-5, step_loss=0.00563]Steps:   1%|▏         | 14963/1000000 [4:59:23<2528:32:45,  9.24s/it, lr=1e-5, step_loss=0.00563][RANK-0]: Step: [14963], local_loss=0.018023649230599403, train_loss=0.021402690559625626, time_cost=2.508854866027832
Steps:   1%|▏         | 14963/1000000 [4:59:23<2528:32:45,  9.24s/it, lr=1e-5, step_loss=0.018]  Steps:   1%|▏         | 14964/1000000 [4:59:36<2803:11:14, 10.24s/it, lr=1e-5, step_loss=0.018][RANK-0]: Step: [14964], local_loss=0.014684857800602913, train_loss=0.07730332762002945, time_cost=1.2960100173950195
Steps:   1%|▏         | 14964/1000000 [4:59:36<2803:11:14, 10.24s/it, lr=1e-5, step_loss=0.0147]Steps:   1%|▏         | 14965/1000000 [4:59:43<2561:54:21,  9.36s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [14965], local_loss=0.053594063967466354, train_loss=0.02234571799635887, time_cost=2.924541473388672
Steps:   1%|▏         | 14965/1000000 [4:59:43<2561:54:21,  9.36s/it, lr=1e-5, step_loss=0.0536]Steps:   1%|▏         | 14966/1000000 [4:59:49<2296:02:21,  8.39s/it, lr=1e-5, step_loss=0.0536][RANK-0]: Step: [14966], local_loss=0.01851709373295307, train_loss=0.14847558736801147, time_cost=3.299039125442505
Steps:   1%|▏         | 14966/1000000 [4:59:49<2296:02:21,  8.39s/it, lr=1e-5, step_loss=0.0185]Steps:   1%|▏         | 14967/1000000 [5:00:01<2523:23:58,  9.22s/it, lr=1e-5, step_loss=0.0185][RANK-0]: Step: [14967], local_loss=0.03385856747627258, train_loss=0.043002352118492126, time_cost=2.7067456245422363
Steps:   1%|▏         | 14967/1000000 [5:00:01<2523:23:58,  9.22s/it, lr=1e-5, step_loss=0.0339]Steps:   1%|▏         | 14968/1000000 [5:00:17<3132:08:53, 11.45s/it, lr=1e-5, step_loss=0.0339][RANK-0]: Step: [14968], local_loss=0.005345182493329048, train_loss=0.07653853297233582, time_cost=8.044683933258057
Steps:   1%|▏         | 14968/1000000 [5:00:17<3132:08:53, 11.45s/it, lr=1e-5, step_loss=0.00535]Steps:   1%|▏         | 14969/1000000 [5:00:31<3326:28:42, 12.16s/it, lr=1e-5, step_loss=0.00535][RANK-0]: Step: [14969], local_loss=0.011761806905269623, train_loss=0.046815820038318634, time_cost=4.3030009269714355
Steps:   1%|▏         | 14969/1000000 [5:00:31<3326:28:42, 12.16s/it, lr=1e-5, step_loss=0.0118] Steps:   1%|▏         | 14970/1000000 [5:00:42<3261:14:03, 11.92s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [14970], local_loss=0.029513167217373848, train_loss=0.06903909891843796, time_cost=1.7578997611999512
Steps:   1%|▏         | 14970/1000000 [5:00:42<3261:14:03, 11.92s/it, lr=1e-5, step_loss=0.0295]Steps:   1%|▏         | 14971/1000000 [5:00:56<3414:46:39, 12.48s/it, lr=1e-5, step_loss=0.0295][RANK-0]: Step: [14971], local_loss=0.022537769749760628, train_loss=0.0354018434882164, time_cost=4.771652698516846
Steps:   1%|▏         | 14971/1000000 [5:00:56<3414:46:39, 12.48s/it, lr=1e-5, step_loss=0.0225]Steps:   1%|▏         | 14972/1000000 [5:01:01<2758:23:56, 10.08s/it, lr=1e-5, step_loss=0.0225][RANK-0]: Step: [14972], local_loss=0.006871397607028484, train_loss=0.012170154601335526, time_cost=1.6899082660675049
Steps:   1%|▏         | 14972/1000000 [5:01:01<2758:23:56, 10.08s/it, lr=1e-5, step_loss=0.00687]Steps:   1%|▏         | 14973/1000000 [5:01:08<2531:45:11,  9.25s/it, lr=1e-5, step_loss=0.00687][RANK-0]: Step: [14973], local_loss=0.010027647018432617, train_loss=58.16704559326172, time_cost=3.421003580093384
Steps:   1%|▏         | 14973/1000000 [5:01:08<2531:45:11,  9.25s/it, lr=1e-5, step_loss=0.01]   Steps:   1%|▏         | 14974/1000000 [5:01:17<2518:33:20,  9.20s/it, lr=1e-5, step_loss=0.01][RANK-0]: Step: [14974], local_loss=0.0604991689324379, train_loss=0.05613723397254944, time_cost=3.5785183906555176
Steps:   1%|▏         | 14974/1000000 [5:01:17<2518:33:20,  9.20s/it, lr=1e-5, step_loss=0.0605]Steps:   1%|▏         | 14975/1000000 [5:01:30<2803:39:59, 10.25s/it, lr=1e-5, step_loss=0.0605][RANK-0]: Step: [14975], local_loss=0.03658410161733627, train_loss=0.035375092178583145, time_cost=2.8893849849700928
Steps:   1%|▏         | 14975/1000000 [5:01:30<2803:39:59, 10.25s/it, lr=1e-5, step_loss=0.0366]Steps:   1%|▏         | 14976/1000000 [5:01:35<2394:34:49,  8.75s/it, lr=1e-5, step_loss=0.0366][RANK-0]: Step: [14976], local_loss=0.01704169437289238, train_loss=0.1769600361585617, time_cost=2.260026216506958
Steps:   1%|▏         | 14976/1000000 [5:01:35<2394:34:49,  8.75s/it, lr=1e-5, step_loss=0.017] Steps:   1%|▏         | 14977/1000000 [5:01:43<2354:59:37,  8.61s/it, lr=1e-5, step_loss=0.017][RANK-0]: Step: [14977], local_loss=0.015411701053380966, train_loss=0.05635450780391693, time_cost=7.292575836181641
Steps:   1%|▏         | 14977/1000000 [5:01:43<2354:59:37,  8.61s/it, lr=1e-5, step_loss=0.0154]Steps:   1%|▏         | 14978/1000000 [5:01:52<2364:39:58,  8.64s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [14978], local_loss=0.04235377162694931, train_loss=0.06105021387338638, time_cost=4.598029613494873
Steps:   1%|▏         | 14978/1000000 [5:01:52<2364:39:58,  8.64s/it, lr=1e-5, step_loss=0.0424]Steps:   1%|▏         | 14979/1000000 [5:02:04<2681:16:44,  9.80s/it, lr=1e-5, step_loss=0.0424][RANK-0]: Step: [14979], local_loss=0.0157538503408432, train_loss=0.05819885805249214, time_cost=4.056572914123535
Steps:   1%|▏         | 14979/1000000 [5:02:04<2681:16:44,  9.80s/it, lr=1e-5, step_loss=0.0158]Steps:   1%|▏         | 14980/1000000 [5:02:15<2700:42:17,  9.87s/it, lr=1e-5, step_loss=0.0158][RANK-0]: Step: [14980], local_loss=0.011160544119775295, train_loss=0.03562426567077637, time_cost=2.0903499126434326
Steps:   1%|▏         | 14980/1000000 [5:02:15<2700:42:17,  9.87s/it, lr=1e-5, step_loss=0.0112]Steps:   1%|▏         | 14981/1000000 [5:02:26<2794:25:23, 10.21s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [14981], local_loss=0.991702675819397, train_loss=0.18128320574760437, time_cost=9.355064630508423
Steps:   1%|▏         | 14981/1000000 [5:02:26<2794:25:23, 10.21s/it, lr=1e-5, step_loss=0.992] Steps:   1%|▏         | 14982/1000000 [5:02:31<2428:08:19,  8.87s/it, lr=1e-5, step_loss=0.992][RANK-0]: Step: [14982], local_loss=0.1776522845029831, train_loss=0.04170875996351242, time_cost=1.2803401947021484
Steps:   1%|▏         | 14982/1000000 [5:02:31<2428:08:19,  8.87s/it, lr=1e-5, step_loss=0.178]Steps:   1%|▏         | 14983/1000000 [5:02:41<2464:11:11,  9.01s/it, lr=1e-5, step_loss=0.178][RANK-0]: Step: [14983], local_loss=0.008203554898500443, train_loss=0.050577230751514435, time_cost=2.179497718811035
Steps:   1%|▏         | 14983/1000000 [5:02:41<2464:11:11,  9.01s/it, lr=1e-5, step_loss=0.0082]Steps:   1%|▏         | 14984/1000000 [5:02:53<2703:41:27,  9.88s/it, lr=1e-5, step_loss=0.0082][RANK-0]: Step: [14984], local_loss=0.021437522023916245, train_loss=0.04280975088477135, time_cost=4.289448261260986
Steps:   1%|▏         | 14984/1000000 [5:02:53<2703:41:27,  9.88s/it, lr=1e-5, step_loss=0.0214]Steps:   1%|▏         | 14985/1000000 [5:03:04<2795:12:17, 10.22s/it, lr=1e-5, step_loss=0.0214][RANK-0]: Step: [14985], local_loss=0.013058867305517197, train_loss=0.06692707538604736, time_cost=4.022445917129517
Steps:   1%|▏         | 14985/1000000 [5:03:04<2795:12:17, 10.22s/it, lr=1e-5, step_loss=0.0131]Steps:   1%|▏         | 14986/1000000 [5:03:18<3110:49:52, 11.37s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [14986], local_loss=0.013118263334035873, train_loss=0.023586556315422058, time_cost=8.288788318634033
Steps:   1%|▏         | 14986/1000000 [5:03:18<3110:49:52, 11.37s/it, lr=1e-5, step_loss=0.0131]Steps:   1%|▏         | 14987/1000000 [5:03:27<2939:21:56, 10.74s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [14987], local_loss=0.04185914248228073, train_loss=0.031664200127124786, time_cost=2.806729555130005
Steps:   1%|▏         | 14987/1000000 [5:03:27<2939:21:56, 10.74s/it, lr=1e-5, step_loss=0.0419]Steps:   1%|▏         | 14988/1000000 [5:03:38<2965:06:56, 10.84s/it, lr=1e-5, step_loss=0.0419][RANK-0]: Step: [14988], local_loss=0.04528738930821419, train_loss=0.18084633350372314, time_cost=3.5661613941192627
Steps:   1%|▏         | 14988/1000000 [5:03:38<2965:06:56, 10.84s/it, lr=1e-5, step_loss=0.0453]Steps:   1%|▏         | 14989/1000000 [5:03:44<2562:55:26,  9.37s/it, lr=1e-5, step_loss=0.0453][RANK-0]: Step: [14989], local_loss=0.02529233880341053, train_loss=0.01682550087571144, time_cost=4.8602821826934814
Steps:   1%|▏         | 14989/1000000 [5:03:44<2562:55:26,  9.37s/it, lr=1e-5, step_loss=0.0253]Steps:   1%|▏         | 14990/1000000 [5:03:54<2661:48:17,  9.73s/it, lr=1e-5, step_loss=0.0253][RANK-0]: Step: [14990], local_loss=0.04264327883720398, train_loss=0.030596420168876648, time_cost=5.048052549362183
Steps:   1%|▏         | 14990/1000000 [5:03:54<2661:48:17,  9.73s/it, lr=1e-5, step_loss=0.0426]Steps:   1%|▏         | 14991/1000000 [5:04:03<2585:32:15,  9.45s/it, lr=1e-5, step_loss=0.0426][RANK-0]: Step: [14991], local_loss=0.11805418133735657, train_loss=0.039668336510658264, time_cost=1.2512407302856445
Steps:   1%|▏         | 14991/1000000 [5:04:03<2585:32:15,  9.45s/it, lr=1e-5, step_loss=0.118] Steps:   1%|▏         | 14992/1000000 [5:04:12<2530:24:26,  9.25s/it, lr=1e-5, step_loss=0.118][RANK-0]: Step: [14992], local_loss=0.06206664443016052, train_loss=0.044359996914863586, time_cost=2.6154134273529053
Steps:   1%|▏         | 14992/1000000 [5:04:12<2530:24:26,  9.25s/it, lr=1e-5, step_loss=0.0621]Steps:   1%|▏         | 14993/1000000 [5:04:18<2277:24:19,  8.32s/it, lr=1e-5, step_loss=0.0621][RANK-0]: Step: [14993], local_loss=0.00429752841591835, train_loss=0.14423403143882751, time_cost=1.9264562129974365
Steps:   1%|▏         | 14993/1000000 [5:04:18<2277:24:19,  8.32s/it, lr=1e-5, step_loss=0.0043]Steps:   1%|▏         | 14994/1000000 [5:04:23<1995:22:46,  7.29s/it, lr=1e-5, step_loss=0.0043][RANK-0]: Step: [14994], local_loss=0.06508456915616989, train_loss=0.039533257484436035, time_cost=2.3237664699554443
Steps:   1%|▏         | 14994/1000000 [5:04:23<1995:22:46,  7.29s/it, lr=1e-5, step_loss=0.0651]Steps:   1%|▏         | 14995/1000000 [5:04:31<2014:28:54,  7.36s/it, lr=1e-5, step_loss=0.0651][RANK-0]: Step: [14995], local_loss=0.6284631490707397, train_loss=0.10391630977392197, time_cost=1.4157311916351318
Steps:   1%|▏         | 14995/1000000 [5:04:31<2014:28:54,  7.36s/it, lr=1e-5, step_loss=0.628] Steps:   1%|▏         | 14996/1000000 [5:04:42<2319:13:53,  8.48s/it, lr=1e-5, step_loss=0.628][RANK-0]: Step: [14996], local_loss=0.017426704987883568, train_loss=0.0746159479022026, time_cost=4.855468511581421
Steps:   1%|▏         | 14996/1000000 [5:04:42<2319:13:53,  8.48s/it, lr=1e-5, step_loss=0.0174]Steps:   1%|▏         | 14997/1000000 [5:04:48<2114:56:33,  7.73s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [14997], local_loss=0.00821920670568943, train_loss=0.04432462155818939, time_cost=1.2147493362426758
Steps:   1%|▏         | 14997/1000000 [5:04:48<2114:56:33,  7.73s/it, lr=1e-5, step_loss=0.00822]Steps:   1%|▏         | 14998/1000000 [5:04:54<1970:17:01,  7.20s/it, lr=1e-5, step_loss=0.00822][RANK-0]: Step: [14998], local_loss=0.008506854996085167, train_loss=0.022678963840007782, time_cost=1.205686330795288
Steps:   1%|▏         | 14998/1000000 [5:04:54<1970:17:01,  7.20s/it, lr=1e-5, step_loss=0.00851]Steps:   1%|▏         | 14999/1000000 [5:05:04<2246:27:38,  8.21s/it, lr=1e-5, step_loss=0.00851][RANK-0]: Step: [14999], local_loss=0.04895856976509094, train_loss=0.03646227344870567, time_cost=3.8604767322540283
Steps:   1%|▏         | 14999/1000000 [5:05:04<2246:27:38,  8.21s/it, lr=1e-5, step_loss=0.049]  Steps:   2%|▏         | 15000/1000000 [5:05:15<2465:38:18,  9.01s/it, lr=1e-5, step_loss=0.049][RANK-0]: Step: [15000], local_loss=0.010953709483146667, train_loss=0.1530054658651352, time_cost=1.2270545959472656
09/18/2024 14:29:18 - INFO - accelerate.accelerator - Saving current state to /home/save_dir/runs/allinpaint_stage1/checkpoint-15000
09/18/2024 14:29:18 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-18 14:29:18,474] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-09-18 14:29:18,503] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/mp_rank_00_model_states.pt
[2024-09-18 14:29:18,504] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 14:29:35,249] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 14:29:35,260] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-18 14:29:35,260] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt...
[2024-09-18 14:29:35,260] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
[2024-09-18 14:29:35,260] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-09-18 14:29:35,260] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2024-09-18 14:29:35,260] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2024-09-18 14:29:35,260] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt...
[2024-09-18 14:29:35,260] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt...
[2024-09-18 14:30:07,892] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt.
[2024-09-18 14:30:07,893] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt
[2024-09-18 14:30:07,893] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 14:30:10,786] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt.
[2024-09-18 14:30:10,787] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt
[2024-09-18 14:30:10,787] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 14:30:10,859] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt.
[2024-09-18 14:30:10,859] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt
[2024-09-18 14:30:10,859] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 14:30:11,258] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-18 14:30:11,315] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-18 14:30:11,316] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 14:30:11,571] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2024-09-18 14:30:11,572] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[2024-09-18 14:30:11,572] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 14:30:11,646] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
[2024-09-18 14:30:11,647] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
[2024-09-18 14:30:11,647] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 14:30:11,722] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2024-09-18 14:30:11,722] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[2024-09-18 14:30:11,722] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 14:30:11,811] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-09-18 14:30:11,812] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-09-18 14:30:11,812] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/18/2024 14:30:11 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/pytorch_model
{'norm_num_groups', 'dropout', 'use_additional_conditions'} was not found in config. Values will be initialized to default values.
Configuration saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/model_ema/config.json
Model weights saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/model_ema/diffusion_pytorch_model.safetensors
Configuration saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/model/config.json
Model weights saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/model/diffusion_pytorch_model.safetensors
09/18/2024 14:31:18 - INFO - accelerate.checkpointing - Scheduler state saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/scheduler.bin
09/18/2024 14:31:18 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/sampler.bin
09/18/2024 14:31:18 - INFO - accelerate.checkpointing - Random states saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-15000/random_states_0.pkl
09/18/2024 14:31:18 - INFO - __main__ - Saved state to /home/save_dir/runs/allinpaint_stage1/checkpoint-15000
Steps:   2%|▏         | 15000/1000000 [5:07:15<2465:38:18,  9.01s/it, lr=1e-5, step_loss=0.011]Steps:   2%|▏         | 15001/1000000 [5:07:22<12112:19:51, 44.27s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [15001], local_loss=0.0664018914103508, train_loss=0.04341889172792435, time_cost=1.1887142658233643
Steps:   2%|▏         | 15001/1000000 [5:07:22<12112:19:51, 44.27s/it, lr=1e-5, step_loss=0.0664]Steps:   2%|▏         | 15002/1000000 [5:07:35<9567:07:54, 34.97s/it, lr=1e-5, step_loss=0.0664] [RANK-0]: Step: [15002], local_loss=0.009025155566632748, train_loss=0.11038168519735336, time_cost=4.679073810577393
Steps:   2%|▏         | 15002/1000000 [5:07:35<9567:07:54, 34.97s/it, lr=1e-5, step_loss=0.00903]Steps:   2%|▏         | 15003/1000000 [5:07:51<7986:31:10, 29.19s/it, lr=1e-5, step_loss=0.00903][RANK-0]: Step: [15003], local_loss=0.02536092698574066, train_loss=0.0588790662586689, time_cost=6.293683290481567
Steps:   2%|▏         | 15003/1000000 [5:07:51<7986:31:10, 29.19s/it, lr=1e-5, step_loss=0.0254] Steps:   2%|▏         | 15004/1000000 [5:08:07<6904:16:21, 25.23s/it, lr=1e-5, step_loss=0.0254][RANK-0]: Step: [15004], local_loss=0.004802236333489418, train_loss=0.03196771442890167, time_cost=8.47372317314148
Steps:   2%|▏         | 15004/1000000 [5:08:07<6904:16:21, 25.23s/it, lr=1e-5, step_loss=0.0048]Steps:   2%|▏         | 15005/1000000 [5:08:17<5728:44:05, 20.94s/it, lr=1e-5, step_loss=0.0048][RANK-0]: Step: [15005], local_loss=0.02567053958773613, train_loss=0.02281268872320652, time_cost=1.7831251621246338
Steps:   2%|▏         | 15005/1000000 [5:08:17<5728:44:05, 20.94s/it, lr=1e-5, step_loss=0.0257]Steps:   2%|▏         | 15006/1000000 [5:08:25<4625:29:52, 16.91s/it, lr=1e-5, step_loss=0.0257][RANK-0]: Step: [15006], local_loss=0.030210983008146286, train_loss=0.2063785344362259, time_cost=4.508682727813721
Steps:   2%|▏         | 15006/1000000 [5:08:25<4625:29:52, 16.91s/it, lr=1e-5, step_loss=0.0302]Steps:   2%|▏         | 15007/1000000 [5:08:38<4345:33:05, 15.88s/it, lr=1e-5, step_loss=0.0302][RANK-0]: Step: [15007], local_loss=0.009531447663903236, train_loss=31.772851943969727, time_cost=3.4838109016418457
Steps:   2%|▏         | 15007/1000000 [5:08:38<4345:33:05, 15.88s/it, lr=1e-5, step_loss=0.00953]Steps:   2%|▏         | 15008/1000000 [5:08:44<3466:42:27, 12.67s/it, lr=1e-5, step_loss=0.00953][RANK-0]: Step: [15008], local_loss=0.019244976341724396, train_loss=0.01748669147491455, time_cost=3.972959280014038
Steps:   2%|▏         | 15008/1000000 [5:08:44<3466:42:27, 12.67s/it, lr=1e-5, step_loss=0.0192] Steps:   2%|▏         | 15009/1000000 [5:08:55<3338:44:11, 12.20s/it, lr=1e-5, step_loss=0.0192][RANK-0]: Step: [15009], local_loss=0.01608860306441784, train_loss=0.02302943542599678, time_cost=4.166036128997803
Steps:   2%|▏         | 15009/1000000 [5:08:55<3338:44:11, 12.20s/it, lr=1e-5, step_loss=0.0161]Steps:   2%|▏         | 15010/1000000 [5:09:01<2848:08:02, 10.41s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [15010], local_loss=0.010687915608286858, train_loss=0.03522860258817673, time_cost=2.2816531658172607
Steps:   2%|▏         | 15010/1000000 [5:09:01<2848:08:02, 10.41s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 15011/1000000 [5:09:14<3071:47:12, 11.23s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [15011], local_loss=0.025478119030594826, train_loss=0.07551519572734833, time_cost=10.767616033554077
Steps:   2%|▏         | 15011/1000000 [5:09:14<3071:47:12, 11.23s/it, lr=1e-5, step_loss=0.0255]Steps:   2%|▏         | 15012/1000000 [5:09:23<2881:55:00, 10.53s/it, lr=1e-5, step_loss=0.0255][RANK-0]: Step: [15012], local_loss=0.08251237869262695, train_loss=0.050542332231998444, time_cost=2.6508097648620605
Steps:   2%|▏         | 15012/1000000 [5:09:23<2881:55:00, 10.53s/it, lr=1e-5, step_loss=0.0825]Steps:   2%|▏         | 15013/1000000 [5:09:30<2590:54:43,  9.47s/it, lr=1e-5, step_loss=0.0825][RANK-0]: Step: [15013], local_loss=0.01439093891531229, train_loss=0.05462828278541565, time_cost=1.529052495956421
Steps:   2%|▏         | 15013/1000000 [5:09:30<2590:54:43,  9.47s/it, lr=1e-5, step_loss=0.0144]Steps:   2%|▏         | 15014/1000000 [5:09:45<3083:33:20, 11.27s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [15014], local_loss=1.0092120170593262, train_loss=0.1663050651550293, time_cost=6.784725666046143
Steps:   2%|▏         | 15014/1000000 [5:09:45<3083:33:20, 11.27s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 15015/1000000 [5:09:57<3122:49:28, 11.41s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [15015], local_loss=0.015630103647708893, train_loss=0.0227959044277668, time_cost=1.1946887969970703
Steps:   2%|▏         | 15015/1000000 [5:09:57<3122:49:28, 11.41s/it, lr=1e-5, step_loss=0.0156]Steps:   2%|▏         | 15016/1000000 [5:10:05<2784:15:35, 10.18s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [15016], local_loss=0.004479163326323032, train_loss=0.04465247690677643, time_cost=1.54213285446167
Steps:   2%|▏         | 15016/1000000 [5:10:05<2784:15:35, 10.18s/it, lr=1e-5, step_loss=0.00448]Steps:   2%|▏         | 15017/1000000 [5:10:12<2587:20:38,  9.46s/it, lr=1e-5, step_loss=0.00448][RANK-0]: Step: [15017], local_loss=0.016569094732403755, train_loss=0.03212253004312515, time_cost=3.172685146331787
Steps:   2%|▏         | 15017/1000000 [5:10:12<2587:20:38,  9.46s/it, lr=1e-5, step_loss=0.0166] Steps:   2%|▏         | 15018/1000000 [5:10:18<2287:27:04,  8.36s/it, lr=1e-5, step_loss=0.0166][RANK-0]: Step: [15018], local_loss=0.0038213650695979595, train_loss=12.637565612792969, time_cost=3.066084146499634
Steps:   2%|▏         | 15018/1000000 [5:10:18<2287:27:04,  8.36s/it, lr=1e-5, step_loss=0.00382]Steps:   2%|▏         | 15019/1000000 [5:10:30<2574:16:49,  9.41s/it, lr=1e-5, step_loss=0.00382][RANK-0]: Step: [15019], local_loss=0.007932540029287338, train_loss=0.03243068605661392, time_cost=2.7103898525238037
Steps:   2%|▏         | 15019/1000000 [5:10:30<2574:16:49,  9.41s/it, lr=1e-5, step_loss=0.00793]Steps:   2%|▏         | 15020/1000000 [5:10:34<2134:41:03,  7.80s/it, lr=1e-5, step_loss=0.00793][RANK-0]: Step: [15020], local_loss=0.020406708121299744, train_loss=0.034216880798339844, time_cost=1.3292450904846191
Steps:   2%|▏         | 15020/1000000 [5:10:34<2134:41:03,  7.80s/it, lr=1e-5, step_loss=0.0204] Steps:   2%|▏         | 15021/1000000 [5:10:39<1896:54:51,  6.93s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [15021], local_loss=0.00936418492347002, train_loss=0.06288447231054306, time_cost=2.4803402423858643
Steps:   2%|▏         | 15021/1000000 [5:10:39<1896:54:51,  6.93s/it, lr=1e-5, step_loss=0.00936]Steps:   2%|▏         | 15022/1000000 [5:10:54<2535:50:42,  9.27s/it, lr=1e-5, step_loss=0.00936][RANK-0]: Step: [15022], local_loss=0.008505556732416153, train_loss=0.03149835020303726, time_cost=5.2818591594696045
Steps:   2%|▏         | 15022/1000000 [5:10:54<2535:50:42,  9.27s/it, lr=1e-5, step_loss=0.00851]Steps:   2%|▏         | 15023/1000000 [5:11:04<2663:12:42,  9.73s/it, lr=1e-5, step_loss=0.00851][RANK-0]: Step: [15023], local_loss=0.38781502842903137, train_loss=0.0698661208152771, time_cost=3.0899817943573
Steps:   2%|▏         | 15023/1000000 [5:11:04<2663:12:42,  9.73s/it, lr=1e-5, step_loss=0.388]  Steps:   2%|▏         | 15024/1000000 [5:11:21<3200:24:40, 11.70s/it, lr=1e-5, step_loss=0.388][RANK-0]: Step: [15024], local_loss=0.0035444600507616997, train_loss=0.07709558308124542, time_cost=7.941025495529175
Steps:   2%|▏         | 15024/1000000 [5:11:21<3200:24:40, 11.70s/it, lr=1e-5, step_loss=0.00354]Steps:   2%|▏         | 15025/1000000 [5:11:38<3629:29:59, 13.27s/it, lr=1e-5, step_loss=0.00354][RANK-0]: Step: [15025], local_loss=0.019266314804553986, train_loss=0.04580600932240486, time_cost=8.434195280075073
Steps:   2%|▏         | 15025/1000000 [5:11:38<3629:29:59, 13.27s/it, lr=1e-5, step_loss=0.0193] Steps:   2%|▏         | 15026/1000000 [5:11:43<2953:23:31, 10.79s/it, lr=1e-5, step_loss=0.0193][RANK-0]: Step: [15026], local_loss=0.01604790799319744, train_loss=0.018017549067735672, time_cost=2.288132429122925
Steps:   2%|▏         | 15026/1000000 [5:11:43<2953:23:31, 10.79s/it, lr=1e-5, step_loss=0.016] Steps:   2%|▏         | 15027/1000000 [5:11:55<3059:45:00, 11.18s/it, lr=1e-5, step_loss=0.016][RANK-0]: Step: [15027], local_loss=0.11311529576778412, train_loss=0.15324711799621582, time_cost=5.500717878341675
Steps:   2%|▏         | 15027/1000000 [5:11:55<3059:45:00, 11.18s/it, lr=1e-5, step_loss=0.113]Steps:   2%|▏         | 15028/1000000 [5:12:08<3189:27:47, 11.66s/it, lr=1e-5, step_loss=0.113][RANK-0]: Step: [15028], local_loss=0.01668751798570156, train_loss=0.05138043314218521, time_cost=5.789654731750488
Steps:   2%|▏         | 15028/1000000 [5:12:08<3189:27:47, 11.66s/it, lr=1e-5, step_loss=0.0167]Steps:   2%|▏         | 15029/1000000 [5:12:15<2823:03:03, 10.32s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [15029], local_loss=0.012465658597648144, train_loss=0.04462706297636032, time_cost=1.245115041732788
Steps:   2%|▏         | 15029/1000000 [5:12:15<2823:03:03, 10.32s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 15030/1000000 [5:12:24<2705:26:10,  9.89s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [15030], local_loss=0.17171530425548553, train_loss=0.04331788420677185, time_cost=2.860541820526123
Steps:   2%|▏         | 15030/1000000 [5:12:24<2705:26:10,  9.89s/it, lr=1e-5, step_loss=0.172] Steps:   2%|▏         | 15031/1000000 [5:12:33<2655:14:04,  9.70s/it, lr=1e-5, step_loss=0.172][RANK-0]: Step: [15031], local_loss=0.07114405930042267, train_loss=0.023088641464710236, time_cost=3.098262310028076
Steps:   2%|▏         | 15031/1000000 [5:12:33<2655:14:04,  9.70s/it, lr=1e-5, step_loss=0.0711]Steps:   2%|▏         | 15032/1000000 [5:12:48<3098:24:49, 11.32s/it, lr=1e-5, step_loss=0.0711][RANK-0]: Step: [15032], local_loss=0.012095644138753414, train_loss=0.08286577463150024, time_cost=6.618855714797974
Steps:   2%|▏         | 15032/1000000 [5:12:48<3098:24:49, 11.32s/it, lr=1e-5, step_loss=0.0121]Steps:   2%|▏         | 15033/1000000 [5:12:57<2901:32:38, 10.60s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [15033], local_loss=0.0049839927814900875, train_loss=0.030180901288986206, time_cost=4.896801471710205
Steps:   2%|▏         | 15033/1000000 [5:12:57<2901:32:38, 10.60s/it, lr=1e-5, step_loss=0.00498]Steps:   2%|▏         | 15034/1000000 [5:13:03<2547:00:51,  9.31s/it, lr=1e-5, step_loss=0.00498][RANK-0]: Step: [15034], local_loss=0.024040929973125458, train_loss=0.051916658878326416, time_cost=2.182690382003784
Steps:   2%|▏         | 15034/1000000 [5:13:03<2547:00:51,  9.31s/it, lr=1e-5, step_loss=0.024]  Steps:   2%|▏         | 15035/1000000 [5:13:08<2139:04:56,  7.82s/it, lr=1e-5, step_loss=0.024][RANK-0]: Step: [15035], local_loss=0.010695422068238258, train_loss=0.04205245524644852, time_cost=1.6698763370513916
Steps:   2%|▏         | 15035/1000000 [5:13:08<2139:04:56,  7.82s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 15036/1000000 [5:13:15<2077:18:27,  7.59s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [15036], local_loss=0.006554490886628628, train_loss=0.15347503125667572, time_cost=2.881964683532715
Steps:   2%|▏         | 15036/1000000 [5:13:15<2077:18:27,  7.59s/it, lr=1e-5, step_loss=0.00655]Steps:   2%|▏         | 15037/1000000 [5:13:26<2360:28:32,  8.63s/it, lr=1e-5, step_loss=0.00655][RANK-0]: Step: [15037], local_loss=0.046513352543115616, train_loss=0.03602725267410278, time_cost=3.754425048828125
Steps:   2%|▏         | 15037/1000000 [5:13:26<2360:28:32,  8.63s/it, lr=1e-5, step_loss=0.0465] Steps:   2%|▏         | 15038/1000000 [5:13:35<2421:06:10,  8.85s/it, lr=1e-5, step_loss=0.0465][RANK-0]: Step: [15038], local_loss=0.007056966423988342, train_loss=0.03400471806526184, time_cost=2.069789409637451
Steps:   2%|▏         | 15038/1000000 [5:13:35<2421:06:10,  8.85s/it, lr=1e-5, step_loss=0.00706]Steps:   2%|▏         | 15039/1000000 [5:13:39<2022:25:20,  7.39s/it, lr=1e-5, step_loss=0.00706][RANK-0]: Step: [15039], local_loss=0.004482946824282408, train_loss=28.78230857849121, time_cost=1.639394760131836
Steps:   2%|▏         | 15039/1000000 [5:13:39<2022:25:20,  7.39s/it, lr=1e-5, step_loss=0.00448]Steps:   2%|▏         | 15040/1000000 [5:13:46<1991:44:22,  7.28s/it, lr=1e-5, step_loss=0.00448][RANK-0]: Step: [15040], local_loss=0.015087198466062546, train_loss=0.024594737216830254, time_cost=2.0142199993133545
Steps:   2%|▏         | 15040/1000000 [5:13:46<1991:44:22,  7.28s/it, lr=1e-5, step_loss=0.0151] Steps:   2%|▏         | 15041/1000000 [5:13:59<2485:21:12,  9.08s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [15041], local_loss=0.012512575834989548, train_loss=0.04386438801884651, time_cost=5.1465394496917725
Steps:   2%|▏         | 15041/1000000 [5:13:59<2485:21:12,  9.08s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 15042/1000000 [5:14:15<3038:32:54, 11.11s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [15042], local_loss=0.008835220709443092, train_loss=0.017978426069021225, time_cost=6.421398639678955
Steps:   2%|▏         | 15042/1000000 [5:14:15<3038:32:54, 11.11s/it, lr=1e-5, step_loss=0.00884]Steps:   2%|▏         | 15043/1000000 [5:14:22<2665:52:00,  9.74s/it, lr=1e-5, step_loss=0.00884][RANK-0]: Step: [15043], local_loss=0.1163993626832962, train_loss=0.04315660148859024, time_cost=2.1247620582580566
Steps:   2%|▏         | 15043/1000000 [5:14:22<2665:52:00,  9.74s/it, lr=1e-5, step_loss=0.116]  Steps:   2%|▏         | 15044/1000000 [5:14:31<2613:26:03,  9.55s/it, lr=1e-5, step_loss=0.116][RANK-0]: Step: [15044], local_loss=0.02065718173980713, train_loss=0.134202241897583, time_cost=1.2530057430267334
Steps:   2%|▏         | 15044/1000000 [5:14:31<2613:26:03,  9.55s/it, lr=1e-5, step_loss=0.0207]Steps:   2%|▏         | 15045/1000000 [5:14:36<2236:55:20,  8.18s/it, lr=1e-5, step_loss=0.0207][RANK-0]: Step: [15045], local_loss=0.016386689618229866, train_loss=0.059685416519641876, time_cost=2.201601028442383
Steps:   2%|▏         | 15045/1000000 [5:14:36<2236:55:20,  8.18s/it, lr=1e-5, step_loss=0.0164]Steps:   2%|▏         | 15046/1000000 [5:14:43<2142:39:54,  7.83s/it, lr=1e-5, step_loss=0.0164][RANK-0]: Step: [15046], local_loss=0.05901440605521202, train_loss=0.10190488398075104, time_cost=2.569096326828003
Steps:   2%|▏         | 15046/1000000 [5:14:43<2142:39:54,  7.83s/it, lr=1e-5, step_loss=0.059] Steps:   2%|▏         | 15047/1000000 [5:14:51<2171:32:52,  7.94s/it, lr=1e-5, step_loss=0.059][RANK-0]: Step: [15047], local_loss=0.03574224188923836, train_loss=0.1500462293624878, time_cost=2.899381637573242
Steps:   2%|▏         | 15047/1000000 [5:14:51<2171:32:52,  7.94s/it, lr=1e-5, step_loss=0.0357]Steps:   2%|▏         | 15048/1000000 [5:14:56<1944:01:28,  7.11s/it, lr=1e-5, step_loss=0.0357][RANK-0]: Step: [15048], local_loss=0.0259347353130579, train_loss=0.12595325708389282, time_cost=1.3003270626068115
Steps:   2%|▏         | 15048/1000000 [5:14:56<1944:01:28,  7.11s/it, lr=1e-5, step_loss=0.0259]Steps:   2%|▏         | 15049/1000000 [5:15:10<2521:51:32,  9.22s/it, lr=1e-5, step_loss=0.0259][RANK-0]: Step: [15049], local_loss=0.05696547403931618, train_loss=0.05471797659993172, time_cost=4.680372714996338
Steps:   2%|▏         | 15049/1000000 [5:15:10<2521:51:32,  9.22s/it, lr=1e-5, step_loss=0.057] Steps:   2%|▏         | 15050/1000000 [5:15:20<2520:34:46,  9.21s/it, lr=1e-5, step_loss=0.057][RANK-0]: Step: [15050], local_loss=0.013829553499817848, train_loss=0.01614677906036377, time_cost=6.813446760177612
Steps:   2%|▏         | 15050/1000000 [5:15:20<2520:34:46,  9.21s/it, lr=1e-5, step_loss=0.0138]Steps:   2%|▏         | 15051/1000000 [5:15:29<2550:19:59,  9.32s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [15051], local_loss=0.052706826478242874, train_loss=0.041559502482414246, time_cost=3.814685106277466
Steps:   2%|▏         | 15051/1000000 [5:15:29<2550:19:59,  9.32s/it, lr=1e-5, step_loss=0.0527]Steps:   2%|▏         | 15052/1000000 [5:15:43<2948:01:23, 10.78s/it, lr=1e-5, step_loss=0.0527][RANK-0]: Step: [15052], local_loss=0.05967167392373085, train_loss=0.03489493951201439, time_cost=1.3540232181549072
Steps:   2%|▏         | 15052/1000000 [5:15:43<2948:01:23, 10.78s/it, lr=1e-5, step_loss=0.0597]Steps:   2%|▏         | 15053/1000000 [5:15:51<2663:26:15,  9.73s/it, lr=1e-5, step_loss=0.0597][RANK-0]: Step: [15053], local_loss=0.025281690061092377, train_loss=0.03744082152843475, time_cost=1.3299405574798584
Steps:   2%|▏         | 15053/1000000 [5:15:51<2663:26:15,  9.73s/it, lr=1e-5, step_loss=0.0253]Steps:   2%|▏         | 15054/1000000 [5:15:58<2464:56:30,  9.01s/it, lr=1e-5, step_loss=0.0253][RANK-0]: Step: [15054], local_loss=0.018060913309454918, train_loss=0.07763765752315521, time_cost=2.530989646911621
Steps:   2%|▏         | 15054/1000000 [5:15:58<2464:56:30,  9.01s/it, lr=1e-5, step_loss=0.0181]Steps:   2%|▏         | 15055/1000000 [5:16:03<2149:41:33,  7.86s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [15055], local_loss=0.05434088036417961, train_loss=0.1675347238779068, time_cost=4.422094821929932
Steps:   2%|▏         | 15055/1000000 [5:16:03<2149:41:33,  7.86s/it, lr=1e-5, step_loss=0.0543]Steps:   2%|▏         | 15056/1000000 [5:16:08<1870:22:26,  6.84s/it, lr=1e-5, step_loss=0.0543][RANK-0]: Step: [15056], local_loss=0.020272180438041687, train_loss=0.0361332967877388, time_cost=1.4151439666748047
Steps:   2%|▏         | 15056/1000000 [5:16:08<1870:22:26,  6.84s/it, lr=1e-5, step_loss=0.0203]Steps:   2%|▏         | 15057/1000000 [5:16:13<1748:48:42,  6.39s/it, lr=1e-5, step_loss=0.0203][RANK-0]: Step: [15057], local_loss=0.08870534598827362, train_loss=0.04828360676765442, time_cost=4.148422002792358
Steps:   2%|▏         | 15057/1000000 [5:16:13<1748:48:42,  6.39s/it, lr=1e-5, step_loss=0.0887]Steps:   2%|▏         | 15058/1000000 [5:16:18<1651:08:31,  6.03s/it, lr=1e-5, step_loss=0.0887][RANK-0]: Step: [15058], local_loss=0.011637309566140175, train_loss=0.036679793149232864, time_cost=2.22525691986084
Steps:   2%|▏         | 15058/1000000 [5:16:18<1651:08:31,  6.03s/it, lr=1e-5, step_loss=0.0116]Steps:   2%|▏         | 15059/1000000 [5:16:30<2164:50:13,  7.91s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [15059], local_loss=0.026844972744584084, train_loss=0.049532052129507065, time_cost=8.75303030014038
Steps:   2%|▏         | 15059/1000000 [5:16:30<2164:50:13,  7.91s/it, lr=1e-5, step_loss=0.0268]Steps:   2%|▏         | 15060/1000000 [5:16:44<2602:18:20,  9.51s/it, lr=1e-5, step_loss=0.0268][RANK-0]: Step: [15060], local_loss=0.010710208676755428, train_loss=0.1356237828731537, time_cost=5.212726354598999
Steps:   2%|▏         | 15060/1000000 [5:16:44<2602:18:20,  9.51s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 15061/1000000 [5:16:48<2222:33:18,  8.12s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [15061], local_loss=0.013497264124453068, train_loss=0.013648269698023796, time_cost=1.9944007396697998
Steps:   2%|▏         | 15061/1000000 [5:16:48<2222:33:18,  8.12s/it, lr=1e-5, step_loss=0.0135]Steps:   2%|▏         | 15062/1000000 [5:16:53<1908:52:52,  6.98s/it, lr=1e-5, step_loss=0.0135][RANK-0]: Step: [15062], local_loss=0.0327390693128109, train_loss=0.08161090314388275, time_cost=1.7623765468597412
Steps:   2%|▏         | 15062/1000000 [5:16:53<1908:52:52,  6.98s/it, lr=1e-5, step_loss=0.0327]Steps:   2%|▏         | 15063/1000000 [5:17:02<2117:02:01,  7.74s/it, lr=1e-5, step_loss=0.0327][RANK-0]: Step: [15063], local_loss=0.02814401499927044, train_loss=0.03156363219022751, time_cost=1.8780715465545654
Steps:   2%|▏         | 15063/1000000 [5:17:02<2117:02:01,  7.74s/it, lr=1e-5, step_loss=0.0281]Steps:   2%|▏         | 15064/1000000 [5:17:09<2046:45:31,  7.48s/it, lr=1e-5, step_loss=0.0281][RANK-0]: Step: [15064], local_loss=0.05086171627044678, train_loss=0.024203259497880936, time_cost=1.320667028427124
Steps:   2%|▏         | 15064/1000000 [5:17:09<2046:45:31,  7.48s/it, lr=1e-5, step_loss=0.0509]Steps:   2%|▏         | 15065/1000000 [5:17:14<1846:50:09,  6.75s/it, lr=1e-5, step_loss=0.0509][RANK-0]: Step: [15065], local_loss=0.020054228603839874, train_loss=0.1950594037771225, time_cost=2.0059897899627686
Steps:   2%|▏         | 15065/1000000 [5:17:14<1846:50:09,  6.75s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 15066/1000000 [5:17:23<2049:19:29,  7.49s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [15066], local_loss=0.0044302064925432205, train_loss=0.0375693216919899, time_cost=4.328916311264038
Steps:   2%|▏         | 15066/1000000 [5:17:23<2049:19:29,  7.49s/it, lr=1e-5, step_loss=0.00443]Steps:   2%|▏         | 15067/1000000 [5:17:28<1790:39:15,  6.54s/it, lr=1e-5, step_loss=0.00443][RANK-0]: Step: [15067], local_loss=0.014087642543017864, train_loss=0.018277429044246674, time_cost=1.3801724910736084
Steps:   2%|▏         | 15067/1000000 [5:17:28<1790:39:15,  6.54s/it, lr=1e-5, step_loss=0.0141] Steps:   2%|▏         | 15068/1000000 [5:17:33<1667:41:01,  6.10s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [15068], local_loss=0.007233195006847382, train_loss=0.03839820623397827, time_cost=1.9707322120666504
Steps:   2%|▏         | 15068/1000000 [5:17:33<1667:41:01,  6.10s/it, lr=1e-5, step_loss=0.00723]Steps:   2%|▏         | 15069/1000000 [5:17:40<1745:31:46,  6.38s/it, lr=1e-5, step_loss=0.00723][RANK-0]: Step: [15069], local_loss=0.021056074649095535, train_loss=0.06545338034629822, time_cost=2.366626739501953
Steps:   2%|▏         | 15069/1000000 [5:17:40<1745:31:46,  6.38s/it, lr=1e-5, step_loss=0.0211] Steps:   2%|▏         | 15070/1000000 [5:17:47<1809:11:48,  6.61s/it, lr=1e-5, step_loss=0.0211][RANK-0]: Step: [15070], local_loss=0.021582264453172684, train_loss=0.05042700842022896, time_cost=3.608283758163452
Steps:   2%|▏         | 15070/1000000 [5:17:47<1809:11:48,  6.61s/it, lr=1e-5, step_loss=0.0216]Steps:   2%|▏         | 15071/1000000 [5:17:53<1744:20:59,  6.38s/it, lr=1e-5, step_loss=0.0216][RANK-0]: Step: [15071], local_loss=0.049771539866924286, train_loss=0.0662795826792717, time_cost=1.9560096263885498
Steps:   2%|▏         | 15071/1000000 [5:17:53<1744:20:59,  6.38s/it, lr=1e-5, step_loss=0.0498]Steps:   2%|▏         | 15072/1000000 [5:18:06<2286:08:58,  8.36s/it, lr=1e-5, step_loss=0.0498][RANK-0]: Step: [15072], local_loss=0.003812518436461687, train_loss=0.06653733551502228, time_cost=3.616513967514038
Steps:   2%|▏         | 15072/1000000 [5:18:06<2286:08:58,  8.36s/it, lr=1e-5, step_loss=0.00381]Steps:   2%|▏         | 15073/1000000 [5:18:18<2613:39:07,  9.55s/it, lr=1e-5, step_loss=0.00381][RANK-0]: Step: [15073], local_loss=0.013310209847986698, train_loss=0.14389801025390625, time_cost=2.1341519355773926
Steps:   2%|▏         | 15073/1000000 [5:18:18<2613:39:07,  9.55s/it, lr=1e-5, step_loss=0.0133] Steps:   2%|▏         | 15074/1000000 [5:18:24<2312:40:39,  8.45s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [15074], local_loss=0.10838928073644638, train_loss=0.04177086055278778, time_cost=1.3651633262634277
Steps:   2%|▏         | 15074/1000000 [5:18:24<2312:40:39,  8.45s/it, lr=1e-5, step_loss=0.108] Steps:   2%|▏         | 15075/1000000 [5:18:36<2570:28:06,  9.40s/it, lr=1e-5, step_loss=0.108][RANK-0]: Step: [15075], local_loss=0.019620656967163086, train_loss=0.07396171987056732, time_cost=2.1723504066467285
Steps:   2%|▏         | 15075/1000000 [5:18:36<2570:28:06,  9.40s/it, lr=1e-5, step_loss=0.0196]Steps:   2%|▏         | 15076/1000000 [5:18:43<2375:52:14,  8.68s/it, lr=1e-5, step_loss=0.0196][RANK-0]: Step: [15076], local_loss=0.01835450902581215, train_loss=0.037772972136735916, time_cost=5.35170841217041
Steps:   2%|▏         | 15076/1000000 [5:18:43<2375:52:14,  8.68s/it, lr=1e-5, step_loss=0.0184]Steps:   2%|▏         | 15077/1000000 [5:18:50<2276:54:34,  8.32s/it, lr=1e-5, step_loss=0.0184][RANK-0]: Step: [15077], local_loss=0.06914474815130234, train_loss=14.915681838989258, time_cost=1.5500986576080322
Steps:   2%|▏         | 15077/1000000 [5:18:50<2276:54:34,  8.32s/it, lr=1e-5, step_loss=0.0691]Steps:   2%|▏         | 15078/1000000 [5:18:59<2344:14:48,  8.57s/it, lr=1e-5, step_loss=0.0691][RANK-0]: Step: [15078], local_loss=0.02779521606862545, train_loss=0.046855852007865906, time_cost=1.9245719909667969
Steps:   2%|▏         | 15078/1000000 [5:18:59<2344:14:48,  8.57s/it, lr=1e-5, step_loss=0.0278]Steps:   2%|▏         | 15079/1000000 [5:19:12<2683:41:34,  9.81s/it, lr=1e-5, step_loss=0.0278][RANK-0]: Step: [15079], local_loss=0.014050097204744816, train_loss=0.032172203063964844, time_cost=4.589231014251709
Steps:   2%|▏         | 15079/1000000 [5:19:12<2683:41:34,  9.81s/it, lr=1e-5, step_loss=0.0141]Steps:   2%|▏         | 15080/1000000 [5:19:17<2272:09:03,  8.30s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [15080], local_loss=0.00527964998036623, train_loss=0.007437855005264282, time_cost=1.2407619953155518
Steps:   2%|▏         | 15080/1000000 [5:19:17<2272:09:03,  8.30s/it, lr=1e-5, step_loss=0.00528]Steps:   2%|▏         | 15081/1000000 [5:19:28<2488:25:32,  9.10s/it, lr=1e-5, step_loss=0.00528][RANK-0]: Step: [15081], local_loss=0.04591180756688118, train_loss=0.049692459404468536, time_cost=1.2160251140594482
Steps:   2%|▏         | 15081/1000000 [5:19:28<2488:25:32,  9.10s/it, lr=1e-5, step_loss=0.0459] Steps:   2%|▏         | 15082/1000000 [5:19:34<2223:53:01,  8.13s/it, lr=1e-5, step_loss=0.0459][RANK-0]: Step: [15082], local_loss=0.027793290093541145, train_loss=0.022770730778574944, time_cost=1.7673025131225586
Steps:   2%|▏         | 15082/1000000 [5:19:34<2223:53:01,  8.13s/it, lr=1e-5, step_loss=0.0278]Steps:   2%|▏         | 15083/1000000 [5:19:48<2739:51:20, 10.01s/it, lr=1e-5, step_loss=0.0278][RANK-0]: Step: [15083], local_loss=0.012791501358151436, train_loss=0.05408960580825806, time_cost=1.2295475006103516
Steps:   2%|▏         | 15083/1000000 [5:19:48<2739:51:20, 10.01s/it, lr=1e-5, step_loss=0.0128]Steps:   2%|▏         | 15084/1000000 [5:19:57<2652:54:21,  9.70s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [15084], local_loss=0.01111756730824709, train_loss=0.013524220325052738, time_cost=3.065183401107788
Steps:   2%|▏         | 15084/1000000 [5:19:57<2652:54:21,  9.70s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 15085/1000000 [5:20:02<2258:12:10,  8.25s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [15085], local_loss=0.015590066090226173, train_loss=0.02348170429468155, time_cost=1.8251252174377441
Steps:   2%|▏         | 15085/1000000 [5:20:02<2258:12:10,  8.25s/it, lr=1e-5, step_loss=0.0156]Steps:   2%|▏         | 15086/1000000 [5:20:11<2369:50:44,  8.66s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [15086], local_loss=0.007452749647200108, train_loss=12.11906909942627, time_cost=2.215132236480713
Steps:   2%|▏         | 15086/1000000 [5:20:11<2369:50:44,  8.66s/it, lr=1e-5, step_loss=0.00745]Steps:   2%|▏         | 15087/1000000 [5:20:16<2061:29:36,  7.54s/it, lr=1e-5, step_loss=0.00745][RANK-0]: Step: [15087], local_loss=0.00986594520509243, train_loss=0.049883510917425156, time_cost=2.6117825508117676
Steps:   2%|▏         | 15087/1000000 [5:20:16<2061:29:36,  7.54s/it, lr=1e-5, step_loss=0.00987]Steps:   2%|▏         | 15088/1000000 [5:20:24<2044:51:06,  7.47s/it, lr=1e-5, step_loss=0.00987][RANK-0]: Step: [15088], local_loss=0.1036575436592102, train_loss=0.03675733506679535, time_cost=1.3366172313690186
Steps:   2%|▏         | 15088/1000000 [5:20:24<2044:51:06,  7.47s/it, lr=1e-5, step_loss=0.104]  Steps:   2%|▏         | 15089/1000000 [5:20:30<1923:10:35,  7.03s/it, lr=1e-5, step_loss=0.104][RANK-0]: Step: [15089], local_loss=0.009761925786733627, train_loss=0.025508344173431396, time_cost=1.7113244533538818
Steps:   2%|▏         | 15089/1000000 [5:20:30<1923:10:35,  7.03s/it, lr=1e-5, step_loss=0.00976]Steps:   2%|▏         | 15090/1000000 [5:20:37<1976:02:42,  7.22s/it, lr=1e-5, step_loss=0.00976][RANK-0]: Step: [15090], local_loss=0.07137544453144073, train_loss=0.05943867564201355, time_cost=1.9738342761993408
Steps:   2%|▏         | 15090/1000000 [5:20:37<1976:02:42,  7.22s/it, lr=1e-5, step_loss=0.0714] Steps:   2%|▏         | 15091/1000000 [5:20:47<2140:38:52,  7.82s/it, lr=1e-5, step_loss=0.0714][RANK-0]: Step: [15091], local_loss=0.02027858793735504, train_loss=0.11329467594623566, time_cost=1.661484718322754
Steps:   2%|▏         | 15091/1000000 [5:20:47<2140:38:52,  7.82s/it, lr=1e-5, step_loss=0.0203]Steps:   2%|▏         | 15092/1000000 [5:20:54<2073:02:45,  7.58s/it, lr=1e-5, step_loss=0.0203][RANK-0]: Step: [15092], local_loss=0.0460839606821537, train_loss=0.042901985347270966, time_cost=3.3338067531585693
Steps:   2%|▏         | 15092/1000000 [5:20:54<2073:02:45,  7.58s/it, lr=1e-5, step_loss=0.0461]Steps:   2%|▏         | 15093/1000000 [5:21:04<2282:16:23,  8.34s/it, lr=1e-5, step_loss=0.0461][RANK-0]: Step: [15093], local_loss=0.026701906695961952, train_loss=0.04550071805715561, time_cost=1.3029556274414062
Steps:   2%|▏         | 15093/1000000 [5:21:04<2282:16:23,  8.34s/it, lr=1e-5, step_loss=0.0267]Steps:   2%|▏         | 15094/1000000 [5:21:10<2142:03:27,  7.83s/it, lr=1e-5, step_loss=0.0267][RANK-0]: Step: [15094], local_loss=0.4238118529319763, train_loss=0.2113901525735855, time_cost=5.461354494094849
Steps:   2%|▏         | 15094/1000000 [5:21:10<2142:03:27,  7.83s/it, lr=1e-5, step_loss=0.424] Steps:   2%|▏         | 15095/1000000 [5:21:17<2078:12:20,  7.60s/it, lr=1e-5, step_loss=0.424][RANK-0]: Step: [15095], local_loss=0.05133204162120819, train_loss=0.07088916003704071, time_cost=1.2919526100158691
Steps:   2%|▏         | 15095/1000000 [5:21:17<2078:12:20,  7.60s/it, lr=1e-5, step_loss=0.0513]Steps:   2%|▏         | 15096/1000000 [5:21:29<2398:23:32,  8.77s/it, lr=1e-5, step_loss=0.0513][RANK-0]: Step: [15096], local_loss=0.016925733536481857, train_loss=0.02056307904422283, time_cost=1.9066286087036133
Steps:   2%|▏         | 15096/1000000 [5:21:29<2398:23:32,  8.77s/it, lr=1e-5, step_loss=0.0169]Steps:   2%|▏         | 15097/1000000 [5:21:36<2296:49:50,  8.40s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [15097], local_loss=0.1766781359910965, train_loss=0.03702717274427414, time_cost=1.6777122020721436
Steps:   2%|▏         | 15097/1000000 [5:21:36<2296:49:50,  8.40s/it, lr=1e-5, step_loss=0.177] Steps:   2%|▏         | 15098/1000000 [5:21:47<2445:25:27,  8.94s/it, lr=1e-5, step_loss=0.177][RANK-0]: Step: [15098], local_loss=0.0273036677390337, train_loss=0.028370730578899384, time_cost=1.2608990669250488
Steps:   2%|▏         | 15098/1000000 [5:21:47<2445:25:27,  8.94s/it, lr=1e-5, step_loss=0.0273]Steps:   2%|▏         | 15099/1000000 [5:22:00<2790:57:40, 10.20s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [15099], local_loss=0.011119146831333637, train_loss=0.021067583933472633, time_cost=5.905284643173218
Steps:   2%|▏         | 15099/1000000 [5:22:00<2790:57:40, 10.20s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 15100/1000000 [5:22:15<3222:46:32, 11.78s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [15100], local_loss=0.007464341353625059, train_loss=0.01580837182700634, time_cost=11.836679220199585
Steps:   2%|▏         | 15100/1000000 [5:22:15<3222:46:32, 11.78s/it, lr=1e-5, step_loss=0.00746]Steps:   2%|▏         | 15101/1000000 [5:22:20<2668:19:01,  9.75s/it, lr=1e-5, step_loss=0.00746][RANK-0]: Step: [15101], local_loss=0.04024968668818474, train_loss=0.1547749787569046, time_cost=1.246603012084961
Steps:   2%|▏         | 15101/1000000 [5:22:20<2668:19:01,  9.75s/it, lr=1e-5, step_loss=0.0402] Steps:   2%|▏         | 15102/1000000 [5:22:30<2656:37:08,  9.71s/it, lr=1e-5, step_loss=0.0402][RANK-0]: Step: [15102], local_loss=0.01948990672826767, train_loss=0.018109045922756195, time_cost=3.307720184326172
Steps:   2%|▏         | 15102/1000000 [5:22:30<2656:37:08,  9.71s/it, lr=1e-5, step_loss=0.0195]Steps:   2%|▏         | 15103/1000000 [5:22:43<2944:01:03, 10.76s/it, lr=1e-5, step_loss=0.0195][RANK-0]: Step: [15103], local_loss=0.08471900969743729, train_loss=0.05947607383131981, time_cost=3.9347527027130127
Steps:   2%|▏         | 15103/1000000 [5:22:43<2944:01:03, 10.76s/it, lr=1e-5, step_loss=0.0847]Steps:   2%|▏         | 15104/1000000 [5:22:49<2539:56:23,  9.28s/it, lr=1e-5, step_loss=0.0847][RANK-0]: Step: [15104], local_loss=0.00519670732319355, train_loss=0.022211847826838493, time_cost=1.6653099060058594
Steps:   2%|▏         | 15104/1000000 [5:22:49<2539:56:23,  9.28s/it, lr=1e-5, step_loss=0.0052]Steps:   2%|▏         | 15105/1000000 [5:22:57<2427:50:57,  8.87s/it, lr=1e-5, step_loss=0.0052][RANK-0]: Step: [15105], local_loss=0.009224053472280502, train_loss=0.09845206886529922, time_cost=2.2446448802948
Steps:   2%|▏         | 15105/1000000 [5:22:57<2427:50:57,  8.87s/it, lr=1e-5, step_loss=0.00922]Steps:   2%|▏         | 15106/1000000 [5:23:10<2752:21:35, 10.06s/it, lr=1e-5, step_loss=0.00922][RANK-0]: Step: [15106], local_loss=0.013726059347391129, train_loss=0.04366505146026611, time_cost=5.689903020858765
Steps:   2%|▏         | 15106/1000000 [5:23:10<2752:21:35, 10.06s/it, lr=1e-5, step_loss=0.0137] Steps:   2%|▏         | 15107/1000000 [5:23:14<2288:29:49,  8.36s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [15107], local_loss=0.10282713919878006, train_loss=0.09957201778888702, time_cost=3.6159095764160156
Steps:   2%|▏         | 15107/1000000 [5:23:14<2288:29:49,  8.36s/it, lr=1e-5, step_loss=0.103] Steps:   2%|▏         | 15108/1000000 [5:23:23<2358:07:54,  8.62s/it, lr=1e-5, step_loss=0.103][RANK-0]: Step: [15108], local_loss=0.11774218082427979, train_loss=0.15812183916568756, time_cost=1.8499760627746582
Steps:   2%|▏         | 15108/1000000 [5:23:23<2358:07:54,  8.62s/it, lr=1e-5, step_loss=0.118]Steps:   2%|▏         | 15109/1000000 [5:23:31<2314:38:47,  8.46s/it, lr=1e-5, step_loss=0.118][RANK-0]: Step: [15109], local_loss=0.029769763350486755, train_loss=0.06652390956878662, time_cost=3.2119944095611572
Steps:   2%|▏         | 15109/1000000 [5:23:31<2314:38:47,  8.46s/it, lr=1e-5, step_loss=0.0298]Steps:   2%|▏         | 15110/1000000 [5:23:37<2101:02:27,  7.68s/it, lr=1e-5, step_loss=0.0298][RANK-0]: Step: [15110], local_loss=0.007125644013285637, train_loss=0.01984388940036297, time_cost=1.209883689880371
Steps:   2%|▏         | 15110/1000000 [5:23:37<2101:02:27,  7.68s/it, lr=1e-5, step_loss=0.00713]Steps:   2%|▏         | 15111/1000000 [5:23:45<2125:09:06,  7.77s/it, lr=1e-5, step_loss=0.00713][RANK-0]: Step: [15111], local_loss=0.06362994015216827, train_loss=0.020277418196201324, time_cost=3.716420888900757
Steps:   2%|▏         | 15111/1000000 [5:23:45<2125:09:06,  7.77s/it, lr=1e-5, step_loss=0.0636] Steps:   2%|▏         | 15112/1000000 [5:23:52<2065:31:51,  7.55s/it, lr=1e-5, step_loss=0.0636][RANK-0]: Step: [15112], local_loss=0.006603843066841364, train_loss=0.09387524425983429, time_cost=5.624904155731201
Steps:   2%|▏         | 15112/1000000 [5:23:52<2065:31:51,  7.55s/it, lr=1e-5, step_loss=0.0066]Steps:   2%|▏         | 15113/1000000 [5:24:01<2164:46:53,  7.91s/it, lr=1e-5, step_loss=0.0066][RANK-0]: Step: [15113], local_loss=0.012809745036065578, train_loss=0.06448404490947723, time_cost=2.6526126861572266
Steps:   2%|▏         | 15113/1000000 [5:24:01<2164:46:53,  7.91s/it, lr=1e-5, step_loss=0.0128]Steps:   2%|▏         | 15114/1000000 [5:24:08<2099:19:46,  7.67s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [15114], local_loss=0.10566423088312149, train_loss=0.026995273306965828, time_cost=1.2197186946868896
Steps:   2%|▏         | 15114/1000000 [5:24:08<2099:19:46,  7.67s/it, lr=1e-5, step_loss=0.106] Steps:   2%|▏         | 15115/1000000 [5:24:14<1925:59:41,  7.04s/it, lr=1e-5, step_loss=0.106][RANK-0]: Step: [15115], local_loss=0.04328697919845581, train_loss=0.04655144363641739, time_cost=2.9590909481048584
Steps:   2%|▏         | 15115/1000000 [5:24:14<1925:59:41,  7.04s/it, lr=1e-5, step_loss=0.0433]Steps:   2%|▏         | 15116/1000000 [5:24:28<2546:03:08,  9.31s/it, lr=1e-5, step_loss=0.0433][RANK-0]: Step: [15116], local_loss=1.005741834640503, train_loss=0.18087737262248993, time_cost=5.256582736968994
Steps:   2%|▏         | 15116/1000000 [5:24:28<2546:03:08,  9.31s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 15117/1000000 [5:24:38<2546:36:37,  9.31s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [15117], local_loss=0.010931373573839664, train_loss=0.02204202301800251, time_cost=1.3033854961395264
Steps:   2%|▏         | 15117/1000000 [5:24:38<2546:36:37,  9.31s/it, lr=1e-5, step_loss=0.0109]Steps:   2%|▏         | 15118/1000000 [5:24:48<2671:06:44,  9.76s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [15118], local_loss=0.03376387804746628, train_loss=0.03743840008974075, time_cost=2.442401170730591
Steps:   2%|▏         | 15118/1000000 [5:24:48<2671:06:44,  9.76s/it, lr=1e-5, step_loss=0.0338]Steps:   2%|▏         | 15119/1000000 [5:24:56<2526:35:26,  9.24s/it, lr=1e-5, step_loss=0.0338][RANK-0]: Step: [15119], local_loss=0.9930495023727417, train_loss=0.14315535128116608, time_cost=2.998094081878662
Steps:   2%|▏         | 15119/1000000 [5:24:56<2526:35:26,  9.24s/it, lr=1e-5, step_loss=0.993] Steps:   2%|▏         | 15120/1000000 [5:25:02<2189:04:50,  8.00s/it, lr=1e-5, step_loss=0.993][RANK-0]: Step: [15120], local_loss=0.0050453501753509045, train_loss=0.04028552025556564, time_cost=2.0264620780944824
Steps:   2%|▏         | 15120/1000000 [5:25:02<2189:04:50,  8.00s/it, lr=1e-5, step_loss=0.00505]Steps:   2%|▏         | 15121/1000000 [5:25:12<2425:40:06,  8.87s/it, lr=1e-5, step_loss=0.00505][RANK-0]: Step: [15121], local_loss=0.0407111831009388, train_loss=0.036742690950632095, time_cost=8.019122123718262
Steps:   2%|▏         | 15121/1000000 [5:25:12<2425:40:06,  8.87s/it, lr=1e-5, step_loss=0.0407] Steps:   2%|▏         | 15122/1000000 [5:25:24<2682:53:54,  9.81s/it, lr=1e-5, step_loss=0.0407][RANK-0]: Step: [15122], local_loss=0.013375170528888702, train_loss=0.024220114573836327, time_cost=4.739190578460693
Steps:   2%|▏         | 15122/1000000 [5:25:24<2682:53:54,  9.81s/it, lr=1e-5, step_loss=0.0134]Steps:   2%|▏         | 15123/1000000 [5:25:29<2259:10:26,  8.26s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [15123], local_loss=0.007684681098908186, train_loss=0.01557720173150301, time_cost=1.8446781635284424
Steps:   2%|▏         | 15123/1000000 [5:25:29<2259:10:26,  8.26s/it, lr=1e-5, step_loss=0.00768]Steps:   2%|▏         | 15124/1000000 [5:25:34<2007:48:17,  7.34s/it, lr=1e-5, step_loss=0.00768][RANK-0]: Step: [15124], local_loss=0.06957515329122543, train_loss=0.11210130155086517, time_cost=2.658644676208496
Steps:   2%|▏         | 15124/1000000 [5:25:34<2007:48:17,  7.34s/it, lr=1e-5, step_loss=0.0696] Steps:   2%|▏         | 15125/1000000 [5:25:50<2689:57:02,  9.83s/it, lr=1e-5, step_loss=0.0696][RANK-0]: Step: [15125], local_loss=0.04069225862622261, train_loss=0.030170168727636337, time_cost=6.189468860626221
Steps:   2%|▏         | 15125/1000000 [5:25:50<2689:57:02,  9.83s/it, lr=1e-5, step_loss=0.0407]Steps:   2%|▏         | 15126/1000000 [5:25:55<2298:32:29,  8.40s/it, lr=1e-5, step_loss=0.0407][RANK-0]: Step: [15126], local_loss=0.04319882020354271, train_loss=0.0597403347492218, time_cost=2.2818868160247803
Steps:   2%|▏         | 15126/1000000 [5:25:55<2298:32:29,  8.40s/it, lr=1e-5, step_loss=0.0432]Steps:   2%|▏         | 15127/1000000 [5:26:06<2530:12:45,  9.25s/it, lr=1e-5, step_loss=0.0432][RANK-0]: Step: [15127], local_loss=0.9858735203742981, train_loss=0.563766598701477, time_cost=1.8258171081542969
Steps:   2%|▏         | 15127/1000000 [5:26:06<2530:12:45,  9.25s/it, lr=1e-5, step_loss=0.986] Steps:   2%|▏         | 15128/1000000 [5:26:14<2391:25:31,  8.74s/it, lr=1e-5, step_loss=0.986][RANK-0]: Step: [15128], local_loss=0.016623781993985176, train_loss=0.03817569836974144, time_cost=1.7714288234710693
Steps:   2%|▏         | 15128/1000000 [5:26:14<2391:25:31,  8.74s/it, lr=1e-5, step_loss=0.0166]Steps:   2%|▏         | 15129/1000000 [5:26:27<2746:03:34, 10.04s/it, lr=1e-5, step_loss=0.0166][RANK-0]: Step: [15129], local_loss=0.023778144270181656, train_loss=0.04194725677371025, time_cost=5.4515814781188965
Steps:   2%|▏         | 15129/1000000 [5:26:27<2746:03:34, 10.04s/it, lr=1e-5, step_loss=0.0238]Steps:   2%|▏         | 15130/1000000 [5:26:32<2368:53:59,  8.66s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [15130], local_loss=0.06295900046825409, train_loss=0.045461393892765045, time_cost=1.2861323356628418
Steps:   2%|▏         | 15130/1000000 [5:26:32<2368:53:59,  8.66s/it, lr=1e-5, step_loss=0.063] Steps:   2%|▏         | 15131/1000000 [5:26:38<2161:31:27,  7.90s/it, lr=1e-5, step_loss=0.063][RANK-0]: Step: [15131], local_loss=0.03761262446641922, train_loss=0.05698401853442192, time_cost=3.539125680923462
Steps:   2%|▏         | 15131/1000000 [5:26:38<2161:31:27,  7.90s/it, lr=1e-5, step_loss=0.0376]Steps:   2%|▏         | 15132/1000000 [5:26:51<2510:51:07,  9.18s/it, lr=1e-5, step_loss=0.0376][RANK-0]: Step: [15132], local_loss=0.025387585163116455, train_loss=0.036896299570798874, time_cost=4.800430059432983
Steps:   2%|▏         | 15132/1000000 [5:26:51<2510:51:07,  9.18s/it, lr=1e-5, step_loss=0.0254]Steps:   2%|▏         | 15133/1000000 [5:27:02<2695:17:52,  9.85s/it, lr=1e-5, step_loss=0.0254][RANK-0]: Step: [15133], local_loss=0.11083842813968658, train_loss=0.04525882005691528, time_cost=3.2140021324157715
Steps:   2%|▏         | 15133/1000000 [5:27:02<2695:17:52,  9.85s/it, lr=1e-5, step_loss=0.111] Steps:   2%|▏         | 15134/1000000 [5:27:16<3050:40:04, 11.15s/it, lr=1e-5, step_loss=0.111][RANK-0]: Step: [15134], local_loss=0.006113741546869278, train_loss=14.0947904586792, time_cost=6.2030863761901855
Steps:   2%|▏         | 15134/1000000 [5:27:16<3050:40:04, 11.15s/it, lr=1e-5, step_loss=0.00611]Steps:   2%|▏         | 15135/1000000 [5:27:31<3321:13:19, 12.14s/it, lr=1e-5, step_loss=0.00611][RANK-0]: Step: [15135], local_loss=0.014053392224013805, train_loss=0.016939645633101463, time_cost=4.439723491668701
Steps:   2%|▏         | 15135/1000000 [5:27:31<3321:13:19, 12.14s/it, lr=1e-5, step_loss=0.0141] Steps:   2%|▏         | 15136/1000000 [5:27:43<3331:18:16, 12.18s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [15136], local_loss=0.05257066339254379, train_loss=0.024401333183050156, time_cost=4.709189414978027
Steps:   2%|▏         | 15136/1000000 [5:27:43<3331:18:16, 12.18s/it, lr=1e-5, step_loss=0.0526]Steps:   2%|▏         | 15137/1000000 [5:27:51<2965:31:04, 10.84s/it, lr=1e-5, step_loss=0.0526][RANK-0]: Step: [15137], local_loss=0.008967823348939419, train_loss=0.02132810465991497, time_cost=3.112161636352539
Steps:   2%|▏         | 15137/1000000 [5:27:51<2965:31:04, 10.84s/it, lr=1e-5, step_loss=0.00897]Steps:   2%|▏         | 15138/1000000 [5:28:04<3135:04:14, 11.46s/it, lr=1e-5, step_loss=0.00897][RANK-0]: Step: [15138], local_loss=0.014441350474953651, train_loss=0.046284228563308716, time_cost=4.554769515991211
Steps:   2%|▏         | 15138/1000000 [5:28:04<3135:04:14, 11.46s/it, lr=1e-5, step_loss=0.0144] Steps:   2%|▏         | 15139/1000000 [5:28:09<2677:54:40,  9.79s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [15139], local_loss=0.008595548570156097, train_loss=0.03934873268008232, time_cost=1.4557743072509766
Steps:   2%|▏         | 15139/1000000 [5:28:09<2677:54:40,  9.79s/it, lr=1e-5, step_loss=0.0086]Steps:   2%|▏         | 15140/1000000 [5:28:23<2983:13:27, 10.90s/it, lr=1e-5, step_loss=0.0086][RANK-0]: Step: [15140], local_loss=1.0069127082824707, train_loss=0.18068411946296692, time_cost=1.8357818126678467
Steps:   2%|▏         | 15140/1000000 [5:28:23<2983:13:27, 10.90s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 15141/1000000 [5:28:29<2550:18:20,  9.32s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [15141], local_loss=0.0057248701341450214, train_loss=0.05501716583967209, time_cost=2.590540647506714
Steps:   2%|▏         | 15141/1000000 [5:28:29<2550:18:20,  9.32s/it, lr=1e-5, step_loss=0.00572]Steps:   2%|▏         | 15142/1000000 [5:28:39<2675:20:59,  9.78s/it, lr=1e-5, step_loss=0.00572][RANK-0]: Step: [15142], local_loss=0.009493716061115265, train_loss=0.035527557134628296, time_cost=1.2341818809509277
Steps:   2%|▏         | 15142/1000000 [5:28:39<2675:20:59,  9.78s/it, lr=1e-5, step_loss=0.00949]Steps:   2%|▏         | 15143/1000000 [5:28:45<2358:04:14,  8.62s/it, lr=1e-5, step_loss=0.00949][RANK-0]: Step: [15143], local_loss=0.0515466146171093, train_loss=0.01585773378610611, time_cost=1.3290181159973145
Steps:   2%|▏         | 15143/1000000 [5:28:45<2358:04:14,  8.62s/it, lr=1e-5, step_loss=0.0515] Steps:   2%|▏         | 15144/1000000 [5:28:59<2807:10:29, 10.26s/it, lr=1e-5, step_loss=0.0515][RANK-0]: Step: [15144], local_loss=0.008030696772038937, train_loss=0.06898700445890427, time_cost=12.403333902359009
Steps:   2%|▏         | 15144/1000000 [5:28:59<2807:10:29, 10.26s/it, lr=1e-5, step_loss=0.00803]Steps:   2%|▏         | 15145/1000000 [5:29:04<2335:28:40,  8.54s/it, lr=1e-5, step_loss=0.00803][RANK-0]: Step: [15145], local_loss=0.010020740330219269, train_loss=0.0375148206949234, time_cost=1.2224180698394775
Steps:   2%|▏         | 15145/1000000 [5:29:04<2335:28:40,  8.54s/it, lr=1e-5, step_loss=0.01]   Steps:   2%|▏         | 15146/1000000 [5:29:11<2193:14:44,  8.02s/it, lr=1e-5, step_loss=0.01][RANK-0]: Step: [15146], local_loss=0.11525966972112656, train_loss=0.05294497311115265, time_cost=2.3829550743103027
Steps:   2%|▏         | 15146/1000000 [5:29:11<2193:14:44,  8.02s/it, lr=1e-5, step_loss=0.115]Steps:   2%|▏         | 15147/1000000 [5:29:16<1938:45:59,  7.09s/it, lr=1e-5, step_loss=0.115][RANK-0]: Step: [15147], local_loss=0.0075789825059473515, train_loss=0.03018335998058319, time_cost=1.9310510158538818
Steps:   2%|▏         | 15147/1000000 [5:29:16<1938:45:59,  7.09s/it, lr=1e-5, step_loss=0.00758]Steps:   2%|▏         | 15148/1000000 [5:29:25<2101:30:23,  7.68s/it, lr=1e-5, step_loss=0.00758][RANK-0]: Step: [15148], local_loss=0.022502180188894272, train_loss=0.024475395679473877, time_cost=5.0463457107543945
Steps:   2%|▏         | 15148/1000000 [5:29:25<2101:30:23,  7.68s/it, lr=1e-5, step_loss=0.0225] Steps:   2%|▏         | 15149/1000000 [5:29:39<2642:14:11,  9.66s/it, lr=1e-5, step_loss=0.0225][RANK-0]: Step: [15149], local_loss=0.05099083483219147, train_loss=0.11879482120275497, time_cost=3.572944164276123
Steps:   2%|▏         | 15149/1000000 [5:29:39<2642:14:11,  9.66s/it, lr=1e-5, step_loss=0.051] Steps:   2%|▏         | 15150/1000000 [5:29:46<2420:32:09,  8.85s/it, lr=1e-5, step_loss=0.051][RANK-0]: Step: [15150], local_loss=0.009380524978041649, train_loss=0.0599357932806015, time_cost=3.274691581726074
Steps:   2%|▏         | 15150/1000000 [5:29:46<2420:32:09,  8.85s/it, lr=1e-5, step_loss=0.00938]Steps:   2%|▏         | 15151/1000000 [5:29:50<2053:54:12,  7.51s/it, lr=1e-5, step_loss=0.00938][RANK-0]: Step: [15151], local_loss=0.031748734414577484, train_loss=0.16766640543937683, time_cost=1.6733057498931885
Steps:   2%|▏         | 15151/1000000 [5:29:50<2053:54:12,  7.51s/it, lr=1e-5, step_loss=0.0317] Steps:   2%|▏         | 15152/1000000 [5:30:04<2594:50:04,  9.49s/it, lr=1e-5, step_loss=0.0317][RANK-0]: Step: [15152], local_loss=0.055377811193466187, train_loss=2.498584270477295, time_cost=4.17692494392395
Steps:   2%|▏         | 15152/1000000 [5:30:04<2594:50:04,  9.49s/it, lr=1e-5, step_loss=0.0554]Steps:   2%|▏         | 15153/1000000 [5:30:13<2485:38:43,  9.09s/it, lr=1e-5, step_loss=0.0554][RANK-0]: Step: [15153], local_loss=0.027679739519953728, train_loss=0.02433476597070694, time_cost=3.9816226959228516
Steps:   2%|▏         | 15153/1000000 [5:30:13<2485:38:43,  9.09s/it, lr=1e-5, step_loss=0.0277]Steps:   2%|▏         | 15154/1000000 [5:30:28<3028:54:13, 11.07s/it, lr=1e-5, step_loss=0.0277][RANK-0]: Step: [15154], local_loss=0.016231149435043335, train_loss=0.054837167263031006, time_cost=1.202064037322998
Steps:   2%|▏         | 15154/1000000 [5:30:28<3028:54:13, 11.07s/it, lr=1e-5, step_loss=0.0162]Steps:   2%|▏         | 15155/1000000 [5:30:34<2598:33:00,  9.50s/it, lr=1e-5, step_loss=0.0162][RANK-0]: Step: [15155], local_loss=0.007649287581443787, train_loss=0.07344505190849304, time_cost=1.2281651496887207
Steps:   2%|▏         | 15155/1000000 [5:30:34<2598:33:00,  9.50s/it, lr=1e-5, step_loss=0.00765]Steps:   2%|▏         | 15156/1000000 [5:30:41<2395:45:09,  8.76s/it, lr=1e-5, step_loss=0.00765][RANK-0]: Step: [15156], local_loss=0.04878261685371399, train_loss=0.08194971084594727, time_cost=3.0441160202026367
Steps:   2%|▏         | 15156/1000000 [5:30:41<2395:45:09,  8.76s/it, lr=1e-5, step_loss=0.0488] Steps:   2%|▏         | 15157/1000000 [5:30:51<2447:53:09,  8.95s/it, lr=1e-5, step_loss=0.0488][RANK-0]: Step: [15157], local_loss=0.09398249536752701, train_loss=0.039255306124687195, time_cost=3.093127965927124
Steps:   2%|▏         | 15157/1000000 [5:30:51<2447:53:09,  8.95s/it, lr=1e-5, step_loss=0.094] Steps:   2%|▏         | 15158/1000000 [5:30:58<2285:20:39,  8.35s/it, lr=1e-5, step_loss=0.094][RANK-0]: Step: [15158], local_loss=0.05942942574620247, train_loss=0.04096905142068863, time_cost=5.509654998779297
Steps:   2%|▏         | 15158/1000000 [5:30:58<2285:20:39,  8.35s/it, lr=1e-5, step_loss=0.0594]Steps:   2%|▏         | 15159/1000000 [5:31:03<2058:44:51,  7.53s/it, lr=1e-5, step_loss=0.0594][RANK-0]: Step: [15159], local_loss=0.010957824066281319, train_loss=0.06046554818749428, time_cost=2.8763415813446045
Steps:   2%|▏         | 15159/1000000 [5:31:03<2058:44:51,  7.53s/it, lr=1e-5, step_loss=0.011] Steps:   2%|▏         | 15160/1000000 [5:31:15<2389:29:34,  8.73s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [15160], local_loss=0.05171734839677811, train_loss=30.33310317993164, time_cost=7.22776460647583
Steps:   2%|▏         | 15160/1000000 [5:31:15<2389:29:34,  8.73s/it, lr=1e-5, step_loss=0.0517]Steps:   2%|▏         | 15161/1000000 [5:31:20<2087:36:36,  7.63s/it, lr=1e-5, step_loss=0.0517][RANK-0]: Step: [15161], local_loss=0.012460269965231419, train_loss=0.02451193332672119, time_cost=2.0728864669799805
Steps:   2%|▏         | 15161/1000000 [5:31:20<2087:36:36,  7.63s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 15162/1000000 [5:31:33<2550:20:21,  9.32s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [15162], local_loss=0.08741617947816849, train_loss=0.19951465725898743, time_cost=9.73512864112854
Steps:   2%|▏         | 15162/1000000 [5:31:33<2550:20:21,  9.32s/it, lr=1e-5, step_loss=0.0874]Steps:   2%|▏         | 15163/1000000 [5:31:40<2364:03:52,  8.64s/it, lr=1e-5, step_loss=0.0874][RANK-0]: Step: [15163], local_loss=0.009809440933167934, train_loss=0.013231603428721428, time_cost=2.7710697650909424
Steps:   2%|▏         | 15163/1000000 [5:31:40<2364:03:52,  8.64s/it, lr=1e-5, step_loss=0.00981]Steps:   2%|▏         | 15164/1000000 [5:31:55<2877:43:14, 10.52s/it, lr=1e-5, step_loss=0.00981][RANK-0]: Step: [15164], local_loss=0.08215320110321045, train_loss=0.08451689034700394, time_cost=11.320799112319946
Steps:   2%|▏         | 15164/1000000 [5:31:55<2877:43:14, 10.52s/it, lr=1e-5, step_loss=0.0822] Steps:   2%|▏         | 15165/1000000 [5:32:01<2497:39:32,  9.13s/it, lr=1e-5, step_loss=0.0822][RANK-0]: Step: [15165], local_loss=0.029252327978610992, train_loss=0.026933329179883003, time_cost=1.7525787353515625
Steps:   2%|▏         | 15165/1000000 [5:32:01<2497:39:32,  9.13s/it, lr=1e-5, step_loss=0.0293]Steps:   2%|▏         | 15166/1000000 [5:32:12<2704:37:53,  9.89s/it, lr=1e-5, step_loss=0.0293][RANK-0]: Step: [15166], local_loss=0.009429903700947762, train_loss=29.577974319458008, time_cost=3.031867027282715
Steps:   2%|▏         | 15166/1000000 [5:32:12<2704:37:53,  9.89s/it, lr=1e-5, step_loss=0.00943]Steps:   2%|▏         | 15167/1000000 [5:32:19<2461:24:31,  9.00s/it, lr=1e-5, step_loss=0.00943][RANK-0]: Step: [15167], local_loss=0.007531831972301006, train_loss=0.03794628381729126, time_cost=2.072439193725586
Steps:   2%|▏         | 15167/1000000 [5:32:19<2461:24:31,  9.00s/it, lr=1e-5, step_loss=0.00753]Steps:   2%|▏         | 15168/1000000 [5:32:32<2735:40:18, 10.00s/it, lr=1e-5, step_loss=0.00753][RANK-0]: Step: [15168], local_loss=0.13147202134132385, train_loss=0.044133685529232025, time_cost=2.5280590057373047
Steps:   2%|▏         | 15168/1000000 [5:32:32<2735:40:18, 10.00s/it, lr=1e-5, step_loss=0.131]  Steps:   2%|▏         | 15169/1000000 [5:32:41<2709:43:54,  9.91s/it, lr=1e-5, step_loss=0.131][RANK-0]: Step: [15169], local_loss=0.4217102825641632, train_loss=0.13430459797382355, time_cost=4.275476932525635
Steps:   2%|▏         | 15169/1000000 [5:32:41<2709:43:54,  9.91s/it, lr=1e-5, step_loss=0.422]Steps:   2%|▏         | 15170/1000000 [5:32:49<2532:01:19,  9.26s/it, lr=1e-5, step_loss=0.422][RANK-0]: Step: [15170], local_loss=0.008962679654359818, train_loss=0.027034275233745575, time_cost=3.6095755100250244
Steps:   2%|▏         | 15170/1000000 [5:32:49<2532:01:19,  9.26s/it, lr=1e-5, step_loss=0.00896]Steps:   2%|▏         | 15171/1000000 [5:33:00<2651:02:56,  9.69s/it, lr=1e-5, step_loss=0.00896][RANK-0]: Step: [15171], local_loss=0.028322404250502586, train_loss=0.0288159791380167, time_cost=1.8995249271392822
Steps:   2%|▏         | 15171/1000000 [5:33:00<2651:02:56,  9.69s/it, lr=1e-5, step_loss=0.0283] Steps:   2%|▏         | 15172/1000000 [5:33:11<2735:45:34, 10.00s/it, lr=1e-5, step_loss=0.0283][RANK-0]: Step: [15172], local_loss=0.00914264190942049, train_loss=0.035716570913791656, time_cost=1.44366455078125
Steps:   2%|▏         | 15172/1000000 [5:33:11<2735:45:34, 10.00s/it, lr=1e-5, step_loss=0.00914]Steps:   2%|▏         | 15173/1000000 [5:33:20<2687:39:43,  9.82s/it, lr=1e-5, step_loss=0.00914][RANK-0]: Step: [15173], local_loss=0.006927039939910173, train_loss=0.04654480889439583, time_cost=3.456570863723755
Steps:   2%|▏         | 15173/1000000 [5:33:20<2687:39:43,  9.82s/it, lr=1e-5, step_loss=0.00693]Steps:   2%|▏         | 15174/1000000 [5:33:30<2665:59:21,  9.75s/it, lr=1e-5, step_loss=0.00693][RANK-0]: Step: [15174], local_loss=0.024618180468678474, train_loss=0.027984213083982468, time_cost=2.020331859588623
Steps:   2%|▏         | 15174/1000000 [5:33:30<2665:59:21,  9.75s/it, lr=1e-5, step_loss=0.0246] Steps:   2%|▏         | 15175/1000000 [5:33:38<2520:03:41,  9.21s/it, lr=1e-5, step_loss=0.0246][RANK-0]: Step: [15175], local_loss=0.048460703343153, train_loss=0.10409383475780487, time_cost=3.8115010261535645
Steps:   2%|▏         | 15175/1000000 [5:33:38<2520:03:41,  9.21s/it, lr=1e-5, step_loss=0.0485]Steps:   2%|▏         | 15176/1000000 [5:33:51<2906:18:46, 10.62s/it, lr=1e-5, step_loss=0.0485][RANK-0]: Step: [15176], local_loss=0.045053452253341675, train_loss=0.05686505138874054, time_cost=1.4634225368499756
Steps:   2%|▏         | 15176/1000000 [5:33:51<2906:18:46, 10.62s/it, lr=1e-5, step_loss=0.0451]Steps:   2%|▏         | 15177/1000000 [5:34:06<3213:47:39, 11.75s/it, lr=1e-5, step_loss=0.0451][RANK-0]: Step: [15177], local_loss=0.01458188146352768, train_loss=0.04402550682425499, time_cost=5.8519580364227295
Steps:   2%|▏         | 15177/1000000 [5:34:06<3213:47:39, 11.75s/it, lr=1e-5, step_loss=0.0146]Steps:   2%|▏         | 15178/1000000 [5:34:13<2841:11:58, 10.39s/it, lr=1e-5, step_loss=0.0146][RANK-0]: Step: [15178], local_loss=0.00983906164765358, train_loss=0.036247655749320984, time_cost=3.515047550201416
Steps:   2%|▏         | 15178/1000000 [5:34:13<2841:11:58, 10.39s/it, lr=1e-5, step_loss=0.00984]Steps:   2%|▏         | 15179/1000000 [5:34:24<2917:27:54, 10.66s/it, lr=1e-5, step_loss=0.00984][RANK-0]: Step: [15179], local_loss=0.009765232913196087, train_loss=0.15756183862686157, time_cost=8.34230089187622
Steps:   2%|▏         | 15179/1000000 [5:34:24<2917:27:54, 10.66s/it, lr=1e-5, step_loss=0.00977]Steps:   2%|▏         | 15180/1000000 [5:34:39<3210:29:25, 11.74s/it, lr=1e-5, step_loss=0.00977][RANK-0]: Step: [15180], local_loss=0.03726229444146156, train_loss=0.02318856120109558, time_cost=2.9249556064605713
Steps:   2%|▏         | 15180/1000000 [5:34:39<3210:29:25, 11.74s/it, lr=1e-5, step_loss=0.0373] Steps:   2%|▏         | 15181/1000000 [5:34:46<2852:42:58, 10.43s/it, lr=1e-5, step_loss=0.0373][RANK-0]: Step: [15181], local_loss=0.012715840712189674, train_loss=0.015527591109275818, time_cost=3.1409389972686768
Steps:   2%|▏         | 15181/1000000 [5:34:46<2852:42:58, 10.43s/it, lr=1e-5, step_loss=0.0127]Steps:   2%|▏         | 15182/1000000 [5:34:58<2955:37:48, 10.80s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [15182], local_loss=0.016313951462507248, train_loss=0.06141190230846405, time_cost=6.7720983028411865
Steps:   2%|▏         | 15182/1000000 [5:34:58<2955:37:48, 10.80s/it, lr=1e-5, step_loss=0.0163]Steps:   2%|▏         | 15183/1000000 [5:35:13<3367:36:43, 12.31s/it, lr=1e-5, step_loss=0.0163][RANK-0]: Step: [15183], local_loss=0.04331691935658455, train_loss=0.06086983159184456, time_cost=6.472963094711304
Steps:   2%|▏         | 15183/1000000 [5:35:13<3367:36:43, 12.31s/it, lr=1e-5, step_loss=0.0433]Steps:   2%|▏         | 15184/1000000 [5:35:23<3116:34:01, 11.39s/it, lr=1e-5, step_loss=0.0433][RANK-0]: Step: [15184], local_loss=0.009478139691054821, train_loss=0.025729544460773468, time_cost=2.293891668319702
Steps:   2%|▏         | 15184/1000000 [5:35:23<3116:34:01, 11.39s/it, lr=1e-5, step_loss=0.00948]Steps:   2%|▏         | 15185/1000000 [5:35:31<2881:45:00, 10.53s/it, lr=1e-5, step_loss=0.00948][RANK-0]: Step: [15185], local_loss=0.03810734674334526, train_loss=0.0990571603178978, time_cost=2.661994695663452
Steps:   2%|▏         | 15185/1000000 [5:35:31<2881:45:00, 10.53s/it, lr=1e-5, step_loss=0.0381] Steps:   2%|▏         | 15186/1000000 [5:35:42<2877:08:42, 10.52s/it, lr=1e-5, step_loss=0.0381][RANK-0]: Step: [15186], local_loss=0.105421282351017, train_loss=0.035978659987449646, time_cost=1.6541736125946045
Steps:   2%|▏         | 15186/1000000 [5:35:42<2877:08:42, 10.52s/it, lr=1e-5, step_loss=0.105] Steps:   2%|▏         | 15187/1000000 [5:35:54<2988:02:17, 10.92s/it, lr=1e-5, step_loss=0.105][RANK-0]: Step: [15187], local_loss=0.02134859375655651, train_loss=0.0747358426451683, time_cost=3.0093085765838623
Steps:   2%|▏         | 15187/1000000 [5:35:54<2988:02:17, 10.92s/it, lr=1e-5, step_loss=0.0213]Steps:   2%|▏         | 15188/1000000 [5:36:02<2797:24:50, 10.23s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [15188], local_loss=0.06758356094360352, train_loss=0.04358226805925369, time_cost=3.509063720703125
Steps:   2%|▏         | 15188/1000000 [5:36:02<2797:24:50, 10.23s/it, lr=1e-5, step_loss=0.0676]Steps:   2%|▏         | 15189/1000000 [5:36:10<2581:07:26,  9.44s/it, lr=1e-5, step_loss=0.0676][RANK-0]: Step: [15189], local_loss=0.018805289641022682, train_loss=0.05665828660130501, time_cost=1.6696372032165527
Steps:   2%|▏         | 15189/1000000 [5:36:10<2581:07:26,  9.44s/it, lr=1e-5, step_loss=0.0188]Steps:   2%|▏         | 15190/1000000 [5:36:23<2867:47:11, 10.48s/it, lr=1e-5, step_loss=0.0188][RANK-0]: Step: [15190], local_loss=0.04624297097325325, train_loss=0.03237428516149521, time_cost=4.420888423919678
Steps:   2%|▏         | 15190/1000000 [5:36:23<2867:47:11, 10.48s/it, lr=1e-5, step_loss=0.0462]Steps:   2%|▏         | 15191/1000000 [5:36:28<2475:09:08,  9.05s/it, lr=1e-5, step_loss=0.0462][RANK-0]: Step: [15191], local_loss=0.03666863590478897, train_loss=0.013891342096030712, time_cost=1.6290006637573242
Steps:   2%|▏         | 15191/1000000 [5:36:28<2475:09:08,  9.05s/it, lr=1e-5, step_loss=0.0367]Steps:   2%|▏         | 15192/1000000 [5:36:33<2140:53:43,  7.83s/it, lr=1e-5, step_loss=0.0367][RANK-0]: Step: [15192], local_loss=0.008287575095891953, train_loss=0.08476525545120239, time_cost=2.1823344230651855
Steps:   2%|▏         | 15192/1000000 [5:36:33<2140:53:43,  7.83s/it, lr=1e-5, step_loss=0.00829]Steps:   2%|▏         | 15193/1000000 [5:36:43<2251:21:28,  8.23s/it, lr=1e-5, step_loss=0.00829][RANK-0]: Step: [15193], local_loss=0.3014282286167145, train_loss=0.06258010119199753, time_cost=1.2854886054992676
Steps:   2%|▏         | 15193/1000000 [5:36:43<2251:21:28,  8.23s/it, lr=1e-5, step_loss=0.301]  Steps:   2%|▏         | 15194/1000000 [5:36:58<2842:14:36, 10.39s/it, lr=1e-5, step_loss=0.301][RANK-0]: Step: [15194], local_loss=69.9351577758789, train_loss=8.76233196258545, time_cost=7.129266977310181
Steps:   2%|▏         | 15194/1000000 [5:36:58<2842:14:36, 10.39s/it, lr=1e-5, step_loss=69.9] Steps:   2%|▏         | 15195/1000000 [5:37:10<2988:17:13, 10.92s/it, lr=1e-5, step_loss=69.9][RANK-0]: Step: [15195], local_loss=0.0135454460978508, train_loss=0.04715046286582947, time_cost=10.099836111068726
Steps:   2%|▏         | 15195/1000000 [5:37:10<2988:17:13, 10.92s/it, lr=1e-5, step_loss=0.0135]Steps:   2%|▏         | 15196/1000000 [5:37:19<2822:01:30, 10.32s/it, lr=1e-5, step_loss=0.0135][RANK-0]: Step: [15196], local_loss=0.08087650686502457, train_loss=0.10107819736003876, time_cost=1.2043519020080566
Steps:   2%|▏         | 15196/1000000 [5:37:19<2822:01:30, 10.32s/it, lr=1e-5, step_loss=0.0809]Steps:   2%|▏         | 15197/1000000 [5:37:24<2413:34:12,  8.82s/it, lr=1e-5, step_loss=0.0809][RANK-0]: Step: [15197], local_loss=0.2052057534456253, train_loss=0.05822635814547539, time_cost=2.024273633956909
Steps:   2%|▏         | 15197/1000000 [5:37:24<2413:34:12,  8.82s/it, lr=1e-5, step_loss=0.205] Steps:   2%|▏         | 15198/1000000 [5:37:39<2874:09:09, 10.51s/it, lr=1e-5, step_loss=0.205][RANK-0]: Step: [15198], local_loss=0.009508047252893448, train_loss=0.07107191532850266, time_cost=6.232437610626221
Steps:   2%|▏         | 15198/1000000 [5:37:39<2874:09:09, 10.51s/it, lr=1e-5, step_loss=0.00951]Steps:   2%|▏         | 15199/1000000 [5:37:44<2435:10:25,  8.90s/it, lr=1e-5, step_loss=0.00951][RANK-0]: Step: [15199], local_loss=0.12934617698192596, train_loss=0.038295626640319824, time_cost=1.1975739002227783
Steps:   2%|▏         | 15199/1000000 [5:37:44<2435:10:25,  8.90s/it, lr=1e-5, step_loss=0.129]  Steps:   2%|▏         | 15200/1000000 [5:37:58<2867:58:26, 10.48s/it, lr=1e-5, step_loss=0.129][RANK-0]: Step: [15200], local_loss=0.023097429424524307, train_loss=0.06770718842744827, time_cost=4.4223175048828125
Steps:   2%|▏         | 15200/1000000 [5:37:58<2867:58:26, 10.48s/it, lr=1e-5, step_loss=0.0231]Steps:   2%|▏         | 15201/1000000 [5:38:07<2741:25:08, 10.02s/it, lr=1e-5, step_loss=0.0231][RANK-0]: Step: [15201], local_loss=0.007887626998126507, train_loss=0.0794617235660553, time_cost=3.9585492610931396
Steps:   2%|▏         | 15201/1000000 [5:38:07<2741:25:08, 10.02s/it, lr=1e-5, step_loss=0.00789]Steps:   2%|▏         | 15202/1000000 [5:38:15<2528:06:19,  9.24s/it, lr=1e-5, step_loss=0.00789][RANK-0]: Step: [15202], local_loss=0.14386716485023499, train_loss=0.182656928896904, time_cost=1.9262645244598389
Steps:   2%|▏         | 15202/1000000 [5:38:15<2528:06:19,  9.24s/it, lr=1e-5, step_loss=0.144]  Steps:   2%|▏         | 15203/1000000 [5:38:20<2250:22:31,  8.23s/it, lr=1e-5, step_loss=0.144][RANK-0]: Step: [15203], local_loss=0.06824550777673721, train_loss=0.07407598197460175, time_cost=4.232650518417358
Steps:   2%|▏         | 15203/1000000 [5:38:20<2250:22:31,  8.23s/it, lr=1e-5, step_loss=0.0682]Steps:   2%|▏         | 15204/1000000 [5:38:30<2337:47:50,  8.55s/it, lr=1e-5, step_loss=0.0682][RANK-0]: Step: [15204], local_loss=0.06159352511167526, train_loss=0.07007521390914917, time_cost=2.1681904792785645
Steps:   2%|▏         | 15204/1000000 [5:38:30<2337:47:50,  8.55s/it, lr=1e-5, step_loss=0.0616]Steps:   2%|▏         | 15205/1000000 [5:38:34<1984:11:09,  7.25s/it, lr=1e-5, step_loss=0.0616][RANK-0]: Step: [15205], local_loss=0.0070409090258181095, train_loss=0.06842397898435593, time_cost=1.397249698638916
Steps:   2%|▏         | 15205/1000000 [5:38:34<1984:11:09,  7.25s/it, lr=1e-5, step_loss=0.00704]Steps:   2%|▏         | 15206/1000000 [5:38:39<1791:02:27,  6.55s/it, lr=1e-5, step_loss=0.00704][RANK-0]: Step: [15206], local_loss=0.17783884704113007, train_loss=0.04209878668189049, time_cost=2.221247911453247
Steps:   2%|▏         | 15206/1000000 [5:38:39<1791:02:27,  6.55s/it, lr=1e-5, step_loss=0.178]  Steps:   2%|▏         | 15207/1000000 [5:38:51<2292:37:39,  8.38s/it, lr=1e-5, step_loss=0.178][RANK-0]: Step: [15207], local_loss=0.058191150426864624, train_loss=0.05219346284866333, time_cost=6.01226806640625
Steps:   2%|▏         | 15207/1000000 [5:38:51<2292:37:39,  8.38s/it, lr=1e-5, step_loss=0.0582]Steps:   2%|▏         | 15208/1000000 [5:39:03<2510:13:05,  9.18s/it, lr=1e-5, step_loss=0.0582][RANK-0]: Step: [15208], local_loss=0.014070832170546055, train_loss=0.04028625413775444, time_cost=1.536982774734497
Steps:   2%|▏         | 15208/1000000 [5:39:03<2510:13:05,  9.18s/it, lr=1e-5, step_loss=0.0141]Steps:   2%|▏         | 15209/1000000 [5:39:07<2109:06:05,  7.71s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [15209], local_loss=0.015225458890199661, train_loss=0.14950627088546753, time_cost=1.2307276725769043
Steps:   2%|▏         | 15209/1000000 [5:39:07<2109:06:05,  7.71s/it, lr=1e-5, step_loss=0.0152]Steps:   2%|▏         | 15210/1000000 [5:39:12<1869:59:12,  6.84s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [15210], local_loss=0.006702923681586981, train_loss=0.07176066935062408, time_cost=1.9992821216583252
Steps:   2%|▏         | 15210/1000000 [5:39:12<1869:59:12,  6.84s/it, lr=1e-5, step_loss=0.0067]Steps:   2%|▏         | 15211/1000000 [5:39:16<1674:05:22,  6.12s/it, lr=1e-5, step_loss=0.0067][RANK-0]: Step: [15211], local_loss=0.03778911754488945, train_loss=0.017559539526700974, time_cost=1.5744214057922363
Steps:   2%|▏         | 15211/1000000 [5:39:16<1674:05:22,  6.12s/it, lr=1e-5, step_loss=0.0378]Steps:   2%|▏         | 15212/1000000 [5:39:21<1577:24:20,  5.77s/it, lr=1e-5, step_loss=0.0378][RANK-0]: Step: [15212], local_loss=0.01605781726539135, train_loss=0.14867688715457916, time_cost=2.062649726867676
Steps:   2%|▏         | 15212/1000000 [5:39:21<1577:24:20,  5.77s/it, lr=1e-5, step_loss=0.0161]Steps:   2%|▏         | 15213/1000000 [5:39:34<2202:50:33,  8.05s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [15213], local_loss=0.005109273362904787, train_loss=0.11619602143764496, time_cost=4.1560564041137695
Steps:   2%|▏         | 15213/1000000 [5:39:34<2202:50:33,  8.05s/it, lr=1e-5, step_loss=0.00511]Steps:   2%|▏         | 15214/1000000 [5:39:51<2870:02:11, 10.49s/it, lr=1e-5, step_loss=0.00511][RANK-0]: Step: [15214], local_loss=0.007527779787778854, train_loss=0.03594150394201279, time_cost=7.250680208206177
Steps:   2%|▏         | 15214/1000000 [5:39:51<2870:02:11, 10.49s/it, lr=1e-5, step_loss=0.00753]Steps:   2%|▏         | 15215/1000000 [5:40:02<2908:50:14, 10.63s/it, lr=1e-5, step_loss=0.00753][RANK-0]: Step: [15215], local_loss=0.2021263688802719, train_loss=0.04275989904999733, time_cost=3.2150747776031494
Steps:   2%|▏         | 15215/1000000 [5:40:02<2908:50:14, 10.63s/it, lr=1e-5, step_loss=0.202]  Steps:   2%|▏         | 15216/1000000 [5:40:14<3089:20:07, 11.29s/it, lr=1e-5, step_loss=0.202][RANK-0]: Step: [15216], local_loss=0.02015993744134903, train_loss=0.01332058198750019, time_cost=3.7774250507354736
Steps:   2%|▏         | 15216/1000000 [5:40:14<3089:20:07, 11.29s/it, lr=1e-5, step_loss=0.0202]Steps:   2%|▏         | 15217/1000000 [5:40:26<3078:25:56, 11.25s/it, lr=1e-5, step_loss=0.0202][RANK-0]: Step: [15217], local_loss=0.005847585387527943, train_loss=0.03986024856567383, time_cost=4.085529565811157
Steps:   2%|▏         | 15217/1000000 [5:40:26<3078:25:56, 11.25s/it, lr=1e-5, step_loss=0.00585]Steps:   2%|▏         | 15218/1000000 [5:40:31<2564:15:17,  9.37s/it, lr=1e-5, step_loss=0.00585][RANK-0]: Step: [15218], local_loss=0.01366999838501215, train_loss=0.024778248742222786, time_cost=2.2406561374664307
Steps:   2%|▏         | 15218/1000000 [5:40:31<2564:15:17,  9.37s/it, lr=1e-5, step_loss=0.0137] Steps:   2%|▏         | 15219/1000000 [5:40:46<3028:37:48, 11.07s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [15219], local_loss=0.01572684943675995, train_loss=0.042419351637363434, time_cost=6.119369268417358
Steps:   2%|▏         | 15219/1000000 [5:40:46<3028:37:48, 11.07s/it, lr=1e-5, step_loss=0.0157]Steps:   2%|▏         | 15220/1000000 [5:40:56<2984:00:59, 10.91s/it, lr=1e-5, step_loss=0.0157][RANK-0]: Step: [15220], local_loss=0.01203209813684225, train_loss=0.018611792474985123, time_cost=2.9872701168060303
Steps:   2%|▏         | 15220/1000000 [5:40:56<2984:00:59, 10.91s/it, lr=1e-5, step_loss=0.012] Steps:   2%|▏         | 15221/1000000 [5:41:01<2499:13:36,  9.14s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [15221], local_loss=0.007350284140557051, train_loss=19.776559829711914, time_cost=2.301642656326294
Steps:   2%|▏         | 15221/1000000 [5:41:01<2499:13:36,  9.14s/it, lr=1e-5, step_loss=0.00735]Steps:   2%|▏         | 15222/1000000 [5:41:07<2237:57:50,  8.18s/it, lr=1e-5, step_loss=0.00735][RANK-0]: Step: [15222], local_loss=0.01546271052211523, train_loss=0.07384216040372849, time_cost=1.572967767715454
Steps:   2%|▏         | 15222/1000000 [5:41:07<2237:57:50,  8.18s/it, lr=1e-5, step_loss=0.0155] Steps:   2%|▏         | 15223/1000000 [5:41:17<2353:35:53,  8.60s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [15223], local_loss=0.020152052864432335, train_loss=0.023269234225153923, time_cost=3.325291156768799
Steps:   2%|▏         | 15223/1000000 [5:41:17<2353:35:53,  8.60s/it, lr=1e-5, step_loss=0.0202]Steps:   2%|▏         | 15224/1000000 [5:41:26<2451:14:04,  8.96s/it, lr=1e-5, step_loss=0.0202][RANK-0]: Step: [15224], local_loss=0.027099337428808212, train_loss=0.025388743728399277, time_cost=2.4651975631713867
Steps:   2%|▏         | 15224/1000000 [5:41:26<2451:14:04,  8.96s/it, lr=1e-5, step_loss=0.0271]Steps:   2%|▏         | 15225/1000000 [5:41:45<3230:28:17, 11.81s/it, lr=1e-5, step_loss=0.0271][RANK-0]: Step: [15225], local_loss=0.1294175535440445, train_loss=0.09525781869888306, time_cost=11.616614580154419
Steps:   2%|▏         | 15225/1000000 [5:41:45<3230:28:17, 11.81s/it, lr=1e-5, step_loss=0.129] Steps:   2%|▏         | 15226/1000000 [5:42:00<3506:18:54, 12.82s/it, lr=1e-5, step_loss=0.129][RANK-0]: Step: [15226], local_loss=0.12157920002937317, train_loss=0.03183118253946304, time_cost=6.875264644622803
Steps:   2%|▏         | 15226/1000000 [5:42:00<3506:18:54, 12.82s/it, lr=1e-5, step_loss=0.122]Steps:   2%|▏         | 15227/1000000 [5:42:14<3603:10:24, 13.17s/it, lr=1e-5, step_loss=0.122][RANK-0]: Step: [15227], local_loss=0.01477152481675148, train_loss=0.017500881105661392, time_cost=5.7784247398376465
Steps:   2%|▏         | 15227/1000000 [5:42:14<3603:10:24, 13.17s/it, lr=1e-5, step_loss=0.0148]Steps:   2%|▏         | 15228/1000000 [5:42:20<3007:35:13, 10.99s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [15228], local_loss=0.05651038885116577, train_loss=0.07303743064403534, time_cost=2.0019443035125732
Steps:   2%|▏         | 15228/1000000 [5:42:20<3007:35:13, 10.99s/it, lr=1e-5, step_loss=0.0565]Steps:   2%|▏         | 15229/1000000 [5:42:26<2602:31:27,  9.51s/it, lr=1e-5, step_loss=0.0565][RANK-0]: Step: [15229], local_loss=0.12639716267585754, train_loss=0.08748462051153183, time_cost=1.981229543685913
Steps:   2%|▏         | 15229/1000000 [5:42:26<2602:31:27,  9.51s/it, lr=1e-5, step_loss=0.126] Steps:   2%|▏         | 15230/1000000 [5:42:33<2424:54:28,  8.86s/it, lr=1e-5, step_loss=0.126][RANK-0]: Step: [15230], local_loss=0.044681526720523834, train_loss=0.0486118346452713, time_cost=3.1248385906219482
Steps:   2%|▏         | 15230/1000000 [5:42:33<2424:54:28,  8.86s/it, lr=1e-5, step_loss=0.0447]Steps:   2%|▏         | 15231/1000000 [5:42:38<2068:16:37,  7.56s/it, lr=1e-5, step_loss=0.0447][RANK-0]: Step: [15231], local_loss=0.018408412113785744, train_loss=0.16749908030033112, time_cost=1.5343503952026367
Steps:   2%|▏         | 15231/1000000 [5:42:38<2068:16:37,  7.56s/it, lr=1e-5, step_loss=0.0184]Steps:   2%|▏         | 15232/1000000 [5:42:53<2694:52:10,  9.85s/it, lr=1e-5, step_loss=0.0184][RANK-0]: Step: [15232], local_loss=0.05279424041509628, train_loss=0.17847350239753723, time_cost=6.407045602798462
Steps:   2%|▏         | 15232/1000000 [5:42:53<2694:52:10,  9.85s/it, lr=1e-5, step_loss=0.0528]Steps:   2%|▏         | 15233/1000000 [5:43:01<2510:37:42,  9.18s/it, lr=1e-5, step_loss=0.0528][RANK-0]: Step: [15233], local_loss=0.005949496757239103, train_loss=0.056183360517024994, time_cost=1.7194147109985352
Steps:   2%|▏         | 15233/1000000 [5:43:01<2510:37:42,  9.18s/it, lr=1e-5, step_loss=0.00595]Steps:   2%|▏         | 15234/1000000 [5:43:15<2925:36:15, 10.70s/it, lr=1e-5, step_loss=0.00595][RANK-0]: Step: [15234], local_loss=0.10481604933738708, train_loss=0.03445139527320862, time_cost=10.083882331848145
Steps:   2%|▏         | 15234/1000000 [5:43:15<2925:36:15, 10.70s/it, lr=1e-5, step_loss=0.105]  Steps:   2%|▏         | 15235/1000000 [5:43:28<3125:57:47, 11.43s/it, lr=1e-5, step_loss=0.105][RANK-0]: Step: [15235], local_loss=0.022756166756153107, train_loss=0.016140496358275414, time_cost=9.308237075805664
Steps:   2%|▏         | 15235/1000000 [5:43:28<3125:57:47, 11.43s/it, lr=1e-5, step_loss=0.0228]Steps:   2%|▏         | 15236/1000000 [5:43:35<2745:29:07, 10.04s/it, lr=1e-5, step_loss=0.0228][RANK-0]: Step: [15236], local_loss=0.057957619428634644, train_loss=0.016317201778292656, time_cost=1.3098316192626953
Steps:   2%|▏         | 15236/1000000 [5:43:35<2745:29:07, 10.04s/it, lr=1e-5, step_loss=0.058] Steps:   2%|▏         | 15237/1000000 [5:43:40<2385:40:06,  8.72s/it, lr=1e-5, step_loss=0.058][RANK-0]: Step: [15237], local_loss=0.01144244521856308, train_loss=0.0743449330329895, time_cost=1.9263026714324951
Steps:   2%|▏         | 15237/1000000 [5:43:40<2385:40:06,  8.72s/it, lr=1e-5, step_loss=0.0114]Steps:   2%|▏         | 15238/1000000 [5:43:53<2716:59:05,  9.93s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [15238], local_loss=0.01650075800716877, train_loss=0.03149612620472908, time_cost=6.202775716781616
Steps:   2%|▏         | 15238/1000000 [5:43:53<2716:59:05,  9.93s/it, lr=1e-5, step_loss=0.0165]Steps:   2%|▏         | 15239/1000000 [5:44:04<2824:01:14, 10.32s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [15239], local_loss=0.07426878809928894, train_loss=0.029097173362970352, time_cost=1.6746923923492432
Steps:   2%|▏         | 15239/1000000 [5:44:04<2824:01:14, 10.32s/it, lr=1e-5, step_loss=0.0743]Steps:   2%|▏         | 15240/1000000 [5:44:09<2385:37:47,  8.72s/it, lr=1e-5, step_loss=0.0743][RANK-0]: Step: [15240], local_loss=0.005953907035291195, train_loss=0.06126444414258003, time_cost=1.8573863506317139
Steps:   2%|▏         | 15240/1000000 [5:44:09<2385:37:47,  8.72s/it, lr=1e-5, step_loss=0.00595]Steps:   2%|▏         | 15241/1000000 [5:44:20<2547:05:26,  9.31s/it, lr=1e-5, step_loss=0.00595][RANK-0]: Step: [15241], local_loss=0.00906499195843935, train_loss=0.06770963966846466, time_cost=8.65982961654663
Steps:   2%|▏         | 15241/1000000 [5:44:20<2547:05:26,  9.31s/it, lr=1e-5, step_loss=0.00906]Steps:   2%|▏         | 15242/1000000 [5:44:32<2772:43:45, 10.14s/it, lr=1e-5, step_loss=0.00906][RANK-0]: Step: [15242], local_loss=0.06894955784082413, train_loss=0.11562816798686981, time_cost=2.7545368671417236
Steps:   2%|▏         | 15242/1000000 [5:44:32<2772:43:45, 10.14s/it, lr=1e-5, step_loss=0.0689] Steps:   2%|▏         | 15243/1000000 [5:44:49<3307:22:40, 12.09s/it, lr=1e-5, step_loss=0.0689][RANK-0]: Step: [15243], local_loss=0.00467841187492013, train_loss=0.11650915443897247, time_cost=13.138053894042969
Steps:   2%|▏         | 15243/1000000 [5:44:49<3307:22:40, 12.09s/it, lr=1e-5, step_loss=0.00468]Steps:   2%|▏         | 15244/1000000 [5:45:02<3364:36:22, 12.30s/it, lr=1e-5, step_loss=0.00468][RANK-0]: Step: [15244], local_loss=0.011546612717211246, train_loss=0.07856851816177368, time_cost=1.2429587841033936
Steps:   2%|▏         | 15244/1000000 [5:45:02<3364:36:22, 12.30s/it, lr=1e-5, step_loss=0.0115] Steps:   2%|▏         | 15245/1000000 [5:45:16<3546:35:13, 12.97s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [15245], local_loss=0.010694194585084915, train_loss=0.031592950224876404, time_cost=1.2561516761779785
Steps:   2%|▏         | 15245/1000000 [5:45:16<3546:35:13, 12.97s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 15246/1000000 [5:45:29<3512:42:44, 12.84s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [15246], local_loss=0.06649832427501678, train_loss=0.05939285084605217, time_cost=4.987425327301025
Steps:   2%|▏         | 15246/1000000 [5:45:29<3512:42:44, 12.84s/it, lr=1e-5, step_loss=0.0665]Steps:   2%|▏         | 15247/1000000 [5:45:34<2895:43:05, 10.59s/it, lr=1e-5, step_loss=0.0665][RANK-0]: Step: [15247], local_loss=0.038376640528440475, train_loss=1.3777083158493042, time_cost=3.174675464630127
Steps:   2%|▏         | 15247/1000000 [5:45:34<2895:43:05, 10.59s/it, lr=1e-5, step_loss=0.0384]Steps:   2%|▏         | 15248/1000000 [5:45:45<2960:51:00, 10.82s/it, lr=1e-5, step_loss=0.0384][RANK-0]: Step: [15248], local_loss=0.09223302453756332, train_loss=0.07511521875858307, time_cost=2.1523244380950928
Steps:   2%|▏         | 15248/1000000 [5:45:45<2960:51:00, 10.82s/it, lr=1e-5, step_loss=0.0922]Steps:   2%|▏         | 15249/1000000 [5:45:58<3127:21:00, 11.43s/it, lr=1e-5, step_loss=0.0922][RANK-0]: Step: [15249], local_loss=0.013258686289191246, train_loss=0.014208251610398293, time_cost=3.690105676651001
Steps:   2%|▏         | 15249/1000000 [5:45:58<3127:21:00, 11.43s/it, lr=1e-5, step_loss=0.0133]Steps:   2%|▏         | 15250/1000000 [5:46:12<3285:34:30, 12.01s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [15250], local_loss=0.008020970039069653, train_loss=0.012710459530353546, time_cost=3.4611620903015137
Steps:   2%|▏         | 15250/1000000 [5:46:12<3285:34:30, 12.01s/it, lr=1e-5, step_loss=0.00802]Steps:   2%|▏         | 15251/1000000 [5:46:18<2793:02:19, 10.21s/it, lr=1e-5, step_loss=0.00802][RANK-0]: Step: [15251], local_loss=0.059971101582050323, train_loss=0.016827702522277832, time_cost=4.566795110702515
Steps:   2%|▏         | 15251/1000000 [5:46:18<2793:02:19, 10.21s/it, lr=1e-5, step_loss=0.06]   Steps:   2%|▏         | 15252/1000000 [5:46:33<3218:32:07, 11.77s/it, lr=1e-5, step_loss=0.06][RANK-0]: Step: [15252], local_loss=0.034339141100645065, train_loss=0.016727034002542496, time_cost=12.038364887237549
Steps:   2%|▏         | 15252/1000000 [5:46:33<3218:32:07, 11.77s/it, lr=1e-5, step_loss=0.0343]Steps:   2%|▏         | 15253/1000000 [5:46:46<3330:34:10, 12.18s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [15253], local_loss=0.01321214996278286, train_loss=0.030708663165569305, time_cost=9.828892230987549
Steps:   2%|▏         | 15253/1000000 [5:46:46<3330:34:10, 12.18s/it, lr=1e-5, step_loss=0.0132]Steps:   2%|▏         | 15254/1000000 [5:46:57<3217:39:38, 11.76s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [15254], local_loss=0.010463452897965908, train_loss=0.025326959788799286, time_cost=1.6400723457336426
Steps:   2%|▏         | 15254/1000000 [5:46:57<3217:39:38, 11.76s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 15255/1000000 [5:47:03<2732:48:35,  9.99s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [15255], local_loss=0.02717454917728901, train_loss=0.07004307210445404, time_cost=1.6945605278015137
Steps:   2%|▏         | 15255/1000000 [5:47:03<2732:48:35,  9.99s/it, lr=1e-5, step_loss=0.0272]Steps:   2%|▏         | 15256/1000000 [5:47:10<2517:10:50,  9.20s/it, lr=1e-5, step_loss=0.0272][RANK-0]: Step: [15256], local_loss=0.07131586968898773, train_loss=0.0679238811135292, time_cost=1.4989261627197266
Steps:   2%|▏         | 15256/1000000 [5:47:10<2517:10:50,  9.20s/it, lr=1e-5, step_loss=0.0713]Steps:   2%|▏         | 15257/1000000 [5:47:24<2857:46:54, 10.45s/it, lr=1e-5, step_loss=0.0713][RANK-0]: Step: [15257], local_loss=0.02195580303668976, train_loss=0.1188274696469307, time_cost=5.872691869735718
Steps:   2%|▏         | 15257/1000000 [5:47:24<2857:46:54, 10.45s/it, lr=1e-5, step_loss=0.022] Steps:   2%|▏         | 15258/1000000 [5:47:30<2518:35:10,  9.21s/it, lr=1e-5, step_loss=0.022][RANK-0]: Step: [15258], local_loss=0.00827851239591837, train_loss=0.0261665191501379, time_cost=2.1396381855010986
Steps:   2%|▏         | 15258/1000000 [5:47:30<2518:35:10,  9.21s/it, lr=1e-5, step_loss=0.00828]Steps:   2%|▏         | 15259/1000000 [5:47:43<2809:31:00, 10.27s/it, lr=1e-5, step_loss=0.00828][RANK-0]: Step: [15259], local_loss=0.01549747958779335, train_loss=0.023082610219717026, time_cost=7.201918125152588
Steps:   2%|▏         | 15259/1000000 [5:47:43<2809:31:00, 10.27s/it, lr=1e-5, step_loss=0.0155] Steps:   2%|▏         | 15260/1000000 [5:47:47<2350:44:58,  8.59s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [15260], local_loss=0.008099707774817944, train_loss=0.17553915083408356, time_cost=2.351553440093994
Steps:   2%|▏         | 15260/1000000 [5:47:47<2350:44:58,  8.59s/it, lr=1e-5, step_loss=0.0081]Steps:   2%|▏         | 15261/1000000 [5:48:02<2860:28:58, 10.46s/it, lr=1e-5, step_loss=0.0081][RANK-0]: Step: [15261], local_loss=0.014649753458797932, train_loss=0.01344786211848259, time_cost=3.091904878616333
Steps:   2%|▏         | 15261/1000000 [5:48:02<2860:28:58, 10.46s/it, lr=1e-5, step_loss=0.0146]Steps:   2%|▏         | 15262/1000000 [5:48:13<2881:11:58, 10.53s/it, lr=1e-5, step_loss=0.0146][RANK-0]: Step: [15262], local_loss=0.009214555844664574, train_loss=0.024689795449376106, time_cost=5.3506622314453125
Steps:   2%|▏         | 15262/1000000 [5:48:13<2881:11:58, 10.53s/it, lr=1e-5, step_loss=0.00921]Steps:   2%|▏         | 15263/1000000 [5:48:25<3012:51:19, 11.01s/it, lr=1e-5, step_loss=0.00921][RANK-0]: Step: [15263], local_loss=0.013151979073882103, train_loss=0.019166581332683563, time_cost=1.191321611404419
Steps:   2%|▏         | 15263/1000000 [5:48:25<3012:51:19, 11.01s/it, lr=1e-5, step_loss=0.0132] Steps:   2%|▏         | 15264/1000000 [5:48:32<2652:35:43,  9.70s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [15264], local_loss=0.011464335955679417, train_loss=0.03488190472126007, time_cost=2.451080799102783
Steps:   2%|▏         | 15264/1000000 [5:48:32<2652:35:43,  9.70s/it, lr=1e-5, step_loss=0.0115]Steps:   2%|▏         | 15265/1000000 [5:48:38<2352:48:59,  8.60s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [15265], local_loss=0.0815545991063118, train_loss=0.03062470443546772, time_cost=1.5005254745483398
Steps:   2%|▏         | 15265/1000000 [5:48:38<2352:48:59,  8.60s/it, lr=1e-5, step_loss=0.0816]Steps:   2%|▏         | 15266/1000000 [5:48:43<2124:22:00,  7.77s/it, lr=1e-5, step_loss=0.0816][RANK-0]: Step: [15266], local_loss=0.01974170096218586, train_loss=0.02677132561802864, time_cost=3.1034696102142334
Steps:   2%|▏         | 15266/1000000 [5:48:43<2124:22:00,  7.77s/it, lr=1e-5, step_loss=0.0197]Steps:   2%|▏         | 15267/1000000 [5:48:49<1927:06:58,  7.05s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [15267], local_loss=0.07903293520212173, train_loss=0.17049893736839294, time_cost=2.988617420196533
Steps:   2%|▏         | 15267/1000000 [5:48:49<1927:06:58,  7.05s/it, lr=1e-5, step_loss=0.079] Steps:   2%|▏         | 15268/1000000 [5:48:57<2028:44:22,  7.42s/it, lr=1e-5, step_loss=0.079][RANK-0]: Step: [15268], local_loss=0.051280006766319275, train_loss=0.08559753000736237, time_cost=1.5084826946258545
Steps:   2%|▏         | 15268/1000000 [5:48:57<2028:44:22,  7.42s/it, lr=1e-5, step_loss=0.0513]Steps:   2%|▏         | 15269/1000000 [5:49:07<2219:04:02,  8.11s/it, lr=1e-5, step_loss=0.0513][RANK-0]: Step: [15269], local_loss=0.01965266279876232, train_loss=0.03811858966946602, time_cost=1.556236982345581
Steps:   2%|▏         | 15269/1000000 [5:49:07<2219:04:02,  8.11s/it, lr=1e-5, step_loss=0.0197]Steps:   2%|▏         | 15270/1000000 [5:49:13<2082:16:06,  7.61s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [15270], local_loss=0.0076354132033884525, train_loss=0.05702075734734535, time_cost=2.713766098022461
Steps:   2%|▏         | 15270/1000000 [5:49:13<2082:16:06,  7.61s/it, lr=1e-5, step_loss=0.00764]Steps:   2%|▏         | 15271/1000000 [5:49:24<2310:04:29,  8.45s/it, lr=1e-5, step_loss=0.00764][RANK-0]: Step: [15271], local_loss=0.018066566437482834, train_loss=0.034855883568525314, time_cost=2.045468330383301
Steps:   2%|▏         | 15271/1000000 [5:49:24<2310:04:29,  8.45s/it, lr=1e-5, step_loss=0.0181] Steps:   2%|▏         | 15272/1000000 [5:49:29<2042:07:04,  7.47s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [15272], local_loss=0.11676866561174393, train_loss=0.032570548355579376, time_cost=2.6256091594696045
Steps:   2%|▏         | 15272/1000000 [5:49:29<2042:07:04,  7.47s/it, lr=1e-5, step_loss=0.117] Steps:   2%|▏         | 15273/1000000 [5:49:37<2102:56:07,  7.69s/it, lr=1e-5, step_loss=0.117][RANK-0]: Step: [15273], local_loss=0.00509064132347703, train_loss=0.03006152994930744, time_cost=2.141860008239746
Steps:   2%|▏         | 15273/1000000 [5:49:37<2102:56:07,  7.69s/it, lr=1e-5, step_loss=0.00509]Steps:   2%|▏         | 15274/1000000 [5:49:46<2229:11:02,  8.15s/it, lr=1e-5, step_loss=0.00509][RANK-0]: Step: [15274], local_loss=0.08358165621757507, train_loss=0.04412420094013214, time_cost=1.9254674911499023
Steps:   2%|▏         | 15274/1000000 [5:49:46<2229:11:02,  8.15s/it, lr=1e-5, step_loss=0.0836] Steps:   2%|▏         | 15275/1000000 [5:49:51<1916:38:42,  7.01s/it, lr=1e-5, step_loss=0.0836][RANK-0]: Step: [15275], local_loss=0.11679213494062424, train_loss=0.05710044130682945, time_cost=1.4215023517608643
Steps:   2%|▏         | 15275/1000000 [5:49:51<1916:38:42,  7.01s/it, lr=1e-5, step_loss=0.117] Steps:   2%|▏         | 15276/1000000 [5:49:57<1832:47:46,  6.70s/it, lr=1e-5, step_loss=0.117][RANK-0]: Step: [15276], local_loss=0.05687938630580902, train_loss=0.2685467004776001, time_cost=1.2616755962371826
Steps:   2%|▏         | 15276/1000000 [5:49:57<1832:47:46,  6.70s/it, lr=1e-5, step_loss=0.0569]Steps:   2%|▏         | 15277/1000000 [5:50:08<2258:20:06,  8.26s/it, lr=1e-5, step_loss=0.0569][RANK-0]: Step: [15277], local_loss=0.055110760033130646, train_loss=0.04448753222823143, time_cost=3.8280017375946045
Steps:   2%|▏         | 15277/1000000 [5:50:08<2258:20:06,  8.26s/it, lr=1e-5, step_loss=0.0551]Steps:   2%|▏         | 15278/1000000 [5:50:22<2698:37:26,  9.87s/it, lr=1e-5, step_loss=0.0551][RANK-0]: Step: [15278], local_loss=0.03737388923764229, train_loss=0.02500176802277565, time_cost=6.5483832359313965
Steps:   2%|▏         | 15278/1000000 [5:50:22<2698:37:26,  9.87s/it, lr=1e-5, step_loss=0.0374]Steps:   2%|▏         | 15279/1000000 [5:50:26<2243:11:11,  8.20s/it, lr=1e-5, step_loss=0.0374][RANK-0]: Step: [15279], local_loss=0.034127309918403625, train_loss=0.04286620765924454, time_cost=1.4932303428649902
Steps:   2%|▏         | 15279/1000000 [5:50:26<2243:11:11,  8.20s/it, lr=1e-5, step_loss=0.0341]Steps:   2%|▏         | 15280/1000000 [5:50:31<1985:54:12,  7.26s/it, lr=1e-5, step_loss=0.0341][RANK-0]: Step: [15280], local_loss=0.03363844007253647, train_loss=0.04086345434188843, time_cost=3.8557441234588623
Steps:   2%|▏         | 15280/1000000 [5:50:31<1985:54:12,  7.26s/it, lr=1e-5, step_loss=0.0336]Steps:   2%|▏         | 15281/1000000 [5:50:42<2271:11:00,  8.30s/it, lr=1e-5, step_loss=0.0336][RANK-0]: Step: [15281], local_loss=0.07169462740421295, train_loss=0.1587938815355301, time_cost=3.4972004890441895
Steps:   2%|▏         | 15281/1000000 [5:50:42<2271:11:00,  8.30s/it, lr=1e-5, step_loss=0.0717]Steps:   2%|▏         | 15282/1000000 [5:50:47<1962:47:40,  7.18s/it, lr=1e-5, step_loss=0.0717][RANK-0]: Step: [15282], local_loss=0.08109157532453537, train_loss=0.07918614149093628, time_cost=3.5709877014160156
Steps:   2%|▏         | 15282/1000000 [5:50:47<1962:47:40,  7.18s/it, lr=1e-5, step_loss=0.0811]Steps:   2%|▏         | 15283/1000000 [5:50:58<2277:17:29,  8.33s/it, lr=1e-5, step_loss=0.0811][RANK-0]: Step: [15283], local_loss=0.009303824976086617, train_loss=0.08086326718330383, time_cost=5.9352381229400635
Steps:   2%|▏         | 15283/1000000 [5:50:58<2277:17:29,  8.33s/it, lr=1e-5, step_loss=0.0093]Steps:   2%|▏         | 15284/1000000 [5:51:03<2011:21:59,  7.35s/it, lr=1e-5, step_loss=0.0093][RANK-0]: Step: [15284], local_loss=0.02283334918320179, train_loss=0.022283945232629776, time_cost=2.1989200115203857
Steps:   2%|▏         | 15284/1000000 [5:51:03<2011:21:59,  7.35s/it, lr=1e-5, step_loss=0.0228]Steps:   2%|▏         | 15285/1000000 [5:51:12<2191:17:31,  8.01s/it, lr=1e-5, step_loss=0.0228][RANK-0]: Step: [15285], local_loss=0.06355015933513641, train_loss=0.029000241309404373, time_cost=1.7926442623138428
Steps:   2%|▏         | 15285/1000000 [5:51:12<2191:17:31,  8.01s/it, lr=1e-5, step_loss=0.0636]Steps:   2%|▏         | 15286/1000000 [5:51:21<2240:56:44,  8.19s/it, lr=1e-5, step_loss=0.0636][RANK-0]: Step: [15286], local_loss=0.06440769135951996, train_loss=0.03141311556100845, time_cost=2.5977487564086914
Steps:   2%|▏         | 15286/1000000 [5:51:21<2240:56:44,  8.19s/it, lr=1e-5, step_loss=0.0644]Steps:   2%|▏         | 15287/1000000 [5:51:29<2205:38:38,  8.06s/it, lr=1e-5, step_loss=0.0644][RANK-0]: Step: [15287], local_loss=0.06438306719064713, train_loss=0.029122933745384216, time_cost=2.1215503215789795
Steps:   2%|▏         | 15287/1000000 [5:51:29<2205:38:38,  8.06s/it, lr=1e-5, step_loss=0.0644]Steps:   2%|▏         | 15288/1000000 [5:51:45<2875:10:47, 10.51s/it, lr=1e-5, step_loss=0.0644][RANK-0]: Step: [15288], local_loss=0.02017032355070114, train_loss=0.04480239376425743, time_cost=7.883184909820557
Steps:   2%|▏         | 15288/1000000 [5:51:45<2875:10:47, 10.51s/it, lr=1e-5, step_loss=0.0202]Steps:   2%|▏         | 15289/1000000 [5:52:00<3282:16:42, 12.00s/it, lr=1e-5, step_loss=0.0202][RANK-0]: Step: [15289], local_loss=0.007854829542338848, train_loss=0.0471104197204113, time_cost=7.1412131786346436
Steps:   2%|▏         | 15289/1000000 [5:52:00<3282:16:42, 12.00s/it, lr=1e-5, step_loss=0.00785]Steps:   2%|▏         | 15290/1000000 [5:52:08<2916:19:41, 10.66s/it, lr=1e-5, step_loss=0.00785][RANK-0]: Step: [15290], local_loss=0.004460892174392939, train_loss=0.1011827290058136, time_cost=2.0511298179626465
Steps:   2%|▏         | 15290/1000000 [5:52:08<2916:19:41, 10.66s/it, lr=1e-5, step_loss=0.00446]Steps:   2%|▏         | 15291/1000000 [5:52:22<3228:03:47, 11.80s/it, lr=1e-5, step_loss=0.00446][RANK-0]: Step: [15291], local_loss=0.02249283157289028, train_loss=0.050847768783569336, time_cost=2.4055333137512207
Steps:   2%|▏         | 15291/1000000 [5:52:22<3228:03:47, 11.80s/it, lr=1e-5, step_loss=0.0225] Steps:   2%|▏         | 15292/1000000 [5:52:29<2831:58:28, 10.35s/it, lr=1e-5, step_loss=0.0225][RANK-0]: Step: [15292], local_loss=0.007056397385895252, train_loss=0.024315085262060165, time_cost=2.2517192363739014
Steps:   2%|▏         | 15292/1000000 [5:52:29<2831:58:28, 10.35s/it, lr=1e-5, step_loss=0.00706]Steps:   2%|▏         | 15293/1000000 [5:52:40<2855:58:58, 10.44s/it, lr=1e-5, step_loss=0.00706][RANK-0]: Step: [15293], local_loss=0.05130894109606743, train_loss=0.07480023801326752, time_cost=3.1086266040802
Steps:   2%|▏         | 15293/1000000 [5:52:40<2855:58:58, 10.44s/it, lr=1e-5, step_loss=0.0513] Steps:   2%|▏         | 15294/1000000 [5:52:50<2783:53:09, 10.18s/it, lr=1e-5, step_loss=0.0513][RANK-0]: Step: [15294], local_loss=0.006808177102357149, train_loss=0.02777996100485325, time_cost=3.46628999710083
Steps:   2%|▏         | 15294/1000000 [5:52:50<2783:53:09, 10.18s/it, lr=1e-5, step_loss=0.00681]Steps:   2%|▏         | 15295/1000000 [5:53:00<2834:29:30, 10.36s/it, lr=1e-5, step_loss=0.00681][RANK-0]: Step: [15295], local_loss=0.013071935623884201, train_loss=0.03950648009777069, time_cost=2.347947597503662
Steps:   2%|▏         | 15295/1000000 [5:53:00<2834:29:30, 10.36s/it, lr=1e-5, step_loss=0.0131] Steps:   2%|▏         | 15296/1000000 [5:53:11<2880:31:02, 10.53s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [15296], local_loss=0.015466425567865372, train_loss=0.010798681527376175, time_cost=3.616881847381592
Steps:   2%|▏         | 15296/1000000 [5:53:11<2880:31:02, 10.53s/it, lr=1e-5, step_loss=0.0155]Steps:   2%|▏         | 15297/1000000 [5:53:22<2909:20:47, 10.64s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [15297], local_loss=0.0679171085357666, train_loss=0.03456979617476463, time_cost=2.0849545001983643
Steps:   2%|▏         | 15297/1000000 [5:53:22<2909:20:47, 10.64s/it, lr=1e-5, step_loss=0.0679]Steps:   2%|▏         | 15298/1000000 [5:53:28<2490:15:08,  9.10s/it, lr=1e-5, step_loss=0.0679][RANK-0]: Step: [15298], local_loss=0.006998933851718903, train_loss=0.1445566564798355, time_cost=1.3097915649414062
Steps:   2%|▏         | 15298/1000000 [5:53:28<2490:15:08,  9.10s/it, lr=1e-5, step_loss=0.007] Steps:   2%|▏         | 15299/1000000 [5:53:36<2415:29:12,  8.83s/it, lr=1e-5, step_loss=0.007][RANK-0]: Step: [15299], local_loss=0.024910226464271545, train_loss=0.043273262679576874, time_cost=1.7948648929595947
Steps:   2%|▏         | 15299/1000000 [5:53:36<2415:29:12,  8.83s/it, lr=1e-5, step_loss=0.0249]Steps:   2%|▏         | 15300/1000000 [5:53:47<2590:26:34,  9.47s/it, lr=1e-5, step_loss=0.0249][RANK-0]: Step: [15300], local_loss=0.027875572443008423, train_loss=0.02272452786564827, time_cost=3.1198272705078125
Steps:   2%|▏         | 15300/1000000 [5:53:47<2590:26:34,  9.47s/it, lr=1e-5, step_loss=0.0279]Steps:   2%|▏         | 15301/1000000 [5:53:53<2328:11:26,  8.51s/it, lr=1e-5, step_loss=0.0279][RANK-0]: Step: [15301], local_loss=0.04183923453092575, train_loss=0.032830625772476196, time_cost=5.305126190185547
Steps:   2%|▏         | 15301/1000000 [5:53:53<2328:11:26,  8.51s/it, lr=1e-5, step_loss=0.0418]Steps:   2%|▏         | 15302/1000000 [5:54:01<2273:21:12,  8.31s/it, lr=1e-5, step_loss=0.0418][RANK-0]: Step: [15302], local_loss=0.014374983496963978, train_loss=0.06333004683256149, time_cost=3.830860137939453
Steps:   2%|▏         | 15302/1000000 [5:54:01<2273:21:12,  8.31s/it, lr=1e-5, step_loss=0.0144]Steps:   2%|▏         | 15303/1000000 [5:54:14<2675:22:30,  9.78s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [15303], local_loss=0.03494882583618164, train_loss=0.044781576842069626, time_cost=1.2746524810791016
Steps:   2%|▏         | 15303/1000000 [5:54:14<2675:22:30,  9.78s/it, lr=1e-5, step_loss=0.0349]Steps:   2%|▏         | 15304/1000000 [5:54:21<2438:16:45,  8.91s/it, lr=1e-5, step_loss=0.0349][RANK-0]: Step: [15304], local_loss=0.010258381254971027, train_loss=0.07487604767084122, time_cost=1.2122905254364014
Steps:   2%|▏         | 15304/1000000 [5:54:21<2438:16:45,  8.91s/it, lr=1e-5, step_loss=0.0103]Steps:   2%|▏         | 15305/1000000 [5:54:26<2082:25:39,  7.61s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [15305], local_loss=0.022896237671375275, train_loss=0.02322724461555481, time_cost=1.6911070346832275
Steps:   2%|▏         | 15305/1000000 [5:54:26<2082:25:39,  7.61s/it, lr=1e-5, step_loss=0.0229]Steps:   2%|▏         | 15306/1000000 [5:54:33<2040:34:04,  7.46s/it, lr=1e-5, step_loss=0.0229][RANK-0]: Step: [15306], local_loss=0.016572726890444756, train_loss=0.032581448554992676, time_cost=2.9643454551696777
Steps:   2%|▏         | 15306/1000000 [5:54:33<2040:34:04,  7.46s/it, lr=1e-5, step_loss=0.0166]Steps:   2%|▏         | 15307/1000000 [5:54:40<2015:25:08,  7.37s/it, lr=1e-5, step_loss=0.0166][RANK-0]: Step: [15307], local_loss=0.028631504625082016, train_loss=0.08092457801103592, time_cost=2.807715892791748
Steps:   2%|▏         | 15307/1000000 [5:54:40<2015:25:08,  7.37s/it, lr=1e-5, step_loss=0.0286]Steps:   2%|▏         | 15308/1000000 [5:54:47<1985:57:23,  7.26s/it, lr=1e-5, step_loss=0.0286][RANK-0]: Step: [15308], local_loss=0.004865780007094145, train_loss=0.08226785063743591, time_cost=5.118542194366455
Steps:   2%|▏         | 15308/1000000 [5:54:47<1985:57:23,  7.26s/it, lr=1e-5, step_loss=0.00487]Steps:   2%|▏         | 15309/1000000 [5:54:58<2288:03:03,  8.37s/it, lr=1e-5, step_loss=0.00487][RANK-0]: Step: [15309], local_loss=0.019838932901620865, train_loss=0.03388840705156326, time_cost=2.32498836517334
Steps:   2%|▏         | 15309/1000000 [5:54:58<2288:03:03,  8.37s/it, lr=1e-5, step_loss=0.0198] Steps:   2%|▏         | 15310/1000000 [5:55:11<2701:30:37,  9.88s/it, lr=1e-5, step_loss=0.0198][RANK-0]: Step: [15310], local_loss=0.007497042417526245, train_loss=0.03645123541355133, time_cost=3.500624895095825
Steps:   2%|▏         | 15310/1000000 [5:55:11<2701:30:37,  9.88s/it, lr=1e-5, step_loss=0.0075]Steps:   2%|▏         | 15311/1000000 [5:55:22<2778:07:17, 10.16s/it, lr=1e-5, step_loss=0.0075][RANK-0]: Step: [15311], local_loss=0.009162215515971184, train_loss=0.04312540218234062, time_cost=3.5191619396209717
Steps:   2%|▏         | 15311/1000000 [5:55:22<2778:07:17, 10.16s/it, lr=1e-5, step_loss=0.00916]Steps:   2%|▏         | 15312/1000000 [5:55:27<2354:01:52,  8.61s/it, lr=1e-5, step_loss=0.00916][RANK-0]: Step: [15312], local_loss=0.006171697285026312, train_loss=0.032483115792274475, time_cost=1.9405462741851807
Steps:   2%|▏         | 15312/1000000 [5:55:27<2354:01:52,  8.61s/it, lr=1e-5, step_loss=0.00617]Steps:   2%|▏         | 15313/1000000 [5:55:33<2116:17:39,  7.74s/it, lr=1e-5, step_loss=0.00617][RANK-0]: Step: [15313], local_loss=0.06980247795581818, train_loss=0.027521474286913872, time_cost=3.0527212619781494
Steps:   2%|▏         | 15313/1000000 [5:55:33<2116:17:39,  7.74s/it, lr=1e-5, step_loss=0.0698] Steps:   2%|▏         | 15314/1000000 [5:55:40<2079:05:50,  7.60s/it, lr=1e-5, step_loss=0.0698][RANK-0]: Step: [15314], local_loss=0.05327258259057999, train_loss=0.06273241341114044, time_cost=2.672556161880493
Steps:   2%|▏         | 15314/1000000 [5:55:40<2079:05:50,  7.60s/it, lr=1e-5, step_loss=0.0533]Steps:   2%|▏         | 15315/1000000 [5:55:50<2269:38:51,  8.30s/it, lr=1e-5, step_loss=0.0533][RANK-0]: Step: [15315], local_loss=0.043576519936323166, train_loss=0.031066522002220154, time_cost=7.563086748123169
Steps:   2%|▏         | 15315/1000000 [5:55:50<2269:38:51,  8.30s/it, lr=1e-5, step_loss=0.0436]Steps:   2%|▏         | 15316/1000000 [5:56:05<2839:43:58, 10.38s/it, lr=1e-5, step_loss=0.0436][RANK-0]: Step: [15316], local_loss=0.02802613191306591, train_loss=0.027050698176026344, time_cost=6.290494680404663
Steps:   2%|▏         | 15316/1000000 [5:56:05<2839:43:58, 10.38s/it, lr=1e-5, step_loss=0.028] Steps:   2%|▏         | 15317/1000000 [5:56:10<2408:50:02,  8.81s/it, lr=1e-5, step_loss=0.028][RANK-0]: Step: [15317], local_loss=0.17624862492084503, train_loss=0.03699300438165665, time_cost=2.0215578079223633
Steps:   2%|▏         | 15317/1000000 [5:56:10<2408:50:02,  8.81s/it, lr=1e-5, step_loss=0.176]Steps:   2%|▏         | 15318/1000000 [5:56:22<2600:31:45,  9.51s/it, lr=1e-5, step_loss=0.176][RANK-0]: Step: [15318], local_loss=0.0077639296650886536, train_loss=0.02087133750319481, time_cost=3.122394561767578
Steps:   2%|▏         | 15318/1000000 [5:56:22<2600:31:45,  9.51s/it, lr=1e-5, step_loss=0.00776]Steps:   2%|▏         | 15319/1000000 [5:56:29<2466:27:21,  9.02s/it, lr=1e-5, step_loss=0.00776][RANK-0]: Step: [15319], local_loss=0.006706406362354755, train_loss=0.03267788514494896, time_cost=4.107684850692749
Steps:   2%|▏         | 15319/1000000 [5:56:29<2466:27:21,  9.02s/it, lr=1e-5, step_loss=0.00671]Steps:   2%|▏         | 15320/1000000 [5:56:43<2860:23:55, 10.46s/it, lr=1e-5, step_loss=0.00671][RANK-0]: Step: [15320], local_loss=0.0065233176574110985, train_loss=0.025553414598107338, time_cost=3.576780080795288
Steps:   2%|▏         | 15320/1000000 [5:56:43<2860:23:55, 10.46s/it, lr=1e-5, step_loss=0.00652]Steps:   2%|▏         | 15321/1000000 [5:56:55<2930:17:56, 10.71s/it, lr=1e-5, step_loss=0.00652][RANK-0]: Step: [15321], local_loss=0.20547644793987274, train_loss=0.04854102432727814, time_cost=2.149524688720703
Steps:   2%|▏         | 15321/1000000 [5:56:55<2930:17:56, 10.71s/it, lr=1e-5, step_loss=0.205]  Steps:   2%|▏         | 15322/1000000 [5:57:03<2702:19:54,  9.88s/it, lr=1e-5, step_loss=0.205][RANK-0]: Step: [15322], local_loss=0.020331542938947678, train_loss=0.03284945338964462, time_cost=1.9798107147216797
Steps:   2%|▏         | 15322/1000000 [5:57:03<2702:19:54,  9.88s/it, lr=1e-5, step_loss=0.0203]Steps:   2%|▏         | 15323/1000000 [5:57:10<2507:14:15,  9.17s/it, lr=1e-5, step_loss=0.0203][RANK-0]: Step: [15323], local_loss=0.06275781989097595, train_loss=0.02149946615099907, time_cost=1.4032089710235596
Steps:   2%|▏         | 15323/1000000 [5:57:10<2507:14:15,  9.17s/it, lr=1e-5, step_loss=0.0628]Steps:   2%|▏         | 15324/1000000 [5:57:20<2555:44:45,  9.34s/it, lr=1e-5, step_loss=0.0628][RANK-0]: Step: [15324], local_loss=0.037505730986595154, train_loss=0.05241885408759117, time_cost=2.058678388595581
Steps:   2%|▏         | 15324/1000000 [5:57:20<2555:44:45,  9.34s/it, lr=1e-5, step_loss=0.0375]Steps:   2%|▏         | 15325/1000000 [5:57:25<2208:13:10,  8.07s/it, lr=1e-5, step_loss=0.0375][RANK-0]: Step: [15325], local_loss=0.10661431401968002, train_loss=0.07080511748790741, time_cost=2.1644041538238525
Steps:   2%|▏         | 15325/1000000 [5:57:25<2208:13:10,  8.07s/it, lr=1e-5, step_loss=0.107] Steps:   2%|▏         | 15326/1000000 [5:57:34<2323:56:06,  8.50s/it, lr=1e-5, step_loss=0.107][RANK-0]: Step: [15326], local_loss=0.007566102780401707, train_loss=0.01996595598757267, time_cost=7.187986135482788
Steps:   2%|▏         | 15326/1000000 [5:57:34<2323:56:06,  8.50s/it, lr=1e-5, step_loss=0.00757]Steps:   2%|▏         | 15327/1000000 [5:57:45<2505:35:41,  9.16s/it, lr=1e-5, step_loss=0.00757][RANK-0]: Step: [15327], local_loss=0.02268272638320923, train_loss=0.028634535148739815, time_cost=3.2768473625183105
Steps:   2%|▏         | 15327/1000000 [5:57:45<2505:35:41,  9.16s/it, lr=1e-5, step_loss=0.0227] Steps:   2%|▏         | 15328/1000000 [5:57:55<2565:08:53,  9.38s/it, lr=1e-5, step_loss=0.0227][RANK-0]: Step: [15328], local_loss=0.022514797747135162, train_loss=0.050334177911281586, time_cost=2.747821092605591
Steps:   2%|▏         | 15328/1000000 [5:57:55<2565:08:53,  9.38s/it, lr=1e-5, step_loss=0.0225]Steps:   2%|▏         | 15329/1000000 [5:57:59<2167:06:03,  7.92s/it, lr=1e-5, step_loss=0.0225][RANK-0]: Step: [15329], local_loss=0.007900478318333626, train_loss=0.02924269251525402, time_cost=1.670705795288086
Steps:   2%|▏         | 15329/1000000 [5:58:00<2167:06:03,  7.92s/it, lr=1e-5, step_loss=0.0079]Steps:   2%|▏         | 15330/1000000 [5:58:11<2428:33:04,  8.88s/it, lr=1e-5, step_loss=0.0079][RANK-0]: Step: [15330], local_loss=0.03592239320278168, train_loss=0.0745973289012909, time_cost=1.8068995475769043
Steps:   2%|▏         | 15330/1000000 [5:58:11<2428:33:04,  8.88s/it, lr=1e-5, step_loss=0.0359]Steps:   2%|▏         | 15331/1000000 [5:58:17<2223:08:37,  8.13s/it, lr=1e-5, step_loss=0.0359][RANK-0]: Step: [15331], local_loss=0.008925136178731918, train_loss=0.02362661063671112, time_cost=1.637796401977539
Steps:   2%|▏         | 15331/1000000 [5:58:17<2223:08:37,  8.13s/it, lr=1e-5, step_loss=0.00893]Steps:   2%|▏         | 15332/1000000 [5:58:30<2611:59:13,  9.55s/it, lr=1e-5, step_loss=0.00893][RANK-0]: Step: [15332], local_loss=0.0066665904596447945, train_loss=0.03430383279919624, time_cost=1.2187395095825195
Steps:   2%|▏         | 15332/1000000 [5:58:30<2611:59:13,  9.55s/it, lr=1e-5, step_loss=0.00667]Steps:   2%|▏         | 15333/1000000 [5:58:35<2254:45:50,  8.24s/it, lr=1e-5, step_loss=0.00667][RANK-0]: Step: [15333], local_loss=0.09720294177532196, train_loss=0.02753867395222187, time_cost=2.402263641357422
Steps:   2%|▏         | 15333/1000000 [5:58:35<2254:45:50,  8.24s/it, lr=1e-5, step_loss=0.0972] Steps:   2%|▏         | 15334/1000000 [5:58:46<2482:09:41,  9.07s/it, lr=1e-5, step_loss=0.0972][RANK-0]: Step: [15334], local_loss=0.016757993027567863, train_loss=0.06692814826965332, time_cost=2.4935340881347656
Steps:   2%|▏         | 15334/1000000 [5:58:46<2482:09:41,  9.07s/it, lr=1e-5, step_loss=0.0168]Steps:   2%|▏         | 15335/1000000 [5:58:51<2144:17:03,  7.84s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [15335], local_loss=0.0134225869551301, train_loss=0.03741401806473732, time_cost=2.2502057552337646
Steps:   2%|▏         | 15335/1000000 [5:58:51<2144:17:03,  7.84s/it, lr=1e-5, step_loss=0.0134]Steps:   2%|▏         | 15336/1000000 [5:58:56<1911:18:59,  6.99s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [15336], local_loss=1.007583737373352, train_loss=0.1586928814649582, time_cost=2.1176598072052
Steps:   2%|▏         | 15336/1000000 [5:58:56<1911:18:59,  6.99s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 15337/1000000 [5:59:01<1772:51:54,  6.48s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [15337], local_loss=0.007759863045066595, train_loss=0.03523707389831543, time_cost=2.5753328800201416
Steps:   2%|▏         | 15337/1000000 [5:59:01<1772:51:54,  6.48s/it, lr=1e-5, step_loss=0.00776]Steps:   2%|▏         | 15338/1000000 [5:59:08<1824:51:26,  6.67s/it, lr=1e-5, step_loss=0.00776][RANK-0]: Step: [15338], local_loss=0.10165981948375702, train_loss=0.055190976709127426, time_cost=1.5700387954711914
Steps:   2%|▏         | 15338/1000000 [5:59:08<1824:51:26,  6.67s/it, lr=1e-5, step_loss=0.102]  Steps:   2%|▏         | 15339/1000000 [5:59:12<1603:11:14,  5.86s/it, lr=1e-5, step_loss=0.102][RANK-0]: Step: [15339], local_loss=0.007225803565233946, train_loss=0.14799028635025024, time_cost=1.2531273365020752
Steps:   2%|▏         | 15339/1000000 [5:59:12<1603:11:14,  5.86s/it, lr=1e-5, step_loss=0.00723]Steps:   2%|▏         | 15340/1000000 [5:59:18<1559:45:31,  5.70s/it, lr=1e-5, step_loss=0.00723][RANK-0]: Step: [15340], local_loss=0.015506362542510033, train_loss=0.036880653351545334, time_cost=2.2565813064575195
Steps:   2%|▏         | 15340/1000000 [5:59:18<1559:45:31,  5.70s/it, lr=1e-5, step_loss=0.0155] Steps:   2%|▏         | 15341/1000000 [5:59:23<1509:57:34,  5.52s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [15341], local_loss=0.016303427517414093, train_loss=0.0383000373840332, time_cost=2.397414445877075
Steps:   2%|▏         | 15341/1000000 [5:59:23<1509:57:34,  5.52s/it, lr=1e-5, step_loss=0.0163]Steps:   2%|▏         | 15342/1000000 [5:59:30<1653:15:15,  6.04s/it, lr=1e-5, step_loss=0.0163][RANK-0]: Step: [15342], local_loss=0.3747469484806061, train_loss=0.17312636971473694, time_cost=2.1726322174072266
Steps:   2%|▏         | 15342/1000000 [5:59:30<1653:15:15,  6.04s/it, lr=1e-5, step_loss=0.375] Steps:   2%|▏         | 15343/1000000 [5:59:39<1846:39:03,  6.75s/it, lr=1e-5, step_loss=0.375][RANK-0]: Step: [15343], local_loss=0.02888224646449089, train_loss=0.05154787749052048, time_cost=1.8067371845245361
Steps:   2%|▏         | 15343/1000000 [5:59:39<1846:39:03,  6.75s/it, lr=1e-5, step_loss=0.0289]Steps:   2%|▏         | 15344/1000000 [5:59:46<1939:23:39,  7.09s/it, lr=1e-5, step_loss=0.0289][RANK-0]: Step: [15344], local_loss=0.026627693325281143, train_loss=0.05083305761218071, time_cost=2.2308082580566406
Steps:   2%|▏         | 15344/1000000 [5:59:46<1939:23:39,  7.09s/it, lr=1e-5, step_loss=0.0266]Steps:   2%|▏         | 15345/1000000 [5:59:55<2051:14:09,  7.50s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [15345], local_loss=0.006618895102292299, train_loss=0.0887676551938057, time_cost=1.548173427581787
Steps:   2%|▏         | 15345/1000000 [5:59:55<2051:14:09,  7.50s/it, lr=1e-5, step_loss=0.00662]Steps:   2%|▏         | 15346/1000000 [6:00:00<1870:11:52,  6.84s/it, lr=1e-5, step_loss=0.00662][RANK-0]: Step: [15346], local_loss=0.14986717700958252, train_loss=0.03926472365856171, time_cost=3.938518762588501
Steps:   2%|▏         | 15346/1000000 [6:00:00<1870:11:52,  6.84s/it, lr=1e-5, step_loss=0.15]   Steps:   2%|▏         | 15347/1000000 [6:00:13<2375:14:46,  8.68s/it, lr=1e-5, step_loss=0.15][RANK-0]: Step: [15347], local_loss=0.04867292195558548, train_loss=0.09801970422267914, time_cost=6.227625608444214
Steps:   2%|▏         | 15347/1000000 [6:00:13<2375:14:46,  8.68s/it, lr=1e-5, step_loss=0.0487]Steps:   2%|▏         | 15348/1000000 [6:00:28<2895:17:07, 10.59s/it, lr=1e-5, step_loss=0.0487][RANK-0]: Step: [15348], local_loss=0.005874682683497667, train_loss=0.029323313385248184, time_cost=6.565134763717651
Steps:   2%|▏         | 15348/1000000 [6:00:28<2895:17:07, 10.59s/it, lr=1e-5, step_loss=0.00587]Steps:   2%|▏         | 15349/1000000 [6:00:36<2703:49:38,  9.89s/it, lr=1e-5, step_loss=0.00587][RANK-0]: Step: [15349], local_loss=0.01800122670829296, train_loss=0.016642028465867043, time_cost=4.0723161697387695
Steps:   2%|▏         | 15349/1000000 [6:00:36<2703:49:38,  9.89s/it, lr=1e-5, step_loss=0.018]  Steps:   2%|▏         | 15350/1000000 [6:00:44<2535:59:17,  9.27s/it, lr=1e-5, step_loss=0.018][RANK-0]: Step: [15350], local_loss=0.01892593689262867, train_loss=0.04169450327754021, time_cost=2.1222753524780273
Steps:   2%|▏         | 15350/1000000 [6:00:44<2535:59:17,  9.27s/it, lr=1e-5, step_loss=0.0189]Steps:   2%|▏         | 15351/1000000 [6:00:58<2923:50:27, 10.69s/it, lr=1e-5, step_loss=0.0189][RANK-0]: Step: [15351], local_loss=0.005980941001325846, train_loss=0.016890617087483406, time_cost=2.311673402786255
Steps:   2%|▏         | 15351/1000000 [6:00:58<2923:50:27, 10.69s/it, lr=1e-5, step_loss=0.00598]Steps:   2%|▏         | 15352/1000000 [6:01:06<2658:09:25,  9.72s/it, lr=1e-5, step_loss=0.00598][RANK-0]: Step: [15352], local_loss=0.013644261285662651, train_loss=0.014370989054441452, time_cost=1.731142282485962
Steps:   2%|▏         | 15352/1000000 [6:01:06<2658:09:25,  9.72s/it, lr=1e-5, step_loss=0.0136] Steps:   2%|▏         | 15353/1000000 [6:01:15<2659:45:37,  9.72s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [15353], local_loss=0.04078077897429466, train_loss=0.027502262964844704, time_cost=2.2491443157196045
Steps:   2%|▏         | 15353/1000000 [6:01:15<2659:45:37,  9.72s/it, lr=1e-5, step_loss=0.0408]Steps:   2%|▏         | 15354/1000000 [6:01:27<2806:08:51, 10.26s/it, lr=1e-5, step_loss=0.0408][RANK-0]: Step: [15354], local_loss=0.006603680085390806, train_loss=0.08955684304237366, time_cost=3.14658784866333
Steps:   2%|▏         | 15354/1000000 [6:01:27<2806:08:51, 10.26s/it, lr=1e-5, step_loss=0.0066]Steps:   2%|▏         | 15355/1000000 [6:01:39<2983:52:31, 10.91s/it, lr=1e-5, step_loss=0.0066][RANK-0]: Step: [15355], local_loss=0.06535708159208298, train_loss=0.062489449977874756, time_cost=1.2290501594543457
Steps:   2%|▏         | 15355/1000000 [6:01:39<2983:52:31, 10.91s/it, lr=1e-5, step_loss=0.0654]Steps:   2%|▏         | 15356/1000000 [6:01:51<3023:45:08, 11.06s/it, lr=1e-5, step_loss=0.0654][RANK-0]: Step: [15356], local_loss=0.006660084705799818, train_loss=0.02250530943274498, time_cost=3.2721569538116455
Steps:   2%|▏         | 15356/1000000 [6:01:51<3023:45:08, 11.06s/it, lr=1e-5, step_loss=0.00666]Steps:   2%|▏         | 15357/1000000 [6:02:01<2962:26:54, 10.83s/it, lr=1e-5, step_loss=0.00666][RANK-0]: Step: [15357], local_loss=0.023670397698879242, train_loss=0.05643535032868385, time_cost=3.679784059524536
Steps:   2%|▏         | 15357/1000000 [6:02:01<2962:26:54, 10.83s/it, lr=1e-5, step_loss=0.0237] Steps:   2%|▏         | 15358/1000000 [6:02:08<2632:32:09,  9.62s/it, lr=1e-5, step_loss=0.0237][RANK-0]: Step: [15358], local_loss=0.017329096794128418, train_loss=0.030552811920642853, time_cost=2.2889277935028076
Steps:   2%|▏         | 15358/1000000 [6:02:08<2632:32:09,  9.62s/it, lr=1e-5, step_loss=0.0173]Steps:   2%|▏         | 15359/1000000 [6:02:13<2228:13:01,  8.15s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [15359], local_loss=0.3473156988620758, train_loss=0.05721244588494301, time_cost=1.202042579650879
Steps:   2%|▏         | 15359/1000000 [6:02:13<2228:13:01,  8.15s/it, lr=1e-5, step_loss=0.347] Steps:   2%|▏         | 15360/1000000 [6:02:27<2779:58:39, 10.16s/it, lr=1e-5, step_loss=0.347][RANK-0]: Step: [15360], local_loss=0.18880674242973328, train_loss=0.0527617409825325, time_cost=12.216607570648193
Steps:   2%|▏         | 15360/1000000 [6:02:27<2779:58:39, 10.16s/it, lr=1e-5, step_loss=0.189]Steps:   2%|▏         | 15361/1000000 [6:02:39<2889:13:27, 10.56s/it, lr=1e-5, step_loss=0.189][RANK-0]: Step: [15361], local_loss=0.07926899194717407, train_loss=0.2733009457588196, time_cost=2.1668879985809326
Steps:   2%|▏         | 15361/1000000 [6:02:39<2889:13:27, 10.56s/it, lr=1e-5, step_loss=0.0793]Steps:   2%|▏         | 15362/1000000 [6:02:44<2442:38:26,  8.93s/it, lr=1e-5, step_loss=0.0793][RANK-0]: Step: [15362], local_loss=0.032942455261945724, train_loss=0.015250583179295063, time_cost=1.4663677215576172
Steps:   2%|▏         | 15362/1000000 [6:02:44<2442:38:26,  8.93s/it, lr=1e-5, step_loss=0.0329]Steps:   2%|▏         | 15363/1000000 [6:02:50<2156:50:22,  7.89s/it, lr=1e-5, step_loss=0.0329][RANK-0]: Step: [15363], local_loss=0.02366836555302143, train_loss=0.05154913291335106, time_cost=4.4742138385772705
Steps:   2%|▏         | 15363/1000000 [6:02:50<2156:50:22,  7.89s/it, lr=1e-5, step_loss=0.0237]Steps:   2%|▏         | 15364/1000000 [6:02:55<1957:14:48,  7.16s/it, lr=1e-5, step_loss=0.0237][RANK-0]: Step: [15364], local_loss=0.02898603491485119, train_loss=0.04106402024626732, time_cost=1.2107112407684326
Steps:   2%|▏         | 15364/1000000 [6:02:55<1957:14:48,  7.16s/it, lr=1e-5, step_loss=0.029] Steps:   2%|▏         | 15365/1000000 [6:03:02<1928:33:14,  7.05s/it, lr=1e-5, step_loss=0.029][RANK-0]: Step: [15365], local_loss=0.03793603181838989, train_loss=0.04280867055058479, time_cost=2.738152027130127
Steps:   2%|▏         | 15365/1000000 [6:03:02<1928:33:14,  7.05s/it, lr=1e-5, step_loss=0.0379]Steps:   2%|▏         | 15366/1000000 [6:03:10<2022:19:39,  7.39s/it, lr=1e-5, step_loss=0.0379][RANK-0]: Step: [15366], local_loss=0.007800155319273472, train_loss=0.008297382853925228, time_cost=4.260461091995239
Steps:   2%|▏         | 15366/1000000 [6:03:10<2022:19:39,  7.39s/it, lr=1e-5, step_loss=0.0078]Steps:   2%|▏         | 15367/1000000 [6:03:23<2456:59:13,  8.98s/it, lr=1e-5, step_loss=0.0078][RANK-0]: Step: [15367], local_loss=0.029490027576684952, train_loss=0.07020189613103867, time_cost=8.774460554122925
Steps:   2%|▏         | 15367/1000000 [6:03:23<2456:59:13,  8.98s/it, lr=1e-5, step_loss=0.0295]Steps:   2%|▏         | 15368/1000000 [6:03:28<2144:07:00,  7.84s/it, lr=1e-5, step_loss=0.0295][RANK-0]: Step: [15368], local_loss=0.08112932741641998, train_loss=0.022770943120121956, time_cost=3.949554443359375
Steps:   2%|▏         | 15368/1000000 [6:03:28<2144:07:00,  7.84s/it, lr=1e-5, step_loss=0.0811]Steps:   2%|▏         | 15369/1000000 [6:03:37<2284:57:03,  8.35s/it, lr=1e-5, step_loss=0.0811][RANK-0]: Step: [15369], local_loss=0.004068078938871622, train_loss=0.027957860380411148, time_cost=4.08077597618103
Steps:   2%|▏         | 15369/1000000 [6:03:37<2284:57:03,  8.35s/it, lr=1e-5, step_loss=0.00407]Steps:   2%|▏         | 15370/1000000 [6:03:52<2759:48:23, 10.09s/it, lr=1e-5, step_loss=0.00407][RANK-0]: Step: [15370], local_loss=0.004133397247642279, train_loss=0.02897701784968376, time_cost=1.2078688144683838
Steps:   2%|▏         | 15370/1000000 [6:03:52<2759:48:23, 10.09s/it, lr=1e-5, step_loss=0.00413]Steps:   2%|▏         | 15371/1000000 [6:04:06<3098:42:41, 11.33s/it, lr=1e-5, step_loss=0.00413][RANK-0]: Step: [15371], local_loss=0.005955557804554701, train_loss=0.06901869922876358, time_cost=4.617151975631714
Steps:   2%|▏         | 15371/1000000 [6:04:06<3098:42:41, 11.33s/it, lr=1e-5, step_loss=0.00596]Steps:   2%|▏         | 15372/1000000 [6:04:14<2883:56:44, 10.54s/it, lr=1e-5, step_loss=0.00596][RANK-0]: Step: [15372], local_loss=0.11338287591934204, train_loss=0.07487842440605164, time_cost=2.4157590866088867
Steps:   2%|▏         | 15372/1000000 [6:04:14<2883:56:44, 10.54s/it, lr=1e-5, step_loss=0.113]  Steps:   2%|▏         | 15373/1000000 [6:04:25<2867:03:09, 10.48s/it, lr=1e-5, step_loss=0.113][RANK-0]: Step: [15373], local_loss=0.2297166883945465, train_loss=0.20886367559432983, time_cost=1.840717077255249
Steps:   2%|▏         | 15373/1000000 [6:04:25<2867:03:09, 10.48s/it, lr=1e-5, step_loss=0.23] Steps:   2%|▏         | 15374/1000000 [6:04:41<3296:59:52, 12.05s/it, lr=1e-5, step_loss=0.23][RANK-0]: Step: [15374], local_loss=0.014468410983681679, train_loss=0.040264278650283813, time_cost=7.884730339050293
Steps:   2%|▏         | 15374/1000000 [6:04:41<3296:59:52, 12.05s/it, lr=1e-5, step_loss=0.0145]Steps:   2%|▏         | 15375/1000000 [6:04:48<2888:43:47, 10.56s/it, lr=1e-5, step_loss=0.0145][RANK-0]: Step: [15375], local_loss=0.008216891437768936, train_loss=0.03119882568717003, time_cost=3.0510833263397217
Steps:   2%|▏         | 15375/1000000 [6:04:48<2888:43:47, 10.56s/it, lr=1e-5, step_loss=0.00822]Steps:   2%|▏         | 15376/1000000 [6:04:56<2688:06:10,  9.83s/it, lr=1e-5, step_loss=0.00822][RANK-0]: Step: [15376], local_loss=0.034808605909347534, train_loss=0.04187189042568207, time_cost=4.023817300796509
Steps:   2%|▏         | 15376/1000000 [6:04:56<2688:06:10,  9.83s/it, lr=1e-5, step_loss=0.0348] Steps:   2%|▏         | 15377/1000000 [6:05:06<2757:57:05, 10.08s/it, lr=1e-5, step_loss=0.0348][RANK-0]: Step: [15377], local_loss=0.015599841251969337, train_loss=0.08956543356180191, time_cost=6.10006308555603
Steps:   2%|▏         | 15377/1000000 [6:05:06<2757:57:05, 10.08s/it, lr=1e-5, step_loss=0.0156]Steps:   2%|▏         | 15378/1000000 [6:05:11<2296:45:58,  8.40s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [15378], local_loss=0.06051506847143173, train_loss=0.030460745096206665, time_cost=1.7951459884643555
Steps:   2%|▏         | 15378/1000000 [6:05:11<2296:45:58,  8.40s/it, lr=1e-5, step_loss=0.0605]Steps:   2%|▏         | 15379/1000000 [6:05:18<2201:32:13,  8.05s/it, lr=1e-5, step_loss=0.0605][RANK-0]: Step: [15379], local_loss=0.012635868042707443, train_loss=0.10128074884414673, time_cost=1.5898215770721436
Steps:   2%|▏         | 15379/1000000 [6:05:18<2201:32:13,  8.05s/it, lr=1e-5, step_loss=0.0126]Steps:   2%|▏         | 15380/1000000 [6:05:31<2572:59:53,  9.41s/it, lr=1e-5, step_loss=0.0126][RANK-0]: Step: [15380], local_loss=0.02728569321334362, train_loss=0.03320920467376709, time_cost=9.925436973571777
Steps:   2%|▏         | 15380/1000000 [6:05:31<2572:59:53,  9.41s/it, lr=1e-5, step_loss=0.0273]Steps:   2%|▏         | 15381/1000000 [6:05:42<2760:20:40, 10.09s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [15381], local_loss=0.008543135598301888, train_loss=0.0782843679189682, time_cost=3.2512972354888916
Steps:   2%|▏         | 15381/1000000 [6:05:42<2760:20:40, 10.09s/it, lr=1e-5, step_loss=0.00854]Steps:   2%|▏         | 15382/1000000 [6:05:48<2407:11:39,  8.80s/it, lr=1e-5, step_loss=0.00854][RANK-0]: Step: [15382], local_loss=0.06440635025501251, train_loss=0.04746086522936821, time_cost=2.140378713607788
Steps:   2%|▏         | 15382/1000000 [6:05:48<2407:11:39,  8.80s/it, lr=1e-5, step_loss=0.0644] Steps:   2%|▏         | 15383/1000000 [6:06:03<2888:30:33, 10.56s/it, lr=1e-5, step_loss=0.0644][RANK-0]: Step: [15383], local_loss=0.07944847643375397, train_loss=0.03140789270401001, time_cost=5.539035797119141
Steps:   2%|▏         | 15383/1000000 [6:06:03<2888:30:33, 10.56s/it, lr=1e-5, step_loss=0.0794]Steps:   2%|▏         | 15384/1000000 [6:06:16<3076:28:01, 11.25s/it, lr=1e-5, step_loss=0.0794][RANK-0]: Step: [15384], local_loss=0.005488375201821327, train_loss=0.034705374389886856, time_cost=1.3187880516052246
Steps:   2%|▏         | 15384/1000000 [6:06:16<3076:28:01, 11.25s/it, lr=1e-5, step_loss=0.00549]Steps:   2%|▏         | 15385/1000000 [6:06:26<3041:41:47, 11.12s/it, lr=1e-5, step_loss=0.00549][RANK-0]: Step: [15385], local_loss=0.008465725928544998, train_loss=0.02092086151242256, time_cost=2.456535816192627
Steps:   2%|▏         | 15385/1000000 [6:06:26<3041:41:47, 11.12s/it, lr=1e-5, step_loss=0.00847]Steps:   2%|▏         | 15386/1000000 [6:06:42<3361:34:37, 12.29s/it, lr=1e-5, step_loss=0.00847][RANK-0]: Step: [15386], local_loss=0.18465809524059296, train_loss=0.03822905570268631, time_cost=6.816226243972778
Steps:   2%|▏         | 15386/1000000 [6:06:42<3361:34:37, 12.29s/it, lr=1e-5, step_loss=0.185]  Steps:   2%|▏         | 15387/1000000 [6:06:49<2997:13:58, 10.96s/it, lr=1e-5, step_loss=0.185][RANK-0]: Step: [15387], local_loss=0.03299271687865257, train_loss=0.0639929473400116, time_cost=4.224502086639404
Steps:   2%|▏         | 15387/1000000 [6:06:49<2997:13:58, 10.96s/it, lr=1e-5, step_loss=0.033]Steps:   2%|▏         | 15388/1000000 [6:06:54<2514:02:12,  9.19s/it, lr=1e-5, step_loss=0.033][RANK-0]: Step: [15388], local_loss=0.027995619922876358, train_loss=0.045120637863874435, time_cost=1.2710793018341064
Steps:   2%|▏         | 15388/1000000 [6:06:54<2514:02:12,  9.19s/it, lr=1e-5, step_loss=0.028]Steps:   2%|▏         | 15389/1000000 [6:07:08<2870:26:49, 10.50s/it, lr=1e-5, step_loss=0.028][RANK-0]: Step: [15389], local_loss=0.006096224300563335, train_loss=0.02148425579071045, time_cost=4.675643682479858
Steps:   2%|▏         | 15389/1000000 [6:07:08<2870:26:49, 10.50s/it, lr=1e-5, step_loss=0.0061]Steps:   2%|▏         | 15390/1000000 [6:07:16<2680:21:24,  9.80s/it, lr=1e-5, step_loss=0.0061][RANK-0]: Step: [15390], local_loss=0.01328877080231905, train_loss=0.03334719315171242, time_cost=1.9811384677886963
Steps:   2%|▏         | 15390/1000000 [6:07:16<2680:21:24,  9.80s/it, lr=1e-5, step_loss=0.0133]Steps:   2%|▏         | 15391/1000000 [6:07:21<2240:17:06,  8.19s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [15391], local_loss=0.32350611686706543, train_loss=0.10504139214754105, time_cost=1.4416980743408203
Steps:   2%|▏         | 15391/1000000 [6:07:21<2240:17:06,  8.19s/it, lr=1e-5, step_loss=0.324] Steps:   2%|▏         | 15392/1000000 [6:07:25<1906:12:56,  6.97s/it, lr=1e-5, step_loss=0.324][RANK-0]: Step: [15392], local_loss=0.011769539676606655, train_loss=0.10615746676921844, time_cost=1.418086290359497
Steps:   2%|▏         | 15392/1000000 [6:07:25<1906:12:56,  6.97s/it, lr=1e-5, step_loss=0.0118]Steps:   2%|▏         | 15393/1000000 [6:07:31<1858:56:39,  6.80s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [15393], local_loss=0.009975623339414597, train_loss=0.025801993906497955, time_cost=3.1838724613189697
Steps:   2%|▏         | 15393/1000000 [6:07:31<1858:56:39,  6.80s/it, lr=1e-5, step_loss=0.00998]Steps:   2%|▏         | 15394/1000000 [6:07:36<1727:10:47,  6.32s/it, lr=1e-5, step_loss=0.00998][RANK-0]: Step: [15394], local_loss=0.01183555368334055, train_loss=0.056968994438648224, time_cost=2.0995659828186035
Steps:   2%|▏         | 15394/1000000 [6:07:36<1727:10:47,  6.32s/it, lr=1e-5, step_loss=0.0118] Steps:   2%|▏         | 15395/1000000 [6:07:48<2166:39:32,  7.92s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [15395], local_loss=0.006827587261795998, train_loss=0.037782393395900726, time_cost=2.993751287460327
Steps:   2%|▏         | 15395/1000000 [6:07:48<2166:39:32,  7.92s/it, lr=1e-5, step_loss=0.00683]Steps:   2%|▏         | 15396/1000000 [6:07:54<2043:49:25,  7.47s/it, lr=1e-5, step_loss=0.00683][RANK-0]: Step: [15396], local_loss=0.03995582461357117, train_loss=0.03754299506545067, time_cost=1.3580293655395508
Steps:   2%|▏         | 15396/1000000 [6:07:54<2043:49:25,  7.47s/it, lr=1e-5, step_loss=0.04]   Steps:   2%|▏         | 15397/1000000 [6:08:07<2472:43:24,  9.04s/it, lr=1e-5, step_loss=0.04][RANK-0]: Step: [15397], local_loss=0.12811584770679474, train_loss=0.050047390162944794, time_cost=3.8259971141815186
Steps:   2%|▏         | 15397/1000000 [6:08:07<2472:43:24,  9.04s/it, lr=1e-5, step_loss=0.128]Steps:   2%|▏         | 15398/1000000 [6:08:18<2637:30:37,  9.64s/it, lr=1e-5, step_loss=0.128][RANK-0]: Step: [15398], local_loss=0.007998691871762276, train_loss=0.017067674547433853, time_cost=3.3645546436309814
Steps:   2%|▏         | 15398/1000000 [6:08:18<2637:30:37,  9.64s/it, lr=1e-5, step_loss=0.008]Steps:   2%|▏         | 15399/1000000 [6:08:23<2238:09:05,  8.18s/it, lr=1e-5, step_loss=0.008][RANK-0]: Step: [15399], local_loss=0.038419753313064575, train_loss=0.16052505373954773, time_cost=2.1308095455169678
Steps:   2%|▏         | 15399/1000000 [6:08:23<2238:09:05,  8.18s/it, lr=1e-5, step_loss=0.0384]Steps:   2%|▏         | 15400/1000000 [6:08:34<2508:48:09,  9.17s/it, lr=1e-5, step_loss=0.0384][RANK-0]: Step: [15400], local_loss=0.06452090293169022, train_loss=0.04277585446834564, time_cost=3.6860666275024414
Steps:   2%|▏         | 15400/1000000 [6:08:34<2508:48:09,  9.17s/it, lr=1e-5, step_loss=0.0645]Steps:   2%|▏         | 15401/1000000 [6:08:45<2650:47:04,  9.69s/it, lr=1e-5, step_loss=0.0645][RANK-0]: Step: [15401], local_loss=0.06868335604667664, train_loss=0.04589126259088516, time_cost=2.3275763988494873
Steps:   2%|▏         | 15401/1000000 [6:08:45<2650:47:04,  9.69s/it, lr=1e-5, step_loss=0.0687]Steps:   2%|▏         | 15402/1000000 [6:08:56<2774:44:12, 10.15s/it, lr=1e-5, step_loss=0.0687][RANK-0]: Step: [15402], local_loss=0.011168798431754112, train_loss=0.015866965055465698, time_cost=1.5331497192382812
Steps:   2%|▏         | 15402/1000000 [6:08:56<2774:44:12, 10.15s/it, lr=1e-5, step_loss=0.0112]Steps:   2%|▏         | 15403/1000000 [6:09:05<2661:33:31,  9.73s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [15403], local_loss=0.008163239806890488, train_loss=0.04378591105341911, time_cost=1.7839305400848389
Steps:   2%|▏         | 15403/1000000 [6:09:05<2661:33:31,  9.73s/it, lr=1e-5, step_loss=0.00816]Steps:   2%|▏         | 15404/1000000 [6:09:11<2297:01:59,  8.40s/it, lr=1e-5, step_loss=0.00816][RANK-0]: Step: [15404], local_loss=0.00953880324959755, train_loss=0.08067066222429276, time_cost=1.219651699066162
Steps:   2%|▏         | 15404/1000000 [6:09:11<2297:01:59,  8.40s/it, lr=1e-5, step_loss=0.00954]Steps:   2%|▏         | 15405/1000000 [6:09:22<2509:33:41,  9.18s/it, lr=1e-5, step_loss=0.00954][RANK-0]: Step: [15405], local_loss=0.012782727368175983, train_loss=0.02782408706843853, time_cost=2.076134204864502
Steps:   2%|▏         | 15405/1000000 [6:09:22<2509:33:41,  9.18s/it, lr=1e-5, step_loss=0.0128] Steps:   2%|▏         | 15406/1000000 [6:09:27<2242:11:28,  8.20s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [15406], local_loss=0.029619360342621803, train_loss=0.02243785373866558, time_cost=1.418522596359253
Steps:   2%|▏         | 15406/1000000 [6:09:27<2242:11:28,  8.20s/it, lr=1e-5, step_loss=0.0296]Steps:   2%|▏         | 15407/1000000 [6:09:36<2289:12:55,  8.37s/it, lr=1e-5, step_loss=0.0296][RANK-0]: Step: [15407], local_loss=0.022591959685087204, train_loss=0.031302206218242645, time_cost=1.626418113708496
Steps:   2%|▏         | 15407/1000000 [6:09:36<2289:12:55,  8.37s/it, lr=1e-5, step_loss=0.0226]Steps:   2%|▏         | 15408/1000000 [6:09:45<2339:22:39,  8.55s/it, lr=1e-5, step_loss=0.0226][RANK-0]: Step: [15408], local_loss=0.08613349497318268, train_loss=0.04722357168793678, time_cost=3.465481758117676
Steps:   2%|▏         | 15408/1000000 [6:09:45<2339:22:39,  8.55s/it, lr=1e-5, step_loss=0.0861]Steps:   2%|▏         | 15409/1000000 [6:09:59<2730:21:07,  9.98s/it, lr=1e-5, step_loss=0.0861][RANK-0]: Step: [15409], local_loss=0.011445960029959679, train_loss=0.06595878303050995, time_cost=5.304501533508301
Steps:   2%|▏         | 15409/1000000 [6:09:59<2730:21:07,  9.98s/it, lr=1e-5, step_loss=0.0114]Steps:   2%|▏         | 15410/1000000 [6:10:08<2682:36:16,  9.81s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [15410], local_loss=0.09799790382385254, train_loss=0.031608883291482925, time_cost=7.6684019565582275
Steps:   2%|▏         | 15410/1000000 [6:10:08<2682:36:16,  9.81s/it, lr=1e-5, step_loss=0.098] Steps:   2%|▏         | 15411/1000000 [6:10:16<2519:21:43,  9.21s/it, lr=1e-5, step_loss=0.098][RANK-0]: Step: [15411], local_loss=0.03569041192531586, train_loss=7.235696792602539, time_cost=2.390746831893921
Steps:   2%|▏         | 15411/1000000 [6:10:16<2519:21:43,  9.21s/it, lr=1e-5, step_loss=0.0357]Steps:   2%|▏         | 15412/1000000 [6:10:27<2651:47:38,  9.70s/it, lr=1e-5, step_loss=0.0357][RANK-0]: Step: [15412], local_loss=0.034973613917827606, train_loss=0.07626593112945557, time_cost=2.9497227668762207
Steps:   2%|▏         | 15412/1000000 [6:10:27<2651:47:38,  9.70s/it, lr=1e-5, step_loss=0.035] Steps:   2%|▏         | 15413/1000000 [6:10:32<2291:14:28,  8.38s/it, lr=1e-5, step_loss=0.035][RANK-0]: Step: [15413], local_loss=0.006664518266916275, train_loss=0.028475197032094002, time_cost=4.346542596817017
Steps:   2%|▏         | 15413/1000000 [6:10:32<2291:14:28,  8.38s/it, lr=1e-5, step_loss=0.00666]Steps:   2%|▏         | 15414/1000000 [6:10:41<2332:09:31,  8.53s/it, lr=1e-5, step_loss=0.00666][RANK-0]: Step: [15414], local_loss=0.00917966291308403, train_loss=0.08995247632265091, time_cost=3.463715076446533
Steps:   2%|▏         | 15414/1000000 [6:10:41<2332:09:31,  8.53s/it, lr=1e-5, step_loss=0.00918]Steps:   2%|▏         | 15415/1000000 [6:10:48<2202:40:33,  8.05s/it, lr=1e-5, step_loss=0.00918][RANK-0]: Step: [15415], local_loss=0.39894571900367737, train_loss=0.09051196277141571, time_cost=2.6606431007385254
Steps:   2%|▏         | 15415/1000000 [6:10:48<2202:40:33,  8.05s/it, lr=1e-5, step_loss=0.399]  Steps:   2%|▏         | 15416/1000000 [6:10:57<2286:35:49,  8.36s/it, lr=1e-5, step_loss=0.399][RANK-0]: Step: [15416], local_loss=0.008062501437962055, train_loss=0.05039368197321892, time_cost=1.8264427185058594
Steps:   2%|▏         | 15416/1000000 [6:10:57<2286:35:49,  8.36s/it, lr=1e-5, step_loss=0.00806]Steps:   2%|▏         | 15417/1000000 [6:11:05<2262:55:49,  8.27s/it, lr=1e-5, step_loss=0.00806][RANK-0]: Step: [15417], local_loss=0.009042947553098202, train_loss=0.02332943305373192, time_cost=3.956538438796997
Steps:   2%|▏         | 15417/1000000 [6:11:05<2262:55:49,  8.27s/it, lr=1e-5, step_loss=0.00904]Steps:   2%|▏         | 15418/1000000 [6:11:09<1948:01:59,  7.12s/it, lr=1e-5, step_loss=0.00904][RANK-0]: Step: [15418], local_loss=0.008659208193421364, train_loss=0.07319846749305725, time_cost=1.6869583129882812
Steps:   2%|▏         | 15418/1000000 [6:11:09<1948:01:59,  7.12s/it, lr=1e-5, step_loss=0.00866]Steps:   2%|▏         | 15419/1000000 [6:11:21<2336:53:57,  8.54s/it, lr=1e-5, step_loss=0.00866][RANK-0]: Step: [15419], local_loss=0.005448296200484037, train_loss=0.13026535511016846, time_cost=2.6118457317352295
Steps:   2%|▏         | 15419/1000000 [6:11:21<2336:53:57,  8.54s/it, lr=1e-5, step_loss=0.00545]Steps:   2%|▏         | 15420/1000000 [6:11:32<2488:59:08,  9.10s/it, lr=1e-5, step_loss=0.00545][RANK-0]: Step: [15420], local_loss=0.006730465684086084, train_loss=0.05949544906616211, time_cost=2.8145432472229004
Steps:   2%|▏         | 15420/1000000 [6:11:32<2488:59:08,  9.10s/it, lr=1e-5, step_loss=0.00673]Steps:   2%|▏         | 15421/1000000 [6:11:37<2161:25:35,  7.90s/it, lr=1e-5, step_loss=0.00673][RANK-0]: Step: [15421], local_loss=0.014735857024788857, train_loss=17.016490936279297, time_cost=2.17887282371521
Steps:   2%|▏         | 15421/1000000 [6:11:37<2161:25:35,  7.90s/it, lr=1e-5, step_loss=0.0147] Steps:   2%|▏         | 15422/1000000 [6:11:43<2014:26:53,  7.37s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [15422], local_loss=0.00998026505112648, train_loss=0.051308102905750275, time_cost=1.6066405773162842
Steps:   2%|▏         | 15422/1000000 [6:11:43<2014:26:53,  7.37s/it, lr=1e-5, step_loss=0.00998]Steps:   2%|▏         | 15423/1000000 [6:11:48<1819:23:15,  6.65s/it, lr=1e-5, step_loss=0.00998][RANK-0]: Step: [15423], local_loss=0.027344606816768646, train_loss=0.11157765239477158, time_cost=3.7598934173583984
Steps:   2%|▏         | 15423/1000000 [6:11:48<1819:23:15,  6.65s/it, lr=1e-5, step_loss=0.0273] Steps:   2%|▏         | 15424/1000000 [6:12:01<2364:14:54,  8.64s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [15424], local_loss=0.05115176737308502, train_loss=0.03149435669183731, time_cost=3.7409729957580566
Steps:   2%|▏         | 15424/1000000 [6:12:01<2364:14:54,  8.64s/it, lr=1e-5, step_loss=0.0512]Steps:   2%|▏         | 15425/1000000 [6:12:12<2513:12:17,  9.19s/it, lr=1e-5, step_loss=0.0512][RANK-0]: Step: [15425], local_loss=0.02007816731929779, train_loss=0.025338999927043915, time_cost=1.2107110023498535
Steps:   2%|▏         | 15425/1000000 [6:12:12<2513:12:17,  9.19s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 15426/1000000 [6:12:25<2858:38:47, 10.45s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [15426], local_loss=0.009956619702279568, train_loss=0.04429159313440323, time_cost=2.0943334102630615
Steps:   2%|▏         | 15426/1000000 [6:12:25<2858:38:47, 10.45s/it, lr=1e-5, step_loss=0.00996]Steps:   2%|▏         | 15427/1000000 [6:12:30<2386:25:28,  8.73s/it, lr=1e-5, step_loss=0.00996][RANK-0]: Step: [15427], local_loss=0.052175793796777725, train_loss=0.06015225872397423, time_cost=2.2903456687927246
Steps:   2%|▏         | 15427/1000000 [6:12:30<2386:25:28,  8.73s/it, lr=1e-5, step_loss=0.0522] Steps:   2%|▏         | 15428/1000000 [6:12:35<2150:09:30,  7.86s/it, lr=1e-5, step_loss=0.0522][RANK-0]: Step: [15428], local_loss=0.039505477994680405, train_loss=0.07308728992938995, time_cost=2.062282085418701
Steps:   2%|▏         | 15428/1000000 [6:12:35<2150:09:30,  7.86s/it, lr=1e-5, step_loss=0.0395]Steps:   2%|▏         | 15429/1000000 [6:12:47<2445:53:09,  8.94s/it, lr=1e-5, step_loss=0.0395][RANK-0]: Step: [15429], local_loss=0.04549175128340721, train_loss=0.0692068412899971, time_cost=4.094973802566528
Steps:   2%|▏         | 15429/1000000 [6:12:47<2445:53:09,  8.94s/it, lr=1e-5, step_loss=0.0455]Steps:   2%|▏         | 15430/1000000 [6:12:53<2208:11:40,  8.07s/it, lr=1e-5, step_loss=0.0455][RANK-0]: Step: [15430], local_loss=0.03390884771943092, train_loss=0.09451399743556976, time_cost=3.3233587741851807
Steps:   2%|▏         | 15430/1000000 [6:12:53<2208:11:40,  8.07s/it, lr=1e-5, step_loss=0.0339]Steps:   2%|▏         | 15431/1000000 [6:13:04<2430:30:40,  8.89s/it, lr=1e-5, step_loss=0.0339][RANK-0]: Step: [15431], local_loss=0.008732249960303307, train_loss=0.14232520759105682, time_cost=3.1249783039093018
Steps:   2%|▏         | 15431/1000000 [6:13:04<2430:30:40,  8.89s/it, lr=1e-5, step_loss=0.00873]Steps:   2%|▏         | 15432/1000000 [6:13:11<2311:30:57,  8.45s/it, lr=1e-5, step_loss=0.00873][RANK-0]: Step: [15432], local_loss=0.005795891396701336, train_loss=7.7607316970825195, time_cost=3.5733835697174072
Steps:   2%|▏         | 15432/1000000 [6:13:11<2311:30:57,  8.45s/it, lr=1e-5, step_loss=0.0058] Steps:   2%|▏         | 15433/1000000 [6:13:17<2103:50:54,  7.69s/it, lr=1e-5, step_loss=0.0058][RANK-0]: Step: [15433], local_loss=0.008812028914690018, train_loss=0.022258203476667404, time_cost=4.815153121948242
Steps:   2%|▏         | 15433/1000000 [6:13:17<2103:50:54,  7.69s/it, lr=1e-5, step_loss=0.00881]Steps:   2%|▏         | 15434/1000000 [6:13:26<2194:36:39,  8.02s/it, lr=1e-5, step_loss=0.00881][RANK-0]: Step: [15434], local_loss=0.14879384636878967, train_loss=0.07151372730731964, time_cost=3.7614026069641113
Steps:   2%|▏         | 15434/1000000 [6:13:26<2194:36:39,  8.02s/it, lr=1e-5, step_loss=0.149]  Steps:   2%|▏         | 15435/1000000 [6:13:38<2560:55:35,  9.36s/it, lr=1e-5, step_loss=0.149][RANK-0]: Step: [15435], local_loss=0.102264404296875, train_loss=0.04477988928556442, time_cost=4.216109752655029
Steps:   2%|▏         | 15435/1000000 [6:13:38<2560:55:35,  9.36s/it, lr=1e-5, step_loss=0.102]Steps:   2%|▏         | 15436/1000000 [6:13:52<2869:25:48, 10.49s/it, lr=1e-5, step_loss=0.102][RANK-0]: Step: [15436], local_loss=0.01405922882258892, train_loss=0.022863784804940224, time_cost=4.4621741771698
Steps:   2%|▏         | 15436/1000000 [6:13:52<2869:25:48, 10.49s/it, lr=1e-5, step_loss=0.0141]Steps:   2%|▏         | 15437/1000000 [6:14:02<2896:23:04, 10.59s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [15437], local_loss=0.007275410462170839, train_loss=0.04281117767095566, time_cost=2.2143900394439697
Steps:   2%|▏         | 15437/1000000 [6:14:02<2896:23:04, 10.59s/it, lr=1e-5, step_loss=0.00728]Steps:   2%|▏         | 15438/1000000 [6:14:18<3336:58:10, 12.20s/it, lr=1e-5, step_loss=0.00728][RANK-0]: Step: [15438], local_loss=0.049371276050806046, train_loss=0.01796722784638405, time_cost=7.960508346557617
Steps:   2%|▏         | 15438/1000000 [6:14:18<3336:58:10, 12.20s/it, lr=1e-5, step_loss=0.0494] Steps:   2%|▏         | 15439/1000000 [6:14:31<3377:37:10, 12.35s/it, lr=1e-5, step_loss=0.0494][RANK-0]: Step: [15439], local_loss=0.013248869217932224, train_loss=0.051520608365535736, time_cost=6.000169992446899
Steps:   2%|▏         | 15439/1000000 [6:14:31<3377:37:10, 12.35s/it, lr=1e-5, step_loss=0.0132]Steps:   2%|▏         | 15440/1000000 [6:14:42<3299:56:37, 12.07s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [15440], local_loss=0.04628775641322136, train_loss=0.0905788391828537, time_cost=2.804765462875366
Steps:   2%|▏         | 15440/1000000 [6:14:42<3299:56:37, 12.07s/it, lr=1e-5, step_loss=0.0463]Steps:   2%|▏         | 15441/1000000 [6:14:52<3100:51:53, 11.34s/it, lr=1e-5, step_loss=0.0463][RANK-0]: Step: [15441], local_loss=0.012513667345046997, train_loss=0.037441033869981766, time_cost=3.612149238586426
Steps:   2%|▏         | 15441/1000000 [6:14:52<3100:51:53, 11.34s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 15442/1000000 [6:15:06<3353:07:06, 12.26s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [15442], local_loss=0.018157772719860077, train_loss=0.022235456854104996, time_cost=8.75077223777771
Steps:   2%|▏         | 15442/1000000 [6:15:06<3353:07:06, 12.26s/it, lr=1e-5, step_loss=0.0182]Steps:   2%|▏         | 15443/1000000 [6:15:19<3414:31:35, 12.49s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [15443], local_loss=0.011738776229321957, train_loss=0.0933692678809166, time_cost=1.2101850509643555
Steps:   2%|▏         | 15443/1000000 [6:15:19<3414:31:35, 12.49s/it, lr=1e-5, step_loss=0.0117]Steps:   2%|▏         | 15444/1000000 [6:15:24<2741:24:44, 10.02s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [15444], local_loss=0.011590059846639633, train_loss=0.048402637243270874, time_cost=1.4728989601135254
Steps:   2%|▏         | 15444/1000000 [6:15:24<2741:24:44, 10.02s/it, lr=1e-5, step_loss=0.0116]Steps:   2%|▏         | 15445/1000000 [6:15:28<2283:36:09,  8.35s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [15445], local_loss=0.010145142674446106, train_loss=0.0125814788043499, time_cost=3.314269542694092
Steps:   2%|▏         | 15445/1000000 [6:15:28<2283:36:09,  8.35s/it, lr=1e-5, step_loss=0.0101]Steps:   2%|▏         | 15446/1000000 [6:15:35<2196:04:37,  8.03s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [15446], local_loss=0.012910169549286366, train_loss=0.05434978008270264, time_cost=2.806978464126587
Steps:   2%|▏         | 15446/1000000 [6:15:35<2196:04:37,  8.03s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 15447/1000000 [6:15:41<2023:53:41,  7.40s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [15447], local_loss=0.006018337793648243, train_loss=17.344131469726562, time_cost=1.8196780681610107
Steps:   2%|▏         | 15447/1000000 [6:15:41<2023:53:41,  7.40s/it, lr=1e-5, step_loss=0.00602]Steps:   2%|▏         | 15448/1000000 [6:15:46<1782:22:14,  6.52s/it, lr=1e-5, step_loss=0.00602][RANK-0]: Step: [15448], local_loss=1.0027433633804321, train_loss=46.6814079284668, time_cost=2.029963970184326
Steps:   2%|▏         | 15448/1000000 [6:15:46<1782:22:14,  6.52s/it, lr=1e-5, step_loss=1]      Steps:   2%|▏         | 15449/1000000 [6:15:57<2181:00:25,  7.97s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [15449], local_loss=0.03791532665491104, train_loss=0.03984962776303291, time_cost=5.463440418243408
Steps:   2%|▏         | 15449/1000000 [6:15:57<2181:00:25,  7.97s/it, lr=1e-5, step_loss=0.0379]Steps:   2%|▏         | 15450/1000000 [6:16:12<2716:47:27,  9.93s/it, lr=1e-5, step_loss=0.0379][RANK-0]: Step: [15450], local_loss=0.012820564210414886, train_loss=0.02893708646297455, time_cost=5.989128112792969
Steps:   2%|▏         | 15450/1000000 [6:16:12<2716:47:27,  9.93s/it, lr=1e-5, step_loss=0.0128]Steps:   2%|▏         | 15451/1000000 [6:16:18<2378:30:17,  8.70s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [15451], local_loss=0.028934989124536514, train_loss=0.14296074211597443, time_cost=1.4192543029785156
Steps:   2%|▏         | 15451/1000000 [6:16:18<2378:30:17,  8.70s/it, lr=1e-5, step_loss=0.0289]Steps:   2%|▏         | 15452/1000000 [6:16:27<2420:22:26,  8.85s/it, lr=1e-5, step_loss=0.0289][RANK-0]: Step: [15452], local_loss=0.04769602417945862, train_loss=0.1621798872947693, time_cost=4.187894105911255
Steps:   2%|▏         | 15452/1000000 [6:16:27<2420:22:26,  8.85s/it, lr=1e-5, step_loss=0.0477]Steps:   2%|▏         | 15453/1000000 [6:16:36<2492:15:49,  9.11s/it, lr=1e-5, step_loss=0.0477][RANK-0]: Step: [15453], local_loss=0.022388653829693794, train_loss=0.014406026341021061, time_cost=5.3974220752716064
Steps:   2%|▏         | 15453/1000000 [6:16:36<2492:15:49,  9.11s/it, lr=1e-5, step_loss=0.0224]Steps:   2%|▏         | 15454/1000000 [6:16:44<2322:06:20,  8.49s/it, lr=1e-5, step_loss=0.0224][RANK-0]: Step: [15454], local_loss=0.17708833515644073, train_loss=0.045363109558820724, time_cost=2.583069086074829
Steps:   2%|▏         | 15454/1000000 [6:16:44<2322:06:20,  8.49s/it, lr=1e-5, step_loss=0.177] Steps:   2%|▏         | 15455/1000000 [6:16:50<2140:07:52,  7.83s/it, lr=1e-5, step_loss=0.177][RANK-0]: Step: [15455], local_loss=0.007765952032059431, train_loss=0.045807015150785446, time_cost=1.8088197708129883
Steps:   2%|▏         | 15455/1000000 [6:16:50<2140:07:52,  7.83s/it, lr=1e-5, step_loss=0.00777]Steps:   2%|▏         | 15456/1000000 [6:17:00<2307:22:16,  8.44s/it, lr=1e-5, step_loss=0.00777][RANK-0]: Step: [15456], local_loss=0.018128708004951477, train_loss=0.20938657224178314, time_cost=3.7571802139282227
Steps:   2%|▏         | 15456/1000000 [6:17:00<2307:22:16,  8.44s/it, lr=1e-5, step_loss=0.0181] Steps:   2%|▏         | 15457/1000000 [6:17:04<1979:33:38,  7.24s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [15457], local_loss=0.024103963747620583, train_loss=0.024160154163837433, time_cost=1.4665513038635254
Steps:   2%|▏         | 15457/1000000 [6:17:04<1979:33:38,  7.24s/it, lr=1e-5, step_loss=0.0241]Steps:   2%|▏         | 15458/1000000 [6:17:11<1938:29:13,  7.09s/it, lr=1e-5, step_loss=0.0241][RANK-0]: Step: [15458], local_loss=0.06683587282896042, train_loss=0.05736510455608368, time_cost=5.689876556396484
Steps:   2%|▏         | 15458/1000000 [6:17:11<1938:29:13,  7.09s/it, lr=1e-5, step_loss=0.0668]Steps:   2%|▏         | 15459/1000000 [6:17:17<1839:00:49,  6.72s/it, lr=1e-5, step_loss=0.0668][RANK-0]: Step: [15459], local_loss=0.03112061321735382, train_loss=0.03379756957292557, time_cost=1.2733283042907715
Steps:   2%|▏         | 15459/1000000 [6:17:17<1839:00:49,  6.72s/it, lr=1e-5, step_loss=0.0311]Steps:   2%|▏         | 15460/1000000 [6:17:27<2158:46:01,  7.89s/it, lr=1e-5, step_loss=0.0311][RANK-0]: Step: [15460], local_loss=0.004867143463343382, train_loss=0.016725167632102966, time_cost=1.2157764434814453
Steps:   2%|▏         | 15460/1000000 [6:17:27<2158:46:01,  7.89s/it, lr=1e-5, step_loss=0.00487]Steps:   2%|▏         | 15461/1000000 [6:17:39<2483:55:53,  9.08s/it, lr=1e-5, step_loss=0.00487][RANK-0]: Step: [15461], local_loss=0.14695711433887482, train_loss=0.06063583493232727, time_cost=9.340977907180786
Steps:   2%|▏         | 15461/1000000 [6:17:39<2483:55:53,  9.08s/it, lr=1e-5, step_loss=0.147]  Steps:   2%|▏         | 15462/1000000 [6:17:52<2771:58:06, 10.14s/it, lr=1e-5, step_loss=0.147][RANK-0]: Step: [15462], local_loss=0.03952797129750252, train_loss=4.592670440673828, time_cost=3.440054178237915
Steps:   2%|▏         | 15462/1000000 [6:17:52<2771:58:06, 10.14s/it, lr=1e-5, step_loss=0.0395]Steps:   2%|▏         | 15463/1000000 [6:18:02<2786:06:56, 10.19s/it, lr=1e-5, step_loss=0.0395][RANK-0]: Step: [15463], local_loss=0.024621589109301567, train_loss=0.03257623314857483, time_cost=2.626829147338867
Steps:   2%|▏         | 15463/1000000 [6:18:02<2786:06:56, 10.19s/it, lr=1e-5, step_loss=0.0246]Steps:   2%|▏         | 15464/1000000 [6:18:07<2378:30:28,  8.70s/it, lr=1e-5, step_loss=0.0246][RANK-0]: Step: [15464], local_loss=1.0008553266525269, train_loss=0.15793132781982422, time_cost=2.074566125869751
Steps:   2%|▏         | 15464/1000000 [6:18:07<2378:30:28,  8.70s/it, lr=1e-5, step_loss=1]     Steps:   2%|▏         | 15465/1000000 [6:18:21<2807:57:11, 10.27s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [15465], local_loss=0.03492686524987221, train_loss=0.032090917229652405, time_cost=4.111582040786743
Steps:   2%|▏         | 15465/1000000 [6:18:21<2807:57:11, 10.27s/it, lr=1e-5, step_loss=0.0349]Steps:   2%|▏         | 15466/1000000 [6:18:27<2461:22:33,  9.00s/it, lr=1e-5, step_loss=0.0349][RANK-0]: Step: [15466], local_loss=1.0148065090179443, train_loss=0.14071646332740784, time_cost=2.1494216918945312
Steps:   2%|▏         | 15466/1000000 [6:18:27<2461:22:33,  9.00s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 15467/1000000 [6:18:32<2087:16:25,  7.63s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [15467], local_loss=0.03577295318245888, train_loss=0.0724848061800003, time_cost=1.414529800415039
Steps:   2%|▏         | 15467/1000000 [6:18:32<2087:16:25,  7.63s/it, lr=1e-5, step_loss=0.0358]Steps:   2%|▏         | 15468/1000000 [6:18:43<2394:02:38,  8.75s/it, lr=1e-5, step_loss=0.0358][RANK-0]: Step: [15468], local_loss=0.04178749397397041, train_loss=0.02528643235564232, time_cost=6.380384683609009
Steps:   2%|▏         | 15468/1000000 [6:18:43<2394:02:38,  8.75s/it, lr=1e-5, step_loss=0.0418]Steps:   2%|▏         | 15469/1000000 [6:18:53<2448:41:51,  8.95s/it, lr=1e-5, step_loss=0.0418][RANK-0]: Step: [15469], local_loss=0.4271291494369507, train_loss=0.08313656598329544, time_cost=2.0350852012634277
Steps:   2%|▏         | 15469/1000000 [6:18:53<2448:41:51,  8.95s/it, lr=1e-5, step_loss=0.427] Steps:   2%|▏         | 15470/1000000 [6:19:06<2852:53:08, 10.43s/it, lr=1e-5, step_loss=0.427][RANK-0]: Step: [15470], local_loss=0.046501606702804565, train_loss=0.08846442401409149, time_cost=1.2903270721435547
Steps:   2%|▏         | 15470/1000000 [6:19:06<2852:53:08, 10.43s/it, lr=1e-5, step_loss=0.0465]Steps:   2%|▏         | 15471/1000000 [6:19:19<3009:30:11, 11.00s/it, lr=1e-5, step_loss=0.0465][RANK-0]: Step: [15471], local_loss=0.024932272732257843, train_loss=0.06616073101758957, time_cost=4.416438817977905
Steps:   2%|▏         | 15471/1000000 [6:19:19<3009:30:11, 11.00s/it, lr=1e-5, step_loss=0.0249]Steps:   2%|▏         | 15472/1000000 [6:19:25<2612:10:59,  9.55s/it, lr=1e-5, step_loss=0.0249][RANK-0]: Step: [15472], local_loss=0.005434466525912285, train_loss=0.01650705561041832, time_cost=1.6119279861450195
Steps:   2%|▏         | 15472/1000000 [6:19:25<2612:10:59,  9.55s/it, lr=1e-5, step_loss=0.00543]Steps:   2%|▏         | 15473/1000000 [6:19:33<2459:22:56,  8.99s/it, lr=1e-5, step_loss=0.00543][RANK-0]: Step: [15473], local_loss=0.03308764472603798, train_loss=0.06704695522785187, time_cost=2.0659759044647217
Steps:   2%|▏         | 15473/1000000 [6:19:33<2459:22:56,  8.99s/it, lr=1e-5, step_loss=0.0331] Steps:   2%|▏         | 15474/1000000 [6:19:47<2870:05:02, 10.49s/it, lr=1e-5, step_loss=0.0331][RANK-0]: Step: [15474], local_loss=0.00782471988350153, train_loss=0.017572056502103806, time_cost=4.237911224365234
Steps:   2%|▏         | 15474/1000000 [6:19:47<2870:05:02, 10.49s/it, lr=1e-5, step_loss=0.00782]Steps:   2%|▏         | 15475/1000000 [6:19:59<3050:24:58, 11.15s/it, lr=1e-5, step_loss=0.00782][RANK-0]: Step: [15475], local_loss=0.019093265756964684, train_loss=0.013790363445878029, time_cost=4.483327150344849
Steps:   2%|▏         | 15475/1000000 [6:19:59<3050:24:58, 11.15s/it, lr=1e-5, step_loss=0.0191] Steps:   2%|▏         | 15476/1000000 [6:20:05<2627:09:09,  9.61s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [15476], local_loss=0.02589324861764908, train_loss=0.09515431523323059, time_cost=1.8178048133850098
Steps:   2%|▏         | 15476/1000000 [6:20:05<2627:09:09,  9.61s/it, lr=1e-5, step_loss=0.0259]Steps:   2%|▏         | 15477/1000000 [6:20:14<2575:54:04,  9.42s/it, lr=1e-5, step_loss=0.0259][RANK-0]: Step: [15477], local_loss=0.029827041551470757, train_loss=0.038277000188827515, time_cost=3.2820041179656982
Steps:   2%|▏         | 15477/1000000 [6:20:14<2575:54:04,  9.42s/it, lr=1e-5, step_loss=0.0298]Steps:   2%|▏         | 15478/1000000 [6:20:26<2740:33:31, 10.02s/it, lr=1e-5, step_loss=0.0298][RANK-0]: Step: [15478], local_loss=0.031599968671798706, train_loss=0.06512857973575592, time_cost=1.941110372543335
Steps:   2%|▏         | 15478/1000000 [6:20:26<2740:33:31, 10.02s/it, lr=1e-5, step_loss=0.0316]Steps:   2%|▏         | 15479/1000000 [6:20:36<2799:03:12, 10.24s/it, lr=1e-5, step_loss=0.0316][RANK-0]: Step: [15479], local_loss=0.00552921649068594, train_loss=0.01632499322295189, time_cost=1.3285903930664062
Steps:   2%|▏         | 15479/1000000 [6:20:36<2799:03:12, 10.24s/it, lr=1e-5, step_loss=0.00553]Steps:   2%|▏         | 15480/1000000 [6:20:49<2977:38:25, 10.89s/it, lr=1e-5, step_loss=0.00553][RANK-0]: Step: [15480], local_loss=0.01433239784091711, train_loss=0.022064536809921265, time_cost=5.701997756958008
Steps:   2%|▏         | 15480/1000000 [6:20:49<2977:38:25, 10.89s/it, lr=1e-5, step_loss=0.0143] Steps:   2%|▏         | 15481/1000000 [6:20:54<2502:42:58,  9.15s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [15481], local_loss=0.0060242158360779285, train_loss=0.032855913043022156, time_cost=4.08644962310791
Steps:   2%|▏         | 15481/1000000 [6:20:54<2502:42:58,  9.15s/it, lr=1e-5, step_loss=0.00602]Steps:   2%|▏         | 15482/1000000 [6:20:59<2185:00:19,  7.99s/it, lr=1e-5, step_loss=0.00602][RANK-0]: Step: [15482], local_loss=0.02784735895693302, train_loss=0.04492802172899246, time_cost=1.2672994136810303
Steps:   2%|▏         | 15482/1000000 [6:20:59<2185:00:19,  7.99s/it, lr=1e-5, step_loss=0.0278] Steps:   2%|▏         | 15483/1000000 [6:21:07<2142:53:04,  7.84s/it, lr=1e-5, step_loss=0.0278][RANK-0]: Step: [15483], local_loss=0.011994592845439911, train_loss=0.051683299243450165, time_cost=3.7709240913391113
Steps:   2%|▏         | 15483/1000000 [6:21:07<2142:53:04,  7.84s/it, lr=1e-5, step_loss=0.012] Steps:   2%|▏         | 15484/1000000 [6:21:11<1858:20:55,  6.80s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [15484], local_loss=0.015682008117437363, train_loss=0.019768159836530685, time_cost=1.5100579261779785
Steps:   2%|▏         | 15484/1000000 [6:21:11<1858:20:55,  6.80s/it, lr=1e-5, step_loss=0.0157]Steps:   2%|▏         | 15485/1000000 [6:21:18<1868:54:29,  6.83s/it, lr=1e-5, step_loss=0.0157][RANK-0]: Step: [15485], local_loss=0.031564682722091675, train_loss=0.07723912596702576, time_cost=3.0424396991729736
Steps:   2%|▏         | 15485/1000000 [6:21:18<1868:54:29,  6.83s/it, lr=1e-5, step_loss=0.0316]Steps:   2%|▏         | 15486/1000000 [6:21:33<2524:58:02,  9.23s/it, lr=1e-5, step_loss=0.0316][RANK-0]: Step: [15486], local_loss=0.00343115720897913, train_loss=0.016733719035983086, time_cost=7.535509824752808
Steps:   2%|▏         | 15486/1000000 [6:21:33<2524:58:02,  9.23s/it, lr=1e-5, step_loss=0.00343]Steps:   2%|▏         | 15487/1000000 [6:21:42<2510:13:11,  9.18s/it, lr=1e-5, step_loss=0.00343][RANK-0]: Step: [15487], local_loss=0.004349446855485439, train_loss=0.026486869901418686, time_cost=1.218879222869873
Steps:   2%|▏         | 15487/1000000 [6:21:42<2510:13:11,  9.18s/it, lr=1e-5, step_loss=0.00435]Steps:   2%|▏         | 15488/1000000 [6:21:54<2787:12:42, 10.19s/it, lr=1e-5, step_loss=0.00435][RANK-0]: Step: [15488], local_loss=0.11606757342815399, train_loss=11.45469856262207, time_cost=7.10907506942749
Steps:   2%|▏         | 15488/1000000 [6:21:54<2787:12:42, 10.19s/it, lr=1e-5, step_loss=0.116]  Steps:   2%|▏         | 15489/1000000 [6:22:03<2637:31:28,  9.64s/it, lr=1e-5, step_loss=0.116][RANK-0]: Step: [15489], local_loss=0.009939382784068584, train_loss=6.977734565734863, time_cost=1.2159607410430908
Steps:   2%|▏         | 15489/1000000 [6:22:03<2637:31:28,  9.64s/it, lr=1e-5, step_loss=0.00994]Steps:   2%|▏         | 15490/1000000 [6:22:17<3040:01:04, 11.12s/it, lr=1e-5, step_loss=0.00994][RANK-0]: Step: [15490], local_loss=0.4675547480583191, train_loss=0.09205225110054016, time_cost=4.736355543136597
Steps:   2%|▏         | 15490/1000000 [6:22:17<3040:01:04, 11.12s/it, lr=1e-5, step_loss=0.468]  Steps:   2%|▏         | 15491/1000000 [6:22:23<2611:50:54,  9.55s/it, lr=1e-5, step_loss=0.468][RANK-0]: Step: [15491], local_loss=0.02007298544049263, train_loss=0.016567042097449303, time_cost=1.4342823028564453
Steps:   2%|▏         | 15491/1000000 [6:22:23<2611:50:54,  9.55s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 15492/1000000 [6:22:30<2393:43:37,  8.75s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [15492], local_loss=0.41677677631378174, train_loss=0.08047455549240112, time_cost=1.2810697555541992
Steps:   2%|▏         | 15492/1000000 [6:22:30<2393:43:37,  8.75s/it, lr=1e-5, step_loss=0.417] Steps:   2%|▏         | 15493/1000000 [6:22:37<2263:34:39,  8.28s/it, lr=1e-5, step_loss=0.417][RANK-0]: Step: [15493], local_loss=0.04822520911693573, train_loss=0.05900948867201805, time_cost=1.1996262073516846
Steps:   2%|▏         | 15493/1000000 [6:22:37<2263:34:39,  8.28s/it, lr=1e-5, step_loss=0.0482]Steps:   2%|▏         | 15494/1000000 [6:22:49<2506:35:54,  9.17s/it, lr=1e-5, step_loss=0.0482][RANK-0]: Step: [15494], local_loss=0.007804151624441147, train_loss=0.15826398134231567, time_cost=2.451833486557007
Steps:   2%|▏         | 15494/1000000 [6:22:49<2506:35:54,  9.17s/it, lr=1e-5, step_loss=0.0078]Steps:   2%|▏         | 15495/1000000 [6:22:59<2592:21:23,  9.48s/it, lr=1e-5, step_loss=0.0078][RANK-0]: Step: [15495], local_loss=0.00947655737400055, train_loss=0.020837824791669846, time_cost=4.054812669754028
Steps:   2%|▏         | 15495/1000000 [6:22:59<2592:21:23,  9.48s/it, lr=1e-5, step_loss=0.00948]Steps:   2%|▏         | 15496/1000000 [6:23:05<2288:41:38,  8.37s/it, lr=1e-5, step_loss=0.00948][RANK-0]: Step: [15496], local_loss=0.017615551128983498, train_loss=0.15803413093090057, time_cost=3.320272207260132
Steps:   2%|▏         | 15496/1000000 [6:23:05<2288:41:38,  8.37s/it, lr=1e-5, step_loss=0.0176] Steps:   2%|▏         | 15497/1000000 [6:23:09<1967:28:20,  7.19s/it, lr=1e-5, step_loss=0.0176][RANK-0]: Step: [15497], local_loss=0.01777508109807968, train_loss=0.03979676216840744, time_cost=1.3002822399139404
Steps:   2%|▏         | 15497/1000000 [6:23:09<1967:28:20,  7.19s/it, lr=1e-5, step_loss=0.0178]Steps:   2%|▏         | 15498/1000000 [6:23:14<1780:57:47,  6.51s/it, lr=1e-5, step_loss=0.0178][RANK-0]: Step: [15498], local_loss=0.05768090859055519, train_loss=0.04046880453824997, time_cost=1.2427208423614502
Steps:   2%|▏         | 15498/1000000 [6:23:14<1780:57:47,  6.51s/it, lr=1e-5, step_loss=0.0577]Steps:   2%|▏         | 15499/1000000 [6:23:19<1645:44:04,  6.02s/it, lr=1e-5, step_loss=0.0577][RANK-0]: Step: [15499], local_loss=0.015501770190894604, train_loss=0.14769792556762695, time_cost=1.8310420513153076
Steps:   2%|▏         | 15499/1000000 [6:23:19<1645:44:04,  6.02s/it, lr=1e-5, step_loss=0.0155]Steps:   2%|▏         | 15500/1000000 [6:23:34<2431:17:42,  8.89s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [15500], local_loss=0.034052882343530655, train_loss=0.0333961583673954, time_cost=7.042981863021851
Steps:   2%|▏         | 15500/1000000 [6:23:34<2431:17:42,  8.89s/it, lr=1e-5, step_loss=0.0341]Steps:   2%|▏         | 15501/1000000 [6:23:47<2740:03:07, 10.02s/it, lr=1e-5, step_loss=0.0341][RANK-0]: Step: [15501], local_loss=0.011803037486970425, train_loss=0.06555400043725967, time_cost=3.22619891166687
Steps:   2%|▏         | 15501/1000000 [6:23:47<2740:03:07, 10.02s/it, lr=1e-5, step_loss=0.0118]Steps:   2%|▏         | 15502/1000000 [6:23:53<2410:13:03,  8.81s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [15502], local_loss=0.00977832917124033, train_loss=0.022303840145468712, time_cost=1.5578539371490479
Steps:   2%|▏         | 15502/1000000 [6:23:53<2410:13:03,  8.81s/it, lr=1e-5, step_loss=0.00978]Steps:   2%|▏         | 15503/1000000 [6:24:07<2846:48:07, 10.41s/it, lr=1e-5, step_loss=0.00978][RANK-0]: Step: [15503], local_loss=0.03725837171077728, train_loss=0.046209581196308136, time_cost=1.1902601718902588
Steps:   2%|▏         | 15503/1000000 [6:24:07<2846:48:07, 10.41s/it, lr=1e-5, step_loss=0.0373] Steps:   2%|▏         | 15504/1000000 [6:24:20<3015:06:43, 11.03s/it, lr=1e-5, step_loss=0.0373][RANK-0]: Step: [15504], local_loss=0.008253422565758228, train_loss=0.023112311959266663, time_cost=2.5992674827575684
Steps:   2%|▏         | 15504/1000000 [6:24:20<3015:06:43, 11.03s/it, lr=1e-5, step_loss=0.00825]Steps:   2%|▏         | 15505/1000000 [6:24:29<2853:00:04, 10.43s/it, lr=1e-5, step_loss=0.00825][RANK-0]: Step: [15505], local_loss=0.31201258301734924, train_loss=0.06457731127738953, time_cost=2.3575098514556885
Steps:   2%|▏         | 15505/1000000 [6:24:29<2853:00:04, 10.43s/it, lr=1e-5, step_loss=0.312]  Steps:   2%|▏         | 15506/1000000 [6:24:38<2777:48:43, 10.16s/it, lr=1e-5, step_loss=0.312][RANK-0]: Step: [15506], local_loss=0.04654107615351677, train_loss=0.022358981892466545, time_cost=3.9878432750701904
Steps:   2%|▏         | 15506/1000000 [6:24:38<2777:48:43, 10.16s/it, lr=1e-5, step_loss=0.0465]Steps:   2%|▏         | 15507/1000000 [6:24:43<2378:22:57,  8.70s/it, lr=1e-5, step_loss=0.0465][RANK-0]: Step: [15507], local_loss=0.017804566770792007, train_loss=0.035951949656009674, time_cost=2.486382007598877
Steps:   2%|▏         | 15507/1000000 [6:24:43<2378:22:57,  8.70s/it, lr=1e-5, step_loss=0.0178]Steps:   2%|▏         | 15508/1000000 [6:24:48<2047:35:13,  7.49s/it, lr=1e-5, step_loss=0.0178][RANK-0]: Step: [15508], local_loss=0.12196066975593567, train_loss=0.062185440212488174, time_cost=1.8154385089874268
Steps:   2%|▏         | 15508/1000000 [6:24:48<2047:35:13,  7.49s/it, lr=1e-5, step_loss=0.122] Steps:   2%|▏         | 15509/1000000 [6:24:53<1840:40:17,  6.73s/it, lr=1e-5, step_loss=0.122][RANK-0]: Step: [15509], local_loss=0.009437336586415768, train_loss=0.05165252462029457, time_cost=2.470825672149658
Steps:   2%|▏         | 15509/1000000 [6:24:53<1840:40:17,  6.73s/it, lr=1e-5, step_loss=0.00944]Steps:   2%|▏         | 15510/1000000 [6:24:57<1628:02:57,  5.95s/it, lr=1e-5, step_loss=0.00944][RANK-0]: Step: [15510], local_loss=0.009908037260174751, train_loss=0.05246700718998909, time_cost=1.3325226306915283
Steps:   2%|▏         | 15510/1000000 [6:24:57<1628:02:57,  5.95s/it, lr=1e-5, step_loss=0.00991]Steps:   2%|▏         | 15511/1000000 [6:25:04<1724:00:44,  6.30s/it, lr=1e-5, step_loss=0.00991][RANK-0]: Step: [15511], local_loss=0.061025604605674744, train_loss=0.15612153708934784, time_cost=2.7189862728118896
Steps:   2%|▏         | 15511/1000000 [6:25:04<1724:00:44,  6.30s/it, lr=1e-5, step_loss=0.061]  Steps:   2%|▏         | 15512/1000000 [6:25:11<1720:59:44,  6.29s/it, lr=1e-5, step_loss=0.061][RANK-0]: Step: [15512], local_loss=0.38552701473236084, train_loss=0.08518495410680771, time_cost=1.6257109642028809
Steps:   2%|▏         | 15512/1000000 [6:25:11<1720:59:44,  6.29s/it, lr=1e-5, step_loss=0.386]Steps:   2%|▏         | 15513/1000000 [6:25:18<1793:02:06,  6.56s/it, lr=1e-5, step_loss=0.386][RANK-0]: Step: [15513], local_loss=0.01690826192498207, train_loss=0.16752631962299347, time_cost=2.3990893363952637
Steps:   2%|▏         | 15513/1000000 [6:25:18<1793:02:06,  6.56s/it, lr=1e-5, step_loss=0.0169]Steps:   2%|▏         | 15514/1000000 [6:25:26<1946:17:44,  7.12s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [15514], local_loss=0.024382995441555977, train_loss=0.014168508350849152, time_cost=1.5846233367919922
Steps:   2%|▏         | 15514/1000000 [6:25:26<1946:17:44,  7.12s/it, lr=1e-5, step_loss=0.0244]Steps:   2%|▏         | 15515/1000000 [6:25:37<2252:26:40,  8.24s/it, lr=1e-5, step_loss=0.0244][RANK-0]: Step: [15515], local_loss=0.023344090208411217, train_loss=0.08036849647760391, time_cost=7.374667167663574
Steps:   2%|▏         | 15515/1000000 [6:25:37<2252:26:40,  8.24s/it, lr=1e-5, step_loss=0.0233]Steps:   2%|▏         | 15516/1000000 [6:25:43<2053:18:33,  7.51s/it, lr=1e-5, step_loss=0.0233][RANK-0]: Step: [15516], local_loss=0.02480173483490944, train_loss=0.025553762912750244, time_cost=1.3372457027435303
Steps:   2%|▏         | 15516/1000000 [6:25:43<2053:18:33,  7.51s/it, lr=1e-5, step_loss=0.0248]Steps:   2%|▏         | 15517/1000000 [6:25:48<1851:44:46,  6.77s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [15517], local_loss=0.019169459119439125, train_loss=0.031144164502620697, time_cost=2.1317861080169678
Steps:   2%|▏         | 15517/1000000 [6:25:48<1851:44:46,  6.77s/it, lr=1e-5, step_loss=0.0192]Steps:   2%|▏         | 15518/1000000 [6:25:55<1883:50:21,  6.89s/it, lr=1e-5, step_loss=0.0192][RANK-0]: Step: [15518], local_loss=0.015059495344758034, train_loss=0.029366210103034973, time_cost=3.3104071617126465
Steps:   2%|▏         | 15518/1000000 [6:25:55<1883:50:21,  6.89s/it, lr=1e-5, step_loss=0.0151]Steps:   2%|▏         | 15519/1000000 [6:26:02<1909:40:38,  6.98s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [15519], local_loss=0.010677885264158249, train_loss=0.04682052135467529, time_cost=1.2228646278381348
Steps:   2%|▏         | 15519/1000000 [6:26:02<1909:40:38,  6.98s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 15520/1000000 [6:26:10<1965:32:23,  7.19s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [15520], local_loss=0.004561550449579954, train_loss=0.07512350380420685, time_cost=2.7359538078308105
Steps:   2%|▏         | 15520/1000000 [6:26:10<1965:32:23,  7.19s/it, lr=1e-5, step_loss=0.00456]Steps:   2%|▏         | 15521/1000000 [6:26:16<1860:40:17,  6.80s/it, lr=1e-5, step_loss=0.00456][RANK-0]: Step: [15521], local_loss=0.010848393663764, train_loss=0.029346471652388573, time_cost=4.005641460418701
Steps:   2%|▏         | 15521/1000000 [6:26:16<1860:40:17,  6.80s/it, lr=1e-5, step_loss=0.0108] Steps:   2%|▏         | 15522/1000000 [6:26:27<2231:39:25,  8.16s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [15522], local_loss=0.06866513937711716, train_loss=0.05453033372759819, time_cost=2.6567912101745605
Steps:   2%|▏         | 15522/1000000 [6:26:27<2231:39:25,  8.16s/it, lr=1e-5, step_loss=0.0687]Steps:   2%|▏         | 15523/1000000 [6:26:32<1981:07:16,  7.24s/it, lr=1e-5, step_loss=0.0687][RANK-0]: Step: [15523], local_loss=1.0176515579223633, train_loss=0.1496410220861435, time_cost=1.2175188064575195
Steps:   2%|▏         | 15523/1000000 [6:26:32<1981:07:16,  7.24s/it, lr=1e-5, step_loss=1.02]  Steps:   2%|▏         | 15524/1000000 [6:26:43<2277:49:59,  8.33s/it, lr=1e-5, step_loss=1.02][RANK-0]: Step: [15524], local_loss=0.050166524946689606, train_loss=0.1472463756799698, time_cost=2.6392300128936768
Steps:   2%|▏         | 15524/1000000 [6:26:43<2277:49:59,  8.33s/it, lr=1e-5, step_loss=0.0502]Steps:   2%|▏         | 15525/1000000 [6:26:49<2059:21:44,  7.53s/it, lr=1e-5, step_loss=0.0502][RANK-0]: Step: [15525], local_loss=0.0037963991053402424, train_loss=0.022221216931939125, time_cost=2.6339120864868164
Steps:   2%|▏         | 15525/1000000 [6:26:49<2059:21:44,  7.53s/it, lr=1e-5, step_loss=0.0038]Steps:   2%|▏         | 15526/1000000 [6:27:02<2549:03:24,  9.32s/it, lr=1e-5, step_loss=0.0038][RANK-0]: Step: [15526], local_loss=0.058092791587114334, train_loss=0.03933277726173401, time_cost=1.209059238433838
Steps:   2%|▏         | 15526/1000000 [6:27:02<2549:03:24,  9.32s/it, lr=1e-5, step_loss=0.0581]Steps:   2%|▏         | 15527/1000000 [6:27:07<2187:10:34,  8.00s/it, lr=1e-5, step_loss=0.0581][RANK-0]: Step: [15527], local_loss=0.08096876740455627, train_loss=0.02982155606150627, time_cost=1.994887113571167
Steps:   2%|▏         | 15527/1000000 [6:27:07<2187:10:34,  8.00s/it, lr=1e-5, step_loss=0.081] Steps:   2%|▏         | 15528/1000000 [6:27:12<1952:28:32,  7.14s/it, lr=1e-5, step_loss=0.081][RANK-0]: Step: [15528], local_loss=0.010638532228767872, train_loss=0.06568925082683563, time_cost=2.233093023300171
Steps:   2%|▏         | 15528/1000000 [6:27:12<1952:28:32,  7.14s/it, lr=1e-5, step_loss=0.0106]Steps:   2%|▏         | 15529/1000000 [6:27:22<2140:12:25,  7.83s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [15529], local_loss=0.007067153230309486, train_loss=0.017579877749085426, time_cost=1.7211318016052246
Steps:   2%|▏         | 15529/1000000 [6:27:22<2140:12:25,  7.83s/it, lr=1e-5, step_loss=0.00707]Steps:   2%|▏         | 15530/1000000 [6:27:27<1948:49:25,  7.13s/it, lr=1e-5, step_loss=0.00707][RANK-0]: Step: [15530], local_loss=0.016301173716783524, train_loss=0.02517261728644371, time_cost=1.3928828239440918
Steps:   2%|▏         | 15530/1000000 [6:27:27<1948:49:25,  7.13s/it, lr=1e-5, step_loss=0.0163] Steps:   2%|▏         | 15531/1000000 [6:27:32<1777:39:42,  6.50s/it, lr=1e-5, step_loss=0.0163][RANK-0]: Step: [15531], local_loss=0.013825371861457825, train_loss=0.17260225117206573, time_cost=2.3812403678894043
Steps:   2%|▏         | 15531/1000000 [6:27:32<1777:39:42,  6.50s/it, lr=1e-5, step_loss=0.0138]Steps:   2%|▏         | 15532/1000000 [6:27:43<2082:13:10,  7.61s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [15532], local_loss=0.011193601414561272, train_loss=0.03007158637046814, time_cost=2.5521109104156494
Steps:   2%|▏         | 15532/1000000 [6:27:43<2082:13:10,  7.61s/it, lr=1e-5, step_loss=0.0112]Steps:   2%|▏         | 15533/1000000 [6:27:48<1878:49:49,  6.87s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [15533], local_loss=0.004256135318428278, train_loss=0.02713867463171482, time_cost=2.3847079277038574
Steps:   2%|▏         | 15533/1000000 [6:27:48<1878:49:49,  6.87s/it, lr=1e-5, step_loss=0.00426]Steps:   2%|▏         | 15534/1000000 [6:27:53<1736:43:46,  6.35s/it, lr=1e-5, step_loss=0.00426][RANK-0]: Step: [15534], local_loss=0.03438548743724823, train_loss=0.049210090190172195, time_cost=1.3324058055877686
Steps:   2%|▏         | 15534/1000000 [6:27:53<1736:43:46,  6.35s/it, lr=1e-5, step_loss=0.0344] Steps:   2%|▏         | 15535/1000000 [6:28:05<2196:50:57,  8.03s/it, lr=1e-5, step_loss=0.0344][RANK-0]: Step: [15535], local_loss=0.02189875952899456, train_loss=0.03309192880988121, time_cost=7.169977426528931
Steps:   2%|▏         | 15535/1000000 [6:28:05<2196:50:57,  8.03s/it, lr=1e-5, step_loss=0.0219]Steps:   2%|▏         | 15536/1000000 [6:28:09<1877:14:42,  6.86s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [15536], local_loss=0.02688129059970379, train_loss=0.06583196669816971, time_cost=1.6531667709350586
Steps:   2%|▏         | 15536/1000000 [6:28:09<1877:14:42,  6.86s/it, lr=1e-5, step_loss=0.0269]Steps:   2%|▏         | 15537/1000000 [6:28:14<1734:54:59,  6.34s/it, lr=1e-5, step_loss=0.0269][RANK-0]: Step: [15537], local_loss=0.006416120566427708, train_loss=0.05202193558216095, time_cost=2.223989725112915
Steps:   2%|▏         | 15537/1000000 [6:28:14<1734:54:59,  6.34s/it, lr=1e-5, step_loss=0.00642]Steps:   2%|▏         | 15538/1000000 [6:28:18<1577:31:23,  5.77s/it, lr=1e-5, step_loss=0.00642][RANK-0]: Step: [15538], local_loss=0.041570086032152176, train_loss=44.07830047607422, time_cost=1.2136704921722412
Steps:   2%|▏         | 15538/1000000 [6:28:18<1577:31:23,  5.77s/it, lr=1e-5, step_loss=0.0416] Steps:   2%|▏         | 15539/1000000 [6:28:26<1732:48:04,  6.34s/it, lr=1e-5, step_loss=0.0416][RANK-0]: Step: [15539], local_loss=0.008474547415971756, train_loss=0.01680707558989525, time_cost=3.8725807666778564
Steps:   2%|▏         | 15539/1000000 [6:28:26<1732:48:04,  6.34s/it, lr=1e-5, step_loss=0.00847]Steps:   2%|▏         | 15540/1000000 [6:28:34<1836:04:24,  6.71s/it, lr=1e-5, step_loss=0.00847][RANK-0]: Step: [15540], local_loss=0.004883734509348869, train_loss=0.05008256807923317, time_cost=1.2021281719207764
Steps:   2%|▏         | 15540/1000000 [6:28:34<1836:04:24,  6.71s/it, lr=1e-5, step_loss=0.00488]Steps:   2%|▏         | 15541/1000000 [6:28:41<1897:09:27,  6.94s/it, lr=1e-5, step_loss=0.00488][RANK-0]: Step: [15541], local_loss=0.014753817580640316, train_loss=0.025084076449275017, time_cost=1.5658979415893555
Steps:   2%|▏         | 15541/1000000 [6:28:41<1897:09:27,  6.94s/it, lr=1e-5, step_loss=0.0148] Steps:   2%|▏         | 15542/1000000 [6:28:55<2433:53:03,  8.90s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [15542], local_loss=0.028923021629452705, train_loss=0.09197874367237091, time_cost=2.590036153793335
Steps:   2%|▏         | 15542/1000000 [6:28:55<2433:53:03,  8.90s/it, lr=1e-5, step_loss=0.0289]Steps:   2%|▏         | 15543/1000000 [6:29:06<2634:51:42,  9.64s/it, lr=1e-5, step_loss=0.0289][RANK-0]: Step: [15543], local_loss=0.037543218582868576, train_loss=0.04653598368167877, time_cost=2.696559429168701
Steps:   2%|▏         | 15543/1000000 [6:29:06<2634:51:42,  9.64s/it, lr=1e-5, step_loss=0.0375]Steps:   2%|▏         | 15544/1000000 [6:29:17<2761:53:40, 10.10s/it, lr=1e-5, step_loss=0.0375][RANK-0]: Step: [15544], local_loss=0.016920093446969986, train_loss=0.020490799099206924, time_cost=2.9530117511749268
Steps:   2%|▏         | 15544/1000000 [6:29:17<2761:53:40, 10.10s/it, lr=1e-5, step_loss=0.0169]Steps:   2%|▏         | 15545/1000000 [6:29:23<2389:40:47,  8.74s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [15545], local_loss=0.028372475877404213, train_loss=0.020867563784122467, time_cost=1.4659860134124756
Steps:   2%|▏         | 15545/1000000 [6:29:23<2389:40:47,  8.74s/it, lr=1e-5, step_loss=0.0284]Steps:   2%|▏         | 15546/1000000 [6:29:30<2264:29:12,  8.28s/it, lr=1e-5, step_loss=0.0284][RANK-0]: Step: [15546], local_loss=0.05570057034492493, train_loss=0.030202368274331093, time_cost=2.8790807723999023
Steps:   2%|▏         | 15546/1000000 [6:29:30<2264:29:12,  8.28s/it, lr=1e-5, step_loss=0.0557]Steps:   2%|▏         | 15547/1000000 [6:29:38<2246:39:45,  8.22s/it, lr=1e-5, step_loss=0.0557][RANK-0]: Step: [15547], local_loss=0.00807782169431448, train_loss=0.02730632573366165, time_cost=4.521139144897461
Steps:   2%|▏         | 15547/1000000 [6:29:38<2246:39:45,  8.22s/it, lr=1e-5, step_loss=0.00808]Steps:   2%|▏         | 15548/1000000 [6:29:43<1998:22:18,  7.31s/it, lr=1e-5, step_loss=0.00808][RANK-0]: Step: [15548], local_loss=0.03511325269937515, train_loss=0.15013916790485382, time_cost=1.4304041862487793
Steps:   2%|▏         | 15548/1000000 [6:29:43<1998:22:18,  7.31s/it, lr=1e-5, step_loss=0.0351] Steps:   2%|▏         | 15549/1000000 [6:29:52<2150:17:11,  7.86s/it, lr=1e-5, step_loss=0.0351][RANK-0]: Step: [15549], local_loss=0.05037976801395416, train_loss=0.17475970089435577, time_cost=1.506378412246704
Steps:   2%|▏         | 15549/1000000 [6:29:52<2150:17:11,  7.86s/it, lr=1e-5, step_loss=0.0504]Steps:   2%|▏         | 15550/1000000 [6:30:04<2458:29:05,  8.99s/it, lr=1e-5, step_loss=0.0504][RANK-0]: Step: [15550], local_loss=0.0384797640144825, train_loss=0.16012510657310486, time_cost=6.085160255432129
Steps:   2%|▏         | 15550/1000000 [6:30:04<2458:29:05,  8.99s/it, lr=1e-5, step_loss=0.0385]Steps:   2%|▏         | 15551/1000000 [6:30:11<2299:31:30,  8.41s/it, lr=1e-5, step_loss=0.0385][RANK-0]: Step: [15551], local_loss=0.16856808960437775, train_loss=0.03937305137515068, time_cost=2.3986012935638428
Steps:   2%|▏         | 15551/1000000 [6:30:11<2299:31:30,  8.41s/it, lr=1e-5, step_loss=0.169] Steps:   2%|▏         | 15552/1000000 [6:30:18<2212:38:59,  8.09s/it, lr=1e-5, step_loss=0.169][RANK-0]: Step: [15552], local_loss=0.10461211949586868, train_loss=0.03534412384033203, time_cost=3.011861562728882
Steps:   2%|▏         | 15552/1000000 [6:30:18<2212:38:59,  8.09s/it, lr=1e-5, step_loss=0.105]Steps:   2%|▏         | 15553/1000000 [6:30:25<2068:39:45,  7.56s/it, lr=1e-5, step_loss=0.105][RANK-0]: Step: [15553], local_loss=0.009411857463419437, train_loss=0.024173498153686523, time_cost=1.2154052257537842
Steps:   2%|▏         | 15553/1000000 [6:30:25<2068:39:45,  7.56s/it, lr=1e-5, step_loss=0.00941]Steps:   2%|▏         | 15554/1000000 [6:30:34<2189:31:46,  8.01s/it, lr=1e-5, step_loss=0.00941][RANK-0]: Step: [15554], local_loss=0.014672022312879562, train_loss=0.021031677722930908, time_cost=2.2256574630737305
Steps:   2%|▏         | 15554/1000000 [6:30:34<2189:31:46,  8.01s/it, lr=1e-5, step_loss=0.0147] Steps:   2%|▏         | 15555/1000000 [6:30:38<1877:44:37,  6.87s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [15555], local_loss=0.07688047736883163, train_loss=0.03162030130624771, time_cost=2.7346351146698
Steps:   2%|▏         | 15555/1000000 [6:30:38<1877:44:37,  6.87s/it, lr=1e-5, step_loss=0.0769]Steps:   2%|▏         | 15556/1000000 [6:30:47<2080:52:27,  7.61s/it, lr=1e-5, step_loss=0.0769][RANK-0]: Step: [15556], local_loss=0.07727732509374619, train_loss=0.04707441106438637, time_cost=1.2076737880706787
Steps:   2%|▏         | 15556/1000000 [6:30:47<2080:52:27,  7.61s/it, lr=1e-5, step_loss=0.0773]Steps:   2%|▏         | 15557/1000000 [6:30:54<2039:39:07,  7.46s/it, lr=1e-5, step_loss=0.0773][RANK-0]: Step: [15557], local_loss=0.004352306015789509, train_loss=0.02982574887573719, time_cost=1.7779638767242432
Steps:   2%|▏         | 15557/1000000 [6:30:54<2039:39:07,  7.46s/it, lr=1e-5, step_loss=0.00435]Steps:   2%|▏         | 15558/1000000 [6:31:04<2240:45:55,  8.19s/it, lr=1e-5, step_loss=0.00435][RANK-0]: Step: [15558], local_loss=0.010183960199356079, train_loss=8.613402366638184, time_cost=8.243403911590576
Steps:   2%|▏         | 15558/1000000 [6:31:04<2240:45:55,  8.19s/it, lr=1e-5, step_loss=0.0102] Steps:   2%|▏         | 15559/1000000 [6:31:11<2153:19:20,  7.87s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [15559], local_loss=0.02493259683251381, train_loss=0.06981076300144196, time_cost=3.4205853939056396
Steps:   2%|▏         | 15559/1000000 [6:31:11<2153:19:20,  7.87s/it, lr=1e-5, step_loss=0.0249]Steps:   2%|▏         | 15560/1000000 [6:31:23<2415:21:40,  8.83s/it, lr=1e-5, step_loss=0.0249][RANK-0]: Step: [15560], local_loss=0.20207728445529938, train_loss=0.14562247693538666, time_cost=2.527662754058838
Steps:   2%|▏         | 15560/1000000 [6:31:23<2415:21:40,  8.83s/it, lr=1e-5, step_loss=0.202] Steps:   2%|▏         | 15561/1000000 [6:31:28<2176:23:31,  7.96s/it, lr=1e-5, step_loss=0.202][RANK-0]: Step: [15561], local_loss=0.19755421578884125, train_loss=0.061868634074926376, time_cost=1.4543490409851074
Steps:   2%|▏         | 15561/1000000 [6:31:28<2176:23:31,  7.96s/it, lr=1e-5, step_loss=0.198]Steps:   2%|▏         | 15562/1000000 [6:31:40<2431:54:00,  8.89s/it, lr=1e-5, step_loss=0.198][RANK-0]: Step: [15562], local_loss=0.006673290394246578, train_loss=0.06353043019771576, time_cost=3.7003724575042725
Steps:   2%|▏         | 15562/1000000 [6:31:40<2431:54:00,  8.89s/it, lr=1e-5, step_loss=0.00667]Steps:   2%|▏         | 15563/1000000 [6:31:50<2600:19:25,  9.51s/it, lr=1e-5, step_loss=0.00667][RANK-0]: Step: [15563], local_loss=0.006343237590044737, train_loss=0.1206965446472168, time_cost=4.578745365142822
Steps:   2%|▏         | 15563/1000000 [6:31:50<2600:19:25,  9.51s/it, lr=1e-5, step_loss=0.00634]Steps:   2%|▏         | 15564/1000000 [6:32:04<2924:38:30, 10.70s/it, lr=1e-5, step_loss=0.00634][RANK-0]: Step: [15564], local_loss=0.04787604138255119, train_loss=0.06690176576375961, time_cost=1.3334267139434814
Steps:   2%|▏         | 15564/1000000 [6:32:04<2924:38:30, 10.70s/it, lr=1e-5, step_loss=0.0479] Steps:   2%|▏         | 15565/1000000 [6:32:10<2547:49:36,  9.32s/it, lr=1e-5, step_loss=0.0479][RANK-0]: Step: [15565], local_loss=0.010800402611494064, train_loss=0.03718475252389908, time_cost=2.501281261444092
Steps:   2%|▏         | 15565/1000000 [6:32:10<2547:49:36,  9.32s/it, lr=1e-5, step_loss=0.0108]Steps:   2%|▏         | 15566/1000000 [6:32:18<2399:42:56,  8.78s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [15566], local_loss=0.013113096356391907, train_loss=0.042285315692424774, time_cost=2.994142770767212
Steps:   2%|▏         | 15566/1000000 [6:32:18<2399:42:56,  8.78s/it, lr=1e-5, step_loss=0.0131]Steps:   2%|▏         | 15567/1000000 [6:32:33<2926:48:44, 10.70s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [15567], local_loss=0.07536033540964127, train_loss=0.17866122722625732, time_cost=5.408966541290283
Steps:   2%|▏         | 15567/1000000 [6:32:33<2926:48:44, 10.70s/it, lr=1e-5, step_loss=0.0754]Steps:   2%|▏         | 15568/1000000 [6:32:41<2685:58:48,  9.82s/it, lr=1e-5, step_loss=0.0754][RANK-0]: Step: [15568], local_loss=0.01268046349287033, train_loss=0.14358928799629211, time_cost=1.75813627243042
Steps:   2%|▏         | 15568/1000000 [6:32:41<2685:58:48,  9.82s/it, lr=1e-5, step_loss=0.0127]Steps:   2%|▏         | 15569/1000000 [6:32:50<2625:38:12,  9.60s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [15569], local_loss=0.012281329371035099, train_loss=0.042702481150627136, time_cost=2.633920907974243
Steps:   2%|▏         | 15569/1000000 [6:32:50<2625:38:12,  9.60s/it, lr=1e-5, step_loss=0.0123]Steps:   2%|▏         | 15570/1000000 [6:32:56<2323:54:45,  8.50s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [15570], local_loss=0.1916908621788025, train_loss=0.05405258387327194, time_cost=3.09161114692688
Steps:   2%|▏         | 15570/1000000 [6:32:56<2323:54:45,  8.50s/it, lr=1e-5, step_loss=0.192] Steps:   2%|▏         | 15571/1000000 [6:33:03<2208:16:44,  8.08s/it, lr=1e-5, step_loss=0.192][RANK-0]: Step: [15571], local_loss=0.022606918588280678, train_loss=0.03401722386479378, time_cost=2.654572010040283
Steps:   2%|▏         | 15571/1000000 [6:33:03<2208:16:44,  8.08s/it, lr=1e-5, step_loss=0.0226]Steps:   2%|▏         | 15572/1000000 [6:33:18<2778:01:19, 10.16s/it, lr=1e-5, step_loss=0.0226][RANK-0]: Step: [15572], local_loss=0.05559545382857323, train_loss=0.2226513922214508, time_cost=11.615381717681885
Steps:   2%|▏         | 15572/1000000 [6:33:18<2778:01:19, 10.16s/it, lr=1e-5, step_loss=0.0556]Steps:   2%|▏         | 15573/1000000 [6:33:26<2636:53:13,  9.64s/it, lr=1e-5, step_loss=0.0556][RANK-0]: Step: [15573], local_loss=0.016054796054959297, train_loss=0.022661369293928146, time_cost=4.425785779953003
Steps:   2%|▏         | 15573/1000000 [6:33:26<2636:53:13,  9.64s/it, lr=1e-5, step_loss=0.0161]Steps:   2%|▏         | 15574/1000000 [6:33:30<2176:26:40,  7.96s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [15574], local_loss=0.049927420914173126, train_loss=0.05243149399757385, time_cost=1.2772550582885742
Steps:   2%|▏         | 15574/1000000 [6:33:30<2176:26:40,  7.96s/it, lr=1e-5, step_loss=0.0499]Steps:   2%|▏         | 15575/1000000 [6:33:39<2235:58:10,  8.18s/it, lr=1e-5, step_loss=0.0499][RANK-0]: Step: [15575], local_loss=0.149429053068161, train_loss=0.05734359845519066, time_cost=2.5420544147491455
Steps:   2%|▏         | 15575/1000000 [6:33:39<2235:58:10,  8.18s/it, lr=1e-5, step_loss=0.149] Steps:   2%|▏         | 15576/1000000 [6:33:53<2764:04:50, 10.11s/it, lr=1e-5, step_loss=0.149][RANK-0]: Step: [15576], local_loss=0.012900306843221188, train_loss=0.017599325627088547, time_cost=1.2132213115692139
Steps:   2%|▏         | 15576/1000000 [6:33:53<2764:04:50, 10.11s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 15577/1000000 [6:34:00<2478:16:43,  9.06s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [15577], local_loss=0.011746319942176342, train_loss=0.03314206004142761, time_cost=1.21431303024292
Steps:   2%|▏         | 15577/1000000 [6:34:00<2478:16:43,  9.06s/it, lr=1e-5, step_loss=0.0117]Steps:   2%|▏         | 15578/1000000 [6:34:09<2502:08:11,  9.15s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [15578], local_loss=0.026706332340836525, train_loss=0.04863418638706207, time_cost=5.78933310508728
Steps:   2%|▏         | 15578/1000000 [6:34:09<2502:08:11,  9.15s/it, lr=1e-5, step_loss=0.0267]Steps:   2%|▏         | 15579/1000000 [6:34:21<2696:47:00,  9.86s/it, lr=1e-5, step_loss=0.0267][RANK-0]: Step: [15579], local_loss=0.0503714494407177, train_loss=0.0348631851375103, time_cost=3.317157030105591
Steps:   2%|▏         | 15579/1000000 [6:34:21<2696:47:00,  9.86s/it, lr=1e-5, step_loss=0.0504]Steps:   2%|▏         | 15580/1000000 [6:34:25<2245:10:57,  8.21s/it, lr=1e-5, step_loss=0.0504][RANK-0]: Step: [15580], local_loss=0.3712567985057831, train_loss=0.07858584821224213, time_cost=1.7320306301116943
Steps:   2%|▏         | 15580/1000000 [6:34:25<2245:10:57,  8.21s/it, lr=1e-5, step_loss=0.371] Steps:   2%|▏         | 15581/1000000 [6:34:38<2637:36:01,  9.65s/it, lr=1e-5, step_loss=0.371][RANK-0]: Step: [15581], local_loss=0.006090318318456411, train_loss=0.018079636618494987, time_cost=5.955573081970215
Steps:   2%|▏         | 15581/1000000 [6:34:38<2637:36:01,  9.65s/it, lr=1e-5, step_loss=0.00609]Steps:   2%|▏         | 15582/1000000 [6:34:44<2277:45:47,  8.33s/it, lr=1e-5, step_loss=0.00609][RANK-0]: Step: [15582], local_loss=0.043347008526325226, train_loss=0.026008455082774162, time_cost=2.8124232292175293
Steps:   2%|▏         | 15582/1000000 [6:34:44<2277:45:47,  8.33s/it, lr=1e-5, step_loss=0.0433] Steps:   2%|▏         | 15583/1000000 [6:34:55<2503:57:38,  9.16s/it, lr=1e-5, step_loss=0.0433][RANK-0]: Step: [15583], local_loss=0.0074723404832184315, train_loss=0.040040042251348495, time_cost=3.8093655109405518
Steps:   2%|▏         | 15583/1000000 [6:34:55<2503:57:38,  9.16s/it, lr=1e-5, step_loss=0.00747]Steps:   2%|▏         | 15584/1000000 [6:35:07<2759:47:08, 10.09s/it, lr=1e-5, step_loss=0.00747][RANK-0]: Step: [15584], local_loss=0.3844812214374542, train_loss=0.06715899705886841, time_cost=1.2423732280731201
Steps:   2%|▏         | 15584/1000000 [6:35:07<2759:47:08, 10.09s/it, lr=1e-5, step_loss=0.384]  Steps:   2%|▏         | 15585/1000000 [6:35:11<2283:19:58,  8.35s/it, lr=1e-5, step_loss=0.384][RANK-0]: Step: [15585], local_loss=0.013897492550313473, train_loss=0.023951534181833267, time_cost=2.475778102874756
Steps:   2%|▏         | 15585/1000000 [6:35:11<2283:19:58,  8.35s/it, lr=1e-5, step_loss=0.0139]Steps:   2%|▏         | 15586/1000000 [6:35:16<2007:43:36,  7.34s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [15586], local_loss=0.026483118534088135, train_loss=0.024334076792001724, time_cost=2.311784267425537
Steps:   2%|▏         | 15586/1000000 [6:35:16<2007:43:36,  7.34s/it, lr=1e-5, step_loss=0.0265]Steps:   2%|▏         | 15587/1000000 [6:35:27<2291:34:03,  8.38s/it, lr=1e-5, step_loss=0.0265][RANK-0]: Step: [15587], local_loss=0.018080271780490875, train_loss=0.026960015296936035, time_cost=4.209447383880615
Steps:   2%|▏         | 15587/1000000 [6:35:27<2291:34:03,  8.38s/it, lr=1e-5, step_loss=0.0181]Steps:   2%|▏         | 15588/1000000 [6:35:34<2216:04:15,  8.10s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [15588], local_loss=0.008617171086370945, train_loss=0.0173588115721941, time_cost=5.226836204528809
Steps:   2%|▏         | 15588/1000000 [6:35:34<2216:04:15,  8.10s/it, lr=1e-5, step_loss=0.00862]Steps:   2%|▏         | 15589/1000000 [6:35:41<2125:47:48,  7.77s/it, lr=1e-5, step_loss=0.00862][RANK-0]: Step: [15589], local_loss=0.008895151317119598, train_loss=0.011015417985618114, time_cost=2.4730255603790283
Steps:   2%|▏         | 15589/1000000 [6:35:41<2125:47:48,  7.77s/it, lr=1e-5, step_loss=0.0089] Steps:   2%|▏         | 15590/1000000 [6:35:49<2072:52:19,  7.58s/it, lr=1e-5, step_loss=0.0089][RANK-0]: Step: [15590], local_loss=0.05033746361732483, train_loss=0.03402918577194214, time_cost=2.888990640640259
Steps:   2%|▏         | 15590/1000000 [6:35:49<2072:52:19,  7.58s/it, lr=1e-5, step_loss=0.0503]Steps:   2%|▏         | 15591/1000000 [6:35:57<2116:29:40,  7.74s/it, lr=1e-5, step_loss=0.0503][RANK-0]: Step: [15591], local_loss=0.02543313428759575, train_loss=0.0537930466234684, time_cost=2.4388153553009033
Steps:   2%|▏         | 15591/1000000 [6:35:57<2116:29:40,  7.74s/it, lr=1e-5, step_loss=0.0254]Steps:   2%|▏         | 15592/1000000 [6:36:08<2433:22:07,  8.90s/it, lr=1e-5, step_loss=0.0254][RANK-0]: Step: [15592], local_loss=0.005518237128853798, train_loss=1.090060830116272, time_cost=5.454664945602417
Steps:   2%|▏         | 15592/1000000 [6:36:08<2433:22:07,  8.90s/it, lr=1e-5, step_loss=0.00552]Steps:   2%|▏         | 15593/1000000 [6:36:17<2401:44:59,  8.78s/it, lr=1e-5, step_loss=0.00552][RANK-0]: Step: [15593], local_loss=0.005295829847455025, train_loss=0.16278886795043945, time_cost=3.2239441871643066
Steps:   2%|▏         | 15593/1000000 [6:36:17<2401:44:59,  8.78s/it, lr=1e-5, step_loss=0.0053] Steps:   2%|▏         | 15594/1000000 [6:36:31<2828:11:37, 10.34s/it, lr=1e-5, step_loss=0.0053][RANK-0]: Step: [15594], local_loss=0.007142487447708845, train_loss=0.38645321130752563, time_cost=6.207723617553711
Steps:   2%|▏         | 15594/1000000 [6:36:31<2828:11:37, 10.34s/it, lr=1e-5, step_loss=0.00714]Steps:   2%|▏         | 15595/1000000 [6:36:45<3108:10:39, 11.37s/it, lr=1e-5, step_loss=0.00714][RANK-0]: Step: [15595], local_loss=0.005621781572699547, train_loss=0.1397213339805603, time_cost=4.736748456954956
Steps:   2%|▏         | 15595/1000000 [6:36:45<3108:10:39, 11.37s/it, lr=1e-5, step_loss=0.00562]Steps:   2%|▏         | 15596/1000000 [6:36:55<3060:38:12, 11.19s/it, lr=1e-5, step_loss=0.00562][RANK-0]: Step: [15596], local_loss=0.013542700558900833, train_loss=0.08756927400827408, time_cost=3.81042742729187
Steps:   2%|▏         | 15596/1000000 [6:36:55<3060:38:12, 11.19s/it, lr=1e-5, step_loss=0.0135] Steps:   2%|▏         | 15597/1000000 [6:37:04<2836:28:36, 10.37s/it, lr=1e-5, step_loss=0.0135][RANK-0]: Step: [15597], local_loss=0.007058187387883663, train_loss=0.09724284708499908, time_cost=3.301635980606079
Steps:   2%|▏         | 15597/1000000 [6:37:04<2836:28:36, 10.37s/it, lr=1e-5, step_loss=0.00706]Steps:   2%|▏         | 15598/1000000 [6:37:09<2414:16:54,  8.83s/it, lr=1e-5, step_loss=0.00706][RANK-0]: Step: [15598], local_loss=0.03264898434281349, train_loss=0.026556510478258133, time_cost=3.9708094596862793
Steps:   2%|▏         | 15598/1000000 [6:37:09<2414:16:54,  8.83s/it, lr=1e-5, step_loss=0.0326] Steps:   2%|▏         | 15599/1000000 [6:37:18<2419:29:43,  8.85s/it, lr=1e-5, step_loss=0.0326][RANK-0]: Step: [15599], local_loss=0.03587358072400093, train_loss=0.07484135031700134, time_cost=2.945590019226074
Steps:   2%|▏         | 15599/1000000 [6:37:18<2419:29:43,  8.85s/it, lr=1e-5, step_loss=0.0359]Steps:   2%|▏         | 15600/1000000 [6:37:29<2582:35:11,  9.44s/it, lr=1e-5, step_loss=0.0359][RANK-0]: Step: [15600], local_loss=0.012744734063744545, train_loss=0.19200938940048218, time_cost=2.135711431503296
Steps:   2%|▏         | 15600/1000000 [6:37:29<2582:35:11,  9.44s/it, lr=1e-5, step_loss=0.0127]Steps:   2%|▏         | 15601/1000000 [6:37:33<2168:14:44,  7.93s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [15601], local_loss=0.039301253855228424, train_loss=0.02455110102891922, time_cost=3.165303945541382
Steps:   2%|▏         | 15601/1000000 [6:37:33<2168:14:44,  7.93s/it, lr=1e-5, step_loss=0.0393]Steps:   2%|▏         | 15602/1000000 [6:37:48<2738:18:35, 10.01s/it, lr=1e-5, step_loss=0.0393][RANK-0]: Step: [15602], local_loss=0.010992239229381084, train_loss=0.03173946216702461, time_cost=5.639688730239868
Steps:   2%|▏         | 15602/1000000 [6:37:48<2738:18:35, 10.01s/it, lr=1e-5, step_loss=0.011] Steps:   2%|▏         | 15603/1000000 [6:37:56<2533:07:06,  9.26s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [15603], local_loss=0.02064868062734604, train_loss=0.07780296355485916, time_cost=3.45090913772583
Steps:   2%|▏         | 15603/1000000 [6:37:56<2533:07:06,  9.26s/it, lr=1e-5, step_loss=0.0206]Steps:   2%|▏         | 15604/1000000 [6:38:08<2757:19:56, 10.08s/it, lr=1e-5, step_loss=0.0206][RANK-0]: Step: [15604], local_loss=0.05113076791167259, train_loss=0.11063607782125473, time_cost=1.294283151626587
Steps:   2%|▏         | 15604/1000000 [6:38:08<2757:19:56, 10.08s/it, lr=1e-5, step_loss=0.0511]Steps:   2%|▏         | 15605/1000000 [6:38:22<3080:44:46, 11.27s/it, lr=1e-5, step_loss=0.0511][RANK-0]: Step: [15605], local_loss=0.008525251410901546, train_loss=0.07597243785858154, time_cost=4.464200496673584
Steps:   2%|▏         | 15605/1000000 [6:38:22<3080:44:46, 11.27s/it, lr=1e-5, step_loss=0.00853]Steps:   2%|▏         | 15606/1000000 [6:38:29<2769:05:03, 10.13s/it, lr=1e-5, step_loss=0.00853][RANK-0]: Step: [15606], local_loss=0.14463676512241364, train_loss=0.2750568985939026, time_cost=1.7013812065124512
Steps:   2%|▏         | 15606/1000000 [6:38:29<2769:05:03, 10.13s/it, lr=1e-5, step_loss=0.145]  Steps:   2%|▏         | 15607/1000000 [6:38:43<3060:51:29, 11.19s/it, lr=1e-5, step_loss=0.145][RANK-0]: Step: [15607], local_loss=0.004201638977974653, train_loss=8.871679306030273, time_cost=1.9214184284210205
Steps:   2%|▏         | 15607/1000000 [6:38:43<3060:51:29, 11.19s/it, lr=1e-5, step_loss=0.0042]Steps:   2%|▏         | 15608/1000000 [6:38:49<2687:11:17,  9.83s/it, lr=1e-5, step_loss=0.0042][RANK-0]: Step: [15608], local_loss=0.006328396499156952, train_loss=0.02136976830661297, time_cost=1.4622957706451416
Steps:   2%|▏         | 15608/1000000 [6:38:49<2687:11:17,  9.83s/it, lr=1e-5, step_loss=0.00633]Steps:   2%|▏         | 15609/1000000 [6:38:55<2352:16:30,  8.60s/it, lr=1e-5, step_loss=0.00633][RANK-0]: Step: [15609], local_loss=0.0042337835766375065, train_loss=0.11116281896829605, time_cost=2.9886441230773926
Steps:   2%|▏         | 15609/1000000 [6:38:55<2352:16:30,  8.60s/it, lr=1e-5, step_loss=0.00423]Steps:   2%|▏         | 15610/1000000 [6:39:05<2493:16:37,  9.12s/it, lr=1e-5, step_loss=0.00423][RANK-0]: Step: [15610], local_loss=0.046790916472673416, train_loss=17.047578811645508, time_cost=2.3905487060546875
Steps:   2%|▏         | 15610/1000000 [6:39:05<2493:16:37,  9.12s/it, lr=1e-5, step_loss=0.0468] Steps:   2%|▏         | 15611/1000000 [6:39:14<2414:16:59,  8.83s/it, lr=1e-5, step_loss=0.0468][RANK-0]: Step: [15611], local_loss=0.007991538383066654, train_loss=28.26620101928711, time_cost=3.7519643306732178
Steps:   2%|▏         | 15611/1000000 [6:39:14<2414:16:59,  8.83s/it, lr=1e-5, step_loss=0.00799]Steps:   2%|▏         | 15612/1000000 [6:39:26<2730:39:06,  9.99s/it, lr=1e-5, step_loss=0.00799][RANK-0]: Step: [15612], local_loss=0.06366720050573349, train_loss=0.05664185434579849, time_cost=4.919127702713013
Steps:   2%|▏         | 15612/1000000 [6:39:26<2730:39:06,  9.99s/it, lr=1e-5, step_loss=0.0637] Steps:   2%|▏         | 15613/1000000 [6:39:32<2344:28:26,  8.57s/it, lr=1e-5, step_loss=0.0637][RANK-0]: Step: [15613], local_loss=0.016027506440877914, train_loss=0.02307170256972313, time_cost=2.6094136238098145
Steps:   2%|▏         | 15613/1000000 [6:39:32<2344:28:26,  8.57s/it, lr=1e-5, step_loss=0.016] Steps:   2%|▏         | 15614/1000000 [6:39:37<2075:39:00,  7.59s/it, lr=1e-5, step_loss=0.016][RANK-0]: Step: [15614], local_loss=0.004649835173040628, train_loss=0.04769787937402725, time_cost=2.886439800262451
Steps:   2%|▏         | 15614/1000000 [6:39:37<2075:39:00,  7.59s/it, lr=1e-5, step_loss=0.00465]Steps:   2%|▏         | 15615/1000000 [6:39:50<2571:10:47,  9.40s/it, lr=1e-5, step_loss=0.00465][RANK-0]: Step: [15615], local_loss=0.003752528689801693, train_loss=0.012232628650963306, time_cost=5.304409503936768
Steps:   2%|▏         | 15615/1000000 [6:39:50<2571:10:47,  9.40s/it, lr=1e-5, step_loss=0.00375]Steps:   2%|▏         | 15616/1000000 [6:39:55<2209:42:17,  8.08s/it, lr=1e-5, step_loss=0.00375][RANK-0]: Step: [15616], local_loss=0.010436407290399075, train_loss=0.04751342162489891, time_cost=3.728815793991089
Steps:   2%|▏         | 15616/1000000 [6:39:55<2209:42:17,  8.08s/it, lr=1e-5, step_loss=0.0104] Steps:   2%|▏         | 15617/1000000 [6:40:06<2429:46:23,  8.89s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [15617], local_loss=0.012801036238670349, train_loss=0.047039248049259186, time_cost=2.505244493484497
Steps:   2%|▏         | 15617/1000000 [6:40:06<2429:46:23,  8.89s/it, lr=1e-5, step_loss=0.0128]Steps:   2%|▏         | 15618/1000000 [6:40:17<2563:34:31,  9.38s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [15618], local_loss=0.04565777629613876, train_loss=0.021426718682050705, time_cost=9.176487922668457
Steps:   2%|▏         | 15618/1000000 [6:40:17<2563:34:31,  9.38s/it, lr=1e-5, step_loss=0.0457]Steps:   2%|▏         | 15619/1000000 [6:40:22<2263:12:46,  8.28s/it, lr=1e-5, step_loss=0.0457][RANK-0]: Step: [15619], local_loss=0.053146157413721085, train_loss=0.039102062582969666, time_cost=1.7702860832214355
Steps:   2%|▏         | 15619/1000000 [6:40:22<2263:12:46,  8.28s/it, lr=1e-5, step_loss=0.0531]Steps:   2%|▏         | 15620/1000000 [6:40:30<2177:49:01,  7.96s/it, lr=1e-5, step_loss=0.0531][RANK-0]: Step: [15620], local_loss=0.0601961649954319, train_loss=0.038689881563186646, time_cost=2.6213414669036865
Steps:   2%|▏         | 15620/1000000 [6:40:30<2177:49:01,  7.96s/it, lr=1e-5, step_loss=0.0602]Steps:   2%|▏         | 15621/1000000 [6:40:38<2242:17:32,  8.20s/it, lr=1e-5, step_loss=0.0602][RANK-0]: Step: [15621], local_loss=0.006757800001651049, train_loss=0.11310890316963196, time_cost=1.3062562942504883
Steps:   2%|▏         | 15621/1000000 [6:40:38<2242:17:32,  8.20s/it, lr=1e-5, step_loss=0.00676]Steps:   2%|▏         | 15622/1000000 [6:40:51<2596:37:18,  9.50s/it, lr=1e-5, step_loss=0.00676][RANK-0]: Step: [15622], local_loss=0.2994726002216339, train_loss=0.07614775002002716, time_cost=4.078927278518677
Steps:   2%|▏         | 15622/1000000 [6:40:51<2596:37:18,  9.50s/it, lr=1e-5, step_loss=0.299]  Steps:   2%|▏         | 15623/1000000 [6:41:05<2985:24:51, 10.92s/it, lr=1e-5, step_loss=0.299][RANK-0]: Step: [15623], local_loss=0.0050330692902207375, train_loss=0.011291499249637127, time_cost=7.4817280769348145
Steps:   2%|▏         | 15623/1000000 [6:41:05<2985:24:51, 10.92s/it, lr=1e-5, step_loss=0.00503]Steps:   2%|▏         | 15624/1000000 [6:41:18<3149:06:59, 11.52s/it, lr=1e-5, step_loss=0.00503][RANK-0]: Step: [15624], local_loss=0.005977982189506292, train_loss=0.018085112795233727, time_cost=3.696650981903076
Steps:   2%|▏         | 15624/1000000 [6:41:18<3149:06:59, 11.52s/it, lr=1e-5, step_loss=0.00598]Steps:   2%|▏         | 15625/1000000 [6:41:31<3272:07:58, 11.97s/it, lr=1e-5, step_loss=0.00598][RANK-0]: Step: [15625], local_loss=0.014326440170407295, train_loss=0.019450737163424492, time_cost=3.680990695953369
Steps:   2%|▏         | 15625/1000000 [6:41:31<3272:07:58, 11.97s/it, lr=1e-5, step_loss=0.0143] Steps:   2%|▏         | 15626/1000000 [6:41:35<2650:09:53,  9.69s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [15626], local_loss=0.07287479937076569, train_loss=0.04113946855068207, time_cost=1.581094741821289
Steps:   2%|▏         | 15626/1000000 [6:41:35<2650:09:53,  9.69s/it, lr=1e-5, step_loss=0.0729]Steps:   2%|▏         | 15627/1000000 [6:41:46<2715:39:04,  9.93s/it, lr=1e-5, step_loss=0.0729][RANK-0]: Step: [15627], local_loss=0.033727340400218964, train_loss=0.02533002756536007, time_cost=2.7586843967437744
Steps:   2%|▏         | 15627/1000000 [6:41:46<2715:39:04,  9.93s/it, lr=1e-5, step_loss=0.0337]Steps:   2%|▏         | 15628/1000000 [6:42:01<3162:41:50, 11.57s/it, lr=1e-5, step_loss=0.0337][RANK-0]: Step: [15628], local_loss=0.007161623332649469, train_loss=0.0402010902762413, time_cost=9.591418027877808
Steps:   2%|▏         | 15628/1000000 [6:42:01<3162:41:50, 11.57s/it, lr=1e-5, step_loss=0.00716]Steps:   2%|▏         | 15629/1000000 [6:42:20<3708:49:43, 13.56s/it, lr=1e-5, step_loss=0.00716][RANK-0]: Step: [15629], local_loss=0.03967589884996414, train_loss=0.014140350744128227, time_cost=9.130221128463745
Steps:   2%|▏         | 15629/1000000 [6:42:20<3708:49:43, 13.56s/it, lr=1e-5, step_loss=0.0397] Steps:   2%|▏         | 15630/1000000 [6:42:30<3485:34:45, 12.75s/it, lr=1e-5, step_loss=0.0397][RANK-0]: Step: [15630], local_loss=0.015824628993868828, train_loss=0.0225767083466053, time_cost=2.085530996322632
Steps:   2%|▏         | 15630/1000000 [6:42:30<3485:34:45, 12.75s/it, lr=1e-5, step_loss=0.0158]Steps:   2%|▏         | 15631/1000000 [6:42:36<2858:50:51, 10.46s/it, lr=1e-5, step_loss=0.0158][RANK-0]: Step: [15631], local_loss=0.009300276637077332, train_loss=0.014972344040870667, time_cost=1.2059857845306396
Steps:   2%|▏         | 15631/1000000 [6:42:36<2858:50:51, 10.46s/it, lr=1e-5, step_loss=0.0093]Steps:   2%|▏         | 15632/1000000 [6:42:41<2457:22:33,  8.99s/it, lr=1e-5, step_loss=0.0093][RANK-0]: Step: [15632], local_loss=0.012594866566359997, train_loss=0.07982127368450165, time_cost=3.225529432296753
Steps:   2%|▏         | 15632/1000000 [6:42:41<2457:22:33,  8.99s/it, lr=1e-5, step_loss=0.0126]Steps:   2%|▏         | 15633/1000000 [6:42:57<3009:03:59, 11.00s/it, lr=1e-5, step_loss=0.0126][RANK-0]: Step: [15633], local_loss=0.004593780729919672, train_loss=0.06480157375335693, time_cost=7.446274757385254
Steps:   2%|▏         | 15633/1000000 [6:42:57<3009:03:59, 11.00s/it, lr=1e-5, step_loss=0.00459]Steps:   2%|▏         | 15634/1000000 [6:43:02<2543:56:47,  9.30s/it, lr=1e-5, step_loss=0.00459][RANK-0]: Step: [15634], local_loss=0.02785247564315796, train_loss=0.029182959347963333, time_cost=1.2156565189361572
Steps:   2%|▏         | 15634/1000000 [6:43:02<2543:56:47,  9.30s/it, lr=1e-5, step_loss=0.0279] Steps:   2%|▏         | 15635/1000000 [6:43:11<2535:06:17,  9.27s/it, lr=1e-5, step_loss=0.0279][RANK-0]: Step: [15635], local_loss=0.2431022971868515, train_loss=0.05278995633125305, time_cost=7.731976747512817
Steps:   2%|▏         | 15635/1000000 [6:43:11<2535:06:17,  9.27s/it, lr=1e-5, step_loss=0.243] Steps:   2%|▏         | 15636/1000000 [6:43:22<2661:18:05,  9.73s/it, lr=1e-5, step_loss=0.243][RANK-0]: Step: [15636], local_loss=0.05294563248753548, train_loss=0.08265966922044754, time_cost=4.089928150177002
Steps:   2%|▏         | 15636/1000000 [6:43:22<2661:18:05,  9.73s/it, lr=1e-5, step_loss=0.0529]Steps:   2%|▏         | 15637/1000000 [6:43:28<2327:03:45,  8.51s/it, lr=1e-5, step_loss=0.0529][RANK-0]: Step: [15637], local_loss=0.041153084486722946, train_loss=0.11015605181455612, time_cost=2.1393566131591797
Steps:   2%|▏         | 15637/1000000 [6:43:28<2327:03:45,  8.51s/it, lr=1e-5, step_loss=0.0412]Steps:   2%|▏         | 15638/1000000 [6:43:33<2050:42:23,  7.50s/it, lr=1e-5, step_loss=0.0412][RANK-0]: Step: [15638], local_loss=0.003391328966245055, train_loss=0.09963500499725342, time_cost=2.206839084625244
Steps:   2%|▏         | 15638/1000000 [6:43:33<2050:42:23,  7.50s/it, lr=1e-5, step_loss=0.00339]Steps:   2%|▏         | 15639/1000000 [6:43:47<2569:37:16,  9.40s/it, lr=1e-5, step_loss=0.00339][RANK-0]: Step: [15639], local_loss=0.0053998492658138275, train_loss=0.08900469541549683, time_cost=4.348053932189941
Steps:   2%|▏         | 15639/1000000 [6:43:47<2569:37:16,  9.40s/it, lr=1e-5, step_loss=0.0054] Steps:   2%|▏         | 15640/1000000 [6:44:00<2921:54:03, 10.69s/it, lr=1e-5, step_loss=0.0054][RANK-0]: Step: [15640], local_loss=0.1452532261610031, train_loss=0.03453781455755234, time_cost=3.499854564666748
Steps:   2%|▏         | 15640/1000000 [6:44:00<2921:54:03, 10.69s/it, lr=1e-5, step_loss=0.145] Steps:   2%|▏         | 15641/1000000 [6:44:11<2889:45:52, 10.57s/it, lr=1e-5, step_loss=0.145][RANK-0]: Step: [15641], local_loss=0.010673725977540016, train_loss=12.246957778930664, time_cost=8.768412828445435
Steps:   2%|▏         | 15641/1000000 [6:44:11<2889:45:52, 10.57s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 15642/1000000 [6:44:15<2374:27:32,  8.68s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [15642], local_loss=0.01109648123383522, train_loss=0.026690615341067314, time_cost=1.4800159931182861
Steps:   2%|▏         | 15642/1000000 [6:44:15<2374:27:32,  8.68s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 15643/1000000 [6:44:26<2560:16:32,  9.36s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [15643], local_loss=0.03695359453558922, train_loss=0.028669143095612526, time_cost=3.3781299591064453
Steps:   2%|▏         | 15643/1000000 [6:44:26<2560:16:32,  9.36s/it, lr=1e-5, step_loss=0.037] Steps:   2%|▏         | 15644/1000000 [6:44:36<2597:50:00,  9.50s/it, lr=1e-5, step_loss=0.037][RANK-0]: Step: [15644], local_loss=0.02857237681746483, train_loss=0.029308756813406944, time_cost=3.6599793434143066
Steps:   2%|▏         | 15644/1000000 [6:44:36<2597:50:00,  9.50s/it, lr=1e-5, step_loss=0.0286]Steps:   2%|▏         | 15645/1000000 [6:44:40<2190:48:25,  8.01s/it, lr=1e-5, step_loss=0.0286][RANK-0]: Step: [15645], local_loss=0.04233512654900551, train_loss=0.039807409048080444, time_cost=1.6805684566497803
Steps:   2%|▏         | 15645/1000000 [6:44:40<2190:48:25,  8.01s/it, lr=1e-5, step_loss=0.0423]Steps:   2%|▏         | 15646/1000000 [6:44:50<2308:56:51,  8.44s/it, lr=1e-5, step_loss=0.0423][RANK-0]: Step: [15646], local_loss=0.006436832249164581, train_loss=0.0409255251288414, time_cost=4.128899574279785
Steps:   2%|▏         | 15646/1000000 [6:44:50<2308:56:51,  8.44s/it, lr=1e-5, step_loss=0.00644]Steps:   2%|▏         | 15647/1000000 [6:44:56<2095:03:27,  7.66s/it, lr=1e-5, step_loss=0.00644][RANK-0]: Step: [15647], local_loss=0.0051559098064899445, train_loss=0.02619454264640808, time_cost=1.5304973125457764
Steps:   2%|▏         | 15647/1000000 [6:44:56<2095:03:27,  7.66s/it, lr=1e-5, step_loss=0.00516]Steps:   2%|▏         | 15648/1000000 [6:45:01<1918:31:41,  7.02s/it, lr=1e-5, step_loss=0.00516][RANK-0]: Step: [15648], local_loss=0.03153437376022339, train_loss=0.024807538837194443, time_cost=3.095193862915039
Steps:   2%|▏         | 15648/1000000 [6:45:01<1918:31:41,  7.02s/it, lr=1e-5, step_loss=0.0315] Steps:   2%|▏         | 15649/1000000 [6:45:10<2049:43:13,  7.50s/it, lr=1e-5, step_loss=0.0315][RANK-0]: Step: [15649], local_loss=0.004473587032407522, train_loss=0.023616867139935493, time_cost=3.638371706008911
Steps:   2%|▏         | 15649/1000000 [6:45:10<2049:43:13,  7.50s/it, lr=1e-5, step_loss=0.00447]Steps:   2%|▏         | 15650/1000000 [6:45:23<2543:09:31,  9.30s/it, lr=1e-5, step_loss=0.00447][RANK-0]: Step: [15650], local_loss=0.01129573117941618, train_loss=0.046626217663288116, time_cost=4.566904306411743
Steps:   2%|▏         | 15650/1000000 [6:45:23<2543:09:31,  9.30s/it, lr=1e-5, step_loss=0.0113] Steps:   2%|▏         | 15651/1000000 [6:45:28<2141:17:49,  7.83s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [15651], local_loss=0.0388280525803566, train_loss=0.0247315876185894, time_cost=1.4241373538970947
Steps:   2%|▏         | 15651/1000000 [6:45:28<2141:17:49,  7.83s/it, lr=1e-5, step_loss=0.0388]Steps:   2%|▏         | 15652/1000000 [6:45:35<2110:42:19,  7.72s/it, lr=1e-5, step_loss=0.0388][RANK-0]: Step: [15652], local_loss=0.017375390976667404, train_loss=0.01791718602180481, time_cost=2.0077614784240723
Steps:   2%|▏         | 15652/1000000 [6:45:35<2110:42:19,  7.72s/it, lr=1e-5, step_loss=0.0174]Steps:   2%|▏         | 15653/1000000 [6:45:52<2863:51:12, 10.47s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [15653], local_loss=0.007844967767596245, train_loss=0.1528894454240799, time_cost=5.247318983078003
Steps:   2%|▏         | 15653/1000000 [6:45:52<2863:51:12, 10.47s/it, lr=1e-5, step_loss=0.00784]Steps:   2%|▏         | 15654/1000000 [6:46:05<3072:31:07, 11.24s/it, lr=1e-5, step_loss=0.00784][RANK-0]: Step: [15654], local_loss=0.004917331971228123, train_loss=0.011577141471207142, time_cost=1.2446284294128418
Steps:   2%|▏         | 15654/1000000 [6:46:05<3072:31:07, 11.24s/it, lr=1e-5, step_loss=0.00492]Steps:   2%|▏         | 15655/1000000 [6:46:11<2616:30:06,  9.57s/it, lr=1e-5, step_loss=0.00492][RANK-0]: Step: [15655], local_loss=0.04947928711771965, train_loss=0.021230418235063553, time_cost=1.4437148571014404
Steps:   2%|▏         | 15655/1000000 [6:46:11<2616:30:06,  9.57s/it, lr=1e-5, step_loss=0.0495] Steps:   2%|▏         | 15656/1000000 [6:46:15<2216:36:54,  8.11s/it, lr=1e-5, step_loss=0.0495][RANK-0]: Step: [15656], local_loss=0.017131106927990913, train_loss=0.03238750994205475, time_cost=1.698225975036621
Steps:   2%|▏         | 15656/1000000 [6:46:15<2216:36:54,  8.11s/it, lr=1e-5, step_loss=0.0171]Steps:   2%|▏         | 15657/1000000 [6:46:21<1975:00:09,  7.22s/it, lr=1e-5, step_loss=0.0171][RANK-0]: Step: [15657], local_loss=0.010992604307830334, train_loss=0.10995891690254211, time_cost=2.164079427719116
Steps:   2%|▏         | 15657/1000000 [6:46:21<1975:00:09,  7.22s/it, lr=1e-5, step_loss=0.011] Steps:   2%|▏         | 15658/1000000 [6:46:30<2134:49:14,  7.81s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [15658], local_loss=0.10722176730632782, train_loss=28.07648277282715, time_cost=6.981903076171875
Steps:   2%|▏         | 15658/1000000 [6:46:30<2134:49:14,  7.81s/it, lr=1e-5, step_loss=0.107]Steps:   2%|▏         | 15659/1000000 [6:46:36<2037:14:35,  7.45s/it, lr=1e-5, step_loss=0.107][RANK-0]: Step: [15659], local_loss=0.04421154782176018, train_loss=0.02533571794629097, time_cost=1.2109529972076416
Steps:   2%|▏         | 15659/1000000 [6:46:36<2037:14:35,  7.45s/it, lr=1e-5, step_loss=0.0442]Steps:   2%|▏         | 15660/1000000 [6:46:44<2010:51:42,  7.35s/it, lr=1e-5, step_loss=0.0442][RANK-0]: Step: [15660], local_loss=0.3914719521999359, train_loss=0.06851722300052643, time_cost=2.7020435333251953
Steps:   2%|▏         | 15660/1000000 [6:46:44<2010:51:42,  7.35s/it, lr=1e-5, step_loss=0.391] Steps:   2%|▏         | 15661/1000000 [6:46:54<2269:30:44,  8.30s/it, lr=1e-5, step_loss=0.391][RANK-0]: Step: [15661], local_loss=0.013248682953417301, train_loss=0.09105271100997925, time_cost=1.7059574127197266
Steps:   2%|▏         | 15661/1000000 [6:46:54<2269:30:44,  8.30s/it, lr=1e-5, step_loss=0.0132]Steps:   2%|▏         | 15662/1000000 [6:46:58<1951:51:06,  7.14s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [15662], local_loss=0.029163561761379242, train_loss=0.02089376375079155, time_cost=1.5275278091430664
Steps:   2%|▏         | 15662/1000000 [6:46:58<1951:51:06,  7.14s/it, lr=1e-5, step_loss=0.0292]Steps:   2%|▏         | 15663/1000000 [6:47:03<1730:51:46,  6.33s/it, lr=1e-5, step_loss=0.0292][RANK-0]: Step: [15663], local_loss=0.01113869808614254, train_loss=0.024256939068436623, time_cost=1.9039793014526367
Steps:   2%|▏         | 15663/1000000 [6:47:03<1730:51:46,  6.33s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 15664/1000000 [6:47:08<1616:01:56,  5.91s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [15664], local_loss=0.01210557296872139, train_loss=0.15684343874454498, time_cost=1.8297226428985596
Steps:   2%|▏         | 15664/1000000 [6:47:08<1616:01:56,  5.91s/it, lr=1e-5, step_loss=0.0121]Steps:   2%|▏         | 15665/1000000 [6:47:19<2025:36:27,  7.41s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [15665], local_loss=0.026903629302978516, train_loss=0.02587783895432949, time_cost=2.1807262897491455
Steps:   2%|▏         | 15665/1000000 [6:47:19<2025:36:27,  7.41s/it, lr=1e-5, step_loss=0.0269]Steps:   2%|▏         | 15666/1000000 [6:47:26<1987:40:44,  7.27s/it, lr=1e-5, step_loss=0.0269][RANK-0]: Step: [15666], local_loss=0.012737782672047615, train_loss=0.024553272873163223, time_cost=1.2453081607818604
Steps:   2%|▏         | 15666/1000000 [6:47:26<1987:40:44,  7.27s/it, lr=1e-5, step_loss=0.0127]Steps:   2%|▏         | 15667/1000000 [6:47:35<2167:48:36,  7.93s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [15667], local_loss=0.034604959189891815, train_loss=0.03378631919622421, time_cost=3.2527105808258057
Steps:   2%|▏         | 15667/1000000 [6:47:35<2167:48:36,  7.93s/it, lr=1e-5, step_loss=0.0346]Steps:   2%|▏         | 15668/1000000 [6:47:48<2592:24:44,  9.48s/it, lr=1e-5, step_loss=0.0346][RANK-0]: Step: [15668], local_loss=0.10967100411653519, train_loss=0.037471070885658264, time_cost=4.304527282714844
Steps:   2%|▏         | 15668/1000000 [6:47:48<2592:24:44,  9.48s/it, lr=1e-5, step_loss=0.11]  Steps:   2%|▏         | 15669/1000000 [6:47:58<2582:17:45,  9.44s/it, lr=1e-5, step_loss=0.11][RANK-0]: Step: [15669], local_loss=0.013546235859394073, train_loss=0.042166709899902344, time_cost=3.201023578643799
Steps:   2%|▏         | 15669/1000000 [6:47:58<2582:17:45,  9.44s/it, lr=1e-5, step_loss=0.0135]Steps:   2%|▏         | 15670/1000000 [6:48:12<2977:41:05, 10.89s/it, lr=1e-5, step_loss=0.0135][RANK-0]: Step: [15670], local_loss=82.70709991455078, train_loss=13.234606742858887, time_cost=5.630198955535889
Steps:   2%|▏         | 15670/1000000 [6:48:12<2977:41:05, 10.89s/it, lr=1e-5, step_loss=82.7]  Steps:   2%|▏         | 15671/1000000 [6:48:26<3222:19:24, 11.79s/it, lr=1e-5, step_loss=82.7][RANK-0]: Step: [15671], local_loss=0.005358794238418341, train_loss=0.026184197515249252, time_cost=4.621550798416138
Steps:   2%|▏         | 15671/1000000 [6:48:26<3222:19:24, 11.79s/it, lr=1e-5, step_loss=0.00536]Steps:   2%|▏         | 15672/1000000 [6:48:32<2746:49:53, 10.05s/it, lr=1e-5, step_loss=0.00536][RANK-0]: Step: [15672], local_loss=0.007389282342046499, train_loss=0.01839141547679901, time_cost=1.4189982414245605
Steps:   2%|▏         | 15672/1000000 [6:48:32<2746:49:53, 10.05s/it, lr=1e-5, step_loss=0.00739]Steps:   2%|▏         | 15673/1000000 [6:48:37<2325:27:55,  8.50s/it, lr=1e-5, step_loss=0.00739][RANK-0]: Step: [15673], local_loss=0.03565964102745056, train_loss=0.04165733605623245, time_cost=2.444023847579956
Steps:   2%|▏         | 15673/1000000 [6:48:37<2325:27:55,  8.50s/it, lr=1e-5, step_loss=0.0357] Steps:   2%|▏         | 15674/1000000 [6:48:48<2519:21:41,  9.21s/it, lr=1e-5, step_loss=0.0357][RANK-0]: Step: [15674], local_loss=0.10628402233123779, train_loss=0.2908444106578827, time_cost=3.229315757751465
Steps:   2%|▏         | 15674/1000000 [6:48:48<2519:21:41,  9.21s/it, lr=1e-5, step_loss=0.106] Steps:   2%|▏         | 15675/1000000 [6:49:02<2985:24:33, 10.92s/it, lr=1e-5, step_loss=0.106][RANK-0]: Step: [15675], local_loss=0.01575605571269989, train_loss=0.015340365469455719, time_cost=3.4201407432556152
Steps:   2%|▏         | 15675/1000000 [6:49:02<2985:24:33, 10.92s/it, lr=1e-5, step_loss=0.0158]Steps:   2%|▏         | 15676/1000000 [6:49:08<2544:35:20,  9.31s/it, lr=1e-5, step_loss=0.0158][RANK-0]: Step: [15676], local_loss=0.004734508693218231, train_loss=0.0830637738108635, time_cost=1.2893083095550537
Steps:   2%|▏         | 15676/1000000 [6:49:08<2544:35:20,  9.31s/it, lr=1e-5, step_loss=0.00473]Steps:   2%|▏         | 15677/1000000 [6:49:14<2243:23:28,  8.20s/it, lr=1e-5, step_loss=0.00473][RANK-0]: Step: [15677], local_loss=0.01014783326536417, train_loss=0.039840154349803925, time_cost=2.7911322116851807
Steps:   2%|▏         | 15677/1000000 [6:49:14<2243:23:28,  8.20s/it, lr=1e-5, step_loss=0.0101] Steps:   2%|▏         | 15678/1000000 [6:49:23<2361:51:10,  8.64s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [15678], local_loss=0.014440097846090794, train_loss=0.04972486570477486, time_cost=2.729874849319458
Steps:   2%|▏         | 15678/1000000 [6:49:23<2361:51:10,  8.64s/it, lr=1e-5, step_loss=0.0144]Steps:   2%|▏         | 15679/1000000 [6:49:32<2383:42:24,  8.72s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [15679], local_loss=0.052973419427871704, train_loss=0.18825995922088623, time_cost=1.7050631046295166
Steps:   2%|▏         | 15679/1000000 [6:49:32<2383:42:24,  8.72s/it, lr=1e-5, step_loss=0.053] Steps:   2%|▏         | 15680/1000000 [6:49:45<2712:32:32,  9.92s/it, lr=1e-5, step_loss=0.053][RANK-0]: Step: [15680], local_loss=0.010850232094526291, train_loss=0.04376371577382088, time_cost=9.971324682235718
Steps:   2%|▏         | 15680/1000000 [6:49:45<2712:32:32,  9.92s/it, lr=1e-5, step_loss=0.0109]Steps:   2%|▏         | 15681/1000000 [6:49:58<2955:25:41, 10.81s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [15681], local_loss=0.06130107119679451, train_loss=0.02167489379644394, time_cost=4.899867057800293
Steps:   2%|▏         | 15681/1000000 [6:49:58<2955:25:41, 10.81s/it, lr=1e-5, step_loss=0.0613]Steps:   2%|▏         | 15682/1000000 [6:50:05<2659:45:46,  9.73s/it, lr=1e-5, step_loss=0.0613][RANK-0]: Step: [15682], local_loss=0.02896573767066002, train_loss=0.1510169506072998, time_cost=2.677920341491699
Steps:   2%|▏         | 15682/1000000 [6:50:05<2659:45:46,  9.73s/it, lr=1e-5, step_loss=0.029] Steps:   2%|▏         | 15683/1000000 [6:50:17<2840:22:50, 10.39s/it, lr=1e-5, step_loss=0.029][RANK-0]: Step: [15683], local_loss=0.007558157201856375, train_loss=0.018543004989624023, time_cost=4.138721942901611
Steps:   2%|▏         | 15683/1000000 [6:50:17<2840:22:50, 10.39s/it, lr=1e-5, step_loss=0.00756]Steps:   2%|▏         | 15684/1000000 [6:50:26<2753:09:48, 10.07s/it, lr=1e-5, step_loss=0.00756][RANK-0]: Step: [15684], local_loss=0.007002933882176876, train_loss=0.01853599213063717, time_cost=4.2924089431762695
Steps:   2%|▏         | 15684/1000000 [6:50:26<2753:09:48, 10.07s/it, lr=1e-5, step_loss=0.007]  Steps:   2%|▏         | 15685/1000000 [6:50:36<2769:35:34, 10.13s/it, lr=1e-5, step_loss=0.007][RANK-0]: Step: [15685], local_loss=0.15585005283355713, train_loss=0.07891920953989029, time_cost=2.7643134593963623
Steps:   2%|▏         | 15685/1000000 [6:50:36<2769:35:34, 10.13s/it, lr=1e-5, step_loss=0.156]Steps:   2%|▏         | 15686/1000000 [6:50:48<2851:09:10, 10.43s/it, lr=1e-5, step_loss=0.156][RANK-0]: Step: [15686], local_loss=0.011107044294476509, train_loss=0.02022150531411171, time_cost=1.9204509258270264
Steps:   2%|▏         | 15686/1000000 [6:50:48<2851:09:10, 10.43s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 15687/1000000 [6:51:01<3067:48:56, 11.22s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [15687], local_loss=0.012823470868170261, train_loss=0.06636711210012436, time_cost=5.181997060775757
Steps:   2%|▏         | 15687/1000000 [6:51:01<3067:48:56, 11.22s/it, lr=1e-5, step_loss=0.0128]Steps:   2%|▏         | 15688/1000000 [6:51:10<2922:35:41, 10.69s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [15688], local_loss=0.0090238768607378, train_loss=0.04545795917510986, time_cost=1.9274466037750244
Steps:   2%|▏         | 15688/1000000 [6:51:10<2922:35:41, 10.69s/it, lr=1e-5, step_loss=0.00902]Steps:   2%|▏         | 15689/1000000 [6:51:15<2462:24:24,  9.01s/it, lr=1e-5, step_loss=0.00902][RANK-0]: Step: [15689], local_loss=0.007860848680138588, train_loss=0.03290325775742531, time_cost=1.3623929023742676
Steps:   2%|▏         | 15689/1000000 [6:51:15<2462:24:24,  9.01s/it, lr=1e-5, step_loss=0.00786]Steps:   2%|▏         | 15690/1000000 [6:51:20<2147:45:44,  7.86s/it, lr=1e-5, step_loss=0.00786][RANK-0]: Step: [15690], local_loss=0.011193841695785522, train_loss=0.06488724052906036, time_cost=2.695618152618408
Steps:   2%|▏         | 15690/1000000 [6:51:20<2147:45:44,  7.86s/it, lr=1e-5, step_loss=0.0112] Steps:   2%|▏         | 15691/1000000 [6:51:32<2420:41:53,  8.85s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [15691], local_loss=0.06556244194507599, train_loss=0.16364720463752747, time_cost=2.328796863555908
Steps:   2%|▏         | 15691/1000000 [6:51:32<2420:41:53,  8.85s/it, lr=1e-5, step_loss=0.0656]Steps:   2%|▏         | 15692/1000000 [6:51:50<3220:14:13, 11.78s/it, lr=1e-5, step_loss=0.0656][RANK-0]: Step: [15692], local_loss=0.047453537583351135, train_loss=0.05410287529230118, time_cost=10.814191579818726
Steps:   2%|▏         | 15692/1000000 [6:51:50<3220:14:13, 11.78s/it, lr=1e-5, step_loss=0.0475]Steps:   2%|▏         | 15693/1000000 [6:52:01<3156:11:04, 11.54s/it, lr=1e-5, step_loss=0.0475][RANK-0]: Step: [15693], local_loss=0.012254164554178715, train_loss=0.09084086865186691, time_cost=4.700179100036621
Steps:   2%|▏         | 15693/1000000 [6:52:01<3156:11:04, 11.54s/it, lr=1e-5, step_loss=0.0123]Steps:   2%|▏         | 15694/1000000 [6:52:11<3055:20:44, 11.17s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [15694], local_loss=0.007474861573427916, train_loss=0.051504384726285934, time_cost=5.45550799369812
Steps:   2%|▏         | 15694/1000000 [6:52:11<3055:20:44, 11.17s/it, lr=1e-5, step_loss=0.00747]Steps:   2%|▏         | 15695/1000000 [6:52:16<2507:57:33,  9.17s/it, lr=1e-5, step_loss=0.00747][RANK-0]: Step: [15695], local_loss=0.02174307033419609, train_loss=0.14429692924022675, time_cost=1.894085168838501
Steps:   2%|▏         | 15695/1000000 [6:52:16<2507:57:33,  9.17s/it, lr=1e-5, step_loss=0.0217] Steps:   2%|▏         | 15696/1000000 [6:52:21<2169:58:54,  7.94s/it, lr=1e-5, step_loss=0.0217][RANK-0]: Step: [15696], local_loss=0.016203714534640312, train_loss=0.03468149155378342, time_cost=2.172419309616089
Steps:   2%|▏         | 15696/1000000 [6:52:21<2169:58:54,  7.94s/it, lr=1e-5, step_loss=0.0162]Steps:   2%|▏         | 15697/1000000 [6:52:27<1976:37:00,  7.23s/it, lr=1e-5, step_loss=0.0162][RANK-0]: Step: [15697], local_loss=0.007435902953147888, train_loss=0.02175062894821167, time_cost=1.2151985168457031
Steps:   2%|▏         | 15697/1000000 [6:52:27<1976:37:00,  7.23s/it, lr=1e-5, step_loss=0.00744]Steps:   2%|▏         | 15698/1000000 [6:52:36<2143:26:32,  7.84s/it, lr=1e-5, step_loss=0.00744][RANK-0]: Step: [15698], local_loss=0.07705652713775635, train_loss=0.06302888691425323, time_cost=3.0954196453094482
Steps:   2%|▏         | 15698/1000000 [6:52:36<2143:26:32,  7.84s/it, lr=1e-5, step_loss=0.0771] Steps:   2%|▏         | 15699/1000000 [6:52:47<2424:26:11,  8.87s/it, lr=1e-5, step_loss=0.0771][RANK-0]: Step: [15699], local_loss=0.06327300518751144, train_loss=0.030798643827438354, time_cost=1.2228295803070068
Steps:   2%|▏         | 15699/1000000 [6:52:47<2424:26:11,  8.87s/it, lr=1e-5, step_loss=0.0633]Steps:   2%|▏         | 15700/1000000 [6:52:52<2100:44:13,  7.68s/it, lr=1e-5, step_loss=0.0633][RANK-0]: Step: [15700], local_loss=1.0258028507232666, train_loss=0.13847346603870392, time_cost=1.9627008438110352
Steps:   2%|▏         | 15700/1000000 [6:52:52<2100:44:13,  7.68s/it, lr=1e-5, step_loss=1.03]  Steps:   2%|▏         | 15701/1000000 [6:53:01<2244:06:49,  8.21s/it, lr=1e-5, step_loss=1.03][RANK-0]: Step: [15701], local_loss=0.05450994893908501, train_loss=0.08794549852609634, time_cost=3.2088849544525146
Steps:   2%|▏         | 15701/1000000 [6:53:01<2244:06:49,  8.21s/it, lr=1e-5, step_loss=0.0545]Steps:   2%|▏         | 15702/1000000 [6:53:07<1985:20:23,  7.26s/it, lr=1e-5, step_loss=0.0545][RANK-0]: Step: [15702], local_loss=0.01972414366900921, train_loss=0.07298992574214935, time_cost=2.0556437969207764
Steps:   2%|▏         | 15702/1000000 [6:53:07<1985:20:23,  7.26s/it, lr=1e-5, step_loss=0.0197]Steps:   2%|▏         | 15703/1000000 [6:53:21<2562:36:46,  9.37s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [15703], local_loss=0.010767186060547829, train_loss=0.04856887087225914, time_cost=11.259036302566528
Steps:   2%|▏         | 15703/1000000 [6:53:21<2562:36:46,  9.37s/it, lr=1e-5, step_loss=0.0108]Steps:   2%|▏         | 15704/1000000 [6:53:28<2342:04:21,  8.57s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [15704], local_loss=0.08715023100376129, train_loss=0.06400575488805771, time_cost=2.2142810821533203
Steps:   2%|▏         | 15704/1000000 [6:53:28<2342:04:21,  8.57s/it, lr=1e-5, step_loss=0.0872]Steps:   2%|▏         | 15705/1000000 [6:53:42<2816:18:53, 10.30s/it, lr=1e-5, step_loss=0.0872][RANK-0]: Step: [15705], local_loss=0.030687402933835983, train_loss=0.08241702616214752, time_cost=5.060529947280884
Steps:   2%|▏         | 15705/1000000 [6:53:42<2816:18:53, 10.30s/it, lr=1e-5, step_loss=0.0307]Steps:   2%|▏         | 15706/1000000 [6:53:46<2343:52:53,  8.57s/it, lr=1e-5, step_loss=0.0307][RANK-0]: Step: [15706], local_loss=0.03521338105201721, train_loss=0.03016427904367447, time_cost=1.6086819171905518
Steps:   2%|▏         | 15706/1000000 [6:53:46<2343:52:53,  8.57s/it, lr=1e-5, step_loss=0.0352]Steps:   2%|▏         | 15707/1000000 [6:53:52<2066:38:23,  7.56s/it, lr=1e-5, step_loss=0.0352][RANK-0]: Step: [15707], local_loss=0.014639200642704964, train_loss=0.1024550050497055, time_cost=2.4573185443878174
Steps:   2%|▏         | 15707/1000000 [6:53:52<2066:38:23,  7.56s/it, lr=1e-5, step_loss=0.0146]Steps:   2%|▏         | 15708/1000000 [6:53:57<1868:13:37,  6.83s/it, lr=1e-5, step_loss=0.0146][RANK-0]: Step: [15708], local_loss=0.030680237337946892, train_loss=0.22969168424606323, time_cost=1.3139123916625977
Steps:   2%|▏         | 15708/1000000 [6:53:57<1868:13:37,  6.83s/it, lr=1e-5, step_loss=0.0307]Steps:   2%|▏         | 15709/1000000 [6:54:02<1730:41:45,  6.33s/it, lr=1e-5, step_loss=0.0307][RANK-0]: Step: [15709], local_loss=0.00634386483579874, train_loss=0.06818708777427673, time_cost=1.4086649417877197
Steps:   2%|▏         | 15709/1000000 [6:54:02<1730:41:45,  6.33s/it, lr=1e-5, step_loss=0.00634]Steps:   2%|▏         | 15710/1000000 [6:54:11<1928:15:46,  7.05s/it, lr=1e-5, step_loss=0.00634][RANK-0]: Step: [15710], local_loss=0.00634149182587862, train_loss=0.03545437008142471, time_cost=3.2645466327667236
Steps:   2%|▏         | 15710/1000000 [6:54:11<1928:15:46,  7.05s/it, lr=1e-5, step_loss=0.00634]Steps:   2%|▏         | 15711/1000000 [6:54:18<1916:06:23,  7.01s/it, lr=1e-5, step_loss=0.00634][RANK-0]: Step: [15711], local_loss=0.01387537270784378, train_loss=13.638968467712402, time_cost=1.2278661727905273
Steps:   2%|▏         | 15711/1000000 [6:54:18<1916:06:23,  7.01s/it, lr=1e-5, step_loss=0.0139] Steps:   2%|▏         | 15712/1000000 [6:54:23<1798:50:19,  6.58s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [15712], local_loss=0.008037932217121124, train_loss=0.01539603527635336, time_cost=2.9276223182678223
Steps:   2%|▏         | 15712/1000000 [6:54:23<1798:50:19,  6.58s/it, lr=1e-5, step_loss=0.00804]Steps:   2%|▏         | 15713/1000000 [6:54:36<2341:52:29,  8.57s/it, lr=1e-5, step_loss=0.00804][RANK-0]: Step: [15713], local_loss=0.014324210584163666, train_loss=0.09011167287826538, time_cost=3.638016700744629
Steps:   2%|▏         | 15713/1000000 [6:54:36<2341:52:29,  8.57s/it, lr=1e-5, step_loss=0.0143] Steps:   2%|▏         | 15714/1000000 [6:54:42<2072:01:09,  7.58s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [15714], local_loss=0.025358349084854126, train_loss=0.017063923180103302, time_cost=2.3902029991149902
Steps:   2%|▏         | 15714/1000000 [6:54:42<2072:01:09,  7.58s/it, lr=1e-5, step_loss=0.0254]Steps:   2%|▏         | 15715/1000000 [6:54:54<2432:00:35,  8.90s/it, lr=1e-5, step_loss=0.0254][RANK-0]: Step: [15715], local_loss=0.43924447894096375, train_loss=0.08680737018585205, time_cost=4.849127531051636
Steps:   2%|▏         | 15715/1000000 [6:54:54<2432:00:35,  8.90s/it, lr=1e-5, step_loss=0.439] Steps:   2%|▏         | 15716/1000000 [6:55:01<2295:58:45,  8.40s/it, lr=1e-5, step_loss=0.439][RANK-0]: Step: [15716], local_loss=0.03381789103150368, train_loss=0.018719911575317383, time_cost=2.768688678741455
Steps:   2%|▏         | 15716/1000000 [6:55:01<2295:58:45,  8.40s/it, lr=1e-5, step_loss=0.0338]Steps:   2%|▏         | 15717/1000000 [6:55:09<2269:47:16,  8.30s/it, lr=1e-5, step_loss=0.0338][RANK-0]: Step: [15717], local_loss=0.14007069170475006, train_loss=0.0440981462597847, time_cost=4.080791234970093
Steps:   2%|▏         | 15717/1000000 [6:55:09<2269:47:16,  8.30s/it, lr=1e-5, step_loss=0.14]  Steps:   2%|▏         | 15718/1000000 [6:55:22<2667:17:45,  9.76s/it, lr=1e-5, step_loss=0.14][RANK-0]: Step: [15718], local_loss=0.0471799299120903, train_loss=0.07355082035064697, time_cost=3.776944160461426
Steps:   2%|▏         | 15718/1000000 [6:55:22<2667:17:45,  9.76s/it, lr=1e-5, step_loss=0.0472]Steps:   2%|▏         | 15719/1000000 [6:55:29<2428:59:31,  8.88s/it, lr=1e-5, step_loss=0.0472][RANK-0]: Step: [15719], local_loss=0.011477821506559849, train_loss=0.07100548595190048, time_cost=2.0589616298675537
Steps:   2%|▏         | 15719/1000000 [6:55:29<2428:59:31,  8.88s/it, lr=1e-5, step_loss=0.0115]Steps:   2%|▏         | 15720/1000000 [6:55:38<2445:15:34,  8.94s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [15720], local_loss=0.02107793465256691, train_loss=0.03160654753446579, time_cost=1.6466567516326904
Steps:   2%|▏         | 15720/1000000 [6:55:38<2445:15:34,  8.94s/it, lr=1e-5, step_loss=0.0211]Steps:   2%|▏         | 15721/1000000 [6:55:51<2759:51:19, 10.09s/it, lr=1e-5, step_loss=0.0211][RANK-0]: Step: [15721], local_loss=0.008236533030867577, train_loss=0.026220154017210007, time_cost=10.599499464035034
Steps:   2%|▏         | 15721/1000000 [6:55:51<2759:51:19, 10.09s/it, lr=1e-5, step_loss=0.00824]Steps:   2%|▏         | 15722/1000000 [6:56:07<3267:48:00, 11.95s/it, lr=1e-5, step_loss=0.00824][RANK-0]: Step: [15722], local_loss=0.037177518010139465, train_loss=0.02953370288014412, time_cost=8.876593589782715
Steps:   2%|▏         | 15722/1000000 [6:56:07<3267:48:00, 11.95s/it, lr=1e-5, step_loss=0.0372] Steps:   2%|▏         | 15723/1000000 [6:56:15<2910:23:08, 10.64s/it, lr=1e-5, step_loss=0.0372][RANK-0]: Step: [15723], local_loss=0.0338037870824337, train_loss=0.03525605797767639, time_cost=2.3045029640197754
Steps:   2%|▏         | 15723/1000000 [6:56:15<2910:23:08, 10.64s/it, lr=1e-5, step_loss=0.0338]Steps:   2%|▏         | 15724/1000000 [6:56:24<2797:21:40, 10.23s/it, lr=1e-5, step_loss=0.0338][RANK-0]: Step: [15724], local_loss=0.05584239214658737, train_loss=0.023046167567372322, time_cost=1.6919736862182617
Steps:   2%|▏         | 15724/1000000 [6:56:24<2797:21:40, 10.23s/it, lr=1e-5, step_loss=0.0558]Steps:   2%|▏         | 15725/1000000 [6:56:30<2439:32:22,  8.92s/it, lr=1e-5, step_loss=0.0558][RANK-0]: Step: [15725], local_loss=0.01747480407357216, train_loss=0.04957225173711777, time_cost=3.454629898071289
Steps:   2%|▏         | 15725/1000000 [6:56:30<2439:32:22,  8.92s/it, lr=1e-5, step_loss=0.0175]Steps:   2%|▏         | 15726/1000000 [6:56:46<3026:13:53, 11.07s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [15726], local_loss=0.015762312337756157, train_loss=0.08306144922971725, time_cost=6.157517433166504
Steps:   2%|▏         | 15726/1000000 [6:56:46<3026:13:53, 11.07s/it, lr=1e-5, step_loss=0.0158]Steps:   2%|▏         | 15727/1000000 [6:56:56<2985:56:23, 10.92s/it, lr=1e-5, step_loss=0.0158][RANK-0]: Step: [15727], local_loss=0.011093721725046635, train_loss=0.020455043762922287, time_cost=2.305406093597412
Steps:   2%|▏         | 15727/1000000 [6:56:56<2985:56:23, 10.92s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 15728/1000000 [6:57:03<2657:30:59,  9.72s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [15728], local_loss=0.013761746697127819, train_loss=0.030057109892368317, time_cost=3.1452252864837646
Steps:   2%|▏         | 15728/1000000 [6:57:03<2657:30:59,  9.72s/it, lr=1e-5, step_loss=0.0138]Steps:   2%|▏         | 15729/1000000 [6:57:08<2205:09:19,  8.07s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [15729], local_loss=0.03633928671479225, train_loss=0.02454414963722229, time_cost=1.29557466506958
Steps:   2%|▏         | 15729/1000000 [6:57:08<2205:09:19,  8.07s/it, lr=1e-5, step_loss=0.0363]Steps:   2%|▏         | 15730/1000000 [6:57:13<2014:19:09,  7.37s/it, lr=1e-5, step_loss=0.0363][RANK-0]: Step: [15730], local_loss=0.01289583370089531, train_loss=0.02969961240887642, time_cost=1.2995376586914062
Steps:   2%|▏         | 15730/1000000 [6:57:13<2014:19:09,  7.37s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 15731/1000000 [6:57:21<2051:19:05,  7.50s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [15731], local_loss=0.02066813036799431, train_loss=0.0497383214533329, time_cost=3.108592987060547
Steps:   2%|▏         | 15731/1000000 [6:57:21<2051:19:05,  7.50s/it, lr=1e-5, step_loss=0.0207]Steps:   2%|▏         | 15732/1000000 [6:57:33<2453:59:24,  8.98s/it, lr=1e-5, step_loss=0.0207][RANK-0]: Step: [15732], local_loss=0.07960717380046844, train_loss=0.02995670959353447, time_cost=5.187133312225342
Steps:   2%|▏         | 15732/1000000 [6:57:33<2453:59:24,  8.98s/it, lr=1e-5, step_loss=0.0796]Steps:   2%|▏         | 15733/1000000 [6:57:43<2486:15:41,  9.09s/it, lr=1e-5, step_loss=0.0796][RANK-0]: Step: [15733], local_loss=0.019084366038441658, train_loss=0.028750190511345863, time_cost=2.9060826301574707
Steps:   2%|▏         | 15733/1000000 [6:57:43<2486:15:41,  9.09s/it, lr=1e-5, step_loss=0.0191]Steps:   2%|▏         | 15734/1000000 [6:57:50<2345:22:37,  8.58s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [15734], local_loss=0.006724881939589977, train_loss=0.03899195417761803, time_cost=2.882761240005493
Steps:   2%|▏         | 15734/1000000 [6:57:50<2345:22:37,  8.58s/it, lr=1e-5, step_loss=0.00672]Steps:   2%|▏         | 15735/1000000 [6:57:57<2231:50:13,  8.16s/it, lr=1e-5, step_loss=0.00672][RANK-0]: Step: [15735], local_loss=0.3825730085372925, train_loss=0.07764491438865662, time_cost=2.7793025970458984
Steps:   2%|▏         | 15735/1000000 [6:57:57<2231:50:13,  8.16s/it, lr=1e-5, step_loss=0.383]  Steps:   2%|▏         | 15736/1000000 [6:58:03<1979:17:17,  7.24s/it, lr=1e-5, step_loss=0.383][RANK-0]: Step: [15736], local_loss=0.014750905334949493, train_loss=0.01880079135298729, time_cost=1.208573341369629
Steps:   2%|▏         | 15736/1000000 [6:58:03<1979:17:17,  7.24s/it, lr=1e-5, step_loss=0.0148]Steps:   2%|▏         | 15737/1000000 [6:58:14<2330:23:19,  8.52s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [15737], local_loss=0.028896262869238853, train_loss=0.06360095739364624, time_cost=4.172831296920776
Steps:   2%|▏         | 15737/1000000 [6:58:14<2330:23:19,  8.52s/it, lr=1e-5, step_loss=0.0289]Steps:   2%|▏         | 15738/1000000 [6:58:23<2344:48:43,  8.58s/it, lr=1e-5, step_loss=0.0289][RANK-0]: Step: [15738], local_loss=0.024439655244350433, train_loss=0.01857253722846508, time_cost=1.271235466003418
Steps:   2%|▏         | 15738/1000000 [6:58:23<2344:48:43,  8.58s/it, lr=1e-5, step_loss=0.0244]Steps:   2%|▏         | 15739/1000000 [6:58:32<2394:22:20,  8.76s/it, lr=1e-5, step_loss=0.0244][RANK-0]: Step: [15739], local_loss=0.021439028903841972, train_loss=0.03049900196492672, time_cost=7.819244384765625
Steps:   2%|▏         | 15739/1000000 [6:58:32<2394:22:20,  8.76s/it, lr=1e-5, step_loss=0.0214]Steps:   2%|▏         | 15740/1000000 [6:58:39<2251:08:11,  8.23s/it, lr=1e-5, step_loss=0.0214][RANK-0]: Step: [15740], local_loss=0.011187387630343437, train_loss=0.05811869353055954, time_cost=2.6332004070281982
Steps:   2%|▏         | 15740/1000000 [6:58:39<2251:08:11,  8.23s/it, lr=1e-5, step_loss=0.0112]Steps:   2%|▏         | 15741/1000000 [6:58:50<2460:10:04,  9.00s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [15741], local_loss=0.9929221868515015, train_loss=0.1600072681903839, time_cost=7.749018669128418
Steps:   2%|▏         | 15741/1000000 [6:58:50<2460:10:04,  9.00s/it, lr=1e-5, step_loss=0.993] Steps:   2%|▏         | 15742/1000000 [6:58:54<2083:28:38,  7.62s/it, lr=1e-5, step_loss=0.993][RANK-0]: Step: [15742], local_loss=0.03407629579305649, train_loss=0.06206098571419716, time_cost=3.3460545539855957
Steps:   2%|▏         | 15742/1000000 [6:58:54<2083:28:38,  7.62s/it, lr=1e-5, step_loss=0.0341]Steps:   2%|▏         | 15743/1000000 [6:59:12<2922:03:53, 10.69s/it, lr=1e-5, step_loss=0.0341][RANK-0]: Step: [15743], local_loss=0.13009586930274963, train_loss=0.08101804554462433, time_cost=7.709146976470947
Steps:   2%|▏         | 15743/1000000 [6:59:12<2922:03:53, 10.69s/it, lr=1e-5, step_loss=0.13]  Steps:   2%|▏         | 15744/1000000 [6:59:25<3153:02:18, 11.53s/it, lr=1e-5, step_loss=0.13][RANK-0]: Step: [15744], local_loss=0.13280855119228363, train_loss=0.04500020667910576, time_cost=4.574049472808838
Steps:   2%|▏         | 15744/1000000 [6:59:25<3153:02:18, 11.53s/it, lr=1e-5, step_loss=0.133]Steps:   2%|▏         | 15745/1000000 [6:59:33<2847:07:17, 10.41s/it, lr=1e-5, step_loss=0.133][RANK-0]: Step: [15745], local_loss=0.013898284174501896, train_loss=0.05725493282079697, time_cost=3.005335807800293
Steps:   2%|▏         | 15745/1000000 [6:59:33<2847:07:17, 10.41s/it, lr=1e-5, step_loss=0.0139]Steps:   2%|▏         | 15746/1000000 [6:59:41<2616:04:14,  9.57s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [15746], local_loss=0.007236042991280556, train_loss=0.06764747947454453, time_cost=5.810682058334351
Steps:   2%|▏         | 15746/1000000 [6:59:41<2616:04:14,  9.57s/it, lr=1e-5, step_loss=0.00724]Steps:   2%|▏         | 15747/1000000 [6:59:46<2278:53:01,  8.34s/it, lr=1e-5, step_loss=0.00724][RANK-0]: Step: [15747], local_loss=0.011150444857776165, train_loss=0.03506769984960556, time_cost=1.4332339763641357
Steps:   2%|▏         | 15747/1000000 [6:59:46<2278:53:01,  8.34s/it, lr=1e-5, step_loss=0.0112] Steps:   2%|▏         | 15748/1000000 [6:59:51<2011:00:57,  7.36s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [15748], local_loss=0.08022190630435944, train_loss=0.0320909321308136, time_cost=2.117055654525757
Steps:   2%|▏         | 15748/1000000 [6:59:51<2011:00:57,  7.36s/it, lr=1e-5, step_loss=0.0802]Steps:   2%|▏         | 15749/1000000 [7:00:04<2460:12:30,  9.00s/it, lr=1e-5, step_loss=0.0802][RANK-0]: Step: [15749], local_loss=0.016459356993436813, train_loss=0.034453265368938446, time_cost=3.89339280128479
Steps:   2%|▏         | 15749/1000000 [7:00:04<2460:12:30,  9.00s/it, lr=1e-5, step_loss=0.0165]Steps:   2%|▏         | 15750/1000000 [7:00:22<3158:07:45, 11.55s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [15750], local_loss=0.11901124566793442, train_loss=0.051780201494693756, time_cost=9.898120403289795
Steps:   2%|▏         | 15750/1000000 [7:00:22<3158:07:45, 11.55s/it, lr=1e-5, step_loss=0.119] Steps:   2%|▏         | 15751/1000000 [7:00:26<2597:31:09,  9.50s/it, lr=1e-5, step_loss=0.119][RANK-0]: Step: [15751], local_loss=0.07597015798091888, train_loss=0.023210667073726654, time_cost=1.7751762866973877
Steps:   2%|▏         | 15751/1000000 [7:00:26<2597:31:09,  9.50s/it, lr=1e-5, step_loss=0.076]Steps:   2%|▏         | 15752/1000000 [7:00:40<2939:12:01, 10.75s/it, lr=1e-5, step_loss=0.076][RANK-0]: Step: [15752], local_loss=0.032106198370456696, train_loss=0.10018117725849152, time_cost=4.415192365646362
Steps:   2%|▏         | 15752/1000000 [7:00:40<2939:12:01, 10.75s/it, lr=1e-5, step_loss=0.0321]Steps:   2%|▏         | 15753/1000000 [7:00:45<2458:35:38,  8.99s/it, lr=1e-5, step_loss=0.0321][RANK-0]: Step: [15753], local_loss=0.05004417151212692, train_loss=0.016274694353342056, time_cost=2.075550079345703
Steps:   2%|▏         | 15753/1000000 [7:00:45<2458:35:38,  8.99s/it, lr=1e-5, step_loss=0.05]  Steps:   2%|▏         | 15754/1000000 [7:00:50<2147:05:43,  7.85s/it, lr=1e-5, step_loss=0.05][RANK-0]: Step: [15754], local_loss=0.12264537066221237, train_loss=0.04141324758529663, time_cost=2.468519449234009
Steps:   2%|▏         | 15754/1000000 [7:00:50<2147:05:43,  7.85s/it, lr=1e-5, step_loss=0.123]Steps:   2%|▏         | 15755/1000000 [7:00:57<2060:39:09,  7.54s/it, lr=1e-5, step_loss=0.123][RANK-0]: Step: [15755], local_loss=0.008150126785039902, train_loss=0.07214351743459702, time_cost=2.496633291244507
Steps:   2%|▏         | 15755/1000000 [7:00:57<2060:39:09,  7.54s/it, lr=1e-5, step_loss=0.00815]Steps:   2%|▏         | 15756/1000000 [7:01:07<2290:08:06,  8.38s/it, lr=1e-5, step_loss=0.00815][RANK-0]: Step: [15756], local_loss=0.005143036134541035, train_loss=0.022732317447662354, time_cost=1.2213876247406006
Steps:   2%|▏         | 15756/1000000 [7:01:07<2290:08:06,  8.38s/it, lr=1e-5, step_loss=0.00514]Steps:   2%|▏         | 15757/1000000 [7:01:18<2503:03:40,  9.16s/it, lr=1e-5, step_loss=0.00514][RANK-0]: Step: [15757], local_loss=0.059685494750738144, train_loss=0.02535611018538475, time_cost=1.9975297451019287
Steps:   2%|▏         | 15757/1000000 [7:01:18<2503:03:40,  9.16s/it, lr=1e-5, step_loss=0.0597] Steps:   2%|▏         | 15758/1000000 [7:01:23<2161:06:37,  7.90s/it, lr=1e-5, step_loss=0.0597][RANK-0]: Step: [15758], local_loss=0.027892688289284706, train_loss=0.06552006304264069, time_cost=1.2569031715393066
Steps:   2%|▏         | 15758/1000000 [7:01:23<2161:06:37,  7.90s/it, lr=1e-5, step_loss=0.0279]Steps:   2%|▏         | 15759/1000000 [7:01:34<2350:54:26,  8.60s/it, lr=1e-5, step_loss=0.0279][RANK-0]: Step: [15759], local_loss=0.004259743727743626, train_loss=0.02508559264242649, time_cost=2.0454914569854736
Steps:   2%|▏         | 15759/1000000 [7:01:34<2350:54:26,  8.60s/it, lr=1e-5, step_loss=0.00426]Steps:   2%|▏         | 15760/1000000 [7:01:40<2210:11:10,  8.08s/it, lr=1e-5, step_loss=0.00426][RANK-0]: Step: [15760], local_loss=0.01066141203045845, train_loss=0.013375634327530861, time_cost=3.3144373893737793
Steps:   2%|▏         | 15760/1000000 [7:01:40<2210:11:10,  8.08s/it, lr=1e-5, step_loss=0.0107] Steps:   2%|▏         | 15761/1000000 [7:01:47<2094:20:01,  7.66s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [15761], local_loss=0.060351766645908356, train_loss=0.023803669959306717, time_cost=4.9056901931762695
Steps:   2%|▏         | 15761/1000000 [7:01:47<2094:20:01,  7.66s/it, lr=1e-5, step_loss=0.0604]Steps:   2%|▏         | 15762/1000000 [7:01:59<2475:18:54,  9.05s/it, lr=1e-5, step_loss=0.0604][RANK-0]: Step: [15762], local_loss=0.06362701952457428, train_loss=0.04907859116792679, time_cost=1.2089190483093262
Steps:   2%|▏         | 15762/1000000 [7:01:59<2475:18:54,  9.05s/it, lr=1e-5, step_loss=0.0636]Steps:   2%|▏         | 15763/1000000 [7:02:11<2697:34:14,  9.87s/it, lr=1e-5, step_loss=0.0636][RANK-0]: Step: [15763], local_loss=0.009509282186627388, train_loss=0.02300887741148472, time_cost=4.647159099578857
Steps:   2%|▏         | 15763/1000000 [7:02:11<2697:34:14,  9.87s/it, lr=1e-5, step_loss=0.00951]Steps:   2%|▏         | 15764/1000000 [7:02:18<2464:13:40,  9.01s/it, lr=1e-5, step_loss=0.00951][RANK-0]: Step: [15764], local_loss=0.0105820894241333, train_loss=0.021420657634735107, time_cost=2.514322280883789
Steps:   2%|▏         | 15764/1000000 [7:02:18<2464:13:40,  9.01s/it, lr=1e-5, step_loss=0.0106] Steps:   2%|▏         | 15765/1000000 [7:02:26<2366:38:17,  8.66s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [15765], local_loss=0.03425880894064903, train_loss=0.03241150081157684, time_cost=5.67466139793396
Steps:   2%|▏         | 15765/1000000 [7:02:26<2366:38:17,  8.66s/it, lr=1e-5, step_loss=0.0343]Steps:   2%|▏         | 15766/1000000 [7:02:32<2122:46:47,  7.76s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [15766], local_loss=0.022537503391504288, train_loss=0.06548026204109192, time_cost=3.385348320007324
Steps:   2%|▏         | 15766/1000000 [7:02:32<2122:46:47,  7.76s/it, lr=1e-5, step_loss=0.0225]Steps:   2%|▏         | 15767/1000000 [7:02:37<1925:31:12,  7.04s/it, lr=1e-5, step_loss=0.0225][RANK-0]: Step: [15767], local_loss=0.005929108709096909, train_loss=0.046670928597450256, time_cost=3.1331241130828857
Steps:   2%|▏         | 15767/1000000 [7:02:37<1925:31:12,  7.04s/it, lr=1e-5, step_loss=0.00593]Steps:   2%|▏         | 15768/1000000 [7:02:43<1829:09:58,  6.69s/it, lr=1e-5, step_loss=0.00593][RANK-0]: Step: [15768], local_loss=0.007797024678438902, train_loss=0.02792961895465851, time_cost=4.847837209701538
Steps:   2%|▏         | 15768/1000000 [7:02:43<1829:09:58,  6.69s/it, lr=1e-5, step_loss=0.0078] Steps:   2%|▏         | 15769/1000000 [7:02:52<2023:56:37,  7.40s/it, lr=1e-5, step_loss=0.0078][RANK-0]: Step: [15769], local_loss=0.01597461849451065, train_loss=0.10587235540151596, time_cost=3.7067344188690186
Steps:   2%|▏         | 15769/1000000 [7:02:52<2023:56:37,  7.40s/it, lr=1e-5, step_loss=0.016] Steps:   2%|▏         | 15770/1000000 [7:03:03<2334:45:46,  8.54s/it, lr=1e-5, step_loss=0.016][RANK-0]: Step: [15770], local_loss=0.01291509810835123, train_loss=0.1562386006116867, time_cost=1.2213687896728516
Steps:   2%|▏         | 15770/1000000 [7:03:03<2334:45:46,  8.54s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 15771/1000000 [7:03:11<2306:42:23,  8.44s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [15771], local_loss=0.041119448840618134, train_loss=0.06882257759571075, time_cost=3.62522029876709
Steps:   2%|▏         | 15771/1000000 [7:03:11<2306:42:23,  8.44s/it, lr=1e-5, step_loss=0.0411]Steps:   2%|▏         | 15772/1000000 [7:03:16<1993:48:17,  7.29s/it, lr=1e-5, step_loss=0.0411][RANK-0]: Step: [15772], local_loss=0.010277077555656433, train_loss=0.06979506462812424, time_cost=1.8597893714904785
Steps:   2%|▏         | 15772/1000000 [7:03:16<1993:48:17,  7.29s/it, lr=1e-5, step_loss=0.0103]Steps:   2%|▏         | 15773/1000000 [7:03:21<1797:17:18,  6.57s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [15773], local_loss=0.03152576461434364, train_loss=0.04530121386051178, time_cost=2.2220571041107178
Steps:   2%|▏         | 15773/1000000 [7:03:21<1797:17:18,  6.57s/it, lr=1e-5, step_loss=0.0315]Steps:   2%|▏         | 15774/1000000 [7:03:28<1824:02:44,  6.67s/it, lr=1e-5, step_loss=0.0315][RANK-0]: Step: [15774], local_loss=0.006201776210218668, train_loss=0.04324693977832794, time_cost=1.2921946048736572
Steps:   2%|▏         | 15774/1000000 [7:03:28<1824:02:44,  6.67s/it, lr=1e-5, step_loss=0.0062]Steps:   2%|▏         | 15775/1000000 [7:03:35<1842:46:01,  6.74s/it, lr=1e-5, step_loss=0.0062][RANK-0]: Step: [15775], local_loss=0.09107362478971481, train_loss=0.038294173777103424, time_cost=2.6224875450134277
Steps:   2%|▏         | 15775/1000000 [7:03:35<1842:46:01,  6.74s/it, lr=1e-5, step_loss=0.0911]Steps:   2%|▏         | 15776/1000000 [7:03:46<2241:39:37,  8.20s/it, lr=1e-5, step_loss=0.0911][RANK-0]: Step: [15776], local_loss=0.011269418522715569, train_loss=0.024624187499284744, time_cost=3.304342746734619
Steps:   2%|▏         | 15776/1000000 [7:03:46<2241:39:37,  8.20s/it, lr=1e-5, step_loss=0.0113]Steps:   2%|▏         | 15777/1000000 [7:03:53<2131:11:01,  7.80s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [15777], local_loss=0.05598404258489609, train_loss=0.020100608468055725, time_cost=2.7970809936523438
Steps:   2%|▏         | 15777/1000000 [7:03:53<2131:11:01,  7.80s/it, lr=1e-5, step_loss=0.056] Steps:   2%|▏         | 15778/1000000 [7:03:58<1898:22:32,  6.94s/it, lr=1e-5, step_loss=0.056][RANK-0]: Step: [15778], local_loss=0.06780195236206055, train_loss=0.15596505999565125, time_cost=2.1284029483795166
Steps:   2%|▏         | 15778/1000000 [7:03:58<1898:22:32,  6.94s/it, lr=1e-5, step_loss=0.0678]Steps:   2%|▏         | 15779/1000000 [7:04:07<2034:51:10,  7.44s/it, lr=1e-5, step_loss=0.0678][RANK-0]: Step: [15779], local_loss=0.06573425233364105, train_loss=0.060274407267570496, time_cost=1.5576860904693604
Steps:   2%|▏         | 15779/1000000 [7:04:07<2034:51:10,  7.44s/it, lr=1e-5, step_loss=0.0657]Steps:   2%|▏         | 15780/1000000 [7:04:14<2059:25:30,  7.53s/it, lr=1e-5, step_loss=0.0657][RANK-0]: Step: [15780], local_loss=0.010566920042037964, train_loss=0.024213220924139023, time_cost=6.043729543685913
Steps:   2%|▏         | 15780/1000000 [7:04:14<2059:25:30,  7.53s/it, lr=1e-5, step_loss=0.0106]Steps:   2%|▏         | 15781/1000000 [7:04:22<2072:24:42,  7.58s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [15781], local_loss=0.013171345926821232, train_loss=0.04367799311876297, time_cost=4.254674196243286
Steps:   2%|▏         | 15781/1000000 [7:04:22<2072:24:42,  7.58s/it, lr=1e-5, step_loss=0.0132]Steps:   2%|▏         | 15782/1000000 [7:04:31<2182:42:13,  7.98s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [15782], local_loss=0.04846709221601486, train_loss=0.031820960342884064, time_cost=2.782135486602783
Steps:   2%|▏         | 15782/1000000 [7:04:31<2182:42:13,  7.98s/it, lr=1e-5, step_loss=0.0485]Steps:   2%|▏         | 15783/1000000 [7:04:40<2267:22:07,  8.29s/it, lr=1e-5, step_loss=0.0485][RANK-0]: Step: [15783], local_loss=0.009441536851227283, train_loss=0.025662817060947418, time_cost=2.5709943771362305
Steps:   2%|▏         | 15783/1000000 [7:04:40<2267:22:07,  8.29s/it, lr=1e-5, step_loss=0.00944]Steps:   2%|▏         | 15784/1000000 [7:04:51<2509:58:41,  9.18s/it, lr=1e-5, step_loss=0.00944][RANK-0]: Step: [15784], local_loss=0.004709979053586721, train_loss=0.03367915749549866, time_cost=4.0348961353302
Steps:   2%|▏         | 15784/1000000 [7:04:51<2509:58:41,  9.18s/it, lr=1e-5, step_loss=0.00471]Steps:   2%|▏         | 15785/1000000 [7:05:07<3011:00:33, 11.01s/it, lr=1e-5, step_loss=0.00471][RANK-0]: Step: [15785], local_loss=0.09548520296812057, train_loss=0.06587672233581543, time_cost=5.877605199813843
Steps:   2%|▏         | 15785/1000000 [7:05:07<3011:00:33, 11.01s/it, lr=1e-5, step_loss=0.0955] Steps:   2%|▏         | 15786/1000000 [7:05:16<2858:45:41, 10.46s/it, lr=1e-5, step_loss=0.0955][RANK-0]: Step: [15786], local_loss=0.012292381376028061, train_loss=0.021505003795027733, time_cost=3.646991491317749
Steps:   2%|▏         | 15786/1000000 [7:05:16<2858:45:41, 10.46s/it, lr=1e-5, step_loss=0.0123]Steps:   2%|▏         | 15787/1000000 [7:05:23<2589:09:47,  9.47s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [15787], local_loss=0.21708944439888, train_loss=0.05236092954874039, time_cost=2.677525043487549
Steps:   2%|▏         | 15787/1000000 [7:05:23<2589:09:47,  9.47s/it, lr=1e-5, step_loss=0.217] Steps:   2%|▏         | 15788/1000000 [7:05:28<2247:10:27,  8.22s/it, lr=1e-5, step_loss=0.217][RANK-0]: Step: [15788], local_loss=0.016978370025753975, train_loss=0.18323612213134766, time_cost=3.3614089488983154
Steps:   2%|▏         | 15788/1000000 [7:05:28<2247:10:27,  8.22s/it, lr=1e-5, step_loss=0.017]Steps:   2%|▏         | 15789/1000000 [7:05:36<2238:38:44,  8.19s/it, lr=1e-5, step_loss=0.017][RANK-0]: Step: [15789], local_loss=0.00964397843927145, train_loss=0.03020237758755684, time_cost=2.2824044227600098
Steps:   2%|▏         | 15789/1000000 [7:05:36<2238:38:44,  8.19s/it, lr=1e-5, step_loss=0.00964]Steps:   2%|▏         | 15790/1000000 [7:05:43<2153:43:42,  7.88s/it, lr=1e-5, step_loss=0.00964][RANK-0]: Step: [15790], local_loss=0.006145659368485212, train_loss=0.03495991230010986, time_cost=1.5033493041992188
Steps:   2%|▏         | 15790/1000000 [7:05:43<2153:43:42,  7.88s/it, lr=1e-5, step_loss=0.00615]Steps:   2%|▏         | 15791/1000000 [7:05:48<1847:56:52,  6.76s/it, lr=1e-5, step_loss=0.00615][RANK-0]: Step: [15791], local_loss=0.06904301047325134, train_loss=0.057228945195674896, time_cost=1.788323163986206
Steps:   2%|▏         | 15791/1000000 [7:05:48<1847:56:52,  6.76s/it, lr=1e-5, step_loss=0.069]  Steps:   2%|▏         | 15792/1000000 [7:05:53<1726:30:58,  6.32s/it, lr=1e-5, step_loss=0.069][RANK-0]: Step: [15792], local_loss=0.010508928447961807, train_loss=0.04266346991062164, time_cost=2.43349027633667
Steps:   2%|▏         | 15792/1000000 [7:05:53<1726:30:58,  6.32s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 15793/1000000 [7:05:58<1624:13:11,  5.94s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [15793], local_loss=0.010477732867002487, train_loss=0.058372706174850464, time_cost=2.6086525917053223
Steps:   2%|▏         | 15793/1000000 [7:05:58<1624:13:11,  5.94s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 15794/1000000 [7:06:11<2177:28:22,  7.96s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [15794], local_loss=0.05315996706485748, train_loss=0.04143040254712105, time_cost=4.375021934509277
Steps:   2%|▏         | 15794/1000000 [7:06:11<2177:28:22,  7.96s/it, lr=1e-5, step_loss=0.0532]Steps:   2%|▏         | 15795/1000000 [7:06:16<1942:45:14,  7.11s/it, lr=1e-5, step_loss=0.0532][RANK-0]: Step: [15795], local_loss=0.035506926476955414, train_loss=0.0660284161567688, time_cost=2.6246495246887207
Steps:   2%|▏         | 15795/1000000 [7:06:16<1942:45:14,  7.11s/it, lr=1e-5, step_loss=0.0355]Steps:   2%|▏         | 15796/1000000 [7:06:24<2013:37:17,  7.37s/it, lr=1e-5, step_loss=0.0355][RANK-0]: Step: [15796], local_loss=0.004961133934557438, train_loss=0.08630010485649109, time_cost=2.197106122970581
Steps:   2%|▏         | 15796/1000000 [7:06:24<2013:37:17,  7.37s/it, lr=1e-5, step_loss=0.00496]Steps:   2%|▏         | 15797/1000000 [7:06:29<1832:49:22,  6.70s/it, lr=1e-5, step_loss=0.00496][RANK-0]: Step: [15797], local_loss=0.014997045509517193, train_loss=0.03953355550765991, time_cost=2.5344440937042236
Steps:   2%|▏         | 15797/1000000 [7:06:29<1832:49:22,  6.70s/it, lr=1e-5, step_loss=0.015]  Steps:   2%|▏         | 15798/1000000 [7:06:40<2169:44:48,  7.94s/it, lr=1e-5, step_loss=0.015][RANK-0]: Step: [15798], local_loss=0.02740427479147911, train_loss=0.049597594887018204, time_cost=3.750849962234497
Steps:   2%|▏         | 15798/1000000 [7:06:40<2169:44:48,  7.94s/it, lr=1e-5, step_loss=0.0274]Steps:   2%|▏         | 15799/1000000 [7:06:53<2580:01:12,  9.44s/it, lr=1e-5, step_loss=0.0274][RANK-0]: Step: [15799], local_loss=0.03691492974758148, train_loss=0.14272814989089966, time_cost=3.4951140880584717
Steps:   2%|▏         | 15799/1000000 [7:06:53<2580:01:12,  9.44s/it, lr=1e-5, step_loss=0.0369]Steps:   2%|▏         | 15800/1000000 [7:07:05<2777:51:17, 10.16s/it, lr=1e-5, step_loss=0.0369][RANK-0]: Step: [15800], local_loss=0.030332518741488457, train_loss=0.01819407381117344, time_cost=4.321481227874756
Steps:   2%|▏         | 15800/1000000 [7:07:05<2777:51:17, 10.16s/it, lr=1e-5, step_loss=0.0303]Steps:   2%|▏         | 15801/1000000 [7:07:16<2865:33:01, 10.48s/it, lr=1e-5, step_loss=0.0303][RANK-0]: Step: [15801], local_loss=0.012930883094668388, train_loss=0.147706538438797, time_cost=4.147822618484497
Steps:   2%|▏         | 15801/1000000 [7:07:16<2865:33:01, 10.48s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 15802/1000000 [7:07:27<2935:21:16, 10.74s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [15802], local_loss=0.006319642532616854, train_loss=0.024095699191093445, time_cost=1.2230274677276611
Steps:   2%|▏         | 15802/1000000 [7:07:27<2935:21:16, 10.74s/it, lr=1e-5, step_loss=0.00632]Steps:   2%|▏         | 15803/1000000 [7:07:41<3171:03:06, 11.60s/it, lr=1e-5, step_loss=0.00632][RANK-0]: Step: [15803], local_loss=0.026379350572824478, train_loss=0.010427793487906456, time_cost=5.390149831771851
Steps:   2%|▏         | 15803/1000000 [7:07:41<3171:03:06, 11.60s/it, lr=1e-5, step_loss=0.0264] Steps:   2%|▏         | 15804/1000000 [7:07:57<3573:45:10, 13.07s/it, lr=1e-5, step_loss=0.0264][RANK-0]: Step: [15804], local_loss=0.23483695089817047, train_loss=0.0805102214217186, time_cost=3.9425649642944336
Steps:   2%|▏         | 15804/1000000 [7:07:57<3573:45:10, 13.07s/it, lr=1e-5, step_loss=0.235] Steps:   2%|▏         | 15805/1000000 [7:08:02<2925:52:10, 10.70s/it, lr=1e-5, step_loss=0.235][RANK-0]: Step: [15805], local_loss=0.12006267160177231, train_loss=0.18064475059509277, time_cost=2.2492592334747314
Steps:   2%|▏         | 15805/1000000 [7:08:02<2925:52:10, 10.70s/it, lr=1e-5, step_loss=0.12] Steps:   2%|▏         | 15806/1000000 [7:08:12<2822:23:51, 10.32s/it, lr=1e-5, step_loss=0.12][RANK-0]: Step: [15806], local_loss=0.02505560591816902, train_loss=0.01957351341843605, time_cost=3.368546485900879
Steps:   2%|▏         | 15806/1000000 [7:08:12<2822:23:51, 10.32s/it, lr=1e-5, step_loss=0.0251]Steps:   2%|▏         | 15807/1000000 [7:08:19<2532:22:56,  9.26s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [15807], local_loss=0.08879506587982178, train_loss=0.05159233510494232, time_cost=2.398375988006592
Steps:   2%|▏         | 15807/1000000 [7:08:19<2532:22:56,  9.26s/it, lr=1e-5, step_loss=0.0888]Steps:   2%|▏         | 15808/1000000 [7:08:27<2435:17:22,  8.91s/it, lr=1e-5, step_loss=0.0888][RANK-0]: Step: [15808], local_loss=0.007321319077163935, train_loss=0.370235800743103, time_cost=1.2038099765777588
Steps:   2%|▏         | 15808/1000000 [7:08:27<2435:17:22,  8.91s/it, lr=1e-5, step_loss=0.00732]Steps:   2%|▏         | 15809/1000000 [7:08:31<2059:23:59,  7.53s/it, lr=1e-5, step_loss=0.00732][RANK-0]: Step: [15809], local_loss=0.005611302796751261, train_loss=0.040351592004299164, time_cost=1.7856907844543457
Steps:   2%|▏         | 15809/1000000 [7:08:31<2059:23:59,  7.53s/it, lr=1e-5, step_loss=0.00561]Steps:   2%|▏         | 15810/1000000 [7:08:46<2668:29:19,  9.76s/it, lr=1e-5, step_loss=0.00561][RANK-0]: Step: [15810], local_loss=0.0807327851653099, train_loss=0.17645904421806335, time_cost=5.926008701324463
Steps:   2%|▏         | 15810/1000000 [7:08:46<2668:29:19,  9.76s/it, lr=1e-5, step_loss=0.0807] Steps:   2%|▏         | 15811/1000000 [7:08:55<2587:01:04,  9.46s/it, lr=1e-5, step_loss=0.0807][RANK-0]: Step: [15811], local_loss=0.018739497289061546, train_loss=0.01394472923129797, time_cost=1.901534080505371
Steps:   2%|▏         | 15811/1000000 [7:08:55<2587:01:04,  9.46s/it, lr=1e-5, step_loss=0.0187]Steps:   2%|▏         | 15812/1000000 [7:09:02<2396:26:24,  8.77s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [15812], local_loss=0.012757912278175354, train_loss=0.018655190244317055, time_cost=3.0931410789489746
Steps:   2%|▏         | 15812/1000000 [7:09:02<2396:26:24,  8.77s/it, lr=1e-5, step_loss=0.0128]Steps:   2%|▏         | 15813/1000000 [7:09:11<2407:04:10,  8.80s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [15813], local_loss=0.1431559920310974, train_loss=0.041013412177562714, time_cost=1.598313331604004
Steps:   2%|▏         | 15813/1000000 [7:09:11<2407:04:10,  8.80s/it, lr=1e-5, step_loss=0.143] Steps:   2%|▏         | 15814/1000000 [7:09:27<2979:57:23, 10.90s/it, lr=1e-5, step_loss=0.143][RANK-0]: Step: [15814], local_loss=0.017860781401395798, train_loss=0.049660708755254745, time_cost=8.02898359298706
Steps:   2%|▏         | 15814/1000000 [7:09:27<2979:57:23, 10.90s/it, lr=1e-5, step_loss=0.0179]Steps:   2%|▏         | 15815/1000000 [7:09:36<2896:32:50, 10.60s/it, lr=1e-5, step_loss=0.0179][RANK-0]: Step: [15815], local_loss=0.034565720707178116, train_loss=0.02436082437634468, time_cost=1.2169404029846191
Steps:   2%|▏         | 15815/1000000 [7:09:36<2896:32:50, 10.60s/it, lr=1e-5, step_loss=0.0346]Steps:   2%|▏         | 15816/1000000 [7:09:44<2662:27:26,  9.74s/it, lr=1e-5, step_loss=0.0346][RANK-0]: Step: [15816], local_loss=0.006570631638169289, train_loss=0.054320331662893295, time_cost=1.2000720500946045
Steps:   2%|▏         | 15816/1000000 [7:09:44<2662:27:26,  9.74s/it, lr=1e-5, step_loss=0.00657]Steps:   2%|▏         | 15817/1000000 [7:09:49<2286:59:30,  8.37s/it, lr=1e-5, step_loss=0.00657][RANK-0]: Step: [15817], local_loss=0.018017519265413284, train_loss=0.05453359708189964, time_cost=2.399202346801758
Steps:   2%|▏         | 15817/1000000 [7:09:49<2286:59:30,  8.37s/it, lr=1e-5, step_loss=0.018]  Steps:   2%|▏         | 15818/1000000 [7:09:56<2162:14:04,  7.91s/it, lr=1e-5, step_loss=0.018][RANK-0]: Step: [15818], local_loss=0.005041285417973995, train_loss=0.028078768402338028, time_cost=5.450855731964111
Steps:   2%|▏         | 15818/1000000 [7:09:56<2162:14:04,  7.91s/it, lr=1e-5, step_loss=0.00504]Steps:   2%|▏         | 15819/1000000 [7:10:03<2038:52:42,  7.46s/it, lr=1e-5, step_loss=0.00504][RANK-0]: Step: [15819], local_loss=0.051996342837810516, train_loss=0.026531212031841278, time_cost=2.744307518005371
Steps:   2%|▏         | 15819/1000000 [7:10:03<2038:52:42,  7.46s/it, lr=1e-5, step_loss=0.052]  Steps:   2%|▏         | 15820/1000000 [7:10:09<1924:59:38,  7.04s/it, lr=1e-5, step_loss=0.052][RANK-0]: Step: [15820], local_loss=0.012271231971681118, train_loss=0.03731778636574745, time_cost=1.6820735931396484
Steps:   2%|▏         | 15820/1000000 [7:10:09<1924:59:38,  7.04s/it, lr=1e-5, step_loss=0.0123]Steps:   2%|▏         | 15821/1000000 [7:10:21<2370:26:56,  8.67s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [15821], local_loss=0.03927244246006012, train_loss=0.04681892693042755, time_cost=9.750208377838135
Steps:   2%|▏         | 15821/1000000 [7:10:21<2370:26:56,  8.67s/it, lr=1e-5, step_loss=0.0393]Steps:   2%|▏         | 15822/1000000 [7:10:31<2431:10:49,  8.89s/it, lr=1e-5, step_loss=0.0393][RANK-0]: Step: [15822], local_loss=0.01468612439930439, train_loss=0.02055039070546627, time_cost=4.464430570602417
Steps:   2%|▏         | 15822/1000000 [7:10:31<2431:10:49,  8.89s/it, lr=1e-5, step_loss=0.0147]Steps:   2%|▏         | 15823/1000000 [7:10:37<2210:07:04,  8.08s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [15823], local_loss=0.008535419590771198, train_loss=0.1475125402212143, time_cost=2.219878911972046
Steps:   2%|▏         | 15823/1000000 [7:10:37<2210:07:04,  8.08s/it, lr=1e-5, step_loss=0.00854]Steps:   2%|▏         | 15824/1000000 [7:10:44<2172:56:53,  7.95s/it, lr=1e-5, step_loss=0.00854][RANK-0]: Step: [15824], local_loss=0.016650814563035965, train_loss=0.03936932981014252, time_cost=3.3890345096588135
Steps:   2%|▏         | 15824/1000000 [7:10:44<2172:56:53,  7.95s/it, lr=1e-5, step_loss=0.0167] Steps:   2%|▏         | 15825/1000000 [7:10:58<2617:28:53,  9.57s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [15825], local_loss=0.009855941869318485, train_loss=0.024183526635169983, time_cost=4.018184185028076
Steps:   2%|▏         | 15825/1000000 [7:10:58<2617:28:53,  9.57s/it, lr=1e-5, step_loss=0.00986]Steps:   2%|▏         | 15826/1000000 [7:11:11<2885:45:02, 10.56s/it, lr=1e-5, step_loss=0.00986][RANK-0]: Step: [15826], local_loss=0.9866058826446533, train_loss=0.1685408055782318, time_cost=4.730274200439453
Steps:   2%|▏         | 15826/1000000 [7:11:11<2885:45:02, 10.56s/it, lr=1e-5, step_loss=0.987]  Steps:   2%|▏         | 15827/1000000 [7:11:19<2672:56:11,  9.78s/it, lr=1e-5, step_loss=0.987][RANK-0]: Step: [15827], local_loss=0.021704038605093956, train_loss=0.13780909776687622, time_cost=2.088503122329712
Steps:   2%|▏         | 15827/1000000 [7:11:19<2672:56:11,  9.78s/it, lr=1e-5, step_loss=0.0217]Steps:   2%|▏         | 15828/1000000 [7:11:28<2616:30:33,  9.57s/it, lr=1e-5, step_loss=0.0217][RANK-0]: Step: [15828], local_loss=0.005238850135356188, train_loss=0.2969629466533661, time_cost=2.949209690093994
Steps:   2%|▏         | 15828/1000000 [7:11:28<2616:30:33,  9.57s/it, lr=1e-5, step_loss=0.00524]Steps:   2%|▏         | 15829/1000000 [7:11:32<2224:03:31,  8.14s/it, lr=1e-5, step_loss=0.00524][RANK-0]: Step: [15829], local_loss=0.018686888739466667, train_loss=0.02475622668862343, time_cost=1.606595516204834
Steps:   2%|▏         | 15829/1000000 [7:11:32<2224:03:31,  8.14s/it, lr=1e-5, step_loss=0.0187] Steps:   2%|▏         | 15830/1000000 [7:11:39<2119:21:20,  7.75s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [15830], local_loss=0.014276907779276371, train_loss=0.08082423359155655, time_cost=2.828489065170288
Steps:   2%|▏         | 15830/1000000 [7:11:39<2119:21:20,  7.75s/it, lr=1e-5, step_loss=0.0143]Steps:   2%|▏         | 15831/1000000 [7:11:53<2570:54:24,  9.40s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [15831], local_loss=0.03921491652727127, train_loss=0.04597380384802818, time_cost=3.515293598175049
Steps:   2%|▏         | 15831/1000000 [7:11:53<2570:54:24,  9.40s/it, lr=1e-5, step_loss=0.0392]Steps:   2%|▏         | 15832/1000000 [7:12:01<2531:16:08,  9.26s/it, lr=1e-5, step_loss=0.0392][RANK-0]: Step: [15832], local_loss=0.022866560146212578, train_loss=0.020350679755210876, time_cost=3.8575215339660645
Steps:   2%|▏         | 15832/1000000 [7:12:01<2531:16:08,  9.26s/it, lr=1e-5, step_loss=0.0229]Steps:   2%|▏         | 15833/1000000 [7:12:10<2505:14:21,  9.16s/it, lr=1e-5, step_loss=0.0229][RANK-0]: Step: [15833], local_loss=0.10355741530656815, train_loss=0.03008255735039711, time_cost=4.020882844924927
Steps:   2%|▏         | 15833/1000000 [7:12:10<2505:14:21,  9.16s/it, lr=1e-5, step_loss=0.104] Steps:   2%|▏         | 15834/1000000 [7:12:16<2176:44:00,  7.96s/it, lr=1e-5, step_loss=0.104][RANK-0]: Step: [15834], local_loss=0.008136272430419922, train_loss=0.058433905243873596, time_cost=2.2198257446289062
Steps:   2%|▏         | 15834/1000000 [7:12:16<2176:44:00,  7.96s/it, lr=1e-5, step_loss=0.00814]Steps:   2%|▏         | 15835/1000000 [7:12:29<2664:11:39,  9.75s/it, lr=1e-5, step_loss=0.00814][RANK-0]: Step: [15835], local_loss=0.05131911113858223, train_loss=0.03989911079406738, time_cost=6.187565326690674
Steps:   2%|▏         | 15835/1000000 [7:12:29<2664:11:39,  9.75s/it, lr=1e-5, step_loss=0.0513] Steps:   2%|▏         | 15836/1000000 [7:12:39<2641:49:41,  9.66s/it, lr=1e-5, step_loss=0.0513][RANK-0]: Step: [15836], local_loss=0.015428372658789158, train_loss=0.02300112321972847, time_cost=4.588841199874878
Steps:   2%|▏         | 15836/1000000 [7:12:39<2641:49:41,  9.66s/it, lr=1e-5, step_loss=0.0154]Steps:   2%|▏         | 15837/1000000 [7:12:52<2935:08:20, 10.74s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [15837], local_loss=0.01775353215634823, train_loss=0.05435473844408989, time_cost=3.7620201110839844
Steps:   2%|▏         | 15837/1000000 [7:12:52<2935:08:20, 10.74s/it, lr=1e-5, step_loss=0.0178]Steps:   2%|▏         | 15838/1000000 [7:13:11<3628:44:09, 13.27s/it, lr=1e-5, step_loss=0.0178][RANK-0]: Step: [15838], local_loss=0.30017927289009094, train_loss=0.06160765513777733, time_cost=11.489189624786377
Steps:   2%|▏         | 15838/1000000 [7:13:11<3628:44:09, 13.27s/it, lr=1e-5, step_loss=0.3]   Steps:   2%|▏         | 15839/1000000 [7:13:24<3617:11:40, 13.23s/it, lr=1e-5, step_loss=0.3][RANK-0]: Step: [15839], local_loss=0.02196141704916954, train_loss=0.01910526491701603, time_cost=5.436241149902344
Steps:   2%|▏         | 15839/1000000 [7:13:25<3617:11:40, 13.23s/it, lr=1e-5, step_loss=0.022]Steps:   2%|▏         | 15840/1000000 [7:13:31<3031:07:57, 11.09s/it, lr=1e-5, step_loss=0.022][RANK-0]: Step: [15840], local_loss=0.0093853659927845, train_loss=0.01779850199818611, time_cost=1.7147228717803955
Steps:   2%|▏         | 15840/1000000 [7:13:31<3031:07:57, 11.09s/it, lr=1e-5, step_loss=0.00939]Steps:   2%|▏         | 15841/1000000 [7:13:42<3079:29:09, 11.26s/it, lr=1e-5, step_loss=0.00939][RANK-0]: Step: [15841], local_loss=0.005490442737936974, train_loss=0.03006073273718357, time_cost=4.3439929485321045
Steps:   2%|▏         | 15841/1000000 [7:13:42<3079:29:09, 11.26s/it, lr=1e-5, step_loss=0.00549]Steps:   2%|▏         | 15842/1000000 [7:13:46<2491:40:53,  9.11s/it, lr=1e-5, step_loss=0.00549][RANK-0]: Step: [15842], local_loss=0.00808640941977501, train_loss=2.3263490200042725, time_cost=1.304781198501587
Steps:   2%|▏         | 15842/1000000 [7:13:46<2491:40:53,  9.11s/it, lr=1e-5, step_loss=0.00809]Steps:   2%|▏         | 15843/1000000 [7:13:53<2313:24:44,  8.46s/it, lr=1e-5, step_loss=0.00809][RANK-0]: Step: [15843], local_loss=0.00936136394739151, train_loss=0.04709547758102417, time_cost=2.818394899368286
Steps:   2%|▏         | 15843/1000000 [7:13:53<2313:24:44,  8.46s/it, lr=1e-5, step_loss=0.00936]Steps:   2%|▏         | 15844/1000000 [7:14:06<2666:47:32,  9.76s/it, lr=1e-5, step_loss=0.00936][RANK-0]: Step: [15844], local_loss=0.026196269318461418, train_loss=0.04172617197036743, time_cost=3.9446940422058105
Steps:   2%|▏         | 15844/1000000 [7:14:06<2666:47:32,  9.76s/it, lr=1e-5, step_loss=0.0262] Steps:   2%|▏         | 15845/1000000 [7:14:12<2357:42:57,  8.62s/it, lr=1e-5, step_loss=0.0262][RANK-0]: Step: [15845], local_loss=0.006430803798139095, train_loss=0.02656291052699089, time_cost=1.638371229171753
Steps:   2%|▏         | 15845/1000000 [7:14:12<2357:42:57,  8.62s/it, lr=1e-5, step_loss=0.00643]Steps:   2%|▏         | 15846/1000000 [7:14:17<2069:15:41,  7.57s/it, lr=1e-5, step_loss=0.00643][RANK-0]: Step: [15846], local_loss=0.07766292244195938, train_loss=0.06143302470445633, time_cost=2.3519937992095947
Steps:   2%|▏         | 15846/1000000 [7:14:17<2069:15:41,  7.57s/it, lr=1e-5, step_loss=0.0777] Steps:   2%|▏         | 15847/1000000 [7:14:22<1810:39:22,  6.62s/it, lr=1e-5, step_loss=0.0777][RANK-0]: Step: [15847], local_loss=0.010709822177886963, train_loss=0.041762351989746094, time_cost=2.4979586601257324
Steps:   2%|▏         | 15847/1000000 [7:14:22<1810:39:22,  6.62s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 15848/1000000 [7:14:27<1681:40:51,  6.15s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [15848], local_loss=0.0626886785030365, train_loss=0.09039010107517242, time_cost=2.0676217079162598
Steps:   2%|▏         | 15848/1000000 [7:14:27<1681:40:51,  6.15s/it, lr=1e-5, step_loss=0.0627]Steps:   2%|▏         | 15849/1000000 [7:14:32<1611:14:40,  5.89s/it, lr=1e-5, step_loss=0.0627][RANK-0]: Step: [15849], local_loss=0.013151310384273529, train_loss=0.028148524463176727, time_cost=2.6778128147125244
Steps:   2%|▏         | 15849/1000000 [7:14:32<1611:14:40,  5.89s/it, lr=1e-5, step_loss=0.0132]Steps:   2%|▏         | 15850/1000000 [7:14:37<1506:16:27,  5.51s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [15850], local_loss=0.010085965506732464, train_loss=15.253700256347656, time_cost=1.7635533809661865
Steps:   2%|▏         | 15850/1000000 [7:14:37<1506:16:27,  5.51s/it, lr=1e-5, step_loss=0.0101]Steps:   2%|▏         | 15851/1000000 [7:14:48<2027:03:21,  7.41s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [15851], local_loss=0.030110865831375122, train_loss=0.05142369866371155, time_cost=3.142441749572754
Steps:   2%|▏         | 15851/1000000 [7:14:48<2027:03:21,  7.41s/it, lr=1e-5, step_loss=0.0301]Steps:   2%|▏         | 15852/1000000 [7:15:00<2369:57:42,  8.67s/it, lr=1e-5, step_loss=0.0301][RANK-0]: Step: [15852], local_loss=0.002944616600871086, train_loss=0.028878718614578247, time_cost=5.579157829284668
Steps:   2%|▏         | 15852/1000000 [7:15:00<2369:57:42,  8.67s/it, lr=1e-5, step_loss=0.00294]Steps:   2%|▏         | 15853/1000000 [7:15:13<2757:59:56, 10.09s/it, lr=1e-5, step_loss=0.00294][RANK-0]: Step: [15853], local_loss=0.017180142924189568, train_loss=0.048701219260692596, time_cost=4.856853723526001
Steps:   2%|▏         | 15853/1000000 [7:15:13<2757:59:56, 10.09s/it, lr=1e-5, step_loss=0.0172] Steps:   2%|▏         | 15854/1000000 [7:15:31<3359:41:14, 12.29s/it, lr=1e-5, step_loss=0.0172][RANK-0]: Step: [15854], local_loss=0.011581959202885628, train_loss=0.059140197932720184, time_cost=9.590225219726562
Steps:   2%|▏         | 15854/1000000 [7:15:31<3359:41:14, 12.29s/it, lr=1e-5, step_loss=0.0116]Steps:   2%|▏         | 15855/1000000 [7:15:38<2915:56:54, 10.67s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [15855], local_loss=0.5339992046356201, train_loss=0.10101793706417084, time_cost=1.2513396739959717
Steps:   2%|▏         | 15855/1000000 [7:15:38<2915:56:54, 10.67s/it, lr=1e-5, step_loss=0.534] Steps:   2%|▏         | 15856/1000000 [7:15:46<2761:32:53, 10.10s/it, lr=1e-5, step_loss=0.534][RANK-0]: Step: [15856], local_loss=0.029629886150360107, train_loss=0.04731852933764458, time_cost=3.8001549243927
Steps:   2%|▏         | 15856/1000000 [7:15:46<2761:32:53, 10.10s/it, lr=1e-5, step_loss=0.0296]Steps:   2%|▏         | 15857/1000000 [7:15:51<2293:36:57,  8.39s/it, lr=1e-5, step_loss=0.0296][RANK-0]: Step: [15857], local_loss=0.011756474152207375, train_loss=0.03614422306418419, time_cost=1.258237600326538
Steps:   2%|▏         | 15857/1000000 [7:15:51<2293:36:57,  8.39s/it, lr=1e-5, step_loss=0.0118]Steps:   2%|▏         | 15858/1000000 [7:16:01<2473:39:18,  9.05s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [15858], local_loss=0.05937562882900238, train_loss=0.024183904752135277, time_cost=7.892149925231934
Steps:   2%|▏         | 15858/1000000 [7:16:01<2473:39:18,  9.05s/it, lr=1e-5, step_loss=0.0594]Steps:   2%|▏         | 15859/1000000 [7:16:06<2142:43:56,  7.84s/it, lr=1e-5, step_loss=0.0594][RANK-0]: Step: [15859], local_loss=0.04135172814130783, train_loss=0.0716198980808258, time_cost=1.388263463973999
Steps:   2%|▏         | 15859/1000000 [7:16:06<2142:43:56,  7.84s/it, lr=1e-5, step_loss=0.0414]Steps:   2%|▏         | 15860/1000000 [7:16:15<2224:53:16,  8.14s/it, lr=1e-5, step_loss=0.0414][RANK-0]: Step: [15860], local_loss=0.005571606568992138, train_loss=6.568836688995361, time_cost=3.4422779083251953
Steps:   2%|▏         | 15860/1000000 [7:16:15<2224:53:16,  8.14s/it, lr=1e-5, step_loss=0.00557]Steps:   2%|▏         | 15861/1000000 [7:16:24<2240:44:19,  8.20s/it, lr=1e-5, step_loss=0.00557][RANK-0]: Step: [15861], local_loss=0.02088829316198826, train_loss=0.03766125813126564, time_cost=1.9060180187225342
Steps:   2%|▏         | 15861/1000000 [7:16:24<2240:44:19,  8.20s/it, lr=1e-5, step_loss=0.0209] Steps:   2%|▏         | 15862/1000000 [7:16:29<2042:24:54,  7.47s/it, lr=1e-5, step_loss=0.0209][RANK-0]: Step: [15862], local_loss=0.09996034950017929, train_loss=0.053009793162345886, time_cost=3.0564017295837402
Steps:   2%|▏         | 15862/1000000 [7:16:29<2042:24:54,  7.47s/it, lr=1e-5, step_loss=0.1]   Steps:   2%|▏         | 15863/1000000 [7:16:38<2171:42:40,  7.94s/it, lr=1e-5, step_loss=0.1][RANK-0]: Step: [15863], local_loss=0.029849113896489143, train_loss=0.08371643722057343, time_cost=4.092092275619507
Steps:   2%|▏         | 15863/1000000 [7:16:38<2171:42:40,  7.94s/it, lr=1e-5, step_loss=0.0298]Steps:   2%|▏         | 15864/1000000 [7:16:43<1925:50:29,  7.04s/it, lr=1e-5, step_loss=0.0298][RANK-0]: Step: [15864], local_loss=0.026365628466010094, train_loss=0.07446345686912537, time_cost=1.9284982681274414
Steps:   2%|▏         | 15864/1000000 [7:16:43<1925:50:29,  7.04s/it, lr=1e-5, step_loss=0.0264]Steps:   2%|▏         | 15865/1000000 [7:16:53<2096:48:02,  7.67s/it, lr=1e-5, step_loss=0.0264][RANK-0]: Step: [15865], local_loss=0.3455418348312378, train_loss=0.08199647068977356, time_cost=6.901127815246582
Steps:   2%|▏         | 15865/1000000 [7:16:53<2096:48:02,  7.67s/it, lr=1e-5, step_loss=0.346] Steps:   2%|▏         | 15866/1000000 [7:16:58<1940:13:27,  7.10s/it, lr=1e-5, step_loss=0.346][RANK-0]: Step: [15866], local_loss=0.02677621692419052, train_loss=0.03265274688601494, time_cost=1.4479994773864746
Steps:   2%|▏         | 15866/1000000 [7:16:58<1940:13:27,  7.10s/it, lr=1e-5, step_loss=0.0268]Steps:   2%|▏         | 15867/1000000 [7:17:04<1801:27:59,  6.59s/it, lr=1e-5, step_loss=0.0268][RANK-0]: Step: [15867], local_loss=0.006646594498306513, train_loss=0.022153440862894058, time_cost=2.445481300354004
Steps:   2%|▏         | 15867/1000000 [7:17:04<1801:27:59,  6.59s/it, lr=1e-5, step_loss=0.00665]Steps:   2%|▏         | 15868/1000000 [7:17:18<2412:33:00,  8.83s/it, lr=1e-5, step_loss=0.00665][RANK-0]: Step: [15868], local_loss=0.010460607707500458, train_loss=0.0829227939248085, time_cost=3.8549234867095947
Steps:   2%|▏         | 15868/1000000 [7:17:18<2412:33:00,  8.83s/it, lr=1e-5, step_loss=0.0105] Steps:   2%|▏         | 15869/1000000 [7:17:27<2479:09:40,  9.07s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [15869], local_loss=0.00400576600804925, train_loss=0.019289979711174965, time_cost=3.8419172763824463
Steps:   2%|▏         | 15869/1000000 [7:17:27<2479:09:40,  9.07s/it, lr=1e-5, step_loss=0.00401]Steps:   2%|▏         | 15870/1000000 [7:17:33<2184:46:08,  7.99s/it, lr=1e-5, step_loss=0.00401][RANK-0]: Step: [15870], local_loss=0.150493323802948, train_loss=0.07970689982175827, time_cost=3.0304720401763916
Steps:   2%|▏         | 15870/1000000 [7:17:33<2184:46:08,  7.99s/it, lr=1e-5, step_loss=0.15]   Steps:   2%|▏         | 15871/1000000 [7:17:41<2162:56:25,  7.91s/it, lr=1e-5, step_loss=0.15][RANK-0]: Step: [15871], local_loss=0.004342464730143547, train_loss=0.02291666902601719, time_cost=1.9518327713012695
Steps:   2%|▏         | 15871/1000000 [7:17:41<2162:56:25,  7.91s/it, lr=1e-5, step_loss=0.00434]Steps:   2%|▏         | 15872/1000000 [7:17:49<2175:44:55,  7.96s/it, lr=1e-5, step_loss=0.00434][RANK-0]: Step: [15872], local_loss=0.015740159898996353, train_loss=0.04284774884581566, time_cost=6.9934375286102295
Steps:   2%|▏         | 15872/1000000 [7:17:49<2175:44:55,  7.96s/it, lr=1e-5, step_loss=0.0157] Steps:   2%|▏         | 15873/1000000 [7:18:01<2541:40:42,  9.30s/it, lr=1e-5, step_loss=0.0157][RANK-0]: Step: [15873], local_loss=0.02732919529080391, train_loss=0.08305799961090088, time_cost=5.431213617324829
Steps:   2%|▏         | 15873/1000000 [7:18:01<2541:40:42,  9.30s/it, lr=1e-5, step_loss=0.0273]Steps:   2%|▏         | 15874/1000000 [7:18:14<2826:32:53, 10.34s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [15874], local_loss=0.006416783668100834, train_loss=0.028213173151016235, time_cost=1.279404878616333
Steps:   2%|▏         | 15874/1000000 [7:18:14<2826:32:53, 10.34s/it, lr=1e-5, step_loss=0.00642]Steps:   2%|▏         | 15875/1000000 [7:18:25<2901:37:43, 10.61s/it, lr=1e-5, step_loss=0.00642][RANK-0]: Step: [15875], local_loss=0.05036509037017822, train_loss=0.024755921214818954, time_cost=6.390347003936768
Steps:   2%|▏         | 15875/1000000 [7:18:25<2901:37:43, 10.61s/it, lr=1e-5, step_loss=0.0504] Steps:   2%|▏         | 15876/1000000 [7:18:35<2819:32:52, 10.31s/it, lr=1e-5, step_loss=0.0504][RANK-0]: Step: [15876], local_loss=0.023787949234247208, train_loss=0.03230518475174904, time_cost=3.785306453704834
Steps:   2%|▏         | 15876/1000000 [7:18:35<2819:32:52, 10.31s/it, lr=1e-5, step_loss=0.0238]Steps:   2%|▏         | 15877/1000000 [7:18:39<2338:36:59,  8.55s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [15877], local_loss=0.05762121081352234, train_loss=0.03858920931816101, time_cost=1.5283682346343994
Steps:   2%|▏         | 15877/1000000 [7:18:39<2338:36:59,  8.55s/it, lr=1e-5, step_loss=0.0576]Steps:   2%|▏         | 15878/1000000 [7:18:46<2218:25:17,  8.12s/it, lr=1e-5, step_loss=0.0576][RANK-0]: Step: [15878], local_loss=0.24738310277462006, train_loss=0.0651167556643486, time_cost=2.789628028869629
Steps:   2%|▏         | 15878/1000000 [7:18:46<2218:25:17,  8.12s/it, lr=1e-5, step_loss=0.247] Steps:   2%|▏         | 15879/1000000 [7:18:52<1982:24:02,  7.25s/it, lr=1e-5, step_loss=0.247][RANK-0]: Step: [15879], local_loss=0.9903803467750549, train_loss=5.5336127281188965, time_cost=2.433084726333618
Steps:   2%|▏         | 15879/1000000 [7:18:52<1982:24:02,  7.25s/it, lr=1e-5, step_loss=0.99] Steps:   2%|▏         | 15880/1000000 [7:19:02<2245:43:44,  8.22s/it, lr=1e-5, step_loss=0.99][RANK-0]: Step: [15880], local_loss=0.031230861321091652, train_loss=22.725830078125, time_cost=3.945265531539917
Steps:   2%|▏         | 15880/1000000 [7:19:02<2245:43:44,  8.22s/it, lr=1e-5, step_loss=0.0312]Steps:   2%|▏         | 15881/1000000 [7:19:13<2438:31:05,  8.92s/it, lr=1e-5, step_loss=0.0312][RANK-0]: Step: [15881], local_loss=0.004649188369512558, train_loss=0.025721769779920578, time_cost=2.149538040161133
Steps:   2%|▏         | 15881/1000000 [7:19:13<2438:31:05,  8.92s/it, lr=1e-5, step_loss=0.00465]Steps:   2%|▏         | 15882/1000000 [7:19:20<2296:54:52,  8.40s/it, lr=1e-5, step_loss=0.00465][RANK-0]: Step: [15882], local_loss=0.020779002457857132, train_loss=0.019766798242926598, time_cost=2.5577874183654785
Steps:   2%|▏         | 15882/1000000 [7:19:20<2296:54:52,  8.40s/it, lr=1e-5, step_loss=0.0208] Steps:   2%|▏         | 15883/1000000 [7:19:26<2102:00:21,  7.69s/it, lr=1e-5, step_loss=0.0208][RANK-0]: Step: [15883], local_loss=0.11998428404331207, train_loss=0.05261821299791336, time_cost=1.4856846332550049
Steps:   2%|▏         | 15883/1000000 [7:19:26<2102:00:21,  7.69s/it, lr=1e-5, step_loss=0.12]  Steps:   2%|▏         | 15884/1000000 [7:19:38<2445:23:15,  8.95s/it, lr=1e-5, step_loss=0.12][RANK-0]: Step: [15884], local_loss=0.1321660280227661, train_loss=0.08412449806928635, time_cost=1.9869849681854248
Steps:   2%|▏         | 15884/1000000 [7:19:38<2445:23:15,  8.95s/it, lr=1e-5, step_loss=0.132]Steps:   2%|▏         | 15885/1000000 [7:19:49<2603:20:26,  9.52s/it, lr=1e-5, step_loss=0.132][RANK-0]: Step: [15885], local_loss=0.05515943840146065, train_loss=0.034808121621608734, time_cost=1.639575719833374
Steps:   2%|▏         | 15885/1000000 [7:19:49<2603:20:26,  9.52s/it, lr=1e-5, step_loss=0.0552]Steps:   2%|▏         | 15886/1000000 [7:20:03<2994:08:36, 10.95s/it, lr=1e-5, step_loss=0.0552][RANK-0]: Step: [15886], local_loss=0.018405944108963013, train_loss=0.02068670466542244, time_cost=5.536935329437256
Steps:   2%|▏         | 15886/1000000 [7:20:03<2994:08:36, 10.95s/it, lr=1e-5, step_loss=0.0184]Steps:   2%|▏         | 15887/1000000 [7:20:10<2657:35:00,  9.72s/it, lr=1e-5, step_loss=0.0184][RANK-0]: Step: [15887], local_loss=0.032154496759176254, train_loss=0.04592323303222656, time_cost=2.2650163173675537
Steps:   2%|▏         | 15887/1000000 [7:20:10<2657:35:00,  9.72s/it, lr=1e-5, step_loss=0.0322]Steps:   2%|▏         | 15888/1000000 [7:20:26<3166:49:14, 11.58s/it, lr=1e-5, step_loss=0.0322][RANK-0]: Step: [15888], local_loss=0.020136933773756027, train_loss=0.01945589855313301, time_cost=1.2169897556304932
Steps:   2%|▏         | 15888/1000000 [7:20:26<3166:49:14, 11.58s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 15889/1000000 [7:20:37<3167:13:37, 11.59s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [15889], local_loss=0.007922022603452206, train_loss=0.048144400119781494, time_cost=4.0944178104400635
Steps:   2%|▏         | 15889/1000000 [7:20:37<3167:13:37, 11.59s/it, lr=1e-5, step_loss=0.00792]Steps:   2%|▏         | 15890/1000000 [7:20:50<3254:15:25, 11.90s/it, lr=1e-5, step_loss=0.00792][RANK-0]: Step: [15890], local_loss=0.00384441833011806, train_loss=0.04100130498409271, time_cost=4.459993839263916
Steps:   2%|▏         | 15890/1000000 [7:20:50<3254:15:25, 11.90s/it, lr=1e-5, step_loss=0.00384]Steps:   2%|▏         | 15891/1000000 [7:21:05<3556:40:24, 13.01s/it, lr=1e-5, step_loss=0.00384][RANK-0]: Step: [15891], local_loss=0.0048432182520627975, train_loss=0.01894208788871765, time_cost=7.697935581207275
Steps:   2%|▏         | 15891/1000000 [7:21:05<3556:40:24, 13.01s/it, lr=1e-5, step_loss=0.00484]Steps:   2%|▏         | 15892/1000000 [7:21:21<3791:22:49, 13.87s/it, lr=1e-5, step_loss=0.00484][RANK-0]: Step: [15892], local_loss=0.014268001541495323, train_loss=0.025588318705558777, time_cost=7.934008836746216
Steps:   2%|▏         | 15892/1000000 [7:21:21<3791:22:49, 13.87s/it, lr=1e-5, step_loss=0.0143] Steps:   2%|▏         | 15893/1000000 [7:21:34<3711:29:22, 13.58s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [15893], local_loss=0.06875233352184296, train_loss=0.045803003013134, time_cost=1.194695234298706
Steps:   2%|▏         | 15893/1000000 [7:21:34<3711:29:22, 13.58s/it, lr=1e-5, step_loss=0.0688]Steps:   2%|▏         | 15894/1000000 [7:21:50<3876:13:08, 14.18s/it, lr=1e-5, step_loss=0.0688][RANK-0]: Step: [15894], local_loss=0.018710549920797348, train_loss=0.03204407915472984, time_cost=6.548158645629883
Steps:   2%|▏         | 15894/1000000 [7:21:50<3876:13:08, 14.18s/it, lr=1e-5, step_loss=0.0187]Steps:   2%|▏         | 15895/1000000 [7:21:57<3331:20:27, 12.19s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [15895], local_loss=0.008311169221997261, train_loss=0.08189088106155396, time_cost=5.669911623001099
Steps:   2%|▏         | 15895/1000000 [7:21:57<3331:20:27, 12.19s/it, lr=1e-5, step_loss=0.00831]Steps:   2%|▏         | 15896/1000000 [7:22:07<3101:19:15, 11.35s/it, lr=1e-5, step_loss=0.00831][RANK-0]: Step: [15896], local_loss=0.10263021290302277, train_loss=0.0690465122461319, time_cost=2.696242094039917
Steps:   2%|▏         | 15896/1000000 [7:22:07<3101:19:15, 11.35s/it, lr=1e-5, step_loss=0.103]  Steps:   2%|▏         | 15897/1000000 [7:22:17<3045:48:01, 11.14s/it, lr=1e-5, step_loss=0.103][RANK-0]: Step: [15897], local_loss=0.0037642705719918013, train_loss=0.04403303563594818, time_cost=1.3104469776153564
Steps:   2%|▏         | 15897/1000000 [7:22:17<3045:48:01, 11.14s/it, lr=1e-5, step_loss=0.00376]Steps:   2%|▏         | 15898/1000000 [7:22:29<3058:22:15, 11.19s/it, lr=1e-5, step_loss=0.00376][RANK-0]: Step: [15898], local_loss=0.025471702218055725, train_loss=0.031433649361133575, time_cost=2.293361186981201
Steps:   2%|▏         | 15898/1000000 [7:22:29<3058:22:15, 11.19s/it, lr=1e-5, step_loss=0.0255] Steps:   2%|▏         | 15899/1000000 [7:22:38<2894:09:27, 10.59s/it, lr=1e-5, step_loss=0.0255][RANK-0]: Step: [15899], local_loss=0.042420752346515656, train_loss=0.05465768277645111, time_cost=3.6178901195526123
Steps:   2%|▏         | 15899/1000000 [7:22:38<2894:09:27, 10.59s/it, lr=1e-5, step_loss=0.0424]Steps:   2%|▏         | 15900/1000000 [7:22:54<3382:04:00, 12.37s/it, lr=1e-5, step_loss=0.0424][RANK-0]: Step: [15900], local_loss=0.003601754317060113, train_loss=0.038615502417087555, time_cost=3.162317991256714
Steps:   2%|▏         | 15900/1000000 [7:22:54<3382:04:00, 12.37s/it, lr=1e-5, step_loss=0.0036]Steps:   2%|▏         | 15901/1000000 [7:23:03<3106:49:14, 11.37s/it, lr=1e-5, step_loss=0.0036][RANK-0]: Step: [15901], local_loss=0.00972465705126524, train_loss=0.03256125748157501, time_cost=1.19773530960083
Steps:   2%|▏         | 15901/1000000 [7:23:03<3106:49:14, 11.37s/it, lr=1e-5, step_loss=0.00972]Steps:   2%|▏         | 15902/1000000 [7:23:14<3061:36:51, 11.20s/it, lr=1e-5, step_loss=0.00972][RANK-0]: Step: [15902], local_loss=0.01428443007171154, train_loss=0.04603435471653938, time_cost=1.9335863590240479
Steps:   2%|▏         | 15902/1000000 [7:23:14<3061:36:51, 11.20s/it, lr=1e-5, step_loss=0.0143] Steps:   2%|▏         | 15903/1000000 [7:23:28<3253:24:15, 11.90s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [15903], local_loss=0.040543440729379654, train_loss=0.02573184296488762, time_cost=5.192200183868408
Steps:   2%|▏         | 15903/1000000 [7:23:28<3253:24:15, 11.90s/it, lr=1e-5, step_loss=0.0405]Steps:   2%|▏         | 15904/1000000 [7:23:42<3472:34:30, 12.70s/it, lr=1e-5, step_loss=0.0405][RANK-0]: Step: [15904], local_loss=0.006291577126830816, train_loss=0.022230859845876694, time_cost=4.729061841964722
Steps:   2%|▏         | 15904/1000000 [7:23:42<3472:34:30, 12.70s/it, lr=1e-5, step_loss=0.00629]Steps:   2%|▏         | 15905/1000000 [7:23:48<2904:17:23, 10.62s/it, lr=1e-5, step_loss=0.00629][RANK-0]: Step: [15905], local_loss=0.013854634016752243, train_loss=0.030532274395227432, time_cost=1.6108317375183105
Steps:   2%|▏         | 15905/1000000 [7:23:48<2904:17:23, 10.62s/it, lr=1e-5, step_loss=0.0139] Steps:   2%|▏         | 15906/1000000 [7:23:59<2899:02:55, 10.61s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [15906], local_loss=0.043832629919052124, train_loss=0.036599863320589066, time_cost=1.4168477058410645
Steps:   2%|▏         | 15906/1000000 [7:23:59<2899:02:55, 10.61s/it, lr=1e-5, step_loss=0.0438]Steps:   2%|▏         | 15907/1000000 [7:24:11<3027:22:04, 11.07s/it, lr=1e-5, step_loss=0.0438][RANK-0]: Step: [15907], local_loss=0.035864658653736115, train_loss=0.15049995481967926, time_cost=10.293687343597412
Steps:   2%|▏         | 15907/1000000 [7:24:11<3027:22:04, 11.07s/it, lr=1e-5, step_loss=0.0359]Steps:   2%|▏         | 15908/1000000 [7:24:22<3031:33:37, 11.09s/it, lr=1e-5, step_loss=0.0359][RANK-0]: Step: [15908], local_loss=0.014805831015110016, train_loss=0.027817795053124428, time_cost=1.5671319961547852
Steps:   2%|▏         | 15908/1000000 [7:24:22<3031:33:37, 11.09s/it, lr=1e-5, step_loss=0.0148]Steps:   2%|▏         | 15909/1000000 [7:24:34<3107:10:23, 11.37s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [15909], local_loss=0.01003951020538807, train_loss=0.01926681213080883, time_cost=4.988138198852539
Steps:   2%|▏         | 15909/1000000 [7:24:34<3107:10:23, 11.37s/it, lr=1e-5, step_loss=0.01]  Steps:   2%|▏         | 15910/1000000 [7:24:48<3347:13:48, 12.24s/it, lr=1e-5, step_loss=0.01][RANK-0]: Step: [15910], local_loss=0.019601216539740562, train_loss=0.017190415412187576, time_cost=5.1779561042785645
Steps:   2%|▏         | 15910/1000000 [7:24:48<3347:13:48, 12.24s/it, lr=1e-5, step_loss=0.0196]Steps:   2%|▏         | 15911/1000000 [7:25:02<3439:46:01, 12.58s/it, lr=1e-5, step_loss=0.0196][RANK-0]: Step: [15911], local_loss=0.033267270773649216, train_loss=0.017471497878432274, time_cost=4.162729024887085
Steps:   2%|▏         | 15911/1000000 [7:25:02<3439:46:01, 12.58s/it, lr=1e-5, step_loss=0.0333]Steps:   2%|▏         | 15912/1000000 [7:25:16<3571:50:49, 13.07s/it, lr=1e-5, step_loss=0.0333][RANK-0]: Step: [15912], local_loss=0.0039413440972566605, train_loss=0.19115041196346283, time_cost=4.416933298110962
Steps:   2%|▏         | 15912/1000000 [7:25:16<3571:50:49, 13.07s/it, lr=1e-5, step_loss=0.00394]Steps:   2%|▏         | 15913/1000000 [7:25:21<2965:43:04, 10.85s/it, lr=1e-5, step_loss=0.00394][RANK-0]: Step: [15913], local_loss=0.007094584871083498, train_loss=0.07598944008350372, time_cost=3.2862088680267334
Steps:   2%|▏         | 15913/1000000 [7:25:21<2965:43:04, 10.85s/it, lr=1e-5, step_loss=0.00709]Steps:   2%|▏         | 15914/1000000 [7:25:31<2885:27:51, 10.56s/it, lr=1e-5, step_loss=0.00709][RANK-0]: Step: [15914], local_loss=0.025991685688495636, train_loss=0.034265659749507904, time_cost=8.255929231643677
Steps:   2%|▏         | 15914/1000000 [7:25:31<2885:27:51, 10.56s/it, lr=1e-5, step_loss=0.026]  Steps:   2%|▏         | 15915/1000000 [7:25:37<2443:44:52,  8.94s/it, lr=1e-5, step_loss=0.026][RANK-0]: Step: [15915], local_loss=0.028232436627149582, train_loss=7.531770706176758, time_cost=1.4809350967407227
Steps:   2%|▏         | 15915/1000000 [7:25:37<2443:44:52,  8.94s/it, lr=1e-5, step_loss=0.0282]Steps:   2%|▏         | 15916/1000000 [7:25:42<2130:49:25,  7.80s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [15916], local_loss=0.09683000296354294, train_loss=0.07316228002309799, time_cost=1.217301607131958
Steps:   2%|▏         | 15916/1000000 [7:25:42<2130:49:25,  7.80s/it, lr=1e-5, step_loss=0.0968]Steps:   2%|▏         | 15917/1000000 [7:25:47<1910:43:20,  6.99s/it, lr=1e-5, step_loss=0.0968][RANK-0]: Step: [15917], local_loss=1.008563756942749, train_loss=0.21328353881835938, time_cost=2.3450701236724854
Steps:   2%|▏         | 15917/1000000 [7:25:47<1910:43:20,  6.99s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 15918/1000000 [7:25:56<2096:05:00,  7.67s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [15918], local_loss=0.032269030809402466, train_loss=0.1444023847579956, time_cost=2.937246561050415
Steps:   2%|▏         | 15918/1000000 [7:25:56<2096:05:00,  7.67s/it, lr=1e-5, step_loss=0.0323]Steps:   2%|▏         | 15919/1000000 [7:26:05<2206:53:04,  8.07s/it, lr=1e-5, step_loss=0.0323][RANK-0]: Step: [15919], local_loss=0.19270867109298706, train_loss=0.18449822068214417, time_cost=2.5522730350494385
Steps:   2%|▏         | 15919/1000000 [7:26:05<2206:53:04,  8.07s/it, lr=1e-5, step_loss=0.193] Steps:   2%|▏         | 15920/1000000 [7:26:14<2283:42:03,  8.35s/it, lr=1e-5, step_loss=0.193][RANK-0]: Step: [15920], local_loss=0.05572609230875969, train_loss=0.09702664613723755, time_cost=3.387089967727661
Steps:   2%|▏         | 15920/1000000 [7:26:14<2283:42:03,  8.35s/it, lr=1e-5, step_loss=0.0557]Steps:   2%|▏         | 15921/1000000 [7:26:19<2033:11:35,  7.44s/it, lr=1e-5, step_loss=0.0557][RANK-0]: Step: [15921], local_loss=0.008529057726264, train_loss=12.725628852844238, time_cost=1.3758633136749268
Steps:   2%|▏         | 15921/1000000 [7:26:19<2033:11:35,  7.44s/it, lr=1e-5, step_loss=0.00853]Steps:   2%|▏         | 15922/1000000 [7:26:26<2004:54:01,  7.33s/it, lr=1e-5, step_loss=0.00853][RANK-0]: Step: [15922], local_loss=0.007727963849902153, train_loss=0.029730230569839478, time_cost=2.9654250144958496
Steps:   2%|▏         | 15922/1000000 [7:26:26<2004:54:01,  7.33s/it, lr=1e-5, step_loss=0.00773]Steps:   2%|▏         | 15923/1000000 [7:26:31<1766:32:51,  6.46s/it, lr=1e-5, step_loss=0.00773][RANK-0]: Step: [15923], local_loss=0.01335521787405014, train_loss=0.021777864545583725, time_cost=1.461961030960083
Steps:   2%|▏         | 15923/1000000 [7:26:31<1766:32:51,  6.46s/it, lr=1e-5, step_loss=0.0134] Steps:   2%|▏         | 15924/1000000 [7:26:40<1976:02:25,  7.23s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [15924], local_loss=0.018600720912218094, train_loss=0.03219493851065636, time_cost=1.3335449695587158
Steps:   2%|▏         | 15924/1000000 [7:26:40<1976:02:25,  7.23s/it, lr=1e-5, step_loss=0.0186]Steps:   2%|▏         | 15925/1000000 [7:26:54<2527:44:50,  9.25s/it, lr=1e-5, step_loss=0.0186][RANK-0]: Step: [15925], local_loss=0.08028245717287064, train_loss=0.04349616914987564, time_cost=5.176512241363525
Steps:   2%|▏         | 15925/1000000 [7:26:54<2527:44:50,  9.25s/it, lr=1e-5, step_loss=0.0803]Steps:   2%|▏         | 15926/1000000 [7:27:04<2629:27:47,  9.62s/it, lr=1e-5, step_loss=0.0803][RANK-0]: Step: [15926], local_loss=0.007487480528652668, train_loss=0.037947364151477814, time_cost=3.4430649280548096
Steps:   2%|▏         | 15926/1000000 [7:27:04<2629:27:47,  9.62s/it, lr=1e-5, step_loss=0.00749]Steps:   2%|▏         | 15927/1000000 [7:27:18<2941:11:33, 10.76s/it, lr=1e-5, step_loss=0.00749][RANK-0]: Step: [15927], local_loss=0.0282516460865736, train_loss=0.028140457347035408, time_cost=4.434481143951416
Steps:   2%|▏         | 15927/1000000 [7:27:18<2941:11:33, 10.76s/it, lr=1e-5, step_loss=0.0283] Steps:   2%|▏         | 15928/1000000 [7:27:29<2984:58:53, 10.92s/it, lr=1e-5, step_loss=0.0283][RANK-0]: Step: [15928], local_loss=0.012700676918029785, train_loss=0.14133119583129883, time_cost=3.8868212699890137
Steps:   2%|▏         | 15928/1000000 [7:27:29<2984:58:53, 10.92s/it, lr=1e-5, step_loss=0.0127]Steps:   2%|▏         | 15929/1000000 [7:27:42<3127:05:55, 11.44s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [15929], local_loss=0.09932199120521545, train_loss=0.03128720074892044, time_cost=6.212043285369873
Steps:   2%|▏         | 15929/1000000 [7:27:42<3127:05:55, 11.44s/it, lr=1e-5, step_loss=0.0993]Steps:   2%|▏         | 15930/1000000 [7:27:55<3306:33:42, 12.10s/it, lr=1e-5, step_loss=0.0993][RANK-0]: Step: [15930], local_loss=0.09687598794698715, train_loss=0.05751561373472214, time_cost=4.659416198730469
Steps:   2%|▏         | 15930/1000000 [7:27:55<3306:33:42, 12.10s/it, lr=1e-5, step_loss=0.0969]Steps:   2%|▏         | 15931/1000000 [7:28:04<3039:40:43, 11.12s/it, lr=1e-5, step_loss=0.0969][RANK-0]: Step: [15931], local_loss=0.01293946336954832, train_loss=0.049862951040267944, time_cost=1.578566551208496
Steps:   2%|▏         | 15931/1000000 [7:28:04<3039:40:43, 11.12s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 15932/1000000 [7:28:10<2634:06:39,  9.64s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [15932], local_loss=0.00779643002897501, train_loss=0.07094767689704895, time_cost=1.8141181468963623
Steps:   2%|▏         | 15932/1000000 [7:28:10<2634:06:39,  9.64s/it, lr=1e-5, step_loss=0.0078]Steps:   2%|▏         | 15933/1000000 [7:28:16<2283:08:18,  8.35s/it, lr=1e-5, step_loss=0.0078][RANK-0]: Step: [15933], local_loss=0.025887690484523773, train_loss=0.07872529327869415, time_cost=1.2126588821411133
Steps:   2%|▏         | 15933/1000000 [7:28:16<2283:08:18,  8.35s/it, lr=1e-5, step_loss=0.0259]Steps:   2%|▏         | 15934/1000000 [7:28:24<2316:41:36,  8.48s/it, lr=1e-5, step_loss=0.0259][RANK-0]: Step: [15934], local_loss=0.021456124261021614, train_loss=0.059451498091220856, time_cost=1.249288558959961
Steps:   2%|▏         | 15934/1000000 [7:28:24<2316:41:36,  8.48s/it, lr=1e-5, step_loss=0.0215]Steps:   2%|▏         | 15935/1000000 [7:28:38<2746:33:28, 10.05s/it, lr=1e-5, step_loss=0.0215][RANK-0]: Step: [15935], local_loss=0.06076572835445404, train_loss=0.03996002674102783, time_cost=5.101514101028442
Steps:   2%|▏         | 15935/1000000 [7:28:38<2746:33:28, 10.05s/it, lr=1e-5, step_loss=0.0608]Steps:   2%|▏         | 15936/1000000 [7:28:46<2605:10:15,  9.53s/it, lr=1e-5, step_loss=0.0608][RANK-0]: Step: [15936], local_loss=0.015549896284937859, train_loss=0.015102999284863472, time_cost=4.74169921875
Steps:   2%|▏         | 15936/1000000 [7:28:46<2605:10:15,  9.53s/it, lr=1e-5, step_loss=0.0155]Steps:   2%|▏         | 15937/1000000 [7:28:55<2562:17:33,  9.37s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [15937], local_loss=0.0283522829413414, train_loss=0.15385867655277252, time_cost=3.081568479537964
Steps:   2%|▏         | 15937/1000000 [7:28:55<2562:17:33,  9.37s/it, lr=1e-5, step_loss=0.0284]Steps:   2%|▏         | 15938/1000000 [7:29:06<2670:57:34,  9.77s/it, lr=1e-5, step_loss=0.0284][RANK-0]: Step: [15938], local_loss=0.008904663845896721, train_loss=0.08223260194063187, time_cost=8.243173599243164
Steps:   2%|▏         | 15938/1000000 [7:29:06<2670:57:34,  9.77s/it, lr=1e-5, step_loss=0.0089]Steps:   2%|▏         | 15939/1000000 [7:29:16<2668:10:11,  9.76s/it, lr=1e-5, step_loss=0.0089][RANK-0]: Step: [15939], local_loss=0.07851295173168182, train_loss=0.0432593896985054, time_cost=3.277038335800171
Steps:   2%|▏         | 15939/1000000 [7:29:16<2668:10:11,  9.76s/it, lr=1e-5, step_loss=0.0785]Steps:   2%|▏         | 15940/1000000 [7:29:24<2503:42:53,  9.16s/it, lr=1e-5, step_loss=0.0785][RANK-0]: Step: [15940], local_loss=0.03455708175897598, train_loss=0.03369949758052826, time_cost=2.8942790031433105
Steps:   2%|▏         | 15940/1000000 [7:29:24<2503:42:53,  9.16s/it, lr=1e-5, step_loss=0.0346]Steps:   2%|▏         | 15941/1000000 [7:29:30<2275:54:57,  8.33s/it, lr=1e-5, step_loss=0.0346][RANK-0]: Step: [15941], local_loss=0.007284435443580151, train_loss=0.03218381479382515, time_cost=1.9491560459136963
Steps:   2%|▏         | 15941/1000000 [7:29:30<2275:54:57,  8.33s/it, lr=1e-5, step_loss=0.00728]Steps:   2%|▏         | 15942/1000000 [7:29:37<2186:57:17,  8.00s/it, lr=1e-5, step_loss=0.00728][RANK-0]: Step: [15942], local_loss=0.01796986162662506, train_loss=14.34103012084961, time_cost=1.203810453414917
Steps:   2%|▏         | 15942/1000000 [7:29:37<2186:57:17,  8.00s/it, lr=1e-5, step_loss=0.018]  Steps:   2%|▏         | 15943/1000000 [7:29:43<1956:45:42,  7.16s/it, lr=1e-5, step_loss=0.018][RANK-0]: Step: [15943], local_loss=0.3179283142089844, train_loss=0.06364460289478302, time_cost=1.4834342002868652
Steps:   2%|▏         | 15943/1000000 [7:29:43<1956:45:42,  7.16s/it, lr=1e-5, step_loss=0.318]Steps:   2%|▏         | 15944/1000000 [7:29:49<1923:31:27,  7.04s/it, lr=1e-5, step_loss=0.318][RANK-0]: Step: [15944], local_loss=0.14102958142757416, train_loss=0.05740142613649368, time_cost=2.4113309383392334
Steps:   2%|▏         | 15944/1000000 [7:29:49<1923:31:27,  7.04s/it, lr=1e-5, step_loss=0.141]Steps:   2%|▏         | 15945/1000000 [7:29:59<2113:47:58,  7.73s/it, lr=1e-5, step_loss=0.141][RANK-0]: Step: [15945], local_loss=0.007879181765019894, train_loss=0.055260658264160156, time_cost=4.390357255935669
Steps:   2%|▏         | 15945/1000000 [7:29:59<2113:47:58,  7.73s/it, lr=1e-5, step_loss=0.00788]Steps:   2%|▏         | 15946/1000000 [7:30:13<2644:06:55,  9.67s/it, lr=1e-5, step_loss=0.00788][RANK-0]: Step: [15946], local_loss=0.006153943948447704, train_loss=0.051367081701755524, time_cost=5.0326738357543945
Steps:   2%|▏         | 15946/1000000 [7:30:13<2644:06:55,  9.67s/it, lr=1e-5, step_loss=0.00615]Steps:   2%|▏         | 15947/1000000 [7:30:17<2214:36:17,  8.10s/it, lr=1e-5, step_loss=0.00615][RANK-0]: Step: [15947], local_loss=0.018748754635453224, train_loss=0.02698858268558979, time_cost=1.711165428161621
Steps:   2%|▏         | 15947/1000000 [7:30:17<2214:36:17,  8.10s/it, lr=1e-5, step_loss=0.0187] Steps:   2%|▏         | 15948/1000000 [7:30:28<2439:07:54,  8.92s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [15948], local_loss=0.1417464017868042, train_loss=0.04281872510910034, time_cost=1.6602070331573486
Steps:   2%|▏         | 15948/1000000 [7:30:28<2439:07:54,  8.92s/it, lr=1e-5, step_loss=0.142] Steps:   2%|▏         | 15949/1000000 [7:30:33<2147:10:33,  7.86s/it, lr=1e-5, step_loss=0.142][RANK-0]: Step: [15949], local_loss=0.4007973372936249, train_loss=0.06123904138803482, time_cost=2.438530683517456
Steps:   2%|▏         | 15949/1000000 [7:30:33<2147:10:33,  7.86s/it, lr=1e-5, step_loss=0.401]Steps:   2%|▏         | 15950/1000000 [7:30:41<2103:35:40,  7.70s/it, lr=1e-5, step_loss=0.401][RANK-0]: Step: [15950], local_loss=0.028154103085398674, train_loss=0.031612981110811234, time_cost=3.6090667247772217
Steps:   2%|▏         | 15950/1000000 [7:30:41<2103:35:40,  7.70s/it, lr=1e-5, step_loss=0.0282]Steps:   2%|▏         | 15951/1000000 [7:30:56<2703:49:31,  9.89s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [15951], local_loss=0.03333502262830734, train_loss=0.056352078914642334, time_cost=2.6057989597320557
Steps:   2%|▏         | 15951/1000000 [7:30:56<2703:49:31,  9.89s/it, lr=1e-5, step_loss=0.0333]Steps:   2%|▏         | 15952/1000000 [7:31:05<2617:19:22,  9.58s/it, lr=1e-5, step_loss=0.0333][RANK-0]: Step: [15952], local_loss=0.007325534708797932, train_loss=0.03433097153902054, time_cost=3.0089566707611084
Steps:   2%|▏         | 15952/1000000 [7:31:05<2617:19:22,  9.58s/it, lr=1e-5, step_loss=0.00733]Steps:   2%|▏         | 15953/1000000 [7:31:15<2662:47:17,  9.74s/it, lr=1e-5, step_loss=0.00733][RANK-0]: Step: [15953], local_loss=0.05471314489841461, train_loss=0.22733944654464722, time_cost=1.7599906921386719
Steps:   2%|▏         | 15953/1000000 [7:31:15<2662:47:17,  9.74s/it, lr=1e-5, step_loss=0.0547] Steps:   2%|▏         | 15954/1000000 [7:31:22<2431:40:56,  8.90s/it, lr=1e-5, step_loss=0.0547][RANK-0]: Step: [15954], local_loss=0.008889641612768173, train_loss=0.14843881130218506, time_cost=3.172452449798584
Steps:   2%|▏         | 15954/1000000 [7:31:22<2431:40:56,  8.90s/it, lr=1e-5, step_loss=0.00889]Steps:   2%|▏         | 15955/1000000 [7:31:38<3019:35:09, 11.05s/it, lr=1e-5, step_loss=0.00889][RANK-0]: Step: [15955], local_loss=0.06681939214468002, train_loss=0.2193869948387146, time_cost=8.487017631530762
Steps:   2%|▏         | 15955/1000000 [7:31:38<3019:35:09, 11.05s/it, lr=1e-5, step_loss=0.0668] Steps:   2%|▏         | 15956/1000000 [7:31:43<2521:00:22,  9.22s/it, lr=1e-5, step_loss=0.0668][RANK-0]: Step: [15956], local_loss=0.016233740374445915, train_loss=0.031008176505565643, time_cost=1.9701273441314697
Steps:   2%|▏         | 15956/1000000 [7:31:43<2521:00:22,  9.22s/it, lr=1e-5, step_loss=0.0162]Steps:   2%|▏         | 15957/1000000 [7:31:54<2668:54:09,  9.76s/it, lr=1e-5, step_loss=0.0162][RANK-0]: Step: [15957], local_loss=0.01058553159236908, train_loss=0.09280204772949219, time_cost=3.730886697769165
Steps:   2%|▏         | 15957/1000000 [7:31:54<2668:54:09,  9.76s/it, lr=1e-5, step_loss=0.0106]Steps:   2%|▏         | 15958/1000000 [7:31:59<2300:55:58,  8.42s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [15958], local_loss=0.033832259476184845, train_loss=0.10890820622444153, time_cost=4.0377631187438965
Steps:   2%|▏         | 15958/1000000 [7:31:59<2300:55:58,  8.42s/it, lr=1e-5, step_loss=0.0338]Steps:   2%|▏         | 15959/1000000 [7:32:04<2028:19:31,  7.42s/it, lr=1e-5, step_loss=0.0338][RANK-0]: Step: [15959], local_loss=0.06044720113277435, train_loss=0.035204362124204636, time_cost=2.1315925121307373
Steps:   2%|▏         | 15959/1000000 [7:32:04<2028:19:31,  7.42s/it, lr=1e-5, step_loss=0.0604]Steps:   2%|▏         | 15960/1000000 [7:32:18<2557:09:34,  9.36s/it, lr=1e-5, step_loss=0.0604][RANK-0]: Step: [15960], local_loss=0.01928463578224182, train_loss=0.018895065411925316, time_cost=5.986846208572388
Steps:   2%|▏         | 15960/1000000 [7:32:18<2557:09:34,  9.36s/it, lr=1e-5, step_loss=0.0193]Steps:   2%|▏         | 15961/1000000 [7:32:30<2777:13:22, 10.16s/it, lr=1e-5, step_loss=0.0193][RANK-0]: Step: [15961], local_loss=0.05710093677043915, train_loss=0.019078535959124565, time_cost=2.7723710536956787
Steps:   2%|▏         | 15961/1000000 [7:32:30<2777:13:22, 10.16s/it, lr=1e-5, step_loss=0.0571]Steps:   2%|▏         | 15962/1000000 [7:32:39<2682:36:53,  9.81s/it, lr=1e-5, step_loss=0.0571][RANK-0]: Step: [15962], local_loss=0.018721168860793114, train_loss=0.024140525609254837, time_cost=1.4675469398498535
Steps:   2%|▏         | 15962/1000000 [7:32:39<2682:36:53,  9.81s/it, lr=1e-5, step_loss=0.0187]Steps:   2%|▏         | 15963/1000000 [7:32:44<2283:20:45,  8.35s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [15963], local_loss=0.004720789380371571, train_loss=0.020367372781038284, time_cost=3.085689067840576
Steps:   2%|▏         | 15963/1000000 [7:32:44<2283:20:45,  8.35s/it, lr=1e-5, step_loss=0.00472]Steps:   2%|▏         | 15964/1000000 [7:32:53<2371:19:35,  8.68s/it, lr=1e-5, step_loss=0.00472][RANK-0]: Step: [15964], local_loss=0.05400031805038452, train_loss=0.053169477730989456, time_cost=1.294508695602417
Steps:   2%|▏         | 15964/1000000 [7:32:53<2371:19:35,  8.68s/it, lr=1e-5, step_loss=0.054]  Steps:   2%|▏         | 15965/1000000 [7:32:59<2087:04:03,  7.64s/it, lr=1e-5, step_loss=0.054][RANK-0]: Step: [15965], local_loss=0.07745195925235748, train_loss=0.07281625270843506, time_cost=2.288083791732788
Steps:   2%|▏         | 15965/1000000 [7:32:59<2087:04:03,  7.64s/it, lr=1e-5, step_loss=0.0775]Steps:   2%|▏         | 15966/1000000 [7:33:08<2195:11:50,  8.03s/it, lr=1e-5, step_loss=0.0775][RANK-0]: Step: [15966], local_loss=0.44411981105804443, train_loss=0.07967762649059296, time_cost=7.240760326385498
Steps:   2%|▏         | 15966/1000000 [7:33:08<2195:11:50,  8.03s/it, lr=1e-5, step_loss=0.444] Steps:   2%|▏         | 15967/1000000 [7:33:16<2267:22:13,  8.29s/it, lr=1e-5, step_loss=0.444][RANK-0]: Step: [15967], local_loss=0.01684529334306717, train_loss=0.02240128628909588, time_cost=2.657632827758789
Steps:   2%|▏         | 15967/1000000 [7:33:16<2267:22:13,  8.29s/it, lr=1e-5, step_loss=0.0168]Steps:   2%|▏         | 15968/1000000 [7:33:29<2576:54:21,  9.43s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [15968], local_loss=0.020131759345531464, train_loss=14.045129776000977, time_cost=1.208590030670166
Steps:   2%|▏         | 15968/1000000 [7:33:29<2576:54:21,  9.43s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 15969/1000000 [7:33:34<2227:31:54,  8.15s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [15969], local_loss=0.006845889147371054, train_loss=0.048553187400102615, time_cost=2.1378228664398193
Steps:   2%|▏         | 15969/1000000 [7:33:34<2227:31:54,  8.15s/it, lr=1e-5, step_loss=0.00685]Steps:   2%|▏         | 15970/1000000 [7:33:41<2130:30:29,  7.79s/it, lr=1e-5, step_loss=0.00685][RANK-0]: Step: [15970], local_loss=0.021600253880023956, train_loss=0.009700220078229904, time_cost=1.3217012882232666
Steps:   2%|▏         | 15970/1000000 [7:33:41<2130:30:29,  7.79s/it, lr=1e-5, step_loss=0.0216] Steps:   2%|▏         | 15971/1000000 [7:33:52<2405:05:14,  8.80s/it, lr=1e-5, step_loss=0.0216][RANK-0]: Step: [15971], local_loss=0.005140781402587891, train_loss=0.012061449699103832, time_cost=1.7445895671844482
Steps:   2%|▏         | 15971/1000000 [7:33:52<2405:05:14,  8.80s/it, lr=1e-5, step_loss=0.00514]Steps:   2%|▏         | 15972/1000000 [7:33:57<2096:29:36,  7.67s/it, lr=1e-5, step_loss=0.00514][RANK-0]: Step: [15972], local_loss=0.019670212641358376, train_loss=0.032095279544591904, time_cost=2.154160261154175
Steps:   2%|▏         | 15972/1000000 [7:33:57<2096:29:36,  7.67s/it, lr=1e-5, step_loss=0.0197] Steps:   2%|▏         | 15973/1000000 [7:34:07<2320:04:45,  8.49s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [15973], local_loss=0.0761069506406784, train_loss=0.03269793093204498, time_cost=2.2833001613616943
Steps:   2%|▏         | 15973/1000000 [7:34:07<2320:04:45,  8.49s/it, lr=1e-5, step_loss=0.0761]Steps:   2%|▏         | 15974/1000000 [7:34:13<2127:53:08,  7.78s/it, lr=1e-5, step_loss=0.0761][RANK-0]: Step: [15974], local_loss=0.04398324713110924, train_loss=0.14526091516017914, time_cost=1.2078568935394287
Steps:   2%|▏         | 15974/1000000 [7:34:13<2127:53:08,  7.78s/it, lr=1e-5, step_loss=0.044] Steps:   2%|▏         | 15975/1000000 [7:34:19<1913:34:25,  7.00s/it, lr=1e-5, step_loss=0.044][RANK-0]: Step: [15975], local_loss=0.04600491747260094, train_loss=0.12285781651735306, time_cost=1.2284531593322754
Steps:   2%|▏         | 15975/1000000 [7:34:19<1913:34:25,  7.00s/it, lr=1e-5, step_loss=0.046]Steps:   2%|▏         | 15976/1000000 [7:34:26<1917:37:52,  7.02s/it, lr=1e-5, step_loss=0.046][RANK-0]: Step: [15976], local_loss=91.432373046875, train_loss=11.53646183013916, time_cost=5.249598979949951
Steps:   2%|▏         | 15976/1000000 [7:34:26<1917:37:52,  7.02s/it, lr=1e-5, step_loss=91.4] Steps:   2%|▏         | 15977/1000000 [7:34:38<2387:10:38,  8.73s/it, lr=1e-5, step_loss=91.4][RANK-0]: Step: [15977], local_loss=0.029013417661190033, train_loss=0.06451108306646347, time_cost=4.378885746002197
Steps:   2%|▏         | 15977/1000000 [7:34:38<2387:10:38,  8.73s/it, lr=1e-5, step_loss=0.029]Steps:   2%|▏         | 15978/1000000 [7:34:49<2512:29:11,  9.19s/it, lr=1e-5, step_loss=0.029][RANK-0]: Step: [15978], local_loss=0.006938954349607229, train_loss=0.04815636947751045, time_cost=1.2235972881317139
Steps:   2%|▏         | 15978/1000000 [7:34:49<2512:29:11,  9.19s/it, lr=1e-5, step_loss=0.00694]Steps:   2%|▏         | 15979/1000000 [7:34:55<2247:28:24,  8.22s/it, lr=1e-5, step_loss=0.00694][RANK-0]: Step: [15979], local_loss=0.021919449791312218, train_loss=0.13176022469997406, time_cost=1.784376859664917
Steps:   2%|▏         | 15979/1000000 [7:34:55<2247:28:24,  8.22s/it, lr=1e-5, step_loss=0.0219] Steps:   2%|▏         | 15980/1000000 [7:35:08<2642:27:18,  9.67s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [15980], local_loss=0.0830514207482338, train_loss=0.04827733710408211, time_cost=1.7273151874542236
Steps:   2%|▏         | 15980/1000000 [7:35:08<2642:27:18,  9.67s/it, lr=1e-5, step_loss=0.0831]Steps:   2%|▏         | 15981/1000000 [7:35:22<3024:43:13, 11.07s/it, lr=1e-5, step_loss=0.0831][RANK-0]: Step: [15981], local_loss=0.18716055154800415, train_loss=0.04109743982553482, time_cost=6.45024561882019
Steps:   2%|▏         | 15981/1000000 [7:35:22<3024:43:13, 11.07s/it, lr=1e-5, step_loss=0.187] Steps:   2%|▏         | 15982/1000000 [7:35:27<2495:30:40,  9.13s/it, lr=1e-5, step_loss=0.187][RANK-0]: Step: [15982], local_loss=0.01775985024869442, train_loss=0.06845583766698837, time_cost=1.8817734718322754
Steps:   2%|▏         | 15982/1000000 [7:35:27<2495:30:40,  9.13s/it, lr=1e-5, step_loss=0.0178]Steps:   2%|▏         | 15983/1000000 [7:35:38<2676:20:24,  9.79s/it, lr=1e-5, step_loss=0.0178][RANK-0]: Step: [15983], local_loss=0.013028999790549278, train_loss=0.03714140132069588, time_cost=8.983371257781982
Steps:   2%|▏         | 15983/1000000 [7:35:38<2676:20:24,  9.79s/it, lr=1e-5, step_loss=0.013] Steps:   2%|▏         | 15984/1000000 [7:35:52<3057:44:32, 11.19s/it, lr=1e-5, step_loss=0.013][RANK-0]: Step: [15984], local_loss=0.023176243528723717, train_loss=0.04696343094110489, time_cost=5.727756023406982
Steps:   2%|▏         | 15984/1000000 [7:35:52<3057:44:32, 11.19s/it, lr=1e-5, step_loss=0.0232]Steps:   2%|▏         | 15985/1000000 [7:36:08<3410:40:56, 12.48s/it, lr=1e-5, step_loss=0.0232][RANK-0]: Step: [15985], local_loss=0.006216452457010746, train_loss=0.16202771663665771, time_cost=5.025741815567017
Steps:   2%|▏         | 15985/1000000 [7:36:08<3410:40:56, 12.48s/it, lr=1e-5, step_loss=0.00622]Steps:   2%|▏         | 15986/1000000 [7:36:13<2797:46:29, 10.24s/it, lr=1e-5, step_loss=0.00622][RANK-0]: Step: [15986], local_loss=0.057696446776390076, train_loss=0.03046361729502678, time_cost=1.3413569927215576
Steps:   2%|▏         | 15986/1000000 [7:36:13<2797:46:29, 10.24s/it, lr=1e-5, step_loss=0.0577] Steps:   2%|▏         | 15987/1000000 [7:36:23<2804:23:12, 10.26s/it, lr=1e-5, step_loss=0.0577][RANK-0]: Step: [15987], local_loss=0.00725588807836175, train_loss=0.03400075435638428, time_cost=2.5694010257720947
Steps:   2%|▏         | 15987/1000000 [7:36:23<2804:23:12, 10.26s/it, lr=1e-5, step_loss=0.00726]Steps:   2%|▏         | 15988/1000000 [7:36:35<2966:49:08, 10.85s/it, lr=1e-5, step_loss=0.00726][RANK-0]: Step: [15988], local_loss=0.010354053229093552, train_loss=0.024030402302742004, time_cost=4.866771697998047
Steps:   2%|▏         | 15988/1000000 [7:36:35<2966:49:08, 10.85s/it, lr=1e-5, step_loss=0.0104] Steps:   2%|▏         | 15989/1000000 [7:36:40<2486:28:35,  9.10s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [15989], local_loss=0.008881867863237858, train_loss=0.02385244332253933, time_cost=2.1142451763153076
Steps:   2%|▏         | 15989/1000000 [7:36:40<2486:28:35,  9.10s/it, lr=1e-5, step_loss=0.00888]Steps:   2%|▏         | 15990/1000000 [7:36:53<2812:46:50, 10.29s/it, lr=1e-5, step_loss=0.00888][RANK-0]: Step: [15990], local_loss=0.03239106759428978, train_loss=0.0329732820391655, time_cost=1.9118685722351074
Steps:   2%|▏         | 15990/1000000 [7:36:53<2812:46:50, 10.29s/it, lr=1e-5, step_loss=0.0324] Steps:   2%|▏         | 15991/1000000 [7:37:01<2583:28:45,  9.45s/it, lr=1e-5, step_loss=0.0324][RANK-0]: Step: [15991], local_loss=0.01764950528740883, train_loss=0.015245451591908932, time_cost=3.0141422748565674
Steps:   2%|▏         | 15991/1000000 [7:37:01<2583:28:45,  9.45s/it, lr=1e-5, step_loss=0.0176]Steps:   2%|▏         | 15992/1000000 [7:37:13<2797:32:12, 10.23s/it, lr=1e-5, step_loss=0.0176][RANK-0]: Step: [15992], local_loss=0.01105912309139967, train_loss=0.020427044481039047, time_cost=3.972733736038208
Steps:   2%|▏         | 15992/1000000 [7:37:13<2797:32:12, 10.23s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 15993/1000000 [7:37:26<3056:51:08, 11.18s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [15993], local_loss=0.003689012723043561, train_loss=0.022295944392681122, time_cost=5.088056564331055
Steps:   2%|▏         | 15993/1000000 [7:37:26<3056:51:08, 11.18s/it, lr=1e-5, step_loss=0.00369]Steps:   2%|▏         | 15994/1000000 [7:37:34<2735:52:57, 10.01s/it, lr=1e-5, step_loss=0.00369][RANK-0]: Step: [15994], local_loss=0.005512488540261984, train_loss=0.025096524506807327, time_cost=1.7600514888763428
Steps:   2%|▏         | 15994/1000000 [7:37:34<2735:52:57, 10.01s/it, lr=1e-5, step_loss=0.00551]Steps:   2%|▏         | 15995/1000000 [7:37:45<2842:53:10, 10.40s/it, lr=1e-5, step_loss=0.00551][RANK-0]: Step: [15995], local_loss=0.06205008924007416, train_loss=0.03532508388161659, time_cost=1.6664073467254639
Steps:   2%|▏         | 15995/1000000 [7:37:45<2842:53:10, 10.40s/it, lr=1e-5, step_loss=0.0621] Steps:   2%|▏         | 15996/1000000 [7:37:50<2397:42:21,  8.77s/it, lr=1e-5, step_loss=0.0621][RANK-0]: Step: [15996], local_loss=0.014710979536175728, train_loss=0.024275686591863632, time_cost=1.449434518814087
Steps:   2%|▏         | 15996/1000000 [7:37:50<2397:42:21,  8.77s/it, lr=1e-5, step_loss=0.0147]Steps:   2%|▏         | 15997/1000000 [7:37:58<2322:27:01,  8.50s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [15997], local_loss=0.030392814427614212, train_loss=0.161087304353714, time_cost=1.4183998107910156
Steps:   2%|▏         | 15997/1000000 [7:37:58<2322:27:01,  8.50s/it, lr=1e-5, step_loss=0.0304]Steps:   2%|▏         | 15998/1000000 [7:38:05<2189:36:28,  8.01s/it, lr=1e-5, step_loss=0.0304][RANK-0]: Step: [15998], local_loss=0.011949358507990837, train_loss=0.01747017540037632, time_cost=3.061297655105591
Steps:   2%|▏         | 15998/1000000 [7:38:05<2189:36:28,  8.01s/it, lr=1e-5, step_loss=0.0119]Steps:   2%|▏         | 15999/1000000 [7:38:10<1960:47:19,  7.17s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [15999], local_loss=0.024489017203450203, train_loss=0.01948522962629795, time_cost=1.700974702835083
Steps:   2%|▏         | 15999/1000000 [7:38:10<1960:47:19,  7.17s/it, lr=1e-5, step_loss=0.0245]Steps:   2%|▏         | 16000/1000000 [7:38:16<1857:50:50,  6.80s/it, lr=1e-5, step_loss=0.0245][RANK-0]: Step: [16000], local_loss=0.004341190680861473, train_loss=0.014632808975875378, time_cost=2.2837159633636475
09/18/2024 17:02:19 - INFO - accelerate.accelerator - Saving current state to /home/save_dir/runs/allinpaint_stage1/checkpoint-16000
09/18/2024 17:02:19 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-18 17:02:19,222] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-09-18 17:02:19,252] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/mp_rank_00_model_states.pt
[2024-09-18 17:02:19,253] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 17:02:36,086] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 17:02:36,099] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt...
[2024-09-18 17:02:36,099] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2024-09-18 17:02:36,099] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt...
[2024-09-18 17:02:36,099] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
[2024-09-18 17:02:36,099] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-09-18 17:02:36,099] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2024-09-18 17:02:36,099] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt...
[2024-09-18 17:02:36,099] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-18 17:03:10,867] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt.
[2024-09-18 17:03:10,868] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt
[2024-09-18 17:03:10,868] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 17:03:11,734] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt.
[2024-09-18 17:03:11,734] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt
[2024-09-18 17:03:11,735] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 17:03:12,235] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-18 17:03:12,266] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt.
[2024-09-18 17:03:12,267] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt
[2024-09-18 17:03:12,267] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 17:03:12,297] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-18 17:03:12,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 17:03:12,356] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2024-09-18 17:03:12,356] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[2024-09-18 17:03:12,356] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 17:03:12,393] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2024-09-18 17:03:12,393] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[2024-09-18 17:03:12,393] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 17:03:12,427] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
[2024-09-18 17:03:12,427] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
[2024-09-18 17:03:12,427] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 17:03:12,528] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-09-18 17:03:12,528] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-09-18 17:03:12,528] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/18/2024 17:03:12 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/pytorch_model
{'norm_num_groups', 'dropout', 'use_additional_conditions'} was not found in config. Values will be initialized to default values.
Configuration saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/model_ema/config.json
Model weights saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/model_ema/diffusion_pytorch_model.safetensors
Configuration saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/model/config.json
Model weights saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/model/diffusion_pytorch_model.safetensors
09/18/2024 17:04:15 - INFO - accelerate.checkpointing - Scheduler state saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/scheduler.bin
09/18/2024 17:04:15 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/sampler.bin
09/18/2024 17:04:15 - INFO - accelerate.checkpointing - Random states saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-16000/random_states_0.pkl
09/18/2024 17:04:15 - INFO - __main__ - Saved state to /home/save_dir/runs/allinpaint_stage1/checkpoint-16000
Steps:   2%|▏         | 16000/1000000 [7:40:12<1857:50:50,  6.80s/it, lr=1e-5, step_loss=0.00434]Steps:   2%|▏         | 16001/1000000 [7:40:14<11025:01:24, 40.34s/it, lr=1e-5, step_loss=0.00434][RANK-0]: Step: [16001], local_loss=0.056716132909059525, train_loss=0.03961295634508133, time_cost=1.2076010704040527
Steps:   2%|▏         | 16001/1000000 [7:40:14<11025:01:24, 40.34s/it, lr=1e-5, step_loss=0.0567] Steps:   2%|▏         | 16002/1000000 [7:40:23<8437:49:24, 30.87s/it, lr=1e-5, step_loss=0.0567] [RANK-0]: Step: [16002], local_loss=0.20238715410232544, train_loss=0.10225433856248856, time_cost=2.0220768451690674
Steps:   2%|▏         | 16002/1000000 [7:40:23<8437:49:24, 30.87s/it, lr=1e-5, step_loss=0.202] Steps:   2%|▏         | 16003/1000000 [7:40:27<6253:48:41, 22.88s/it, lr=1e-5, step_loss=0.202][RANK-0]: Step: [16003], local_loss=0.04049326106905937, train_loss=0.12532088160514832, time_cost=1.2751352787017822
Steps:   2%|▏         | 16003/1000000 [7:40:27<6253:48:41, 22.88s/it, lr=1e-5, step_loss=0.0405]Steps:   2%|▏         | 16004/1000000 [7:40:32<4722:58:51, 17.28s/it, lr=1e-5, step_loss=0.0405][RANK-0]: Step: [16004], local_loss=0.06681529432535172, train_loss=0.03322764113545418, time_cost=1.4981358051300049
Steps:   2%|▏         | 16004/1000000 [7:40:32<4722:58:51, 17.28s/it, lr=1e-5, step_loss=0.0668]Steps:   2%|▏         | 16005/1000000 [7:40:39<3906:43:19, 14.29s/it, lr=1e-5, step_loss=0.0668][RANK-0]: Step: [16005], local_loss=0.08840807527303696, train_loss=0.030012022703886032, time_cost=1.8222236633300781
Steps:   2%|▏         | 16005/1000000 [7:40:39<3906:43:19, 14.29s/it, lr=1e-5, step_loss=0.0884]Steps:   2%|▏         | 16006/1000000 [7:40:49<3584:26:08, 13.11s/it, lr=1e-5, step_loss=0.0884][RANK-0]: Step: [16006], local_loss=0.0081322705373168, train_loss=0.04648589715361595, time_cost=8.994548797607422
Steps:   2%|▏         | 16006/1000000 [7:40:49<3584:26:08, 13.11s/it, lr=1e-5, step_loss=0.00813]Steps:   2%|▏         | 16007/1000000 [7:41:00<3401:16:36, 12.44s/it, lr=1e-5, step_loss=0.00813][RANK-0]: Step: [16007], local_loss=0.05800461396574974, train_loss=0.08178015053272247, time_cost=3.332970380783081
Steps:   2%|▏         | 16007/1000000 [7:41:00<3401:16:36, 12.44s/it, lr=1e-5, step_loss=0.058]  Steps:   2%|▏         | 16008/1000000 [7:41:07<2962:04:20, 10.84s/it, lr=1e-5, step_loss=0.058][RANK-0]: Step: [16008], local_loss=0.2964164614677429, train_loss=0.06057421863079071, time_cost=1.673133134841919
Steps:   2%|▏         | 16008/1000000 [7:41:07<2962:04:20, 10.84s/it, lr=1e-5, step_loss=0.296]Steps:   2%|▏         | 16009/1000000 [7:41:12<2457:16:20,  8.99s/it, lr=1e-5, step_loss=0.296][RANK-0]: Step: [16009], local_loss=0.06346867978572845, train_loss=0.14947186410427094, time_cost=1.307901382446289
Steps:   2%|▏         | 16009/1000000 [7:41:12<2457:16:20,  8.99s/it, lr=1e-5, step_loss=0.0635]Steps:   2%|▏         | 16010/1000000 [7:41:22<2560:49:51,  9.37s/it, lr=1e-5, step_loss=0.0635][RANK-0]: Step: [16010], local_loss=0.039503369480371475, train_loss=0.05553111806511879, time_cost=1.2475690841674805
Steps:   2%|▏         | 16010/1000000 [7:41:22<2560:49:51,  9.37s/it, lr=1e-5, step_loss=0.0395]Steps:   2%|▏         | 16011/1000000 [7:41:35<2854:30:17, 10.44s/it, lr=1e-5, step_loss=0.0395][RANK-0]: Step: [16011], local_loss=0.032563354820013046, train_loss=0.03892230987548828, time_cost=1.281893253326416
Steps:   2%|▏         | 16011/1000000 [7:41:35<2854:30:17, 10.44s/it, lr=1e-5, step_loss=0.0326]Steps:   2%|▏         | 16012/1000000 [7:41:43<2666:55:25,  9.76s/it, lr=1e-5, step_loss=0.0326][RANK-0]: Step: [16012], local_loss=0.012573814950883389, train_loss=0.017407763749361038, time_cost=6.859519958496094
Steps:   2%|▏         | 16012/1000000 [7:41:43<2666:55:25,  9.76s/it, lr=1e-5, step_loss=0.0126]Steps:   2%|▏         | 16013/1000000 [7:41:59<3132:03:37, 11.46s/it, lr=1e-5, step_loss=0.0126][RANK-0]: Step: [16013], local_loss=0.022449512034654617, train_loss=0.02734488993883133, time_cost=7.291358709335327
Steps:   2%|▏         | 16013/1000000 [7:41:59<3132:03:37, 11.46s/it, lr=1e-5, step_loss=0.0224]Steps:   2%|▏         | 16014/1000000 [7:42:04<2585:59:38,  9.46s/it, lr=1e-5, step_loss=0.0224][RANK-0]: Step: [16014], local_loss=0.013845332898199558, train_loss=0.06395210325717926, time_cost=1.2272603511810303
Steps:   2%|▏         | 16014/1000000 [7:42:04<2585:59:38,  9.46s/it, lr=1e-5, step_loss=0.0138]Steps:   2%|▏         | 16015/1000000 [7:42:12<2506:34:32,  9.17s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [16015], local_loss=0.007868805900216103, train_loss=0.037120696157217026, time_cost=2.8463056087493896
Steps:   2%|▏         | 16015/1000000 [7:42:12<2506:34:32,  9.17s/it, lr=1e-5, step_loss=0.00787]Steps:   2%|▏         | 16016/1000000 [7:42:20<2424:10:50,  8.87s/it, lr=1e-5, step_loss=0.00787][RANK-0]: Step: [16016], local_loss=0.007968034595251083, train_loss=0.02208971045911312, time_cost=3.109853982925415
Steps:   2%|▏         | 16016/1000000 [7:42:20<2424:10:50,  8.87s/it, lr=1e-5, step_loss=0.00797]Steps:   2%|▏         | 16017/1000000 [7:42:26<2178:55:18,  7.97s/it, lr=1e-5, step_loss=0.00797][RANK-0]: Step: [16017], local_loss=0.05147896334528923, train_loss=0.06560872495174408, time_cost=1.946092128753662
Steps:   2%|▏         | 16017/1000000 [7:42:26<2178:55:18,  7.97s/it, lr=1e-5, step_loss=0.0515] Steps:   2%|▏         | 16018/1000000 [7:42:33<2082:45:55,  7.62s/it, lr=1e-5, step_loss=0.0515][RANK-0]: Step: [16018], local_loss=0.006098433863371611, train_loss=0.02357354201376438, time_cost=2.3872323036193848
Steps:   2%|▏         | 16018/1000000 [7:42:33<2082:45:55,  7.62s/it, lr=1e-5, step_loss=0.0061]Steps:   2%|▏         | 16019/1000000 [7:42:38<1876:18:20,  6.86s/it, lr=1e-5, step_loss=0.0061][RANK-0]: Step: [16019], local_loss=0.337930291891098, train_loss=0.10509274899959564, time_cost=1.2177140712738037
Steps:   2%|▏         | 16019/1000000 [7:42:38<1876:18:20,  6.86s/it, lr=1e-5, step_loss=0.338] Steps:   2%|▏         | 16020/1000000 [7:42:43<1680:45:40,  6.15s/it, lr=1e-5, step_loss=0.338][RANK-0]: Step: [16020], local_loss=0.0114946523681283, train_loss=0.02984759956598282, time_cost=1.8427751064300537
Steps:   2%|▏         | 16020/1000000 [7:42:43<1680:45:40,  6.15s/it, lr=1e-5, step_loss=0.0115]Steps:   2%|▏         | 16021/1000000 [7:42:47<1579:14:56,  5.78s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [16021], local_loss=0.0034864344634115696, train_loss=0.04981270432472229, time_cost=4.095900535583496
Steps:   2%|▏         | 16021/1000000 [7:42:47<1579:14:56,  5.78s/it, lr=1e-5, step_loss=0.00349]Steps:   2%|▏         | 16022/1000000 [7:42:56<1813:42:07,  6.64s/it, lr=1e-5, step_loss=0.00349][RANK-0]: Step: [16022], local_loss=0.1793043613433838, train_loss=0.058227669447660446, time_cost=2.812764883041382
Steps:   2%|▏         | 16022/1000000 [7:42:56<1813:42:07,  6.64s/it, lr=1e-5, step_loss=0.179]  Steps:   2%|▏         | 16023/1000000 [7:43:08<2234:18:36,  8.17s/it, lr=1e-5, step_loss=0.179][RANK-0]: Step: [16023], local_loss=0.051603276282548904, train_loss=0.09916707128286362, time_cost=3.9482383728027344
Steps:   2%|▏         | 16023/1000000 [7:43:08<2234:18:36,  8.17s/it, lr=1e-5, step_loss=0.0516]Steps:   2%|▏         | 16024/1000000 [7:43:13<1963:17:23,  7.18s/it, lr=1e-5, step_loss=0.0516][RANK-0]: Step: [16024], local_loss=0.07896707952022552, train_loss=0.07362540811300278, time_cost=2.5027759075164795
Steps:   2%|▏         | 16024/1000000 [7:43:13<1963:17:23,  7.18s/it, lr=1e-5, step_loss=0.079] Steps:   2%|▏         | 16025/1000000 [7:43:23<2181:31:32,  7.98s/it, lr=1e-5, step_loss=0.079][RANK-0]: Step: [16025], local_loss=0.007707878947257996, train_loss=0.020280933007597923, time_cost=1.262385368347168
Steps:   2%|▏         | 16025/1000000 [7:43:23<2181:31:32,  7.98s/it, lr=1e-5, step_loss=0.00771]Steps:   2%|▏         | 16026/1000000 [7:43:35<2526:23:33,  9.24s/it, lr=1e-5, step_loss=0.00771][RANK-0]: Step: [16026], local_loss=0.012141555547714233, train_loss=0.14054493606090546, time_cost=5.215296745300293
Steps:   2%|▏         | 16026/1000000 [7:43:35<2526:23:33,  9.24s/it, lr=1e-5, step_loss=0.0121] Steps:   2%|▏         | 16027/1000000 [7:43:46<2698:03:28,  9.87s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [16027], local_loss=0.04675725847482681, train_loss=0.025236912071704865, time_cost=8.916215896606445
Steps:   2%|▏         | 16027/1000000 [7:43:46<2698:03:28,  9.87s/it, lr=1e-5, step_loss=0.0468]Steps:   2%|▏         | 16028/1000000 [7:44:00<3063:03:22, 11.21s/it, lr=1e-5, step_loss=0.0468][RANK-0]: Step: [16028], local_loss=0.020568734034895897, train_loss=0.0280308797955513, time_cost=10.823863506317139
Steps:   2%|▏         | 16028/1000000 [7:44:00<3063:03:22, 11.21s/it, lr=1e-5, step_loss=0.0206]Steps:   2%|▏         | 16029/1000000 [7:44:05<2553:59:23,  9.34s/it, lr=1e-5, step_loss=0.0206][RANK-0]: Step: [16029], local_loss=0.04060915485024452, train_loss=0.022525427863001823, time_cost=2.136202812194824
Steps:   2%|▏         | 16029/1000000 [7:44:05<2553:59:23,  9.34s/it, lr=1e-5, step_loss=0.0406]Steps:   2%|▏         | 16030/1000000 [7:44:16<2642:47:29,  9.67s/it, lr=1e-5, step_loss=0.0406][RANK-0]: Step: [16030], local_loss=0.006758855190128088, train_loss=0.21743860840797424, time_cost=5.970995903015137
Steps:   2%|▏         | 16030/1000000 [7:44:16<2642:47:29,  9.67s/it, lr=1e-5, step_loss=0.00676]Steps:   2%|▏         | 16031/1000000 [7:44:30<3028:45:07, 11.08s/it, lr=1e-5, step_loss=0.00676][RANK-0]: Step: [16031], local_loss=0.010364992544054985, train_loss=0.0327732227742672, time_cost=10.538373231887817
Steps:   2%|▏         | 16031/1000000 [7:44:30<3028:45:07, 11.08s/it, lr=1e-5, step_loss=0.0104] Steps:   2%|▏         | 16032/1000000 [7:44:46<3403:02:11, 12.45s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [16032], local_loss=0.05750226229429245, train_loss=0.026399502530694008, time_cost=7.227556228637695
Steps:   2%|▏         | 16032/1000000 [7:44:46<3403:02:11, 12.45s/it, lr=1e-5, step_loss=0.0575]Steps:   2%|▏         | 16033/1000000 [7:44:56<3217:43:44, 11.77s/it, lr=1e-5, step_loss=0.0575][RANK-0]: Step: [16033], local_loss=0.025051429867744446, train_loss=0.025901511311531067, time_cost=4.858588218688965
Steps:   2%|▏         | 16033/1000000 [7:44:56<3217:43:44, 11.77s/it, lr=1e-5, step_loss=0.0251]Steps:   2%|▏         | 16034/1000000 [7:45:12<3597:58:26, 13.16s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [16034], local_loss=0.00877587404102087, train_loss=0.02611074596643448, time_cost=5.68504524230957
Steps:   2%|▏         | 16034/1000000 [7:45:12<3597:58:26, 13.16s/it, lr=1e-5, step_loss=0.00878]Steps:   2%|▏         | 16035/1000000 [7:45:26<3670:45:50, 13.43s/it, lr=1e-5, step_loss=0.00878][RANK-0]: Step: [16035], local_loss=0.04210750758647919, train_loss=0.1663426011800766, time_cost=4.652627229690552
Steps:   2%|▏         | 16035/1000000 [7:45:26<3670:45:50, 13.43s/it, lr=1e-5, step_loss=0.0421] Steps:   2%|▏         | 16036/1000000 [7:45:40<3670:29:34, 13.43s/it, lr=1e-5, step_loss=0.0421][RANK-0]: Step: [16036], local_loss=0.010486791841685772, train_loss=19.83074188232422, time_cost=3.437929630279541
Steps:   2%|▏         | 16036/1000000 [7:45:40<3670:29:34, 13.43s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 16037/1000000 [7:45:44<2937:17:27, 10.75s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [16037], local_loss=0.023702211678028107, train_loss=0.024544304236769676, time_cost=2.072037935256958
Steps:   2%|▏         | 16037/1000000 [7:45:44<2937:17:27, 10.75s/it, lr=1e-5, step_loss=0.0237]Steps:   2%|▏         | 16038/1000000 [7:45:55<2950:46:43, 10.80s/it, lr=1e-5, step_loss=0.0237][RANK-0]: Step: [16038], local_loss=0.01887836866080761, train_loss=0.03311661630868912, time_cost=2.0233609676361084
Steps:   2%|▏         | 16038/1000000 [7:45:55<2950:46:43, 10.80s/it, lr=1e-5, step_loss=0.0189]Steps:   2%|▏         | 16039/1000000 [7:46:04<2818:04:17, 10.31s/it, lr=1e-5, step_loss=0.0189][RANK-0]: Step: [16039], local_loss=0.03484943509101868, train_loss=0.021571921184659004, time_cost=3.621340036392212
Steps:   2%|▏         | 16039/1000000 [7:46:04<2818:04:17, 10.31s/it, lr=1e-5, step_loss=0.0348]Steps:   2%|▏         | 16040/1000000 [7:46:10<2451:36:15,  8.97s/it, lr=1e-5, step_loss=0.0348][RANK-0]: Step: [16040], local_loss=0.005766310263425112, train_loss=0.053069885820150375, time_cost=2.0244224071502686
Steps:   2%|▏         | 16040/1000000 [7:46:10<2451:36:15,  8.97s/it, lr=1e-5, step_loss=0.00577]Steps:   2%|▏         | 16041/1000000 [7:46:24<2799:40:04, 10.24s/it, lr=1e-5, step_loss=0.00577][RANK-0]: Step: [16041], local_loss=0.016147809103131294, train_loss=0.06204299256205559, time_cost=3.9122889041900635
Steps:   2%|▏         | 16041/1000000 [7:46:24<2799:40:04, 10.24s/it, lr=1e-5, step_loss=0.0161] Steps:   2%|▏         | 16042/1000000 [7:46:37<3031:59:52, 11.09s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [16042], local_loss=0.007781828287988901, train_loss=0.010789879597723484, time_cost=3.2003679275512695
Steps:   2%|▏         | 16042/1000000 [7:46:37<3031:59:52, 11.09s/it, lr=1e-5, step_loss=0.00778]Steps:   2%|▏         | 16043/1000000 [7:46:46<2917:09:10, 10.67s/it, lr=1e-5, step_loss=0.00778][RANK-0]: Step: [16043], local_loss=0.02283146046102047, train_loss=0.025130584836006165, time_cost=7.836609125137329
Steps:   2%|▏         | 16043/1000000 [7:46:46<2917:09:10, 10.67s/it, lr=1e-5, step_loss=0.0228] Steps:   2%|▏         | 16044/1000000 [7:46:58<3018:47:39, 11.04s/it, lr=1e-5, step_loss=0.0228][RANK-0]: Step: [16044], local_loss=0.040193893015384674, train_loss=0.030013833194971085, time_cost=5.717623949050903
Steps:   2%|▏         | 16044/1000000 [7:46:58<3018:47:39, 11.04s/it, lr=1e-5, step_loss=0.0402]Steps:   2%|▏         | 16045/1000000 [7:47:04<2599:15:03,  9.51s/it, lr=1e-5, step_loss=0.0402][RANK-0]: Step: [16045], local_loss=0.04984866455197334, train_loss=0.022583728656172752, time_cost=1.5798745155334473
Steps:   2%|▏         | 16045/1000000 [7:47:04<2599:15:03,  9.51s/it, lr=1e-5, step_loss=0.0498]Steps:   2%|▏         | 16046/1000000 [7:47:10<2263:42:05,  8.28s/it, lr=1e-5, step_loss=0.0498][RANK-0]: Step: [16046], local_loss=0.010400301776826382, train_loss=0.028372956439852715, time_cost=4.612506151199341
Steps:   2%|▏         | 16046/1000000 [7:47:10<2263:42:05,  8.28s/it, lr=1e-5, step_loss=0.0104]Steps:   2%|▏         | 16047/1000000 [7:47:15<2015:33:08,  7.37s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [16047], local_loss=0.017320729792118073, train_loss=0.01828925684094429, time_cost=2.3299343585968018
Steps:   2%|▏         | 16047/1000000 [7:47:15<2015:33:08,  7.37s/it, lr=1e-5, step_loss=0.0173]Steps:   2%|▏         | 16048/1000000 [7:47:28<2497:17:22,  9.14s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [16048], local_loss=0.06811755895614624, train_loss=0.12060388922691345, time_cost=3.9301469326019287
Steps:   2%|▏         | 16048/1000000 [7:47:28<2497:17:22,  9.14s/it, lr=1e-5, step_loss=0.0681]Steps:   2%|▏         | 16049/1000000 [7:47:39<2667:36:01,  9.76s/it, lr=1e-5, step_loss=0.0681][RANK-0]: Step: [16049], local_loss=0.025089848786592484, train_loss=0.014381783083081245, time_cost=1.2451941967010498
Steps:   2%|▏         | 16049/1000000 [7:47:39<2667:36:01,  9.76s/it, lr=1e-5, step_loss=0.0251]Steps:   2%|▏         | 16050/1000000 [7:47:51<2802:37:39, 10.25s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [16050], local_loss=0.006720368750393391, train_loss=0.03604256361722946, time_cost=1.2395572662353516
Steps:   2%|▏         | 16050/1000000 [7:47:51<2802:37:39, 10.25s/it, lr=1e-5, step_loss=0.00672]Steps:   2%|▏         | 16051/1000000 [7:48:01<2772:41:30, 10.14s/it, lr=1e-5, step_loss=0.00672][RANK-0]: Step: [16051], local_loss=0.02425043284893036, train_loss=0.017025059089064598, time_cost=1.2227697372436523
Steps:   2%|▏         | 16051/1000000 [7:48:01<2772:41:30, 10.14s/it, lr=1e-5, step_loss=0.0243] Steps:   2%|▏         | 16052/1000000 [7:48:13<2956:05:30, 10.82s/it, lr=1e-5, step_loss=0.0243][RANK-0]: Step: [16052], local_loss=0.042421605437994, train_loss=0.027804836630821228, time_cost=2.97817325592041
Steps:   2%|▏         | 16052/1000000 [7:48:13<2956:05:30, 10.82s/it, lr=1e-5, step_loss=0.0424]Steps:   2%|▏         | 16053/1000000 [7:48:22<2803:48:59, 10.26s/it, lr=1e-5, step_loss=0.0424][RANK-0]: Step: [16053], local_loss=0.006661401595920324, train_loss=0.013537304475903511, time_cost=3.364736795425415
Steps:   2%|▏         | 16053/1000000 [7:48:22<2803:48:59, 10.26s/it, lr=1e-5, step_loss=0.00666]Steps:   2%|▏         | 16054/1000000 [7:48:34<2915:34:44, 10.67s/it, lr=1e-5, step_loss=0.00666][RANK-0]: Step: [16054], local_loss=0.013576757162809372, train_loss=0.011457622982561588, time_cost=4.128932952880859
Steps:   2%|▏         | 16054/1000000 [7:48:34<2915:34:44, 10.67s/it, lr=1e-5, step_loss=0.0136] Steps:   2%|▏         | 16055/1000000 [7:48:41<2675:02:21,  9.79s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [16055], local_loss=0.008434392511844635, train_loss=0.020312700420618057, time_cost=2.0053975582122803
Steps:   2%|▏         | 16055/1000000 [7:48:41<2675:02:21,  9.79s/it, lr=1e-5, step_loss=0.00843]Steps:   2%|▏         | 16056/1000000 [7:48:52<2764:41:55, 10.12s/it, lr=1e-5, step_loss=0.00843][RANK-0]: Step: [16056], local_loss=0.03635876625776291, train_loss=0.04348958283662796, time_cost=2.6856143474578857
Steps:   2%|▏         | 16056/1000000 [7:48:52<2764:41:55, 10.12s/it, lr=1e-5, step_loss=0.0364] Steps:   2%|▏         | 16057/1000000 [7:48:57<2340:08:45,  8.56s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [16057], local_loss=0.01538623683154583, train_loss=0.05305178835988045, time_cost=1.4323348999023438
Steps:   2%|▏         | 16057/1000000 [7:48:57<2340:08:45,  8.56s/it, lr=1e-5, step_loss=0.0154]Steps:   2%|▏         | 16058/1000000 [7:49:08<2547:11:25,  9.32s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [16058], local_loss=0.06532925367355347, train_loss=0.024612732231616974, time_cost=8.044960021972656
Steps:   2%|▏         | 16058/1000000 [7:49:08<2547:11:25,  9.32s/it, lr=1e-5, step_loss=0.0653]Steps:   2%|▏         | 16059/1000000 [7:49:17<2466:27:03,  9.02s/it, lr=1e-5, step_loss=0.0653][RANK-0]: Step: [16059], local_loss=0.02535911649465561, train_loss=0.03847527503967285, time_cost=1.2132692337036133
Steps:   2%|▏         | 16059/1000000 [7:49:17<2466:27:03,  9.02s/it, lr=1e-5, step_loss=0.0254]Steps:   2%|▏         | 16060/1000000 [7:49:27<2607:53:12,  9.54s/it, lr=1e-5, step_loss=0.0254][RANK-0]: Step: [16060], local_loss=0.00750365387648344, train_loss=0.01168489083647728, time_cost=1.8616907596588135
Steps:   2%|▏         | 16060/1000000 [7:49:27<2607:53:12,  9.54s/it, lr=1e-5, step_loss=0.0075]Steps:   2%|▏         | 16061/1000000 [7:49:32<2228:44:53,  8.15s/it, lr=1e-5, step_loss=0.0075][RANK-0]: Step: [16061], local_loss=0.004649647511541843, train_loss=0.012670764699578285, time_cost=2.3829522132873535
Steps:   2%|▏         | 16061/1000000 [7:49:32<2228:44:53,  8.15s/it, lr=1e-5, step_loss=0.00465]Steps:   2%|▏         | 16062/1000000 [7:49:38<2054:45:29,  7.52s/it, lr=1e-5, step_loss=0.00465][RANK-0]: Step: [16062], local_loss=0.00598642323166132, train_loss=0.043035976588726044, time_cost=1.8140208721160889
Steps:   2%|▏         | 16062/1000000 [7:49:38<2054:45:29,  7.52s/it, lr=1e-5, step_loss=0.00599]Steps:   2%|▏         | 16063/1000000 [7:49:49<2359:37:53,  8.63s/it, lr=1e-5, step_loss=0.00599][RANK-0]: Step: [16063], local_loss=0.00594038050621748, train_loss=0.058442529290914536, time_cost=4.214822053909302
Steps:   2%|▏         | 16063/1000000 [7:49:49<2359:37:53,  8.63s/it, lr=1e-5, step_loss=0.00594]Steps:   2%|▏         | 16064/1000000 [7:50:00<2526:44:35,  9.24s/it, lr=1e-5, step_loss=0.00594][RANK-0]: Step: [16064], local_loss=0.008263901807367802, train_loss=0.022001447156071663, time_cost=1.251314401626587
Steps:   2%|▏         | 16064/1000000 [7:50:00<2526:44:35,  9.24s/it, lr=1e-5, step_loss=0.00826]Steps:   2%|▏         | 16065/1000000 [7:50:05<2167:28:56,  7.93s/it, lr=1e-5, step_loss=0.00826][RANK-0]: Step: [16065], local_loss=0.009425191208720207, train_loss=0.03792860358953476, time_cost=1.2183358669281006
Steps:   2%|▏         | 16065/1000000 [7:50:05<2167:28:56,  7.93s/it, lr=1e-5, step_loss=0.00943]Steps:   2%|▏         | 16066/1000000 [7:50:12<2091:02:55,  7.65s/it, lr=1e-5, step_loss=0.00943][RANK-0]: Step: [16066], local_loss=0.004741509445011616, train_loss=0.15317994356155396, time_cost=5.142306566238403
Steps:   2%|▏         | 16066/1000000 [7:50:12<2091:02:55,  7.65s/it, lr=1e-5, step_loss=0.00474]Steps:   2%|▏         | 16067/1000000 [7:50:18<1981:07:15,  7.25s/it, lr=1e-5, step_loss=0.00474][RANK-0]: Step: [16067], local_loss=0.09122682362794876, train_loss=0.041751764714717865, time_cost=1.6352815628051758
Steps:   2%|▏         | 16067/1000000 [7:50:18<1981:07:15,  7.25s/it, lr=1e-5, step_loss=0.0912] Steps:   2%|▏         | 16068/1000000 [7:50:28<2197:59:18,  8.04s/it, lr=1e-5, step_loss=0.0912][RANK-0]: Step: [16068], local_loss=0.049270857125520706, train_loss=0.17583222687244415, time_cost=4.426974534988403
Steps:   2%|▏         | 16068/1000000 [7:50:28<2197:59:18,  8.04s/it, lr=1e-5, step_loss=0.0493]Steps:   2%|▏         | 16069/1000000 [7:50:40<2483:48:31,  9.09s/it, lr=1e-5, step_loss=0.0493][RANK-0]: Step: [16069], local_loss=0.01740412600338459, train_loss=0.08561296761035919, time_cost=6.536393880844116
Steps:   2%|▏         | 16069/1000000 [7:50:40<2483:48:31,  9.09s/it, lr=1e-5, step_loss=0.0174]Steps:   2%|▏         | 16070/1000000 [7:50:44<2098:07:49,  7.68s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [16070], local_loss=0.06729090958833694, train_loss=0.018792232498526573, time_cost=3.1480062007904053
Steps:   2%|▏         | 16070/1000000 [7:50:44<2098:07:49,  7.68s/it, lr=1e-5, step_loss=0.0673]Steps:   2%|▏         | 16071/1000000 [7:51:00<2763:26:15, 10.11s/it, lr=1e-5, step_loss=0.0673][RANK-0]: Step: [16071], local_loss=0.044996876269578934, train_loss=0.0585399866104126, time_cost=1.219296932220459
Steps:   2%|▏         | 16071/1000000 [7:51:00<2763:26:15, 10.11s/it, lr=1e-5, step_loss=0.045] Steps:   2%|▏         | 16072/1000000 [7:51:06<2423:40:36,  8.87s/it, lr=1e-5, step_loss=0.045][RANK-0]: Step: [16072], local_loss=0.008478382602334023, train_loss=0.06520131975412369, time_cost=1.8851280212402344
Steps:   2%|▏         | 16072/1000000 [7:51:06<2423:40:36,  8.87s/it, lr=1e-5, step_loss=0.00848]Steps:   2%|▏         | 16073/1000000 [7:51:19<2772:57:53, 10.15s/it, lr=1e-5, step_loss=0.00848][RANK-0]: Step: [16073], local_loss=0.04071451723575592, train_loss=0.02571377158164978, time_cost=2.82446551322937
Steps:   2%|▏         | 16073/1000000 [7:51:19<2772:57:53, 10.15s/it, lr=1e-5, step_loss=0.0407] Steps:   2%|▏         | 16074/1000000 [7:51:30<2840:32:13, 10.39s/it, lr=1e-5, step_loss=0.0407][RANK-0]: Step: [16074], local_loss=0.024847377091646194, train_loss=0.044643666595220566, time_cost=4.411395788192749
Steps:   2%|▏         | 16074/1000000 [7:51:30<2840:32:13, 10.39s/it, lr=1e-5, step_loss=0.0248]Steps:   2%|▏         | 16075/1000000 [7:51:35<2404:03:32,  8.80s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [16075], local_loss=0.007987985387444496, train_loss=0.033504415303468704, time_cost=2.178901195526123
Steps:   2%|▏         | 16075/1000000 [7:51:35<2404:03:32,  8.80s/it, lr=1e-5, step_loss=0.00799]Steps:   2%|▏         | 16076/1000000 [7:51:47<2687:44:31,  9.83s/it, lr=1e-5, step_loss=0.00799][RANK-0]: Step: [16076], local_loss=0.021374672651290894, train_loss=0.08278918266296387, time_cost=3.681901693344116
Steps:   2%|▏         | 16076/1000000 [7:51:47<2687:44:31,  9.83s/it, lr=1e-5, step_loss=0.0214] Steps:   2%|▏         | 16077/1000000 [7:51:58<2763:18:12, 10.11s/it, lr=1e-5, step_loss=0.0214][RANK-0]: Step: [16077], local_loss=0.004757490940392017, train_loss=0.04265003278851509, time_cost=3.95428729057312
Steps:   2%|▏         | 16077/1000000 [7:51:58<2763:18:12, 10.11s/it, lr=1e-5, step_loss=0.00476]Steps:   2%|▏         | 16078/1000000 [7:52:12<3071:20:50, 11.24s/it, lr=1e-5, step_loss=0.00476][RANK-0]: Step: [16078], local_loss=0.05932461470365524, train_loss=0.029615404084324837, time_cost=5.660379886627197
Steps:   2%|▏         | 16078/1000000 [7:52:12<3071:20:50, 11.24s/it, lr=1e-5, step_loss=0.0593] Steps:   2%|▏         | 16079/1000000 [7:52:23<3028:11:18, 11.08s/it, lr=1e-5, step_loss=0.0593][RANK-0]: Step: [16079], local_loss=0.1211383044719696, train_loss=0.034005023539066315, time_cost=1.22597074508667
Steps:   2%|▏         | 16079/1000000 [7:52:23<3028:11:18, 11.08s/it, lr=1e-5, step_loss=0.121] Steps:   2%|▏         | 16080/1000000 [7:52:30<2721:07:44,  9.96s/it, lr=1e-5, step_loss=0.121][RANK-0]: Step: [16080], local_loss=0.04595005139708519, train_loss=0.018499117344617844, time_cost=1.668699026107788
Steps:   2%|▏         | 16080/1000000 [7:52:30<2721:07:44,  9.96s/it, lr=1e-5, step_loss=0.046]Steps:   2%|▏         | 16081/1000000 [7:52:40<2761:24:06, 10.10s/it, lr=1e-5, step_loss=0.046][RANK-0]: Step: [16081], local_loss=0.014751509763300419, train_loss=0.03268459439277649, time_cost=1.6687791347503662
Steps:   2%|▏         | 16081/1000000 [7:52:40<2761:24:06, 10.10s/it, lr=1e-5, step_loss=0.0148]Steps:   2%|▏         | 16082/1000000 [7:52:54<3039:31:21, 11.12s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [16082], local_loss=0.036434952169656754, train_loss=0.03974007070064545, time_cost=7.1364829540252686
Steps:   2%|▏         | 16082/1000000 [7:52:54<3039:31:21, 11.12s/it, lr=1e-5, step_loss=0.0364]Steps:   2%|▏         | 16083/1000000 [7:53:07<3187:46:40, 11.66s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [16083], local_loss=0.004961485508829355, train_loss=0.024321798235177994, time_cost=4.857407331466675
Steps:   2%|▏         | 16083/1000000 [7:53:07<3187:46:40, 11.66s/it, lr=1e-5, step_loss=0.00496]Steps:   2%|▏         | 16084/1000000 [7:53:15<2886:34:43, 10.56s/it, lr=1e-5, step_loss=0.00496][RANK-0]: Step: [16084], local_loss=0.08497515320777893, train_loss=0.02684747613966465, time_cost=3.1617329120635986
Steps:   2%|▏         | 16084/1000000 [7:53:15<2886:34:43, 10.56s/it, lr=1e-5, step_loss=0.085]  Steps:   2%|▏         | 16085/1000000 [7:53:27<2998:59:32, 10.97s/it, lr=1e-5, step_loss=0.085][RANK-0]: Step: [16085], local_loss=0.011160147376358509, train_loss=0.03436891734600067, time_cost=3.617450475692749
Steps:   2%|▏         | 16085/1000000 [7:53:27<2998:59:32, 10.97s/it, lr=1e-5, step_loss=0.0112]Steps:   2%|▏         | 16086/1000000 [7:53:31<2442:46:06,  8.94s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [16086], local_loss=0.00711701437830925, train_loss=0.025584880262613297, time_cost=1.5130341053009033
Steps:   2%|▏         | 16086/1000000 [7:53:31<2442:46:06,  8.94s/it, lr=1e-5, step_loss=0.00712]Steps:   2%|▏         | 16087/1000000 [7:53:37<2229:28:52,  8.16s/it, lr=1e-5, step_loss=0.00712][RANK-0]: Step: [16087], local_loss=0.04703831300139427, train_loss=0.018549803644418716, time_cost=2.920301675796509
Steps:   2%|▏         | 16087/1000000 [7:53:37<2229:28:52,  8.16s/it, lr=1e-5, step_loss=0.047]  Steps:   2%|▏         | 16088/1000000 [7:53:44<2122:01:14,  7.76s/it, lr=1e-5, step_loss=0.047][RANK-0]: Step: [16088], local_loss=0.007780540268868208, train_loss=0.03022484853863716, time_cost=3.027256965637207
Steps:   2%|▏         | 16088/1000000 [7:53:44<2122:01:14,  7.76s/it, lr=1e-5, step_loss=0.00778]Steps:   2%|▏         | 16089/1000000 [7:53:51<2050:09:49,  7.50s/it, lr=1e-5, step_loss=0.00778][RANK-0]: Step: [16089], local_loss=0.23690930008888245, train_loss=0.0638778880238533, time_cost=1.2720246315002441
Steps:   2%|▏         | 16089/1000000 [7:53:51<2050:09:49,  7.50s/it, lr=1e-5, step_loss=0.237]  Steps:   2%|▏         | 16090/1000000 [7:53:58<2002:34:30,  7.33s/it, lr=1e-5, step_loss=0.237][RANK-0]: Step: [16090], local_loss=0.05797012150287628, train_loss=0.1576395034790039, time_cost=3.345133066177368
Steps:   2%|▏         | 16090/1000000 [7:53:58<2002:34:30,  7.33s/it, lr=1e-5, step_loss=0.058]Steps:   2%|▏         | 16091/1000000 [7:54:05<1955:59:00,  7.16s/it, lr=1e-5, step_loss=0.058][RANK-0]: Step: [16091], local_loss=0.08398818969726562, train_loss=0.15876945853233337, time_cost=2.904641628265381
Steps:   2%|▏         | 16091/1000000 [7:54:05<1955:59:00,  7.16s/it, lr=1e-5, step_loss=0.084]Steps:   2%|▏         | 16092/1000000 [7:54:14<2124:54:04,  7.77s/it, lr=1e-5, step_loss=0.084][RANK-0]: Step: [16092], local_loss=0.12029726803302765, train_loss=0.034247927367687225, time_cost=3.094914674758911
Steps:   2%|▏         | 16092/1000000 [7:54:14<2124:54:04,  7.77s/it, lr=1e-5, step_loss=0.12] Steps:   2%|▏         | 16093/1000000 [7:54:19<1908:00:44,  6.98s/it, lr=1e-5, step_loss=0.12][RANK-0]: Step: [16093], local_loss=0.019107632339000702, train_loss=0.04022691398859024, time_cost=2.082773447036743
Steps:   2%|▏         | 16093/1000000 [7:54:19<1908:00:44,  6.98s/it, lr=1e-5, step_loss=0.0191]Steps:   2%|▏         | 16094/1000000 [7:54:28<2094:54:57,  7.67s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [16094], local_loss=0.010854627937078476, train_loss=0.02680042013525963, time_cost=2.4254634380340576
Steps:   2%|▏         | 16094/1000000 [7:54:28<2094:54:57,  7.67s/it, lr=1e-5, step_loss=0.0109]Steps:   2%|▏         | 16095/1000000 [7:54:42<2593:27:50,  9.49s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [16095], local_loss=0.009643870405852795, train_loss=0.030660437420010567, time_cost=1.5818076133728027
Steps:   2%|▏         | 16095/1000000 [7:54:42<2593:27:50,  9.49s/it, lr=1e-5, step_loss=0.00964]Steps:   2%|▏         | 16096/1000000 [7:54:51<2570:40:26,  9.41s/it, lr=1e-5, step_loss=0.00964][RANK-0]: Step: [16096], local_loss=0.010573041625320911, train_loss=0.02066691219806671, time_cost=1.7148613929748535
Steps:   2%|▏         | 16096/1000000 [7:54:51<2570:40:26,  9.41s/it, lr=1e-5, step_loss=0.0106] Steps:   2%|▏         | 16097/1000000 [7:54:57<2275:00:37,  8.32s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [16097], local_loss=0.01817730814218521, train_loss=0.03216533362865448, time_cost=1.4070076942443848
Steps:   2%|▏         | 16097/1000000 [7:54:57<2275:00:37,  8.32s/it, lr=1e-5, step_loss=0.0182]Steps:   2%|▏         | 16098/1000000 [7:55:06<2350:24:48,  8.60s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [16098], local_loss=0.007851839996874332, train_loss=0.01918196678161621, time_cost=2.103079319000244
Steps:   2%|▏         | 16098/1000000 [7:55:06<2350:24:48,  8.60s/it, lr=1e-5, step_loss=0.00785]Steps:   2%|▏         | 16099/1000000 [7:55:16<2443:54:23,  8.94s/it, lr=1e-5, step_loss=0.00785][RANK-0]: Step: [16099], local_loss=0.033513832837343216, train_loss=0.03221113979816437, time_cost=4.681732892990112
Steps:   2%|▏         | 16099/1000000 [7:55:16<2443:54:23,  8.94s/it, lr=1e-5, step_loss=0.0335] Steps:   2%|▏         | 16100/1000000 [7:55:22<2216:41:08,  8.11s/it, lr=1e-5, step_loss=0.0335][RANK-0]: Step: [16100], local_loss=0.005767871625721455, train_loss=16.393714904785156, time_cost=1.9275565147399902
Steps:   2%|▏         | 16100/1000000 [7:55:22<2216:41:08,  8.11s/it, lr=1e-5, step_loss=0.00577]Steps:   2%|▏         | 16101/1000000 [7:55:29<2081:58:55,  7.62s/it, lr=1e-5, step_loss=0.00577][RANK-0]: Step: [16101], local_loss=0.039369359612464905, train_loss=0.18822452425956726, time_cost=2.5463593006134033
Steps:   2%|▏         | 16101/1000000 [7:55:29<2081:58:55,  7.62s/it, lr=1e-5, step_loss=0.0394] Steps:   2%|▏         | 16102/1000000 [7:55:40<2424:27:39,  8.87s/it, lr=1e-5, step_loss=0.0394][RANK-0]: Step: [16102], local_loss=0.0597873255610466, train_loss=0.06075398996472359, time_cost=1.3485913276672363
Steps:   2%|▏         | 16102/1000000 [7:55:40<2424:27:39,  8.87s/it, lr=1e-5, step_loss=0.0598]Steps:   2%|▏         | 16103/1000000 [7:55:56<2940:26:36, 10.76s/it, lr=1e-5, step_loss=0.0598][RANK-0]: Step: [16103], local_loss=0.0352427177131176, train_loss=3.1631851196289062, time_cost=3.2999603748321533
Steps:   2%|▏         | 16103/1000000 [7:55:56<2940:26:36, 10.76s/it, lr=1e-5, step_loss=0.0352]Steps:   2%|▏         | 16104/1000000 [7:56:07<2962:56:12, 10.84s/it, lr=1e-5, step_loss=0.0352][RANK-0]: Step: [16104], local_loss=0.005076582543551922, train_loss=0.14453192055225372, time_cost=4.288997650146484
Steps:   2%|▏         | 16104/1000000 [7:56:07<2962:56:12, 10.84s/it, lr=1e-5, step_loss=0.00508]Steps:   2%|▏         | 16105/1000000 [7:56:19<3118:40:10, 11.41s/it, lr=1e-5, step_loss=0.00508][RANK-0]: Step: [16105], local_loss=0.0370350256562233, train_loss=0.0195632204413414, time_cost=5.758819580078125
Steps:   2%|▏         | 16105/1000000 [7:56:19<3118:40:10, 11.41s/it, lr=1e-5, step_loss=0.037]  Steps:   2%|▏         | 16106/1000000 [7:56:30<3020:44:59, 11.05s/it, lr=1e-5, step_loss=0.037][RANK-0]: Step: [16106], local_loss=0.016770262271165848, train_loss=0.07466886937618256, time_cost=4.341456651687622
Steps:   2%|▏         | 16106/1000000 [7:56:30<3020:44:59, 11.05s/it, lr=1e-5, step_loss=0.0168]Steps:   2%|▏         | 16107/1000000 [7:56:35<2530:31:08,  9.26s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [16107], local_loss=0.027745872735977173, train_loss=0.15291520953178406, time_cost=2.254023313522339
Steps:   2%|▏         | 16107/1000000 [7:56:35<2530:31:08,  9.26s/it, lr=1e-5, step_loss=0.0277]Steps:   2%|▏         | 16108/1000000 [7:56:46<2712:53:39,  9.93s/it, lr=1e-5, step_loss=0.0277][RANK-0]: Step: [16108], local_loss=0.00468215299770236, train_loss=0.019932210445404053, time_cost=7.873823165893555
Steps:   2%|▏         | 16108/1000000 [7:56:46<2712:53:39,  9.93s/it, lr=1e-5, step_loss=0.00468]Steps:   2%|▏         | 16109/1000000 [7:56:54<2505:08:53,  9.17s/it, lr=1e-5, step_loss=0.00468][RANK-0]: Step: [16109], local_loss=0.028255287557840347, train_loss=0.09745129942893982, time_cost=1.7596065998077393
Steps:   2%|▏         | 16109/1000000 [7:56:54<2505:08:53,  9.17s/it, lr=1e-5, step_loss=0.0283] Steps:   2%|▏         | 16110/1000000 [7:57:03<2523:40:01,  9.23s/it, lr=1e-5, step_loss=0.0283][RANK-0]: Step: [16110], local_loss=0.03980425372719765, train_loss=0.04277893900871277, time_cost=3.5768706798553467
Steps:   2%|▏         | 16110/1000000 [7:57:03<2523:40:01,  9.23s/it, lr=1e-5, step_loss=0.0398]Steps:   2%|▏         | 16111/1000000 [7:57:12<2480:56:38,  9.08s/it, lr=1e-5, step_loss=0.0398][RANK-0]: Step: [16111], local_loss=0.011327391490340233, train_loss=0.05217084288597107, time_cost=7.34018087387085
Steps:   2%|▏         | 16111/1000000 [7:57:12<2480:56:38,  9.08s/it, lr=1e-5, step_loss=0.0113]Steps:   2%|▏         | 16112/1000000 [7:57:19<2321:17:27,  8.49s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [16112], local_loss=0.2662636935710907, train_loss=0.0646999329328537, time_cost=3.5125958919525146
Steps:   2%|▏         | 16112/1000000 [7:57:19<2321:17:27,  8.49s/it, lr=1e-5, step_loss=0.266] Steps:   2%|▏         | 16113/1000000 [7:57:33<2793:33:40, 10.22s/it, lr=1e-5, step_loss=0.266][RANK-0]: Step: [16113], local_loss=0.014677566476166248, train_loss=0.02911987341940403, time_cost=9.897892951965332
Steps:   2%|▏         | 16113/1000000 [7:57:33<2793:33:40, 10.22s/it, lr=1e-5, step_loss=0.0147]Steps:   2%|▏         | 16114/1000000 [7:57:43<2790:49:08, 10.21s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [16114], local_loss=0.02817394584417343, train_loss=0.02558295801281929, time_cost=4.3970818519592285
Steps:   2%|▏         | 16114/1000000 [7:57:43<2790:49:08, 10.21s/it, lr=1e-5, step_loss=0.0282]Steps:   2%|▏         | 16115/1000000 [7:57:51<2605:26:00,  9.53s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [16115], local_loss=0.1764083206653595, train_loss=0.05452604964375496, time_cost=3.945472478866577
Steps:   2%|▏         | 16115/1000000 [7:57:51<2605:26:00,  9.53s/it, lr=1e-5, step_loss=0.176] Steps:   2%|▏         | 16116/1000000 [7:57:57<2286:02:26,  8.36s/it, lr=1e-5, step_loss=0.176][RANK-0]: Step: [16116], local_loss=0.03805108368396759, train_loss=0.05318029224872589, time_cost=1.5614814758300781
Steps:   2%|▏         | 16116/1000000 [7:57:57<2286:02:26,  8.36s/it, lr=1e-5, step_loss=0.0381]Steps:   2%|▏         | 16117/1000000 [7:58:13<2921:58:28, 10.69s/it, lr=1e-5, step_loss=0.0381][RANK-0]: Step: [16117], local_loss=0.027352582663297653, train_loss=0.048100024461746216, time_cost=7.200422525405884
Steps:   2%|▏         | 16117/1000000 [7:58:13<2921:58:28, 10.69s/it, lr=1e-5, step_loss=0.0274]Steps:   2%|▏         | 16118/1000000 [7:58:24<2942:51:00, 10.77s/it, lr=1e-5, step_loss=0.0274][RANK-0]: Step: [16118], local_loss=0.013126465491950512, train_loss=0.05421833693981171, time_cost=2.005507230758667
Steps:   2%|▏         | 16118/1000000 [7:58:24<2942:51:00, 10.77s/it, lr=1e-5, step_loss=0.0131]Steps:   2%|▏         | 16119/1000000 [7:58:29<2507:15:23,  9.17s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [16119], local_loss=0.017567817121744156, train_loss=0.074811190366745, time_cost=2.943265438079834
Steps:   2%|▏         | 16119/1000000 [7:58:29<2507:15:23,  9.17s/it, lr=1e-5, step_loss=0.0176]Steps:   2%|▏         | 16120/1000000 [7:58:38<2487:06:07,  9.10s/it, lr=1e-5, step_loss=0.0176][RANK-0]: Step: [16120], local_loss=0.029918566346168518, train_loss=0.020308736711740494, time_cost=3.2563302516937256
Steps:   2%|▏         | 16120/1000000 [7:58:38<2487:06:07,  9.10s/it, lr=1e-5, step_loss=0.0299]Steps:   2%|▏         | 16121/1000000 [7:58:54<3040:37:56, 11.13s/it, lr=1e-5, step_loss=0.0299][RANK-0]: Step: [16121], local_loss=0.10841518640518188, train_loss=0.03532605990767479, time_cost=6.3217620849609375
Steps:   2%|▏         | 16121/1000000 [7:58:54<3040:37:56, 11.13s/it, lr=1e-5, step_loss=0.108] Steps:   2%|▏         | 16122/1000000 [7:59:09<3347:31:58, 12.25s/it, lr=1e-5, step_loss=0.108][RANK-0]: Step: [16122], local_loss=0.006840684916824102, train_loss=0.01684163138270378, time_cost=2.6794137954711914
Steps:   2%|▏         | 16122/1000000 [7:59:09<3347:31:58, 12.25s/it, lr=1e-5, step_loss=0.00684]Steps:   2%|▏         | 16123/1000000 [7:59:20<3251:04:22, 11.90s/it, lr=1e-5, step_loss=0.00684][RANK-0]: Step: [16123], local_loss=0.13131915032863617, train_loss=0.03170172870159149, time_cost=7.917720079421997
Steps:   2%|▏         | 16123/1000000 [7:59:20<3251:04:22, 11.90s/it, lr=1e-5, step_loss=0.131]  Steps:   2%|▏         | 16124/1000000 [7:59:32<3258:46:25, 11.92s/it, lr=1e-5, step_loss=0.131][RANK-0]: Step: [16124], local_loss=0.17333120107650757, train_loss=0.0775827094912529, time_cost=3.529278039932251
Steps:   2%|▏         | 16124/1000000 [7:59:32<3258:46:25, 11.92s/it, lr=1e-5, step_loss=0.173]Steps:   2%|▏         | 16125/1000000 [7:59:39<2862:10:52, 10.47s/it, lr=1e-5, step_loss=0.173][RANK-0]: Step: [16125], local_loss=0.017904730513691902, train_loss=0.03750491142272949, time_cost=4.3155677318573
Steps:   2%|▏         | 16125/1000000 [7:59:39<2862:10:52, 10.47s/it, lr=1e-5, step_loss=0.0179]Steps:   2%|▏         | 16126/1000000 [7:59:52<3086:55:38, 11.30s/it, lr=1e-5, step_loss=0.0179][RANK-0]: Step: [16126], local_loss=0.059749651700258255, train_loss=0.11028029024600983, time_cost=4.886650085449219
Steps:   2%|▏         | 16126/1000000 [7:59:52<3086:55:38, 11.30s/it, lr=1e-5, step_loss=0.0597]Steps:   2%|▏         | 16127/1000000 [8:00:04<3076:54:41, 11.26s/it, lr=1e-5, step_loss=0.0597][RANK-0]: Step: [16127], local_loss=0.0038655083626508713, train_loss=0.027164939790964127, time_cost=2.727017879486084
Steps:   2%|▏         | 16127/1000000 [8:00:04<3076:54:41, 11.26s/it, lr=1e-5, step_loss=0.00387]Steps:   2%|▏         | 16128/1000000 [8:00:09<2586:32:44,  9.46s/it, lr=1e-5, step_loss=0.00387][RANK-0]: Step: [16128], local_loss=0.4650763273239136, train_loss=0.09320100396871567, time_cost=2.3435564041137695
Steps:   2%|▏         | 16128/1000000 [8:00:09<2586:32:44,  9.46s/it, lr=1e-5, step_loss=0.465]  Steps:   2%|▏         | 16129/1000000 [8:00:20<2749:11:25, 10.06s/it, lr=1e-5, step_loss=0.465][RANK-0]: Step: [16129], local_loss=0.054836682975292206, train_loss=0.04206588864326477, time_cost=4.922401666641235
Steps:   2%|▏         | 16129/1000000 [8:00:20<2749:11:25, 10.06s/it, lr=1e-5, step_loss=0.0548]Steps:   2%|▏         | 16130/1000000 [8:00:29<2656:55:24,  9.72s/it, lr=1e-5, step_loss=0.0548][RANK-0]: Step: [16130], local_loss=0.012919096276164055, train_loss=0.1403844803571701, time_cost=2.0642812252044678
Steps:   2%|▏         | 16130/1000000 [8:00:29<2656:55:24,  9.72s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 16131/1000000 [8:00:45<3175:01:05, 11.62s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [16131], local_loss=0.04091417044401169, train_loss=0.16841571033000946, time_cost=7.936307191848755
Steps:   2%|▏         | 16131/1000000 [8:00:45<3175:01:05, 11.62s/it, lr=1e-5, step_loss=0.0409]Steps:   2%|▏         | 16132/1000000 [8:00:50<2578:13:36,  9.43s/it, lr=1e-5, step_loss=0.0409][RANK-0]: Step: [16132], local_loss=0.048042964190244675, train_loss=0.03797776997089386, time_cost=3.5689914226531982
Steps:   2%|▏         | 16132/1000000 [8:00:50<2578:13:36,  9.43s/it, lr=1e-5, step_loss=0.048] Steps:   2%|▏         | 16133/1000000 [8:00:54<2205:13:38,  8.07s/it, lr=1e-5, step_loss=0.048][RANK-0]: Step: [16133], local_loss=0.06488977372646332, train_loss=0.0696878731250763, time_cost=1.7712440490722656
Steps:   2%|▏         | 16133/1000000 [8:00:54<2205:13:38,  8.07s/it, lr=1e-5, step_loss=0.0649]Steps:   2%|▏         | 16134/1000000 [8:01:04<2322:58:45,  8.50s/it, lr=1e-5, step_loss=0.0649][RANK-0]: Step: [16134], local_loss=0.03971846401691437, train_loss=0.035653479397296906, time_cost=6.174379110336304
Steps:   2%|▏         | 16134/1000000 [8:01:04<2322:58:45,  8.50s/it, lr=1e-5, step_loss=0.0397]Steps:   2%|▏         | 16135/1000000 [8:01:13<2360:06:14,  8.64s/it, lr=1e-5, step_loss=0.0397][RANK-0]: Step: [16135], local_loss=0.022516850382089615, train_loss=0.0331304594874382, time_cost=1.220226526260376
Steps:   2%|▏         | 16135/1000000 [8:01:13<2360:06:14,  8.64s/it, lr=1e-5, step_loss=0.0225]Steps:   2%|▏         | 16136/1000000 [8:01:22<2403:35:30,  8.79s/it, lr=1e-5, step_loss=0.0225][RANK-0]: Step: [16136], local_loss=0.027682466432452202, train_loss=0.051090385764837265, time_cost=1.7365357875823975
Steps:   2%|▏         | 16136/1000000 [8:01:22<2403:35:30,  8.79s/it, lr=1e-5, step_loss=0.0277]Steps:   2%|▏         | 16137/1000000 [8:01:27<2120:08:54,  7.76s/it, lr=1e-5, step_loss=0.0277][RANK-0]: Step: [16137], local_loss=0.009467929601669312, train_loss=0.04681873321533203, time_cost=2.682204484939575
Steps:   2%|▏         | 16137/1000000 [8:01:27<2120:08:54,  7.76s/it, lr=1e-5, step_loss=0.00947]Steps:   2%|▏         | 16138/1000000 [8:01:34<2035:10:08,  7.45s/it, lr=1e-5, step_loss=0.00947][RANK-0]: Step: [16138], local_loss=0.008264326490461826, train_loss=0.028985051438212395, time_cost=2.5263404846191406
Steps:   2%|▏         | 16138/1000000 [8:01:34<2035:10:08,  7.45s/it, lr=1e-5, step_loss=0.00826]Steps:   2%|▏         | 16139/1000000 [8:01:41<1976:09:42,  7.23s/it, lr=1e-5, step_loss=0.00826][RANK-0]: Step: [16139], local_loss=0.025704652070999146, train_loss=0.050506796687841415, time_cost=2.8619019985198975
Steps:   2%|▏         | 16139/1000000 [8:01:41<1976:09:42,  7.23s/it, lr=1e-5, step_loss=0.0257] Steps:   2%|▏         | 16140/1000000 [8:01:50<2118:21:19,  7.75s/it, lr=1e-5, step_loss=0.0257][RANK-0]: Step: [16140], local_loss=0.10417213290929794, train_loss=0.032487716525793076, time_cost=1.3655736446380615
Steps:   2%|▏         | 16140/1000000 [8:01:50<2118:21:19,  7.75s/it, lr=1e-5, step_loss=0.104] Steps:   2%|▏         | 16141/1000000 [8:01:54<1842:21:21,  6.74s/it, lr=1e-5, step_loss=0.104][RANK-0]: Step: [16141], local_loss=0.06797460466623306, train_loss=0.03355567902326584, time_cost=1.4134533405303955
Steps:   2%|▏         | 16141/1000000 [8:01:54<1842:21:21,  6.74s/it, lr=1e-5, step_loss=0.068]Steps:   2%|▏         | 16142/1000000 [8:02:05<2194:43:26,  8.03s/it, lr=1e-5, step_loss=0.068][RANK-0]: Step: [16142], local_loss=0.023680277168750763, train_loss=0.044835321605205536, time_cost=3.096691608428955
Steps:   2%|▏         | 16142/1000000 [8:02:05<2194:43:26,  8.03s/it, lr=1e-5, step_loss=0.0237]Steps:   2%|▏         | 16143/1000000 [8:02:10<1907:41:12,  6.98s/it, lr=1e-5, step_loss=0.0237][RANK-0]: Step: [16143], local_loss=0.012505041435360909, train_loss=0.08692027628421783, time_cost=1.6206996440887451
Steps:   2%|▏         | 16143/1000000 [8:02:10<1907:41:12,  6.98s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 16144/1000000 [8:02:16<1818:21:06,  6.65s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [16144], local_loss=1.0020426511764526, train_loss=0.2722172737121582, time_cost=3.357083320617676
Steps:   2%|▏         | 16144/1000000 [8:02:16<1818:21:06,  6.65s/it, lr=1e-5, step_loss=1]     Steps:   2%|▏         | 16145/1000000 [8:02:24<1995:32:14,  7.30s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [16145], local_loss=0.021074730902910233, train_loss=0.027992159128189087, time_cost=2.1304478645324707
Steps:   2%|▏         | 16145/1000000 [8:02:24<1995:32:14,  7.30s/it, lr=1e-5, step_loss=0.0211]Steps:   2%|▏         | 16146/1000000 [8:02:34<2211:09:16,  8.09s/it, lr=1e-5, step_loss=0.0211][RANK-0]: Step: [16146], local_loss=0.010591478087008, train_loss=0.022168850526213646, time_cost=1.2157230377197266
Steps:   2%|▏         | 16146/1000000 [8:02:34<2211:09:16,  8.09s/it, lr=1e-5, step_loss=0.0106]Steps:   2%|▏         | 16147/1000000 [8:02:41<2105:18:47,  7.70s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [16147], local_loss=0.00532566849142313, train_loss=0.012960616499185562, time_cost=2.3478994369506836
Steps:   2%|▏         | 16147/1000000 [8:02:41<2105:18:47,  7.70s/it, lr=1e-5, step_loss=0.00533]Steps:   2%|▏         | 16148/1000000 [8:02:55<2564:43:20,  9.38s/it, lr=1e-5, step_loss=0.00533][RANK-0]: Step: [16148], local_loss=0.006601652130484581, train_loss=0.09852030873298645, time_cost=4.009793758392334
Steps:   2%|▏         | 16148/1000000 [8:02:55<2564:43:20,  9.38s/it, lr=1e-5, step_loss=0.0066] Steps:   2%|▏         | 16149/1000000 [8:03:05<2687:05:53,  9.83s/it, lr=1e-5, step_loss=0.0066][RANK-0]: Step: [16149], local_loss=0.03181883320212364, train_loss=0.023226357996463776, time_cost=1.220656156539917
Steps:   2%|▏         | 16149/1000000 [8:03:05<2687:05:53,  9.83s/it, lr=1e-5, step_loss=0.0318]Steps:   2%|▏         | 16150/1000000 [8:03:11<2344:10:25,  8.58s/it, lr=1e-5, step_loss=0.0318][RANK-0]: Step: [16150], local_loss=0.0839640200138092, train_loss=0.02536782994866371, time_cost=2.9278197288513184
Steps:   2%|▏         | 16150/1000000 [8:03:11<2344:10:25,  8.58s/it, lr=1e-5, step_loss=0.084] Steps:   2%|▏         | 16151/1000000 [8:03:19<2281:56:27,  8.35s/it, lr=1e-5, step_loss=0.084][RANK-0]: Step: [16151], local_loss=0.006492302753031254, train_loss=0.027838805690407753, time_cost=2.3027937412261963
Steps:   2%|▏         | 16151/1000000 [8:03:19<2281:56:27,  8.35s/it, lr=1e-5, step_loss=0.00649]Steps:   2%|▏         | 16152/1000000 [8:03:26<2187:01:43,  8.00s/it, lr=1e-5, step_loss=0.00649][RANK-0]: Step: [16152], local_loss=0.010738967917859554, train_loss=0.01886829361319542, time_cost=3.3877060413360596
Steps:   2%|▏         | 16152/1000000 [8:03:26<2187:01:43,  8.00s/it, lr=1e-5, step_loss=0.0107] Steps:   2%|▏         | 16153/1000000 [8:03:31<1934:06:58,  7.08s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [16153], local_loss=0.33066287636756897, train_loss=0.22727467119693756, time_cost=2.6215720176696777
Steps:   2%|▏         | 16153/1000000 [8:03:31<1934:06:58,  7.08s/it, lr=1e-5, step_loss=0.331] Steps:   2%|▏         | 16154/1000000 [8:03:40<2105:26:43,  7.70s/it, lr=1e-5, step_loss=0.331][RANK-0]: Step: [16154], local_loss=0.020699355751276016, train_loss=0.043256163597106934, time_cost=1.2322063446044922
Steps:   2%|▏         | 16154/1000000 [8:03:40<2105:26:43,  7.70s/it, lr=1e-5, step_loss=0.0207]Steps:   2%|▏         | 16155/1000000 [8:03:50<2266:42:33,  8.29s/it, lr=1e-5, step_loss=0.0207][RANK-0]: Step: [16155], local_loss=0.014568579383194447, train_loss=19.91119384765625, time_cost=4.55719780921936
Steps:   2%|▏         | 16155/1000000 [8:03:50<2266:42:33,  8.29s/it, lr=1e-5, step_loss=0.0146]Steps:   2%|▏         | 16156/1000000 [8:03:56<2117:09:13,  7.75s/it, lr=1e-5, step_loss=0.0146][RANK-0]: Step: [16156], local_loss=0.08264721184968948, train_loss=0.02390730381011963, time_cost=2.4014084339141846
Steps:   2%|▏         | 16156/1000000 [8:03:56<2117:09:13,  7.75s/it, lr=1e-5, step_loss=0.0826]Steps:   2%|▏         | 16157/1000000 [8:04:10<2602:49:14,  9.52s/it, lr=1e-5, step_loss=0.0826][RANK-0]: Step: [16157], local_loss=0.020412607118487358, train_loss=0.03410359099507332, time_cost=4.737490892410278
Steps:   2%|▏         | 16157/1000000 [8:04:10<2602:49:14,  9.52s/it, lr=1e-5, step_loss=0.0204]Steps:   2%|▏         | 16158/1000000 [8:04:15<2271:34:15,  8.31s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [16158], local_loss=0.01292004156857729, train_loss=0.021792951971292496, time_cost=2.8540027141571045
Steps:   2%|▏         | 16158/1000000 [8:04:15<2271:34:15,  8.31s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 16159/1000000 [8:04:20<1934:05:34,  7.08s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [16159], local_loss=0.0442286916077137, train_loss=0.08873596042394638, time_cost=1.1955866813659668
Steps:   2%|▏         | 16159/1000000 [8:04:20<1934:05:34,  7.08s/it, lr=1e-5, step_loss=0.0442]Steps:   2%|▏         | 16160/1000000 [8:04:27<1972:02:56,  7.22s/it, lr=1e-5, step_loss=0.0442][RANK-0]: Step: [16160], local_loss=0.03664473816752434, train_loss=0.02171538583934307, time_cost=1.6417603492736816
Steps:   2%|▏         | 16160/1000000 [8:04:27<1972:02:56,  7.22s/it, lr=1e-5, step_loss=0.0366]Steps:   2%|▏         | 16161/1000000 [8:04:36<2143:47:16,  7.84s/it, lr=1e-5, step_loss=0.0366][RANK-0]: Step: [16161], local_loss=0.0376090332865715, train_loss=0.018349217250943184, time_cost=3.071535110473633
Steps:   2%|▏         | 16161/1000000 [8:04:37<2143:47:16,  7.84s/it, lr=1e-5, step_loss=0.0376]Steps:   2%|▏         | 16162/1000000 [8:04:43<2066:28:07,  7.56s/it, lr=1e-5, step_loss=0.0376][RANK-0]: Step: [16162], local_loss=0.018212350085377693, train_loss=0.023510383442044258, time_cost=3.100858449935913
Steps:   2%|▏         | 16162/1000000 [8:04:43<2066:28:07,  7.56s/it, lr=1e-5, step_loss=0.0182]Steps:   2%|▏         | 16163/1000000 [8:04:57<2529:48:10,  9.26s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [16163], local_loss=0.024356799200177193, train_loss=0.05616593733429909, time_cost=4.968812704086304
Steps:   2%|▏         | 16163/1000000 [8:04:57<2529:48:10,  9.26s/it, lr=1e-5, step_loss=0.0244]Steps:   2%|▏         | 16164/1000000 [8:05:10<2891:32:02, 10.58s/it, lr=1e-5, step_loss=0.0244][RANK-0]: Step: [16164], local_loss=0.0074572996236383915, train_loss=0.02237841486930847, time_cost=4.490358829498291
Steps:   2%|▏         | 16164/1000000 [8:05:10<2891:32:02, 10.58s/it, lr=1e-5, step_loss=0.00746]Steps:   2%|▏         | 16165/1000000 [8:05:18<2633:19:26,  9.64s/it, lr=1e-5, step_loss=0.00746][RANK-0]: Step: [16165], local_loss=0.00950108002871275, train_loss=0.025335092097520828, time_cost=1.2563154697418213
Steps:   2%|▏         | 16165/1000000 [8:05:18<2633:19:26,  9.64s/it, lr=1e-5, step_loss=0.0095] Steps:   2%|▏         | 16166/1000000 [8:05:22<2229:20:00,  8.16s/it, lr=1e-5, step_loss=0.0095][RANK-0]: Step: [16166], local_loss=0.0389542356133461, train_loss=0.07283530384302139, time_cost=1.8254008293151855
Steps:   2%|▏         | 16166/1000000 [8:05:22<2229:20:00,  8.16s/it, lr=1e-5, step_loss=0.039] Steps:   2%|▏         | 16167/1000000 [8:05:34<2517:33:40,  9.21s/it, lr=1e-5, step_loss=0.039][RANK-0]: Step: [16167], local_loss=0.037577494978904724, train_loss=0.042412057518959045, time_cost=7.8499085903167725
Steps:   2%|▏         | 16167/1000000 [8:05:34<2517:33:40,  9.21s/it, lr=1e-5, step_loss=0.0376]Steps:   2%|▏         | 16168/1000000 [8:05:43<2485:13:06,  9.09s/it, lr=1e-5, step_loss=0.0376][RANK-0]: Step: [16168], local_loss=0.06532846391201019, train_loss=0.03958591818809509, time_cost=2.2841591835021973
Steps:   2%|▏         | 16168/1000000 [8:05:43<2485:13:06,  9.09s/it, lr=1e-5, step_loss=0.0653]Steps:   2%|▏         | 16169/1000000 [8:05:48<2168:24:58,  7.93s/it, lr=1e-5, step_loss=0.0653][RANK-0]: Step: [16169], local_loss=0.07299275696277618, train_loss=0.08400388062000275, time_cost=2.5069477558135986
Steps:   2%|▏         | 16169/1000000 [8:05:48<2168:24:58,  7.93s/it, lr=1e-5, step_loss=0.073] Steps:   2%|▏         | 16170/1000000 [8:06:00<2456:08:45,  8.99s/it, lr=1e-5, step_loss=0.073][RANK-0]: Step: [16170], local_loss=0.00800103135406971, train_loss=0.05420343577861786, time_cost=2.838046073913574
Steps:   2%|▏         | 16170/1000000 [8:06:00<2456:08:45,  8.99s/it, lr=1e-5, step_loss=0.008]Steps:   2%|▏         | 16171/1000000 [8:06:07<2296:48:56,  8.40s/it, lr=1e-5, step_loss=0.008][RANK-0]: Step: [16171], local_loss=0.9995906352996826, train_loss=0.29327821731567383, time_cost=2.920093536376953
Steps:   2%|▏         | 16171/1000000 [8:06:07<2296:48:56,  8.40s/it, lr=1e-5, step_loss=1]    Steps:   2%|▏         | 16172/1000000 [8:06:12<2027:01:23,  7.42s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [16172], local_loss=0.006018318235874176, train_loss=0.02442755177617073, time_cost=2.5234792232513428
Steps:   2%|▏         | 16172/1000000 [8:06:12<2027:01:23,  7.42s/it, lr=1e-5, step_loss=0.00602]Steps:   2%|▏         | 16173/1000000 [8:06:18<1905:47:36,  6.97s/it, lr=1e-5, step_loss=0.00602][RANK-0]: Step: [16173], local_loss=0.03824108839035034, train_loss=0.038793355226516724, time_cost=3.102525472640991
Steps:   2%|▏         | 16173/1000000 [8:06:18<1905:47:36,  6.97s/it, lr=1e-5, step_loss=0.0382] Steps:   2%|▏         | 16174/1000000 [8:06:29<2230:47:30,  8.16s/it, lr=1e-5, step_loss=0.0382][RANK-0]: Step: [16174], local_loss=0.9877355098724365, train_loss=0.21860072016716003, time_cost=4.1748998165130615
Steps:   2%|▏         | 16174/1000000 [8:06:29<2230:47:30,  8.16s/it, lr=1e-5, step_loss=0.988] Steps:   2%|▏         | 16175/1000000 [8:06:39<2380:48:42,  8.71s/it, lr=1e-5, step_loss=0.988][RANK-0]: Step: [16175], local_loss=0.005217067897319794, train_loss=0.015639042481780052, time_cost=4.664712190628052
Steps:   2%|▏         | 16175/1000000 [8:06:39<2380:48:42,  8.71s/it, lr=1e-5, step_loss=0.00522]Steps:   2%|▏         | 16176/1000000 [8:06:49<2529:20:23,  9.26s/it, lr=1e-5, step_loss=0.00522][RANK-0]: Step: [16176], local_loss=0.06356887519359589, train_loss=0.08420273661613464, time_cost=2.0498087406158447
Steps:   2%|▏         | 16176/1000000 [8:06:49<2529:20:23,  9.26s/it, lr=1e-5, step_loss=0.0636] Steps:   2%|▏         | 16177/1000000 [8:06:57<2406:02:07,  8.80s/it, lr=1e-5, step_loss=0.0636][RANK-0]: Step: [16177], local_loss=0.010694652795791626, train_loss=0.027863822877407074, time_cost=1.528693437576294
Steps:   2%|▏         | 16177/1000000 [8:06:57<2406:02:07,  8.80s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 16178/1000000 [8:07:05<2381:52:41,  8.72s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [16178], local_loss=0.11647722870111465, train_loss=0.04564956948161125, time_cost=1.397934913635254
Steps:   2%|▏         | 16178/1000000 [8:07:05<2381:52:41,  8.72s/it, lr=1e-5, step_loss=0.116] Steps:   2%|▏         | 16179/1000000 [8:07:18<2722:13:47,  9.96s/it, lr=1e-5, step_loss=0.116][RANK-0]: Step: [16179], local_loss=0.006787192542105913, train_loss=0.13804717361927032, time_cost=1.2081079483032227
Steps:   2%|▏         | 16179/1000000 [8:07:18<2722:13:47,  9.96s/it, lr=1e-5, step_loss=0.00679]Steps:   2%|▏         | 16180/1000000 [8:07:34<3190:41:22, 11.68s/it, lr=1e-5, step_loss=0.00679][RANK-0]: Step: [16180], local_loss=0.032381318509578705, train_loss=0.025004060938954353, time_cost=3.9508211612701416
Steps:   2%|▏         | 16180/1000000 [8:07:34<3190:41:22, 11.68s/it, lr=1e-5, step_loss=0.0324] Steps:   2%|▏         | 16181/1000000 [8:07:41<2838:22:43, 10.39s/it, lr=1e-5, step_loss=0.0324][RANK-0]: Step: [16181], local_loss=0.009454491548240185, train_loss=0.02891572006046772, time_cost=1.558833122253418
Steps:   2%|▏         | 16181/1000000 [8:07:41<2838:22:43, 10.39s/it, lr=1e-5, step_loss=0.00945]Steps:   2%|▏         | 16182/1000000 [8:07:48<2557:06:26,  9.36s/it, lr=1e-5, step_loss=0.00945][RANK-0]: Step: [16182], local_loss=44.845252990722656, train_loss=5.646780967712402, time_cost=5.875410318374634
Steps:   2%|▏         | 16182/1000000 [8:07:48<2557:06:26,  9.36s/it, lr=1e-5, step_loss=44.8]   Steps:   2%|▏         | 16183/1000000 [8:07:53<2142:38:00,  7.84s/it, lr=1e-5, step_loss=44.8][RANK-0]: Step: [16183], local_loss=0.047625310719013214, train_loss=0.06058667600154877, time_cost=1.3514344692230225
Steps:   2%|▏         | 16183/1000000 [8:07:53<2142:38:00,  7.84s/it, lr=1e-5, step_loss=0.0476]Steps:   2%|▏         | 16184/1000000 [8:07:58<1920:34:48,  7.03s/it, lr=1e-5, step_loss=0.0476][RANK-0]: Step: [16184], local_loss=0.024395931512117386, train_loss=0.036835432052612305, time_cost=1.9387891292572021
Steps:   2%|▏         | 16184/1000000 [8:07:58<1920:34:48,  7.03s/it, lr=1e-5, step_loss=0.0244]Steps:   2%|▏         | 16185/1000000 [8:08:10<2390:19:51,  8.75s/it, lr=1e-5, step_loss=0.0244][RANK-0]: Step: [16185], local_loss=0.006470009684562683, train_loss=15.660236358642578, time_cost=3.7654097080230713
Steps:   2%|▏         | 16185/1000000 [8:08:10<2390:19:51,  8.75s/it, lr=1e-5, step_loss=0.00647]Steps:   2%|▏         | 16186/1000000 [8:08:15<2021:48:01,  7.40s/it, lr=1e-5, step_loss=0.00647][RANK-0]: Step: [16186], local_loss=0.050459813326597214, train_loss=0.03546687588095665, time_cost=1.6137843132019043
Steps:   2%|▏         | 16186/1000000 [8:08:15<2021:48:01,  7.40s/it, lr=1e-5, step_loss=0.0505] Steps:   2%|▏         | 16187/1000000 [8:08:23<2106:57:50,  7.71s/it, lr=1e-5, step_loss=0.0505][RANK-0]: Step: [16187], local_loss=0.020106058567762375, train_loss=0.12288352102041245, time_cost=1.2288968563079834
Steps:   2%|▏         | 16187/1000000 [8:08:23<2106:57:50,  7.71s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 16188/1000000 [8:08:37<2586:23:54,  9.46s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [16188], local_loss=0.02155289612710476, train_loss=0.054297201335430145, time_cost=1.5404739379882812
Steps:   2%|▏         | 16188/1000000 [8:08:37<2586:23:54,  9.46s/it, lr=1e-5, step_loss=0.0216]Steps:   2%|▏         | 16189/1000000 [8:08:42<2229:03:18,  8.16s/it, lr=1e-5, step_loss=0.0216][RANK-0]: Step: [16189], local_loss=0.02425410971045494, train_loss=0.0194247979670763, time_cost=2.244945764541626
Steps:   2%|▏         | 16189/1000000 [8:08:42<2229:03:18,  8.16s/it, lr=1e-5, step_loss=0.0243]Steps:   2%|▏         | 16190/1000000 [8:08:46<1939:35:58,  7.10s/it, lr=1e-5, step_loss=0.0243][RANK-0]: Step: [16190], local_loss=0.04800815507769585, train_loss=0.044017642736434937, time_cost=3.5531163215637207
Steps:   2%|▏         | 16190/1000000 [8:08:46<1939:35:58,  7.10s/it, lr=1e-5, step_loss=0.048] Steps:   2%|▏         | 16191/1000000 [8:08:56<2118:14:32,  7.75s/it, lr=1e-5, step_loss=0.048][RANK-0]: Step: [16191], local_loss=0.055254556238651276, train_loss=0.02236148715019226, time_cost=2.4230594635009766
Steps:   2%|▏         | 16191/1000000 [8:08:56<2118:14:32,  7.75s/it, lr=1e-5, step_loss=0.0553]Steps:   2%|▏         | 16192/1000000 [8:09:06<2286:48:05,  8.37s/it, lr=1e-5, step_loss=0.0553][RANK-0]: Step: [16192], local_loss=0.02326870709657669, train_loss=0.2816663384437561, time_cost=3.0253307819366455
Steps:   2%|▏         | 16192/1000000 [8:09:06<2286:48:05,  8.37s/it, lr=1e-5, step_loss=0.0233]Steps:   2%|▏         | 16193/1000000 [8:09:18<2653:24:14,  9.71s/it, lr=1e-5, step_loss=0.0233][RANK-0]: Step: [16193], local_loss=0.007811015471816063, train_loss=58.194976806640625, time_cost=1.3203797340393066
Steps:   2%|▏         | 16193/1000000 [8:09:18<2653:24:14,  9.71s/it, lr=1e-5, step_loss=0.00781]Steps:   2%|▏         | 16194/1000000 [8:09:24<2304:02:52,  8.43s/it, lr=1e-5, step_loss=0.00781][RANK-0]: Step: [16194], local_loss=0.02026369422674179, train_loss=0.03537721559405327, time_cost=2.8080127239227295
Steps:   2%|▏         | 16194/1000000 [8:09:24<2304:02:52,  8.43s/it, lr=1e-5, step_loss=0.0203] Steps:   2%|▏         | 16195/1000000 [8:09:37<2694:18:43,  9.86s/it, lr=1e-5, step_loss=0.0203][RANK-0]: Step: [16195], local_loss=0.027309678494930267, train_loss=0.12085659056901932, time_cost=3.130784273147583
Steps:   2%|▏         | 16195/1000000 [8:09:37<2694:18:43,  9.86s/it, lr=1e-5, step_loss=0.0273]Steps:   2%|▏         | 16196/1000000 [8:09:48<2768:47:12, 10.13s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [16196], local_loss=0.27546536922454834, train_loss=0.053799472749233246, time_cost=3.325195074081421
Steps:   2%|▏         | 16196/1000000 [8:09:48<2768:47:12, 10.13s/it, lr=1e-5, step_loss=0.275] Steps:   2%|▏         | 16197/1000000 [8:09:53<2361:30:13,  8.64s/it, lr=1e-5, step_loss=0.275][RANK-0]: Step: [16197], local_loss=0.008021418005228043, train_loss=0.039235472679138184, time_cost=1.9002113342285156
Steps:   2%|▏         | 16197/1000000 [8:09:53<2361:30:13,  8.64s/it, lr=1e-5, step_loss=0.00802]Steps:   2%|▏         | 16198/1000000 [8:10:03<2441:37:44,  8.93s/it, lr=1e-5, step_loss=0.00802][RANK-0]: Step: [16198], local_loss=0.08647438883781433, train_loss=0.02828322909772396, time_cost=2.627873420715332
Steps:   2%|▏         | 16198/1000000 [8:10:03<2441:37:44,  8.93s/it, lr=1e-5, step_loss=0.0865] Steps:   2%|▏         | 16199/1000000 [8:10:15<2741:05:54, 10.03s/it, lr=1e-5, step_loss=0.0865][RANK-0]: Step: [16199], local_loss=0.010058499872684479, train_loss=0.16849297285079956, time_cost=3.296168804168701
Steps:   2%|▏         | 16199/1000000 [8:10:15<2741:05:54, 10.03s/it, lr=1e-5, step_loss=0.0101]Steps:   2%|▏         | 16200/1000000 [8:10:22<2483:20:27,  9.09s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [16200], local_loss=0.016105985268950462, train_loss=0.01652546040713787, time_cost=1.2506871223449707
Steps:   2%|▏         | 16200/1000000 [8:10:22<2483:20:27,  9.09s/it, lr=1e-5, step_loss=0.0161]Steps:   2%|▏         | 16201/1000000 [8:10:30<2394:39:23,  8.76s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [16201], local_loss=0.3715416193008423, train_loss=0.07560931146144867, time_cost=1.5339066982269287
Steps:   2%|▏         | 16201/1000000 [8:10:30<2394:39:23,  8.76s/it, lr=1e-5, step_loss=0.372] Steps:   2%|▏         | 16202/1000000 [8:10:37<2256:14:34,  8.26s/it, lr=1e-5, step_loss=0.372][RANK-0]: Step: [16202], local_loss=0.008515531197190285, train_loss=0.13251696527004242, time_cost=1.4458091259002686
Steps:   2%|▏         | 16202/1000000 [8:10:37<2256:14:34,  8.26s/it, lr=1e-5, step_loss=0.00852]Steps:   2%|▏         | 16203/1000000 [8:10:50<2647:34:45,  9.69s/it, lr=1e-5, step_loss=0.00852][RANK-0]: Step: [16203], local_loss=0.029307575896382332, train_loss=0.03278888389468193, time_cost=4.952514410018921
Steps:   2%|▏         | 16203/1000000 [8:10:50<2647:34:45,  9.69s/it, lr=1e-5, step_loss=0.0293] Steps:   2%|▏         | 16204/1000000 [8:11:01<2759:59:34, 10.10s/it, lr=1e-5, step_loss=0.0293][RANK-0]: Step: [16204], local_loss=0.031140603125095367, train_loss=0.015577418729662895, time_cost=9.924379825592041
Steps:   2%|▏         | 16204/1000000 [8:11:01<2759:59:34, 10.10s/it, lr=1e-5, step_loss=0.0311]Steps:   2%|▏         | 16205/1000000 [8:11:12<2824:44:50, 10.34s/it, lr=1e-5, step_loss=0.0311][RANK-0]: Step: [16205], local_loss=0.12221424281597137, train_loss=0.03297997638583183, time_cost=7.957953929901123
Steps:   2%|▏         | 16205/1000000 [8:11:12<2824:44:50, 10.34s/it, lr=1e-5, step_loss=0.122] Steps:   2%|▏         | 16206/1000000 [8:11:19<2569:03:10,  9.40s/it, lr=1e-5, step_loss=0.122][RANK-0]: Step: [16206], local_loss=0.01775151491165161, train_loss=0.01707647368311882, time_cost=2.2133898735046387
Steps:   2%|▏         | 16206/1000000 [8:11:19<2569:03:10,  9.40s/it, lr=1e-5, step_loss=0.0178]Steps:   2%|▏         | 16207/1000000 [8:11:24<2181:14:15,  7.98s/it, lr=1e-5, step_loss=0.0178][RANK-0]: Step: [16207], local_loss=0.012121441774070263, train_loss=0.10810650885105133, time_cost=2.2507119178771973
Steps:   2%|▏         | 16207/1000000 [8:11:24<2181:14:15,  7.98s/it, lr=1e-5, step_loss=0.0121]Steps:   2%|▏         | 16208/1000000 [8:11:31<2127:39:59,  7.79s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [16208], local_loss=0.05770193412899971, train_loss=49.76343536376953, time_cost=1.793123722076416
Steps:   2%|▏         | 16208/1000000 [8:11:31<2127:39:59,  7.79s/it, lr=1e-5, step_loss=0.0577]Steps:   2%|▏         | 16209/1000000 [8:11:43<2471:25:47,  9.04s/it, lr=1e-5, step_loss=0.0577][RANK-0]: Step: [16209], local_loss=0.011065035127103329, train_loss=0.040241725742816925, time_cost=5.027510166168213
Steps:   2%|▏         | 16209/1000000 [8:11:43<2471:25:47,  9.04s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 16210/1000000 [8:11:58<2964:37:16, 10.85s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [16210], local_loss=0.10654100775718689, train_loss=0.028462346643209457, time_cost=6.750795125961304
Steps:   2%|▏         | 16210/1000000 [8:11:58<2964:37:16, 10.85s/it, lr=1e-5, step_loss=0.107] Steps:   2%|▏         | 16211/1000000 [8:12:12<3166:32:34, 11.59s/it, lr=1e-5, step_loss=0.107][RANK-0]: Step: [16211], local_loss=0.00953198503702879, train_loss=0.029348550364375114, time_cost=6.100938081741333
Steps:   2%|▏         | 16211/1000000 [8:12:12<3166:32:34, 11.59s/it, lr=1e-5, step_loss=0.00953]Steps:   2%|▏         | 16212/1000000 [8:12:26<3425:35:18, 12.54s/it, lr=1e-5, step_loss=0.00953][RANK-0]: Step: [16212], local_loss=0.020511524751782417, train_loss=0.1450163871049881, time_cost=1.2263848781585693
Steps:   2%|▏         | 16212/1000000 [8:12:26<3425:35:18, 12.54s/it, lr=1e-5, step_loss=0.0205] Steps:   2%|▏         | 16213/1000000 [8:12:31<2745:26:11, 10.05s/it, lr=1e-5, step_loss=0.0205][RANK-0]: Step: [16213], local_loss=0.006448841188102961, train_loss=0.04058688133955002, time_cost=3.062504529953003
Steps:   2%|▏         | 16213/1000000 [8:12:31<2745:26:11, 10.05s/it, lr=1e-5, step_loss=0.00645]Steps:   2%|▏         | 16214/1000000 [8:12:44<2984:18:09, 10.92s/it, lr=1e-5, step_loss=0.00645][RANK-0]: Step: [16214], local_loss=0.03845268860459328, train_loss=0.0317382737994194, time_cost=5.464059591293335
Steps:   2%|▏         | 16214/1000000 [8:12:44<2984:18:09, 10.92s/it, lr=1e-5, step_loss=0.0385] Steps:   2%|▏         | 16215/1000000 [8:12:54<2911:16:19, 10.65s/it, lr=1e-5, step_loss=0.0385][RANK-0]: Step: [16215], local_loss=0.006495364475995302, train_loss=0.034024275839328766, time_cost=5.009405851364136
Steps:   2%|▏         | 16215/1000000 [8:12:54<2911:16:19, 10.65s/it, lr=1e-5, step_loss=0.0065]Steps:   2%|▏         | 16216/1000000 [8:13:05<2931:59:05, 10.73s/it, lr=1e-5, step_loss=0.0065][RANK-0]: Step: [16216], local_loss=0.02009432204067707, train_loss=0.036338817328214645, time_cost=2.1217153072357178
Steps:   2%|▏         | 16216/1000000 [8:13:05<2931:59:05, 10.73s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 16217/1000000 [8:13:16<3009:41:35, 11.01s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [16217], local_loss=0.16642440855503082, train_loss=7.956238269805908, time_cost=2.2310476303100586
Steps:   2%|▏         | 16217/1000000 [8:13:16<3009:41:35, 11.01s/it, lr=1e-5, step_loss=0.166] Steps:   2%|▏         | 16218/1000000 [8:13:21<2513:10:08,  9.20s/it, lr=1e-5, step_loss=0.166][RANK-0]: Step: [16218], local_loss=0.009799142368137836, train_loss=0.024258363991975784, time_cost=2.0779154300689697
Steps:   2%|▏         | 16218/1000000 [8:13:21<2513:10:08,  9.20s/it, lr=1e-5, step_loss=0.0098]Steps:   2%|▏         | 16219/1000000 [8:13:34<2773:38:27, 10.15s/it, lr=1e-5, step_loss=0.0098][RANK-0]: Step: [16219], local_loss=0.040308479219675064, train_loss=0.2029668092727661, time_cost=10.445910453796387
Steps:   2%|▏         | 16219/1000000 [8:13:34<2773:38:27, 10.15s/it, lr=1e-5, step_loss=0.0403]Steps:   2%|▏         | 16220/1000000 [8:13:45<2919:52:26, 10.68s/it, lr=1e-5, step_loss=0.0403][RANK-0]: Step: [16220], local_loss=0.04048338532447815, train_loss=0.025581955909729004, time_cost=1.2003588676452637
Steps:   2%|▏         | 16220/1000000 [8:13:45<2919:52:26, 10.68s/it, lr=1e-5, step_loss=0.0405]Steps:   2%|▏         | 16221/1000000 [8:14:00<3206:06:38, 11.73s/it, lr=1e-5, step_loss=0.0405][RANK-0]: Step: [16221], local_loss=0.01161352638155222, train_loss=0.04301324486732483, time_cost=1.2285428047180176
Steps:   2%|▏         | 16221/1000000 [8:14:00<3206:06:38, 11.73s/it, lr=1e-5, step_loss=0.0116]Steps:   2%|▏         | 16222/1000000 [8:14:06<2799:22:47, 10.24s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [16222], local_loss=0.008980568498373032, train_loss=0.010467829182744026, time_cost=1.2581150531768799
Steps:   2%|▏         | 16222/1000000 [8:14:06<2799:22:47, 10.24s/it, lr=1e-5, step_loss=0.00898]Steps:   2%|▏         | 16223/1000000 [8:14:18<2921:03:58, 10.69s/it, lr=1e-5, step_loss=0.00898][RANK-0]: Step: [16223], local_loss=0.16211125254631042, train_loss=0.0809418335556984, time_cost=5.433661222457886
Steps:   2%|▏         | 16223/1000000 [8:14:18<2921:03:58, 10.69s/it, lr=1e-5, step_loss=0.162]  Steps:   2%|▏         | 16224/1000000 [8:14:30<3016:19:00, 11.04s/it, lr=1e-5, step_loss=0.162][RANK-0]: Step: [16224], local_loss=0.007149845361709595, train_loss=0.019405227154493332, time_cost=2.686945676803589
Steps:   2%|▏         | 16224/1000000 [8:14:30<3016:19:00, 11.04s/it, lr=1e-5, step_loss=0.00715]Steps:   2%|▏         | 16225/1000000 [8:14:39<2839:51:28, 10.39s/it, lr=1e-5, step_loss=0.00715][RANK-0]: Step: [16225], local_loss=0.02251666970551014, train_loss=0.029093459248542786, time_cost=2.937347888946533
Steps:   2%|▏         | 16225/1000000 [8:14:39<2839:51:28, 10.39s/it, lr=1e-5, step_loss=0.0225] Steps:   2%|▏         | 16226/1000000 [8:14:45<2453:26:17,  8.98s/it, lr=1e-5, step_loss=0.0225][RANK-0]: Step: [16226], local_loss=0.03797995671629906, train_loss=0.16895590722560883, time_cost=1.2851006984710693
Steps:   2%|▏         | 16226/1000000 [8:14:45<2453:26:17,  8.98s/it, lr=1e-5, step_loss=0.038] Steps:   2%|▏         | 16227/1000000 [8:14:50<2139:54:25,  7.83s/it, lr=1e-5, step_loss=0.038][RANK-0]: Step: [16227], local_loss=0.0930706113576889, train_loss=0.0831342414021492, time_cost=2.4418303966522217
Steps:   2%|▏         | 16227/1000000 [8:14:50<2139:54:25,  7.83s/it, lr=1e-5, step_loss=0.0931]Steps:   2%|▏         | 16228/1000000 [8:14:59<2248:20:50,  8.23s/it, lr=1e-5, step_loss=0.0931][RANK-0]: Step: [16228], local_loss=0.007623282261192799, train_loss=0.04063991457223892, time_cost=2.3360440731048584
Steps:   2%|▏         | 16228/1000000 [8:14:59<2248:20:50,  8.23s/it, lr=1e-5, step_loss=0.00762]Steps:   2%|▏         | 16229/1000000 [8:15:07<2232:59:09,  8.17s/it, lr=1e-5, step_loss=0.00762][RANK-0]: Step: [16229], local_loss=0.14765900373458862, train_loss=0.0484677255153656, time_cost=6.780579328536987
Steps:   2%|▏         | 16229/1000000 [8:15:07<2232:59:09,  8.17s/it, lr=1e-5, step_loss=0.148]  Steps:   2%|▏         | 16230/1000000 [8:15:11<1909:00:29,  6.99s/it, lr=1e-5, step_loss=0.148][RANK-0]: Step: [16230], local_loss=0.02146613970398903, train_loss=0.05414089560508728, time_cost=3.3033034801483154
Steps:   2%|▏         | 16230/1000000 [8:15:11<1909:00:29,  6.99s/it, lr=1e-5, step_loss=0.0215]Steps:   2%|▏         | 16231/1000000 [8:15:20<2040:45:32,  7.47s/it, lr=1e-5, step_loss=0.0215][RANK-0]: Step: [16231], local_loss=0.04866751655936241, train_loss=0.023180903866887093, time_cost=4.6070473194122314
Steps:   2%|▏         | 16231/1000000 [8:15:20<2040:45:32,  7.47s/it, lr=1e-5, step_loss=0.0487]Steps:   2%|▏         | 16232/1000000 [8:15:25<1874:09:52,  6.86s/it, lr=1e-5, step_loss=0.0487][RANK-0]: Step: [16232], local_loss=0.09022568166255951, train_loss=0.19540388882160187, time_cost=2.982661724090576
Steps:   2%|▏         | 16232/1000000 [8:15:25<1874:09:52,  6.86s/it, lr=1e-5, step_loss=0.0902]Steps:   2%|▏         | 16233/1000000 [8:15:34<2048:21:16,  7.50s/it, lr=1e-5, step_loss=0.0902][RANK-0]: Step: [16233], local_loss=0.054306760430336, train_loss=0.026559438556432724, time_cost=2.710963726043701
Steps:   2%|▏         | 16233/1000000 [8:15:34<2048:21:16,  7.50s/it, lr=1e-5, step_loss=0.0543]Steps:   2%|▏         | 16234/1000000 [8:15:41<1986:41:31,  7.27s/it, lr=1e-5, step_loss=0.0543][RANK-0]: Step: [16234], local_loss=0.027211982756853104, train_loss=0.0284663625061512, time_cost=1.2435176372528076
Steps:   2%|▏         | 16234/1000000 [8:15:41<1986:41:31,  7.27s/it, lr=1e-5, step_loss=0.0272]Steps:   2%|▏         | 16235/1000000 [8:15:51<2224:29:04,  8.14s/it, lr=1e-5, step_loss=0.0272][RANK-0]: Step: [16235], local_loss=0.046840593218803406, train_loss=0.04220768064260483, time_cost=7.914327383041382
Steps:   2%|▏         | 16235/1000000 [8:15:51<2224:29:04,  8.14s/it, lr=1e-5, step_loss=0.0468]Steps:   2%|▏         | 16236/1000000 [8:16:02<2422:21:06,  8.86s/it, lr=1e-5, step_loss=0.0468][RANK-0]: Step: [16236], local_loss=0.014866754412651062, train_loss=0.028396304696798325, time_cost=5.027791738510132
Steps:   2%|▏         | 16236/1000000 [8:16:02<2422:21:06,  8.86s/it, lr=1e-5, step_loss=0.0149]Steps:   2%|▏         | 16237/1000000 [8:16:06<2031:36:50,  7.43s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [16237], local_loss=0.006172048393636942, train_loss=0.011951969936490059, time_cost=1.3663063049316406
Steps:   2%|▏         | 16237/1000000 [8:16:06<2031:36:50,  7.43s/it, lr=1e-5, step_loss=0.00617]Steps:   2%|▏         | 16238/1000000 [8:16:13<2018:03:49,  7.38s/it, lr=1e-5, step_loss=0.00617][RANK-0]: Step: [16238], local_loss=0.05557180941104889, train_loss=0.04526548460125923, time_cost=3.132955312728882
Steps:   2%|▏         | 16238/1000000 [8:16:13<2018:03:49,  7.38s/it, lr=1e-5, step_loss=0.0556] Steps:   2%|▏         | 16239/1000000 [8:16:20<2005:14:43,  7.34s/it, lr=1e-5, step_loss=0.0556][RANK-0]: Step: [16239], local_loss=0.07823928445577621, train_loss=0.030377957969903946, time_cost=1.69901442527771
Steps:   2%|▏         | 16239/1000000 [8:16:20<2005:14:43,  7.34s/it, lr=1e-5, step_loss=0.0782]Steps:   2%|▏         | 16240/1000000 [8:16:25<1806:49:34,  6.61s/it, lr=1e-5, step_loss=0.0782][RANK-0]: Step: [16240], local_loss=0.01332998275756836, train_loss=0.05389130860567093, time_cost=1.9352812767028809
Steps:   2%|▏         | 16240/1000000 [8:16:25<1806:49:34,  6.61s/it, lr=1e-5, step_loss=0.0133]Steps:   2%|▏         | 16241/1000000 [8:16:33<1905:55:58,  6.97s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [16241], local_loss=0.05734735354781151, train_loss=0.022821184247732162, time_cost=3.8171374797821045
Steps:   2%|▏         | 16241/1000000 [8:16:33<1905:55:58,  6.97s/it, lr=1e-5, step_loss=0.0573]Steps:   2%|▏         | 16242/1000000 [8:16:47<2448:40:05,  8.96s/it, lr=1e-5, step_loss=0.0573][RANK-0]: Step: [16242], local_loss=0.007490672171115875, train_loss=0.04366576299071312, time_cost=5.48535680770874
Steps:   2%|▏         | 16242/1000000 [8:16:47<2448:40:05,  8.96s/it, lr=1e-5, step_loss=0.00749]Steps:   2%|▏         | 16243/1000000 [8:16:57<2583:06:51,  9.45s/it, lr=1e-5, step_loss=0.00749][RANK-0]: Step: [16243], local_loss=0.008398458361625671, train_loss=0.011572534218430519, time_cost=1.9798383712768555
Steps:   2%|▏         | 16243/1000000 [8:16:57<2583:06:51,  9.45s/it, lr=1e-5, step_loss=0.0084] Steps:   2%|▏         | 16244/1000000 [8:17:08<2695:42:52,  9.86s/it, lr=1e-5, step_loss=0.0084][RANK-0]: Step: [16244], local_loss=0.009695872664451599, train_loss=0.01208257395774126, time_cost=4.121385097503662
Steps:   2%|▏         | 16244/1000000 [8:17:08<2695:42:52,  9.86s/it, lr=1e-5, step_loss=0.0097]Steps:   2%|▏         | 16245/1000000 [8:17:13<2324:09:21,  8.51s/it, lr=1e-5, step_loss=0.0097][RANK-0]: Step: [16245], local_loss=0.029991041868925095, train_loss=0.05296558514237404, time_cost=1.6141431331634521
Steps:   2%|▏         | 16245/1000000 [8:17:13<2324:09:21,  8.51s/it, lr=1e-5, step_loss=0.03]  Steps:   2%|▏         | 16246/1000000 [8:17:21<2221:09:06,  8.13s/it, lr=1e-5, step_loss=0.03][RANK-0]: Step: [16246], local_loss=0.04918090999126434, train_loss=0.0662992000579834, time_cost=3.343940258026123
Steps:   2%|▏         | 16246/1000000 [8:17:21<2221:09:06,  8.13s/it, lr=1e-5, step_loss=0.0492]Steps:   2%|▏         | 16247/1000000 [8:17:34<2630:18:35,  9.63s/it, lr=1e-5, step_loss=0.0492][RANK-0]: Step: [16247], local_loss=0.038103312253952026, train_loss=0.052656177431344986, time_cost=1.2380664348602295
Steps:   2%|▏         | 16247/1000000 [8:17:34<2630:18:35,  9.63s/it, lr=1e-5, step_loss=0.0381]Steps:   2%|▏         | 16248/1000000 [8:17:45<2782:01:51, 10.18s/it, lr=1e-5, step_loss=0.0381][RANK-0]: Step: [16248], local_loss=0.09510349482297897, train_loss=0.03349257633090019, time_cost=1.6046013832092285
Steps:   2%|▏         | 16248/1000000 [8:17:45<2782:01:51, 10.18s/it, lr=1e-5, step_loss=0.0951]Steps:   2%|▏         | 16249/1000000 [8:17:58<3010:32:51, 11.02s/it, lr=1e-5, step_loss=0.0951][RANK-0]: Step: [16249], local_loss=0.028552962467074394, train_loss=0.02230142056941986, time_cost=4.5630552768707275
Steps:   2%|▏         | 16249/1000000 [8:17:58<3010:32:51, 11.02s/it, lr=1e-5, step_loss=0.0286]Steps:   2%|▏         | 16250/1000000 [8:18:06<2776:29:51, 10.16s/it, lr=1e-5, step_loss=0.0286][RANK-0]: Step: [16250], local_loss=0.028299633413553238, train_loss=0.0293828584253788, time_cost=1.211294174194336
Steps:   2%|▏         | 16250/1000000 [8:18:06<2776:29:51, 10.16s/it, lr=1e-5, step_loss=0.0283]Steps:   2%|▏         | 16251/1000000 [8:18:11<2311:45:04,  8.46s/it, lr=1e-5, step_loss=0.0283][RANK-0]: Step: [16251], local_loss=0.059631478041410446, train_loss=0.08618520200252533, time_cost=3.7416751384735107
Steps:   2%|▏         | 16251/1000000 [8:18:11<2311:45:04,  8.46s/it, lr=1e-5, step_loss=0.0596]Steps:   2%|▏         | 16252/1000000 [8:18:16<2051:46:33,  7.51s/it, lr=1e-5, step_loss=0.0596][RANK-0]: Step: [16252], local_loss=0.05101566016674042, train_loss=0.08151736110448837, time_cost=1.1924998760223389
Steps:   2%|▏         | 16252/1000000 [8:18:16<2051:46:33,  7.51s/it, lr=1e-5, step_loss=0.051] Steps:   2%|▏         | 16253/1000000 [8:18:31<2670:27:44,  9.77s/it, lr=1e-5, step_loss=0.051][RANK-0]: Step: [16253], local_loss=0.059121206402778625, train_loss=0.1003289520740509, time_cost=12.131463766098022
Steps:   2%|▏         | 16253/1000000 [8:18:31<2670:27:44,  9.77s/it, lr=1e-5, step_loss=0.0591]Steps:   2%|▏         | 16254/1000000 [8:18:39<2499:46:14,  9.15s/it, lr=1e-5, step_loss=0.0591][RANK-0]: Step: [16254], local_loss=0.057974085211753845, train_loss=0.0238355603069067, time_cost=1.4930918216705322
Steps:   2%|▏         | 16254/1000000 [8:18:39<2499:46:14,  9.15s/it, lr=1e-5, step_loss=0.058] Steps:   2%|▏         | 16255/1000000 [8:18:50<2664:13:44,  9.75s/it, lr=1e-5, step_loss=0.058][RANK-0]: Step: [16255], local_loss=0.008524262346327305, train_loss=0.05924597010016441, time_cost=1.9863901138305664
Steps:   2%|▏         | 16255/1000000 [8:18:50<2664:13:44,  9.75s/it, lr=1e-5, step_loss=0.00852]Steps:   2%|▏         | 16256/1000000 [8:18:54<2220:28:27,  8.13s/it, lr=1e-5, step_loss=0.00852][RANK-0]: Step: [16256], local_loss=0.0656329095363617, train_loss=0.018398266285657883, time_cost=2.5511085987091064
Steps:   2%|▏         | 16256/1000000 [8:18:54<2220:28:27,  8.13s/it, lr=1e-5, step_loss=0.0656] Steps:   2%|▏         | 16257/1000000 [8:19:00<2029:04:41,  7.43s/it, lr=1e-5, step_loss=0.0656][RANK-0]: Step: [16257], local_loss=0.021821029484272003, train_loss=0.0647263154387474, time_cost=2.9116439819335938
Steps:   2%|▏         | 16257/1000000 [8:19:00<2029:04:41,  7.43s/it, lr=1e-5, step_loss=0.0218]Steps:   2%|▏         | 16258/1000000 [8:19:11<2309:49:44,  8.45s/it, lr=1e-5, step_loss=0.0218][RANK-0]: Step: [16258], local_loss=0.6375991106033325, train_loss=0.15105710923671722, time_cost=2.6182775497436523
Steps:   2%|▏         | 16258/1000000 [8:19:11<2309:49:44,  8.45s/it, lr=1e-5, step_loss=0.638] Steps:   2%|▏         | 16259/1000000 [8:19:27<2915:51:19, 10.67s/it, lr=1e-5, step_loss=0.638][RANK-0]: Step: [16259], local_loss=0.007630772888660431, train_loss=0.0349951907992363, time_cost=7.652756929397583
Steps:   2%|▏         | 16259/1000000 [8:19:27<2915:51:19, 10.67s/it, lr=1e-5, step_loss=0.00763]Steps:   2%|▏         | 16260/1000000 [8:19:36<2832:04:11, 10.36s/it, lr=1e-5, step_loss=0.00763][RANK-0]: Step: [16260], local_loss=0.013547858223319054, train_loss=0.022161277011036873, time_cost=1.2000422477722168
Steps:   2%|▏         | 16260/1000000 [8:19:36<2832:04:11, 10.36s/it, lr=1e-5, step_loss=0.0135] Steps:   2%|▏         | 16261/1000000 [8:19:50<3073:35:16, 11.25s/it, lr=1e-5, step_loss=0.0135][RANK-0]: Step: [16261], local_loss=0.012668976560235023, train_loss=0.10310151427984238, time_cost=8.50753927230835
Steps:   2%|▏         | 16261/1000000 [8:19:50<3073:35:16, 11.25s/it, lr=1e-5, step_loss=0.0127]Steps:   2%|▏         | 16262/1000000 [8:20:03<3265:22:29, 11.95s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [16262], local_loss=0.08082126826047897, train_loss=0.030399808660149574, time_cost=2.16497802734375
Steps:   2%|▏         | 16262/1000000 [8:20:03<3265:22:29, 11.95s/it, lr=1e-5, step_loss=0.0808]Steps:   2%|▏         | 16263/1000000 [8:20:12<3035:39:41, 11.11s/it, lr=1e-5, step_loss=0.0808][RANK-0]: Step: [16263], local_loss=0.015858974307775497, train_loss=0.08453671634197235, time_cost=1.2191410064697266
Steps:   2%|▏         | 16263/1000000 [8:20:12<3035:39:41, 11.11s/it, lr=1e-5, step_loss=0.0159]Steps:   2%|▏         | 16264/1000000 [8:20:18<2558:12:20,  9.36s/it, lr=1e-5, step_loss=0.0159][RANK-0]: Step: [16264], local_loss=0.006694698706269264, train_loss=0.013507019728422165, time_cost=2.588317632675171
Steps:   2%|▏         | 16264/1000000 [8:20:18<2558:12:20,  9.36s/it, lr=1e-5, step_loss=0.00669]Steps:   2%|▏         | 16265/1000000 [8:20:25<2357:09:07,  8.63s/it, lr=1e-5, step_loss=0.00669][RANK-0]: Step: [16265], local_loss=0.0056586842983961105, train_loss=0.019988249987363815, time_cost=2.5250487327575684
Steps:   2%|▏         | 16265/1000000 [8:20:25<2357:09:07,  8.63s/it, lr=1e-5, step_loss=0.00566]Steps:   2%|▏         | 16266/1000000 [8:20:30<2081:54:54,  7.62s/it, lr=1e-5, step_loss=0.00566][RANK-0]: Step: [16266], local_loss=0.04453195258975029, train_loss=0.02569453790783882, time_cost=1.2597661018371582
Steps:   2%|▏         | 16266/1000000 [8:20:30<2081:54:54,  7.62s/it, lr=1e-5, step_loss=0.0445] Steps:   2%|▏         | 16267/1000000 [8:20:43<2561:02:34,  9.37s/it, lr=1e-5, step_loss=0.0445][RANK-0]: Step: [16267], local_loss=0.005891142413020134, train_loss=0.017012381926178932, time_cost=11.241079330444336
Steps:   2%|▏         | 16267/1000000 [8:20:43<2561:02:34,  9.37s/it, lr=1e-5, step_loss=0.00589]Steps:   2%|▏         | 16268/1000000 [8:20:49<2262:23:25,  8.28s/it, lr=1e-5, step_loss=0.00589][RANK-0]: Step: [16268], local_loss=0.007783017121255398, train_loss=0.07857038080692291, time_cost=1.3659305572509766
Steps:   2%|▏         | 16268/1000000 [8:20:49<2262:23:25,  8.28s/it, lr=1e-5, step_loss=0.00778]Steps:   2%|▏         | 16269/1000000 [8:21:04<2801:09:16, 10.25s/it, lr=1e-5, step_loss=0.00778][RANK-0]: Step: [16269], local_loss=0.005264237988740206, train_loss=0.03235989809036255, time_cost=6.763069152832031
Steps:   2%|▏         | 16269/1000000 [8:21:04<2801:09:16, 10.25s/it, lr=1e-5, step_loss=0.00526]Steps:   2%|▏         | 16270/1000000 [8:21:11<2562:29:17,  9.38s/it, lr=1e-5, step_loss=0.00526][RANK-0]: Step: [16270], local_loss=0.010237494483590126, train_loss=0.013171886093914509, time_cost=1.5777411460876465
Steps:   2%|▏         | 16270/1000000 [8:21:11<2562:29:17,  9.38s/it, lr=1e-5, step_loss=0.0102] Steps:   2%|▏         | 16271/1000000 [8:21:16<2206:20:33,  8.07s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [16271], local_loss=0.005711267702281475, train_loss=0.019376087933778763, time_cost=2.2562096118927
Steps:   2%|▏         | 16271/1000000 [8:21:16<2206:20:33,  8.07s/it, lr=1e-5, step_loss=0.00571]Steps:   2%|▏         | 16272/1000000 [8:21:21<1956:58:04,  7.16s/it, lr=1e-5, step_loss=0.00571][RANK-0]: Step: [16272], local_loss=0.009247425943613052, train_loss=0.07088156789541245, time_cost=2.171379327774048
Steps:   2%|▏         | 16272/1000000 [8:21:21<1956:58:04,  7.16s/it, lr=1e-5, step_loss=0.00925]Steps:   2%|▏         | 16273/1000000 [8:21:35<2465:44:47,  9.02s/it, lr=1e-5, step_loss=0.00925][RANK-0]: Step: [16273], local_loss=0.018233468756079674, train_loss=0.0657186210155487, time_cost=5.180114030838013
Steps:   2%|▏         | 16273/1000000 [8:21:35<2465:44:47,  9.02s/it, lr=1e-5, step_loss=0.0182] Steps:   2%|▏         | 16274/1000000 [8:21:40<2154:53:11,  7.89s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [16274], local_loss=0.018614575266838074, train_loss=0.021804653108119965, time_cost=1.5330467224121094
Steps:   2%|▏         | 16274/1000000 [8:21:40<2154:53:11,  7.89s/it, lr=1e-5, step_loss=0.0186]Steps:   2%|▏         | 16275/1000000 [8:21:45<1887:08:25,  6.91s/it, lr=1e-5, step_loss=0.0186][RANK-0]: Step: [16275], local_loss=0.020724110305309296, train_loss=0.029914505779743195, time_cost=2.136601448059082
Steps:   2%|▏         | 16275/1000000 [8:21:45<1887:08:25,  6.91s/it, lr=1e-5, step_loss=0.0207]Steps:   2%|▏         | 16276/1000000 [8:21:53<2048:37:34,  7.50s/it, lr=1e-5, step_loss=0.0207][RANK-0]: Step: [16276], local_loss=0.061850666999816895, train_loss=0.09525786340236664, time_cost=6.537730932235718
Steps:   2%|▏         | 16276/1000000 [8:21:53<2048:37:34,  7.50s/it, lr=1e-5, step_loss=0.0619]Steps:   2%|▏         | 16277/1000000 [8:22:01<2031:30:45,  7.43s/it, lr=1e-5, step_loss=0.0619][RANK-0]: Step: [16277], local_loss=0.0700884684920311, train_loss=0.06110945716500282, time_cost=3.608281135559082
Steps:   2%|▏         | 16277/1000000 [8:22:01<2031:30:45,  7.43s/it, lr=1e-5, step_loss=0.0701]Steps:   2%|▏         | 16278/1000000 [8:22:07<1903:29:57,  6.97s/it, lr=1e-5, step_loss=0.0701][RANK-0]: Step: [16278], local_loss=0.12101110070943832, train_loss=0.10379613935947418, time_cost=2.369347333908081
Steps:   2%|▏         | 16278/1000000 [8:22:07<1903:29:57,  6.97s/it, lr=1e-5, step_loss=0.121] Steps:   2%|▏         | 16279/1000000 [8:22:13<1830:25:10,  6.70s/it, lr=1e-5, step_loss=0.121][RANK-0]: Step: [16279], local_loss=1.0086370706558228, train_loss=0.18271978199481964, time_cost=1.8949320316314697
Steps:   2%|▏         | 16279/1000000 [8:22:13<1830:25:10,  6.70s/it, lr=1e-5, step_loss=1.01] Steps:   2%|▏         | 16280/1000000 [8:22:20<1913:29:35,  7.00s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [16280], local_loss=0.00917469896376133, train_loss=0.5234686732292175, time_cost=3.1776304244995117
Steps:   2%|▏         | 16280/1000000 [8:22:20<1913:29:35,  7.00s/it, lr=1e-5, step_loss=0.00917]Steps:   2%|▏         | 16281/1000000 [8:22:28<1927:10:11,  7.05s/it, lr=1e-5, step_loss=0.00917][RANK-0]: Step: [16281], local_loss=0.006368874106556177, train_loss=0.031555529683828354, time_cost=2.713548183441162
Steps:   2%|▏         | 16281/1000000 [8:22:28<1927:10:11,  7.05s/it, lr=1e-5, step_loss=0.00637]Steps:   2%|▏         | 16282/1000000 [8:22:39<2316:59:55,  8.48s/it, lr=1e-5, step_loss=0.00637][RANK-0]: Step: [16282], local_loss=0.013697408139705658, train_loss=0.03256148472428322, time_cost=3.0437889099121094
Steps:   2%|▏         | 16282/1000000 [8:22:39<2316:59:55,  8.48s/it, lr=1e-5, step_loss=0.0137] Steps:   2%|▏         | 16283/1000000 [8:22:45<2079:37:56,  7.61s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [16283], local_loss=0.009597459807991982, train_loss=0.03856891393661499, time_cost=1.5129477977752686
Steps:   2%|▏         | 16283/1000000 [8:22:45<2079:37:56,  7.61s/it, lr=1e-5, step_loss=0.0096]Steps:   2%|▏         | 16284/1000000 [8:22:53<2079:32:36,  7.61s/it, lr=1e-5, step_loss=0.0096][RANK-0]: Step: [16284], local_loss=0.008783344179391861, train_loss=0.046107422560453415, time_cost=3.932722330093384
Steps:   2%|▏         | 16284/1000000 [8:22:53<2079:32:36,  7.61s/it, lr=1e-5, step_loss=0.00878]Steps:   2%|▏         | 16285/1000000 [8:22:57<1845:25:41,  6.75s/it, lr=1e-5, step_loss=0.00878][RANK-0]: Step: [16285], local_loss=0.02005656436085701, train_loss=0.024728424847126007, time_cost=2.426783323287964
Steps:   2%|▏         | 16285/1000000 [8:22:57<1845:25:41,  6.75s/it, lr=1e-5, step_loss=0.0201] Steps:   2%|▏         | 16286/1000000 [8:23:06<2028:45:33,  7.42s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [16286], local_loss=0.03536229953169823, train_loss=0.03903356194496155, time_cost=2.539245128631592
Steps:   2%|▏         | 16286/1000000 [8:23:06<2028:45:33,  7.42s/it, lr=1e-5, step_loss=0.0354]Steps:   2%|▏         | 16287/1000000 [8:23:16<2225:00:39,  8.14s/it, lr=1e-5, step_loss=0.0354][RANK-0]: Step: [16287], local_loss=173.03712463378906, train_loss=21.71043586730957, time_cost=1.5119273662567139
Steps:   2%|▏         | 16287/1000000 [8:23:16<2225:00:39,  8.14s/it, lr=1e-5, step_loss=173]   Steps:   2%|▏         | 16288/1000000 [8:23:32<2832:34:52, 10.37s/it, lr=1e-5, step_loss=173][RANK-0]: Step: [16288], local_loss=0.008396080695092678, train_loss=0.021953241899609566, time_cost=6.690174341201782
Steps:   2%|▏         | 16288/1000000 [8:23:32<2832:34:52, 10.37s/it, lr=1e-5, step_loss=0.0084]Steps:   2%|▏         | 16289/1000000 [8:23:39<2551:25:19,  9.34s/it, lr=1e-5, step_loss=0.0084][RANK-0]: Step: [16289], local_loss=0.021395741030573845, train_loss=0.0825282633304596, time_cost=2.671022891998291
Steps:   2%|▏         | 16289/1000000 [8:23:39<2551:25:19,  9.34s/it, lr=1e-5, step_loss=0.0214]Steps:   2%|▏         | 16290/1000000 [8:23:46<2402:57:52,  8.79s/it, lr=1e-5, step_loss=0.0214][RANK-0]: Step: [16290], local_loss=0.19810238480567932, train_loss=0.048876430839300156, time_cost=1.254192590713501
Steps:   2%|▏         | 16290/1000000 [8:23:46<2402:57:52,  8.79s/it, lr=1e-5, step_loss=0.198] Steps:   2%|▏         | 16291/1000000 [8:23:56<2527:49:14,  9.25s/it, lr=1e-5, step_loss=0.198][RANK-0]: Step: [16291], local_loss=0.006151349283754826, train_loss=0.03830733522772789, time_cost=5.460903882980347
Steps:   2%|▏         | 16291/1000000 [8:23:57<2527:49:14,  9.25s/it, lr=1e-5, step_loss=0.00615]Steps:   2%|▏         | 16292/1000000 [8:24:09<2832:57:08, 10.37s/it, lr=1e-5, step_loss=0.00615][RANK-0]: Step: [16292], local_loss=0.2110530138015747, train_loss=0.04524511098861694, time_cost=4.520288944244385
Steps:   2%|▏         | 16292/1000000 [8:24:09<2832:57:08, 10.37s/it, lr=1e-5, step_loss=0.211]  Steps:   2%|▏         | 16293/1000000 [8:24:14<2387:00:32,  8.74s/it, lr=1e-5, step_loss=0.211][RANK-0]: Step: [16293], local_loss=0.22672419250011444, train_loss=0.05536175146698952, time_cost=1.2234351634979248
Steps:   2%|▏         | 16293/1000000 [8:24:14<2387:00:32,  8.74s/it, lr=1e-5, step_loss=0.227]Steps:   2%|▏         | 16294/1000000 [8:24:20<2148:28:32,  7.86s/it, lr=1e-5, step_loss=0.227][RANK-0]: Step: [16294], local_loss=0.2536846697330475, train_loss=0.12829305231571198, time_cost=1.4076597690582275
Steps:   2%|▏         | 16294/1000000 [8:24:20<2148:28:32,  7.86s/it, lr=1e-5, step_loss=0.254]Steps:   2%|▏         | 16295/1000000 [8:24:26<1981:21:51,  7.25s/it, lr=1e-5, step_loss=0.254][RANK-0]: Step: [16295], local_loss=0.02800188586115837, train_loss=0.05888974666595459, time_cost=1.3546226024627686
Steps:   2%|▏         | 16295/1000000 [8:24:26<1981:21:51,  7.25s/it, lr=1e-5, step_loss=0.028]Steps:   2%|▏         | 16296/1000000 [8:24:35<2084:05:28,  7.63s/it, lr=1e-5, step_loss=0.028][RANK-0]: Step: [16296], local_loss=0.03337905555963516, train_loss=0.06548244506120682, time_cost=2.0619280338287354
Steps:   2%|▏         | 16296/1000000 [8:24:35<2084:05:28,  7.63s/it, lr=1e-5, step_loss=0.0334]Steps:   2%|▏         | 16297/1000000 [8:24:46<2375:20:12,  8.69s/it, lr=1e-5, step_loss=0.0334][RANK-0]: Step: [16297], local_loss=0.08784934878349304, train_loss=0.05071385204792023, time_cost=3.825437307357788
Steps:   2%|▏         | 16297/1000000 [8:24:46<2375:20:12,  8.69s/it, lr=1e-5, step_loss=0.0878]Steps:   2%|▏         | 16298/1000000 [8:24:56<2486:48:46,  9.10s/it, lr=1e-5, step_loss=0.0878][RANK-0]: Step: [16298], local_loss=0.02590484730899334, train_loss=0.04034776985645294, time_cost=2.028461456298828
Steps:   2%|▏         | 16298/1000000 [8:24:56<2486:48:46,  9.10s/it, lr=1e-5, step_loss=0.0259]Steps:   2%|▏         | 16299/1000000 [8:25:05<2535:10:53,  9.28s/it, lr=1e-5, step_loss=0.0259][RANK-0]: Step: [16299], local_loss=0.022210758179426193, train_loss=0.015197718515992165, time_cost=3.630764961242676
Steps:   2%|▏         | 16299/1000000 [8:25:05<2535:10:53,  9.28s/it, lr=1e-5, step_loss=0.0222]Steps:   2%|▏         | 16300/1000000 [8:25:15<2585:59:48,  9.46s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [16300], local_loss=0.03825997933745384, train_loss=0.042403168976306915, time_cost=1.2520573139190674
Steps:   2%|▏         | 16300/1000000 [8:25:15<2585:59:48,  9.46s/it, lr=1e-5, step_loss=0.0383]Steps:   2%|▏         | 16301/1000000 [8:25:27<2747:40:35, 10.06s/it, lr=1e-5, step_loss=0.0383][RANK-0]: Step: [16301], local_loss=0.006004200782626867, train_loss=0.02167215384542942, time_cost=2.1277763843536377
Steps:   2%|▏         | 16301/1000000 [8:25:27<2747:40:35, 10.06s/it, lr=1e-5, step_loss=0.006] Steps:   2%|▏         | 16302/1000000 [8:25:45<3419:15:56, 12.51s/it, lr=1e-5, step_loss=0.006][RANK-0]: Step: [16302], local_loss=0.02555377036333084, train_loss=0.013178940862417221, time_cost=14.120150804519653
Steps:   2%|▏         | 16302/1000000 [8:25:45<3419:15:56, 12.51s/it, lr=1e-5, step_loss=0.0256]Steps:   2%|▏         | 16303/1000000 [8:25:51<2875:13:44, 10.52s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [16303], local_loss=0.004684941843152046, train_loss=0.1046864464879036, time_cost=2.6593542098999023
Steps:   2%|▏         | 16303/1000000 [8:25:51<2875:13:44, 10.52s/it, lr=1e-5, step_loss=0.00468]Steps:   2%|▏         | 16304/1000000 [8:26:09<3508:55:46, 12.84s/it, lr=1e-5, step_loss=0.00468][RANK-0]: Step: [16304], local_loss=0.013022739440202713, train_loss=0.049461618065834045, time_cost=9.364108800888062
Steps:   2%|▏         | 16304/1000000 [8:26:09<3508:55:46, 12.84s/it, lr=1e-5, step_loss=0.013]  Steps:   2%|▏         | 16305/1000000 [8:26:15<2907:24:00, 10.64s/it, lr=1e-5, step_loss=0.013][RANK-0]: Step: [16305], local_loss=0.01870802603662014, train_loss=0.0175691619515419, time_cost=1.4825618267059326
Steps:   2%|▏         | 16305/1000000 [8:26:15<2907:24:00, 10.64s/it, lr=1e-5, step_loss=0.0187]Steps:   2%|▏         | 16306/1000000 [8:26:20<2476:37:22,  9.06s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [16306], local_loss=0.030271029099822044, train_loss=0.021751388907432556, time_cost=2.3655669689178467
Steps:   2%|▏         | 16306/1000000 [8:26:20<2476:37:22,  9.06s/it, lr=1e-5, step_loss=0.0303]Steps:   2%|▏         | 16307/1000000 [8:26:32<2698:10:09,  9.87s/it, lr=1e-5, step_loss=0.0303][RANK-0]: Step: [16307], local_loss=0.010165074840188026, train_loss=0.06591024994850159, time_cost=4.72066330909729
Steps:   2%|▏         | 16307/1000000 [8:26:32<2698:10:09,  9.87s/it, lr=1e-5, step_loss=0.0102]Steps:   2%|▏         | 16308/1000000 [8:26:43<2789:27:45, 10.21s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [16308], local_loss=0.19833125174045563, train_loss=0.03961179405450821, time_cost=2.077789783477783
Steps:   2%|▏         | 16308/1000000 [8:26:43<2789:27:45, 10.21s/it, lr=1e-5, step_loss=0.198] Steps:   2%|▏         | 16309/1000000 [8:26:56<2997:32:42, 10.97s/it, lr=1e-5, step_loss=0.198][RANK-0]: Step: [16309], local_loss=0.026715552434325218, train_loss=0.023047056049108505, time_cost=6.072768449783325
Steps:   2%|▏         | 16309/1000000 [8:26:56<2997:32:42, 10.97s/it, lr=1e-5, step_loss=0.0267]Steps:   2%|▏         | 16310/1000000 [8:27:10<3311:09:07, 12.12s/it, lr=1e-5, step_loss=0.0267][RANK-0]: Step: [16310], local_loss=0.06672067195177078, train_loss=0.12476707249879837, time_cost=4.388011455535889
Steps:   2%|▏         | 16310/1000000 [8:27:10<3311:09:07, 12.12s/it, lr=1e-5, step_loss=0.0667]Steps:   2%|▏         | 16311/1000000 [8:27:16<2757:06:35, 10.09s/it, lr=1e-5, step_loss=0.0667][RANK-0]: Step: [16311], local_loss=0.012853960506618023, train_loss=0.05767136439681053, time_cost=3.5075201988220215
Steps:   2%|▏         | 16311/1000000 [8:27:16<2757:06:35, 10.09s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 16312/1000000 [8:27:28<2943:18:48, 10.77s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [16312], local_loss=0.021730955690145493, train_loss=0.036956705152988434, time_cost=5.36488676071167
Steps:   2%|▏         | 16312/1000000 [8:27:28<2943:18:48, 10.77s/it, lr=1e-5, step_loss=0.0217]Steps:   2%|▏         | 16313/1000000 [8:27:38<2850:39:06, 10.43s/it, lr=1e-5, step_loss=0.0217][RANK-0]: Step: [16313], local_loss=0.10140281915664673, train_loss=0.06012038141489029, time_cost=4.092281103134155
Steps:   2%|▏         | 16313/1000000 [8:27:38<2850:39:06, 10.43s/it, lr=1e-5, step_loss=0.101] Steps:   2%|▏         | 16314/1000000 [8:27:42<2366:41:12,  8.66s/it, lr=1e-5, step_loss=0.101][RANK-0]: Step: [16314], local_loss=0.04995046183466911, train_loss=0.09695897996425629, time_cost=2.188425064086914
Steps:   2%|▏         | 16314/1000000 [8:27:42<2366:41:12,  8.66s/it, lr=1e-5, step_loss=0.05] Steps:   2%|▏         | 16315/1000000 [8:27:48<2126:59:47,  7.78s/it, lr=1e-5, step_loss=0.05][RANK-0]: Step: [16315], local_loss=0.010860607028007507, train_loss=0.03794602304697037, time_cost=4.756969690322876
Steps:   2%|▏         | 16315/1000000 [8:27:48<2126:59:47,  7.78s/it, lr=1e-5, step_loss=0.0109]Steps:   2%|▏         | 16316/1000000 [8:28:04<2762:39:54, 10.11s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [16316], local_loss=0.03769785165786743, train_loss=0.04806821793317795, time_cost=6.273519277572632
Steps:   2%|▏         | 16316/1000000 [8:28:04<2762:39:54, 10.11s/it, lr=1e-5, step_loss=0.0377]Steps:   2%|▏         | 16317/1000000 [8:28:09<2361:48:06,  8.64s/it, lr=1e-5, step_loss=0.0377][RANK-0]: Step: [16317], local_loss=0.00440060393884778, train_loss=30.3089542388916, time_cost=3.381425619125366
Steps:   2%|▏         | 16317/1000000 [8:28:09<2361:48:06,  8.64s/it, lr=1e-5, step_loss=0.0044]Steps:   2%|▏         | 16318/1000000 [8:28:14<2080:03:42,  7.61s/it, lr=1e-5, step_loss=0.0044][RANK-0]: Step: [16318], local_loss=0.019424021244049072, train_loss=0.026608049869537354, time_cost=2.321887254714966
Steps:   2%|▏         | 16318/1000000 [8:28:14<2080:03:42,  7.61s/it, lr=1e-5, step_loss=0.0194]Steps:   2%|▏         | 16319/1000000 [8:28:28<2644:50:04,  9.68s/it, lr=1e-5, step_loss=0.0194][RANK-0]: Step: [16319], local_loss=0.09311150759458542, train_loss=0.03508780896663666, time_cost=6.41839337348938
Steps:   2%|▏         | 16319/1000000 [8:28:28<2644:50:04,  9.68s/it, lr=1e-5, step_loss=0.0931]Steps:   2%|▏         | 16320/1000000 [8:28:41<2901:35:59, 10.62s/it, lr=1e-5, step_loss=0.0931][RANK-0]: Step: [16320], local_loss=0.00962396152317524, train_loss=0.017382699996232986, time_cost=1.210050106048584
Steps:   2%|▏         | 16320/1000000 [8:28:41<2901:35:59, 10.62s/it, lr=1e-5, step_loss=0.00962]Steps:   2%|▏         | 16321/1000000 [8:28:52<2923:04:30, 10.70s/it, lr=1e-5, step_loss=0.00962][RANK-0]: Step: [16321], local_loss=0.015916580334305763, train_loss=0.06599441915750504, time_cost=2.5817084312438965
Steps:   2%|▏         | 16321/1000000 [8:28:52<2923:04:30, 10.70s/it, lr=1e-5, step_loss=0.0159] Steps:   2%|▏         | 16322/1000000 [8:29:04<3018:34:26, 11.05s/it, lr=1e-5, step_loss=0.0159][RANK-0]: Step: [16322], local_loss=0.004011302255094051, train_loss=0.014671145007014275, time_cost=4.3017497062683105
Steps:   2%|▏         | 16322/1000000 [8:29:04<3018:34:26, 11.05s/it, lr=1e-5, step_loss=0.00401]Steps:   2%|▏         | 16323/1000000 [8:29:10<2571:52:03,  9.41s/it, lr=1e-5, step_loss=0.00401][RANK-0]: Step: [16323], local_loss=0.04607035964727402, train_loss=0.08169276267290115, time_cost=1.4296250343322754
Steps:   2%|▏         | 16323/1000000 [8:29:10<2571:52:03,  9.41s/it, lr=1e-5, step_loss=0.0461] Steps:   2%|▏         | 16324/1000000 [8:29:23<2884:14:00, 10.56s/it, lr=1e-5, step_loss=0.0461][RANK-0]: Step: [16324], local_loss=0.046433765441179276, train_loss=0.0807323008775711, time_cost=9.838215351104736
Steps:   2%|▏         | 16324/1000000 [8:29:23<2884:14:00, 10.56s/it, lr=1e-5, step_loss=0.0464]Steps:   2%|▏         | 16325/1000000 [8:29:28<2428:00:03,  8.89s/it, lr=1e-5, step_loss=0.0464][RANK-0]: Step: [16325], local_loss=0.039987556636333466, train_loss=0.05093516409397125, time_cost=2.2465462684631348
Steps:   2%|▏         | 16325/1000000 [8:29:28<2428:00:03,  8.89s/it, lr=1e-5, step_loss=0.04]  Steps:   2%|▏         | 16326/1000000 [8:29:39<2616:00:50,  9.57s/it, lr=1e-5, step_loss=0.04][RANK-0]: Step: [16326], local_loss=0.00913882628083229, train_loss=0.0232500322163105, time_cost=3.32580828666687
Steps:   2%|▏         | 16326/1000000 [8:29:39<2616:00:50,  9.57s/it, lr=1e-5, step_loss=0.00914]Steps:   2%|▏         | 16327/1000000 [8:29:46<2424:09:20,  8.87s/it, lr=1e-5, step_loss=0.00914][RANK-0]: Step: [16327], local_loss=0.275328129529953, train_loss=0.05477086082100868, time_cost=3.207131862640381
Steps:   2%|▏         | 16327/1000000 [8:29:46<2424:09:20,  8.87s/it, lr=1e-5, step_loss=0.275]  Steps:   2%|▏         | 16328/1000000 [8:30:01<2905:22:06, 10.63s/it, lr=1e-5, step_loss=0.275][RANK-0]: Step: [16328], local_loss=0.02386535331606865, train_loss=0.09110917150974274, time_cost=5.764255523681641
Steps:   2%|▏         | 16328/1000000 [8:30:01<2905:22:06, 10.63s/it, lr=1e-5, step_loss=0.0239]Steps:   2%|▏         | 16329/1000000 [8:30:07<2537:51:49,  9.29s/it, lr=1e-5, step_loss=0.0239][RANK-0]: Step: [16329], local_loss=0.03300445154309273, train_loss=0.04367019236087799, time_cost=2.5538406372070312
Steps:   2%|▏         | 16329/1000000 [8:30:07<2537:51:49,  9.29s/it, lr=1e-5, step_loss=0.033] Steps:   2%|▏         | 16330/1000000 [8:30:20<2842:44:24, 10.40s/it, lr=1e-5, step_loss=0.033][RANK-0]: Step: [16330], local_loss=0.009068777784705162, train_loss=0.029125692322850227, time_cost=5.3387131690979
Steps:   2%|▏         | 16330/1000000 [8:30:20<2842:44:24, 10.40s/it, lr=1e-5, step_loss=0.00907]Steps:   2%|▏         | 16331/1000000 [8:30:33<3056:56:17, 11.19s/it, lr=1e-5, step_loss=0.00907][RANK-0]: Step: [16331], local_loss=0.00461122952401638, train_loss=0.05456282198429108, time_cost=11.099251747131348
Steps:   2%|▏         | 16331/1000000 [8:30:33<3056:56:17, 11.19s/it, lr=1e-5, step_loss=0.00461]Steps:   2%|▏         | 16332/1000000 [8:30:39<2582:30:49,  9.45s/it, lr=1e-5, step_loss=0.00461][RANK-0]: Step: [16332], local_loss=0.03399011865258217, train_loss=0.02184608019888401, time_cost=1.5770950317382812
Steps:   2%|▏         | 16332/1000000 [8:30:39<2582:30:49,  9.45s/it, lr=1e-5, step_loss=0.034]  Steps:   2%|▏         | 16333/1000000 [8:30:46<2418:37:03,  8.85s/it, lr=1e-5, step_loss=0.034][RANK-0]: Step: [16333], local_loss=0.11922744661569595, train_loss=0.06906694918870926, time_cost=1.210371971130371
Steps:   2%|▏         | 16333/1000000 [8:30:46<2418:37:03,  8.85s/it, lr=1e-5, step_loss=0.119]Steps:   2%|▏         | 16334/1000000 [8:30:53<2258:29:43,  8.27s/it, lr=1e-5, step_loss=0.119][RANK-0]: Step: [16334], local_loss=0.04945388063788414, train_loss=0.030323540791869164, time_cost=5.641228199005127
Steps:   2%|▏         | 16334/1000000 [8:30:53<2258:29:43,  8.27s/it, lr=1e-5, step_loss=0.0495]Steps:   2%|▏         | 16335/1000000 [8:30:58<1993:08:48,  7.29s/it, lr=1e-5, step_loss=0.0495][RANK-0]: Step: [16335], local_loss=0.16343745589256287, train_loss=0.041261956095695496, time_cost=2.0450901985168457
Steps:   2%|▏         | 16335/1000000 [8:30:58<1993:08:48,  7.29s/it, lr=1e-5, step_loss=0.163] Steps:   2%|▏         | 16336/1000000 [8:31:03<1817:36:33,  6.65s/it, lr=1e-5, step_loss=0.163][RANK-0]: Step: [16336], local_loss=0.03993499279022217, train_loss=0.0266430601477623, time_cost=2.068335771560669
Steps:   2%|▏         | 16336/1000000 [8:31:03<1817:36:33,  6.65s/it, lr=1e-5, step_loss=0.0399]Steps:   2%|▏         | 16337/1000000 [8:31:10<1863:55:38,  6.82s/it, lr=1e-5, step_loss=0.0399][RANK-0]: Step: [16337], local_loss=0.0289632398635149, train_loss=0.04715466499328613, time_cost=1.8829505443572998
Steps:   2%|▏         | 16337/1000000 [8:31:10<1863:55:38,  6.82s/it, lr=1e-5, step_loss=0.029] Steps:   2%|▏         | 16338/1000000 [8:31:20<2132:40:50,  7.81s/it, lr=1e-5, step_loss=0.029][RANK-0]: Step: [16338], local_loss=0.3196236789226532, train_loss=23.897668838500977, time_cost=7.348984718322754
Steps:   2%|▏         | 16338/1000000 [8:31:20<2132:40:50,  7.81s/it, lr=1e-5, step_loss=0.32] Steps:   2%|▏         | 16339/1000000 [8:31:32<2421:07:41,  8.86s/it, lr=1e-5, step_loss=0.32][RANK-0]: Step: [16339], local_loss=0.12228230386972427, train_loss=0.11708398163318634, time_cost=2.2119061946868896
Steps:   2%|▏         | 16339/1000000 [8:31:32<2421:07:41,  8.86s/it, lr=1e-5, step_loss=0.122]Steps:   2%|▏         | 16340/1000000 [8:31:47<2974:03:38, 10.88s/it, lr=1e-5, step_loss=0.122][RANK-0]: Step: [16340], local_loss=0.009873231872916222, train_loss=0.01807982660830021, time_cost=4.958331108093262
Steps:   2%|▏         | 16340/1000000 [8:31:47<2974:03:38, 10.88s/it, lr=1e-5, step_loss=0.00987]Steps:   2%|▏         | 16341/1000000 [8:32:00<3154:14:05, 11.54s/it, lr=1e-5, step_loss=0.00987][RANK-0]: Step: [16341], local_loss=0.04003988206386566, train_loss=0.017088163644075394, time_cost=3.5594594478607178
Steps:   2%|▏         | 16341/1000000 [8:32:00<3154:14:05, 11.54s/it, lr=1e-5, step_loss=0.04]   Steps:   2%|▏         | 16342/1000000 [8:32:07<2772:12:33, 10.15s/it, lr=1e-5, step_loss=0.04][RANK-0]: Step: [16342], local_loss=0.00617974903434515, train_loss=0.017525775358080864, time_cost=2.3657217025756836
Steps:   2%|▏         | 16342/1000000 [8:32:07<2772:12:33, 10.15s/it, lr=1e-5, step_loss=0.00618]Steps:   2%|▏         | 16343/1000000 [8:32:18<2801:28:55, 10.25s/it, lr=1e-5, step_loss=0.00618][RANK-0]: Step: [16343], local_loss=0.030453696846961975, train_loss=0.028081055730581284, time_cost=2.279592275619507
Steps:   2%|▏         | 16343/1000000 [8:32:18<2801:28:55, 10.25s/it, lr=1e-5, step_loss=0.0305] Steps:   2%|▏         | 16344/1000000 [8:32:31<3033:19:41, 11.10s/it, lr=1e-5, step_loss=0.0305][RANK-0]: Step: [16344], local_loss=0.0068704113364219666, train_loss=0.04911604896187782, time_cost=5.324316740036011
Steps:   2%|▏         | 16344/1000000 [8:32:31<3033:19:41, 11.10s/it, lr=1e-5, step_loss=0.00687]Steps:   2%|▏         | 16345/1000000 [8:32:40<2897:21:39, 10.60s/it, lr=1e-5, step_loss=0.00687][RANK-0]: Step: [16345], local_loss=0.027690904214978218, train_loss=0.03752637654542923, time_cost=3.25758957862854
Steps:   2%|▏         | 16345/1000000 [8:32:40<2897:21:39, 10.60s/it, lr=1e-5, step_loss=0.0277] Steps:   2%|▏         | 16346/1000000 [8:32:54<3115:37:23, 11.40s/it, lr=1e-5, step_loss=0.0277][RANK-0]: Step: [16346], local_loss=0.006439856253564358, train_loss=0.03456380218267441, time_cost=5.18225622177124
Steps:   2%|▏         | 16346/1000000 [8:32:54<3115:37:23, 11.40s/it, lr=1e-5, step_loss=0.00644]Steps:   2%|▏         | 16347/1000000 [8:32:58<2541:37:04,  9.30s/it, lr=1e-5, step_loss=0.00644][RANK-0]: Step: [16347], local_loss=0.005998147651553154, train_loss=0.0177755244076252, time_cost=1.5554523468017578
Steps:   2%|▏         | 16347/1000000 [8:32:58<2541:37:04,  9.30s/it, lr=1e-5, step_loss=0.006]  Steps:   2%|▏         | 16348/1000000 [8:33:09<2678:28:18,  9.80s/it, lr=1e-5, step_loss=0.006][RANK-0]: Step: [16348], local_loss=29.61203384399414, train_loss=3.729414224624634, time_cost=4.7807536125183105
Steps:   2%|▏         | 16348/1000000 [8:33:09<2678:28:18,  9.80s/it, lr=1e-5, step_loss=29.6] Steps:   2%|▏         | 16349/1000000 [8:33:15<2365:04:16,  8.66s/it, lr=1e-5, step_loss=29.6][RANK-0]: Step: [16349], local_loss=0.013554524630308151, train_loss=0.025349948555231094, time_cost=1.6897027492523193
Steps:   2%|▏         | 16349/1000000 [8:33:15<2365:04:16,  8.66s/it, lr=1e-5, step_loss=0.0136]Steps:   2%|▏         | 16350/1000000 [8:33:19<2015:40:37,  7.38s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [16350], local_loss=0.028057841584086418, train_loss=0.06916572898626328, time_cost=1.4948184490203857
Steps:   2%|▏         | 16350/1000000 [8:33:19<2015:40:37,  7.38s/it, lr=1e-5, step_loss=0.0281]Steps:   2%|▏         | 16351/1000000 [8:33:30<2263:06:48,  8.28s/it, lr=1e-5, step_loss=0.0281][RANK-0]: Step: [16351], local_loss=0.004305724054574966, train_loss=0.030343255028128624, time_cost=5.280041694641113
Steps:   2%|▏         | 16351/1000000 [8:33:30<2263:06:48,  8.28s/it, lr=1e-5, step_loss=0.00431]Steps:   2%|▏         | 16352/1000000 [8:33:37<2142:55:25,  7.84s/it, lr=1e-5, step_loss=0.00431][RANK-0]: Step: [16352], local_loss=0.010627402924001217, train_loss=0.028649600222706795, time_cost=2.583425760269165
Steps:   2%|▏         | 16352/1000000 [8:33:37<2142:55:25,  7.84s/it, lr=1e-5, step_loss=0.0106] Steps:   2%|▏         | 16353/1000000 [8:33:43<2016:28:43,  7.38s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [16353], local_loss=0.01213052123785019, train_loss=0.021763764321804047, time_cost=5.289847373962402
Steps:   2%|▏         | 16353/1000000 [8:33:43<2016:28:43,  7.38s/it, lr=1e-5, step_loss=0.0121]Steps:   2%|▏         | 16354/1000000 [8:33:48<1832:28:51,  6.71s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [16354], local_loss=0.11814525723457336, train_loss=0.09283547103404999, time_cost=1.5670952796936035
Steps:   2%|▏         | 16354/1000000 [8:33:48<1832:28:51,  6.71s/it, lr=1e-5, step_loss=0.118] Steps:   2%|▏         | 16355/1000000 [8:34:01<2378:56:21,  8.71s/it, lr=1e-5, step_loss=0.118][RANK-0]: Step: [16355], local_loss=0.0048865447752177715, train_loss=0.04494182765483856, time_cost=1.2138354778289795
Steps:   2%|▏         | 16355/1000000 [8:34:01<2378:56:21,  8.71s/it, lr=1e-5, step_loss=0.00489]Steps:   2%|▏         | 16356/1000000 [8:34:15<2804:09:21, 10.26s/it, lr=1e-5, step_loss=0.00489][RANK-0]: Step: [16356], local_loss=0.005888908635824919, train_loss=0.02304537408053875, time_cost=4.743710041046143
Steps:   2%|▏         | 16356/1000000 [8:34:15<2804:09:21, 10.26s/it, lr=1e-5, step_loss=0.00589]Steps:   2%|▏         | 16357/1000000 [8:34:20<2374:33:14,  8.69s/it, lr=1e-5, step_loss=0.00589][RANK-0]: Step: [16357], local_loss=0.01745946891605854, train_loss=0.04795273393392563, time_cost=1.983949899673462
Steps:   2%|▏         | 16357/1000000 [8:34:20<2374:33:14,  8.69s/it, lr=1e-5, step_loss=0.0175] Steps:   2%|▏         | 16358/1000000 [8:34:28<2281:21:54,  8.35s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [16358], local_loss=0.049197595566511154, train_loss=0.0686878114938736, time_cost=3.8448293209075928
Steps:   2%|▏         | 16358/1000000 [8:34:28<2281:21:54,  8.35s/it, lr=1e-5, step_loss=0.0492]Steps:   2%|▏         | 16359/1000000 [8:34:32<1938:57:52,  7.10s/it, lr=1e-5, step_loss=0.0492][RANK-0]: Step: [16359], local_loss=0.060842663049697876, train_loss=0.1779198944568634, time_cost=1.344482183456421
Steps:   2%|▏         | 16359/1000000 [8:34:32<1938:57:52,  7.10s/it, lr=1e-5, step_loss=0.0608]Steps:   2%|▏         | 16360/1000000 [8:34:41<2114:21:04,  7.74s/it, lr=1e-5, step_loss=0.0608][RANK-0]: Step: [16360], local_loss=1.0070371627807617, train_loss=0.17327597737312317, time_cost=1.677609920501709
Steps:   2%|▏         | 16360/1000000 [8:34:41<2114:21:04,  7.74s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 16361/1000000 [8:34:54<2530:36:33,  9.26s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [16361], local_loss=0.0067772818729281425, train_loss=0.025894267484545708, time_cost=3.111534357070923
Steps:   2%|▏         | 16361/1000000 [8:34:54<2530:36:33,  9.26s/it, lr=1e-5, step_loss=0.00678]Steps:   2%|▏         | 16362/1000000 [8:35:01<2331:28:45,  8.53s/it, lr=1e-5, step_loss=0.00678][RANK-0]: Step: [16362], local_loss=0.016748569905757904, train_loss=0.027199571952223778, time_cost=2.583500385284424
Steps:   2%|▏         | 16362/1000000 [8:35:01<2331:28:45,  8.53s/it, lr=1e-5, step_loss=0.0167] Steps:   2%|▏         | 16363/1000000 [8:35:08<2200:55:26,  8.06s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [16363], local_loss=0.029181256890296936, train_loss=0.01895926520228386, time_cost=1.364109754562378
Steps:   2%|▏         | 16363/1000000 [8:35:08<2200:55:26,  8.06s/it, lr=1e-5, step_loss=0.0292]Steps:   2%|▏         | 16364/1000000 [8:35:15<2109:00:00,  7.72s/it, lr=1e-5, step_loss=0.0292][RANK-0]: Step: [16364], local_loss=0.014010285027325153, train_loss=0.05249227583408356, time_cost=2.335283041000366
Steps:   2%|▏         | 16364/1000000 [8:35:15<2109:00:00,  7.72s/it, lr=1e-5, step_loss=0.014] Steps:   2%|▏         | 16365/1000000 [8:35:19<1840:19:19,  6.74s/it, lr=1e-5, step_loss=0.014][RANK-0]: Step: [16365], local_loss=0.09734698385000229, train_loss=0.02114293724298477, time_cost=1.4638807773590088
Steps:   2%|▏         | 16365/1000000 [8:35:19<1840:19:19,  6.74s/it, lr=1e-5, step_loss=0.0973]Steps:   2%|▏         | 16366/1000000 [8:35:25<1728:31:00,  6.33s/it, lr=1e-5, step_loss=0.0973][RANK-0]: Step: [16366], local_loss=0.01665947027504444, train_loss=0.27735239267349243, time_cost=4.391643524169922
Steps:   2%|▏         | 16366/1000000 [8:35:25<1728:31:00,  6.33s/it, lr=1e-5, step_loss=0.0167]Steps:   2%|▏         | 16367/1000000 [8:35:32<1835:13:50,  6.72s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [16367], local_loss=0.07484520226716995, train_loss=0.06517777591943741, time_cost=3.4160711765289307
Steps:   2%|▏         | 16367/1000000 [8:35:32<1835:13:50,  6.72s/it, lr=1e-5, step_loss=0.0748]Steps:   2%|▏         | 16368/1000000 [8:35:39<1839:55:03,  6.73s/it, lr=1e-5, step_loss=0.0748][RANK-0]: Step: [16368], local_loss=0.039588749408721924, train_loss=0.285091757774353, time_cost=1.2095415592193604
Steps:   2%|▏         | 16368/1000000 [8:35:39<1839:55:03,  6.73s/it, lr=1e-5, step_loss=0.0396]Steps:   2%|▏         | 16369/1000000 [8:35:46<1847:03:49,  6.76s/it, lr=1e-5, step_loss=0.0396][RANK-0]: Step: [16369], local_loss=0.008143825456500053, train_loss=0.10590243339538574, time_cost=4.160364866256714
Steps:   2%|▏         | 16369/1000000 [8:35:46<1847:03:49,  6.76s/it, lr=1e-5, step_loss=0.00814]Steps:   2%|▏         | 16370/1000000 [8:35:51<1720:37:59,  6.30s/it, lr=1e-5, step_loss=0.00814][RANK-0]: Step: [16370], local_loss=0.07059650868177414, train_loss=0.02561268024146557, time_cost=1.576077938079834
Steps:   2%|▏         | 16370/1000000 [8:35:51<1720:37:59,  6.30s/it, lr=1e-5, step_loss=0.0706] Steps:   2%|▏         | 16371/1000000 [8:36:07<2523:15:06,  9.23s/it, lr=1e-5, step_loss=0.0706][RANK-0]: Step: [16371], local_loss=0.015476329252123833, train_loss=0.028361298143863678, time_cost=7.09208607673645
Steps:   2%|▏         | 16371/1000000 [8:36:07<2523:15:06,  9.23s/it, lr=1e-5, step_loss=0.0155]Steps:   2%|▏         | 16372/1000000 [8:36:17<2600:42:26,  9.52s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [16372], local_loss=0.0069021424278616905, train_loss=0.023631086573004723, time_cost=2.905406951904297
Steps:   2%|▏         | 16372/1000000 [8:36:17<2600:42:26,  9.52s/it, lr=1e-5, step_loss=0.0069]Steps:   2%|▏         | 16373/1000000 [8:36:22<2166:59:26,  7.93s/it, lr=1e-5, step_loss=0.0069][RANK-0]: Step: [16373], local_loss=0.037283893674612045, train_loss=0.04826545715332031, time_cost=1.5649058818817139
Steps:   2%|▏         | 16373/1000000 [8:36:22<2166:59:26,  7.93s/it, lr=1e-5, step_loss=0.0373]Steps:   2%|▏         | 16374/1000000 [8:36:29<2167:12:12,  7.93s/it, lr=1e-5, step_loss=0.0373][RANK-0]: Step: [16374], local_loss=0.009817751124501228, train_loss=0.02531728893518448, time_cost=4.514141321182251
Steps:   2%|▏         | 16374/1000000 [8:36:29<2167:12:12,  7.93s/it, lr=1e-5, step_loss=0.00982]Steps:   2%|▏         | 16375/1000000 [8:36:34<1863:52:31,  6.82s/it, lr=1e-5, step_loss=0.00982][RANK-0]: Step: [16375], local_loss=0.20857451856136322, train_loss=0.05453271418809891, time_cost=1.3030705451965332
Steps:   2%|▏         | 16375/1000000 [8:36:34<1863:52:31,  6.82s/it, lr=1e-5, step_loss=0.209]  Steps:   2%|▏         | 16376/1000000 [8:36:39<1750:47:42,  6.41s/it, lr=1e-5, step_loss=0.209][RANK-0]: Step: [16376], local_loss=0.04464828595519066, train_loss=0.05791211500763893, time_cost=1.3350653648376465
Steps:   2%|▏         | 16376/1000000 [8:36:39<1750:47:42,  6.41s/it, lr=1e-5, step_loss=0.0446]Steps:   2%|▏         | 16377/1000000 [8:36:53<2328:16:27,  8.52s/it, lr=1e-5, step_loss=0.0446][RANK-0]: Step: [16377], local_loss=0.039651717990636826, train_loss=0.01463436521589756, time_cost=5.871084213256836
Steps:   2%|▏         | 16377/1000000 [8:36:53<2328:16:27,  8.52s/it, lr=1e-5, step_loss=0.0397]Steps:   2%|▏         | 16378/1000000 [8:36:58<2048:19:25,  7.50s/it, lr=1e-5, step_loss=0.0397][RANK-0]: Step: [16378], local_loss=0.0037984554655849934, train_loss=0.05998998135328293, time_cost=2.5194528102874756
Steps:   2%|▏         | 16378/1000000 [8:36:58<2048:19:25,  7.50s/it, lr=1e-5, step_loss=0.0038]Steps:   2%|▏         | 16379/1000000 [8:37:06<2093:57:08,  7.66s/it, lr=1e-5, step_loss=0.0038][RANK-0]: Step: [16379], local_loss=0.026149731129407883, train_loss=0.053126707673072815, time_cost=1.2192647457122803
Steps:   2%|▏         | 16379/1000000 [8:37:06<2093:57:08,  7.66s/it, lr=1e-5, step_loss=0.0261]Steps:   2%|▏         | 16380/1000000 [8:37:13<2085:34:10,  7.63s/it, lr=1e-5, step_loss=0.0261][RANK-0]: Step: [16380], local_loss=1.0020395517349243, train_loss=0.17849206924438477, time_cost=3.9368271827697754
Steps:   2%|▏         | 16380/1000000 [8:37:13<2085:34:10,  7.63s/it, lr=1e-5, step_loss=1]     Steps:   2%|▏         | 16381/1000000 [8:37:28<2679:58:01,  9.81s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [16381], local_loss=0.11096197366714478, train_loss=0.03185627609491348, time_cost=6.824242830276489
Steps:   2%|▏         | 16381/1000000 [8:37:28<2679:58:01,  9.81s/it, lr=1e-5, step_loss=0.111]Steps:   2%|▏         | 16382/1000000 [8:37:34<2387:25:53,  8.74s/it, lr=1e-5, step_loss=0.111][RANK-0]: Step: [16382], local_loss=0.03192462772130966, train_loss=0.030988149344921112, time_cost=1.8379602432250977
Steps:   2%|▏         | 16382/1000000 [8:37:34<2387:25:53,  8.74s/it, lr=1e-5, step_loss=0.0319]Steps:   2%|▏         | 16383/1000000 [8:37:40<2167:34:51,  7.93s/it, lr=1e-5, step_loss=0.0319][RANK-0]: Step: [16383], local_loss=0.11845453083515167, train_loss=0.07015682011842728, time_cost=4.329977512359619
Steps:   2%|▏         | 16383/1000000 [8:37:40<2167:34:51,  7.93s/it, lr=1e-5, step_loss=0.118] Steps:   2%|▏         | 16384/1000000 [8:37:47<2076:52:49,  7.60s/it, lr=1e-5, step_loss=0.118][RANK-0]: Step: [16384], local_loss=0.020916156470775604, train_loss=0.044925473630428314, time_cost=1.2318360805511475
Steps:   2%|▏         | 16384/1000000 [8:37:47<2076:52:49,  7.60s/it, lr=1e-5, step_loss=0.0209]Steps:   2%|▏         | 16385/1000000 [8:37:52<1856:29:25,  6.79s/it, lr=1e-5, step_loss=0.0209][RANK-0]: Step: [16385], local_loss=0.006181108299642801, train_loss=0.047018829733133316, time_cost=2.326634645462036
Steps:   2%|▏         | 16385/1000000 [8:37:52<1856:29:25,  6.79s/it, lr=1e-5, step_loss=0.00618]Steps:   2%|▏         | 16386/1000000 [8:38:01<2036:58:32,  7.46s/it, lr=1e-5, step_loss=0.00618][RANK-0]: Step: [16386], local_loss=0.0063878740184009075, train_loss=0.015473978593945503, time_cost=2.9601528644561768
Steps:   2%|▏         | 16386/1000000 [8:38:01<2036:58:32,  7.46s/it, lr=1e-5, step_loss=0.00639]Steps:   2%|▏         | 16387/1000000 [8:38:10<2175:24:56,  7.96s/it, lr=1e-5, step_loss=0.00639][RANK-0]: Step: [16387], local_loss=0.005491185933351517, train_loss=0.05046466365456581, time_cost=1.537785530090332
Steps:   2%|▏         | 16387/1000000 [8:38:10<2175:24:56,  7.96s/it, lr=1e-5, step_loss=0.00549]Steps:   2%|▏         | 16388/1000000 [8:38:15<1887:33:36,  6.91s/it, lr=1e-5, step_loss=0.00549][RANK-0]: Step: [16388], local_loss=0.0312679186463356, train_loss=0.035103365778923035, time_cost=1.4066684246063232
Steps:   2%|▏         | 16388/1000000 [8:38:15<1887:33:36,  6.91s/it, lr=1e-5, step_loss=0.0313] Steps:   2%|▏         | 16389/1000000 [8:38:20<1734:54:26,  6.35s/it, lr=1e-5, step_loss=0.0313][RANK-0]: Step: [16389], local_loss=0.0077681574039161205, train_loss=0.058111343532800674, time_cost=2.02396559715271
Steps:   2%|▏         | 16389/1000000 [8:38:20<1734:54:26,  6.35s/it, lr=1e-5, step_loss=0.00777]Steps:   2%|▏         | 16390/1000000 [8:38:31<2112:13:10,  7.73s/it, lr=1e-5, step_loss=0.00777][RANK-0]: Step: [16390], local_loss=0.08494903892278671, train_loss=0.05518120154738426, time_cost=3.2245280742645264
Steps:   2%|▏         | 16390/1000000 [8:38:31<2112:13:10,  7.73s/it, lr=1e-5, step_loss=0.0849] Steps:   2%|▏         | 16391/1000000 [8:38:40<2202:27:51,  8.06s/it, lr=1e-5, step_loss=0.0849][RANK-0]: Step: [16391], local_loss=0.02194025181233883, train_loss=0.04600609093904495, time_cost=2.6352574825286865
Steps:   2%|▏         | 16391/1000000 [8:38:40<2202:27:51,  8.06s/it, lr=1e-5, step_loss=0.0219]Steps:   2%|▏         | 16392/1000000 [8:38:53<2636:49:26,  9.65s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [16392], local_loss=0.07720896601676941, train_loss=0.03870313614606857, time_cost=5.88349175453186
Steps:   2%|▏         | 16392/1000000 [8:38:53<2636:49:26,  9.65s/it, lr=1e-5, step_loss=0.0772]Steps:   2%|▏         | 16393/1000000 [8:38:57<2205:16:44,  8.07s/it, lr=1e-5, step_loss=0.0772][RANK-0]: Step: [16393], local_loss=0.011637119576334953, train_loss=0.014257045462727547, time_cost=1.5052247047424316
Steps:   2%|▏         | 16393/1000000 [8:38:57<2205:16:44,  8.07s/it, lr=1e-5, step_loss=0.0116]Steps:   2%|▏         | 16394/1000000 [8:39:02<1947:35:30,  7.13s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [16394], local_loss=0.06191696971654892, train_loss=0.029617590829730034, time_cost=2.4843122959136963
Steps:   2%|▏         | 16394/1000000 [8:39:02<1947:35:30,  7.13s/it, lr=1e-5, step_loss=0.0619]Steps:   2%|▏         | 16395/1000000 [8:39:10<1958:46:56,  7.17s/it, lr=1e-5, step_loss=0.0619][RANK-0]: Step: [16395], local_loss=0.04359591752290726, train_loss=0.03616292402148247, time_cost=2.795464515686035
Steps:   2%|▏         | 16395/1000000 [8:39:10<1958:46:56,  7.17s/it, lr=1e-5, step_loss=0.0436]Steps:   2%|▏         | 16396/1000000 [8:39:23<2500:00:22,  9.15s/it, lr=1e-5, step_loss=0.0436][RANK-0]: Step: [16396], local_loss=0.0065915584564208984, train_loss=0.2455604374408722, time_cost=4.500139474868774
Steps:   2%|▏         | 16396/1000000 [8:39:23<2500:00:22,  9.15s/it, lr=1e-5, step_loss=0.00659]Steps:   2%|▏         | 16397/1000000 [8:39:28<2139:30:08,  7.83s/it, lr=1e-5, step_loss=0.00659][RANK-0]: Step: [16397], local_loss=0.010746839456260204, train_loss=0.02583804354071617, time_cost=1.5271801948547363
Steps:   2%|▏         | 16397/1000000 [8:39:28<2139:30:08,  7.83s/it, lr=1e-5, step_loss=0.0107] Steps:   2%|▏         | 16398/1000000 [8:39:34<1982:07:25,  7.25s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [16398], local_loss=0.02214871719479561, train_loss=0.04694046825170517, time_cost=1.6226181983947754
Steps:   2%|▏         | 16398/1000000 [8:39:34<1982:07:25,  7.25s/it, lr=1e-5, step_loss=0.0221]Steps:   2%|▏         | 16399/1000000 [8:39:40<1851:57:07,  6.78s/it, lr=1e-5, step_loss=0.0221][RANK-0]: Step: [16399], local_loss=0.11271638423204422, train_loss=0.02579948678612709, time_cost=3.3160383701324463
Steps:   2%|▏         | 16399/1000000 [8:39:40<1851:57:07,  6.78s/it, lr=1e-5, step_loss=0.113] Steps:   2%|▏         | 16400/1000000 [8:39:51<2194:43:32,  8.03s/it, lr=1e-5, step_loss=0.113][RANK-0]: Step: [16400], local_loss=0.008507559075951576, train_loss=0.059597790241241455, time_cost=1.173999309539795
Steps:   2%|▏         | 16400/1000000 [8:39:51<2194:43:32,  8.03s/it, lr=1e-5, step_loss=0.00851]Steps:   2%|▏         | 16401/1000000 [8:40:02<2506:55:38,  9.18s/it, lr=1e-5, step_loss=0.00851][RANK-0]: Step: [16401], local_loss=0.04525471106171608, train_loss=0.023388441652059555, time_cost=2.455299139022827
Steps:   2%|▏         | 16401/1000000 [8:40:02<2506:55:38,  9.18s/it, lr=1e-5, step_loss=0.0453] Steps:   2%|▏         | 16402/1000000 [8:40:11<2486:39:15,  9.10s/it, lr=1e-5, step_loss=0.0453][RANK-0]: Step: [16402], local_loss=0.010507702827453613, train_loss=0.020257452502846718, time_cost=2.888948440551758
Steps:   2%|▏         | 16402/1000000 [8:40:11<2486:39:15,  9.10s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 16403/1000000 [8:40:24<2801:26:05, 10.25s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [16403], local_loss=126.05445861816406, train_loss=15.80408763885498, time_cost=1.2303228378295898
Steps:   2%|▏         | 16403/1000000 [8:40:24<2801:26:05, 10.25s/it, lr=1e-5, step_loss=126]   Steps:   2%|▏         | 16404/1000000 [8:40:29<2302:34:01,  8.43s/it, lr=1e-5, step_loss=126][RANK-0]: Step: [16404], local_loss=0.03303682431578636, train_loss=0.01578812673687935, time_cost=1.461057186126709
Steps:   2%|▏         | 16404/1000000 [8:40:29<2302:34:01,  8.43s/it, lr=1e-5, step_loss=0.033]Steps:   2%|▏         | 16405/1000000 [8:40:39<2472:57:57,  9.05s/it, lr=1e-5, step_loss=0.033][RANK-0]: Step: [16405], local_loss=0.042410582304000854, train_loss=0.03563518077135086, time_cost=1.2941064834594727
Steps:   2%|▏         | 16405/1000000 [8:40:39<2472:57:57,  9.05s/it, lr=1e-5, step_loss=0.0424]Steps:   2%|▏         | 16406/1000000 [8:40:44<2132:58:50,  7.81s/it, lr=1e-5, step_loss=0.0424][RANK-0]: Step: [16406], local_loss=0.08343870937824249, train_loss=0.12515348196029663, time_cost=2.1746022701263428
Steps:   2%|▏         | 16406/1000000 [8:40:44<2132:58:50,  7.81s/it, lr=1e-5, step_loss=0.0834]Steps:   2%|▏         | 16407/1000000 [8:40:52<2187:16:11,  8.01s/it, lr=1e-5, step_loss=0.0834][RANK-0]: Step: [16407], local_loss=0.04591819643974304, train_loss=0.2330981343984604, time_cost=4.781754016876221
Steps:   2%|▏         | 16407/1000000 [8:40:52<2187:16:11,  8.01s/it, lr=1e-5, step_loss=0.0459]Steps:   2%|▏         | 16408/1000000 [8:40:58<2025:45:01,  7.41s/it, lr=1e-5, step_loss=0.0459][RANK-0]: Step: [16408], local_loss=0.0074107106775045395, train_loss=0.025057464838027954, time_cost=2.0116117000579834
Steps:   2%|▏         | 16408/1000000 [8:40:58<2025:45:01,  7.41s/it, lr=1e-5, step_loss=0.00741]Steps:   2%|▏         | 16409/1000000 [8:41:04<1896:39:25,  6.94s/it, lr=1e-5, step_loss=0.00741][RANK-0]: Step: [16409], local_loss=0.04852869734168053, train_loss=0.022011809051036835, time_cost=5.2571046352386475
Steps:   2%|▏         | 16409/1000000 [8:41:04<1896:39:25,  6.94s/it, lr=1e-5, step_loss=0.0485] Steps:   2%|▏         | 16410/1000000 [8:41:18<2424:09:23,  8.87s/it, lr=1e-5, step_loss=0.0485][RANK-0]: Step: [16410], local_loss=0.03734413906931877, train_loss=0.04194580763578415, time_cost=1.2108275890350342
Steps:   2%|▏         | 16410/1000000 [8:41:18<2424:09:23,  8.87s/it, lr=1e-5, step_loss=0.0373]Steps:   2%|▏         | 16411/1000000 [8:41:23<2121:50:11,  7.77s/it, lr=1e-5, step_loss=0.0373][RANK-0]: Step: [16411], local_loss=0.015598329715430737, train_loss=0.016904398798942566, time_cost=1.608508825302124
Steps:   2%|▏         | 16411/1000000 [8:41:23<2121:50:11,  7.77s/it, lr=1e-5, step_loss=0.0156]Steps:   2%|▏         | 16412/1000000 [8:41:28<1923:16:37,  7.04s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [16412], local_loss=0.057685595005750656, train_loss=0.14245684444904327, time_cost=2.3980424404144287
Steps:   2%|▏         | 16412/1000000 [8:41:28<1923:16:37,  7.04s/it, lr=1e-5, step_loss=0.0577]Steps:   2%|▏         | 16413/1000000 [8:41:41<2400:47:35,  8.79s/it, lr=1e-5, step_loss=0.0577][RANK-0]: Step: [16413], local_loss=0.206753671169281, train_loss=0.06437190622091293, time_cost=9.43206787109375
Steps:   2%|▏         | 16413/1000000 [8:41:41<2400:47:35,  8.79s/it, lr=1e-5, step_loss=0.207] Steps:   2%|▏         | 16414/1000000 [8:41:53<2630:19:39,  9.63s/it, lr=1e-5, step_loss=0.207][RANK-0]: Step: [16414], local_loss=0.03513018786907196, train_loss=0.03337781876325607, time_cost=1.977719783782959
Steps:   2%|▏         | 16414/1000000 [8:41:53<2630:19:39,  9.63s/it, lr=1e-5, step_loss=0.0351]Steps:   2%|▏         | 16415/1000000 [8:42:02<2638:46:32,  9.66s/it, lr=1e-5, step_loss=0.0351][RANK-0]: Step: [16415], local_loss=0.004831267055124044, train_loss=0.026401814073324203, time_cost=1.8127896785736084
Steps:   2%|▏         | 16415/1000000 [8:42:02<2638:46:32,  9.66s/it, lr=1e-5, step_loss=0.00483]Steps:   2%|▏         | 16416/1000000 [8:42:13<2756:13:47, 10.09s/it, lr=1e-5, step_loss=0.00483][RANK-0]: Step: [16416], local_loss=0.010638508945703506, train_loss=0.018905259668827057, time_cost=3.6907498836517334
Steps:   2%|▏         | 16416/1000000 [8:42:13<2756:13:47, 10.09s/it, lr=1e-5, step_loss=0.0106] Steps:   2%|▏         | 16417/1000000 [8:42:19<2375:54:13,  8.70s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [16417], local_loss=0.011451389640569687, train_loss=0.027359100058674812, time_cost=1.5307519435882568
Steps:   2%|▏         | 16417/1000000 [8:42:19<2375:54:13,  8.70s/it, lr=1e-5, step_loss=0.0115]Steps:   2%|▏         | 16418/1000000 [8:42:25<2183:46:36,  7.99s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [16418], local_loss=0.012516610324382782, train_loss=0.0255911685526371, time_cost=2.0715091228485107
Steps:   2%|▏         | 16418/1000000 [8:42:25<2183:46:36,  7.99s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 16419/1000000 [8:42:31<2022:52:27,  7.40s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [16419], local_loss=0.009064428508281708, train_loss=0.02741263434290886, time_cost=2.45129132270813
Steps:   2%|▏         | 16419/1000000 [8:42:31<2022:52:27,  7.40s/it, lr=1e-5, step_loss=0.00906]Steps:   2%|▏         | 16420/1000000 [8:42:42<2332:02:59,  8.54s/it, lr=1e-5, step_loss=0.00906][RANK-0]: Step: [16420], local_loss=0.03682079166173935, train_loss=0.05639314651489258, time_cost=5.687446355819702
Steps:   2%|▏         | 16420/1000000 [8:42:42<2332:02:59,  8.54s/it, lr=1e-5, step_loss=0.0368] Steps:   2%|▏         | 16421/1000000 [8:42:53<2492:14:56,  9.12s/it, lr=1e-5, step_loss=0.0368][RANK-0]: Step: [16421], local_loss=0.012324173003435135, train_loss=0.06550011783838272, time_cost=5.769769191741943
Steps:   2%|▏         | 16421/1000000 [8:42:53<2492:14:56,  9.12s/it, lr=1e-5, step_loss=0.0123]Steps:   2%|▏         | 16422/1000000 [8:43:02<2490:50:05,  9.12s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [16422], local_loss=0.07609745115041733, train_loss=0.045523546636104584, time_cost=3.895036458969116
Steps:   2%|▏         | 16422/1000000 [8:43:02<2490:50:05,  9.12s/it, lr=1e-5, step_loss=0.0761]Steps:   2%|▏         | 16423/1000000 [8:43:11<2512:57:38,  9.20s/it, lr=1e-5, step_loss=0.0761][RANK-0]: Step: [16423], local_loss=0.007722490467131138, train_loss=0.041609495878219604, time_cost=1.8027193546295166
Steps:   2%|▏         | 16423/1000000 [8:43:11<2512:57:38,  9.20s/it, lr=1e-5, step_loss=0.00772]Steps:   2%|▏         | 16424/1000000 [8:43:23<2696:31:13,  9.87s/it, lr=1e-5, step_loss=0.00772][RANK-0]: Step: [16424], local_loss=0.051639582961797714, train_loss=0.07109029591083527, time_cost=3.9209723472595215
Steps:   2%|▏         | 16424/1000000 [8:43:23<2696:31:13,  9.87s/it, lr=1e-5, step_loss=0.0516] Steps:   2%|▏         | 16425/1000000 [8:43:33<2748:28:54, 10.06s/it, lr=1e-5, step_loss=0.0516][RANK-0]: Step: [16425], local_loss=0.07425298541784286, train_loss=0.06518286466598511, time_cost=1.2332375049591064
Steps:   2%|▏         | 16425/1000000 [8:43:33<2748:28:54, 10.06s/it, lr=1e-5, step_loss=0.0743]Steps:   2%|▏         | 16426/1000000 [8:43:39<2353:21:35,  8.61s/it, lr=1e-5, step_loss=0.0743][RANK-0]: Step: [16426], local_loss=0.003649058286100626, train_loss=0.14359541237354279, time_cost=2.542595624923706
Steps:   2%|▏         | 16426/1000000 [8:43:39<2353:21:35,  8.61s/it, lr=1e-5, step_loss=0.00365]Steps:   2%|▏         | 16427/1000000 [8:43:51<2692:41:19,  9.86s/it, lr=1e-5, step_loss=0.00365][RANK-0]: Step: [16427], local_loss=0.07192084193229675, train_loss=0.03289146348834038, time_cost=3.843654155731201
Steps:   2%|▏         | 16427/1000000 [8:43:51<2692:41:19,  9.86s/it, lr=1e-5, step_loss=0.0719] Steps:   2%|▏         | 16428/1000000 [8:43:57<2305:29:10,  8.44s/it, lr=1e-5, step_loss=0.0719][RANK-0]: Step: [16428], local_loss=0.012446480803191662, train_loss=0.02355467714369297, time_cost=1.808424472808838
Steps:   2%|▏         | 16428/1000000 [8:43:57<2305:29:10,  8.44s/it, lr=1e-5, step_loss=0.0124]Steps:   2%|▏         | 16429/1000000 [8:44:07<2448:51:36,  8.96s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [16429], local_loss=0.14797565340995789, train_loss=0.05567726492881775, time_cost=1.8545382022857666
Steps:   2%|▏         | 16429/1000000 [8:44:07<2448:51:36,  8.96s/it, lr=1e-5, step_loss=0.148] Steps:   2%|▏         | 16430/1000000 [8:44:14<2283:22:36,  8.36s/it, lr=1e-5, step_loss=0.148][RANK-0]: Step: [16430], local_loss=0.00802553165704012, train_loss=0.020126380026340485, time_cost=2.458406448364258
Steps:   2%|▏         | 16430/1000000 [8:44:14<2283:22:36,  8.36s/it, lr=1e-5, step_loss=0.00803]Steps:   2%|▏         | 16431/1000000 [8:44:19<2000:11:32,  7.32s/it, lr=1e-5, step_loss=0.00803][RANK-0]: Step: [16431], local_loss=0.040666963905096054, train_loss=0.0634295791387558, time_cost=3.621220350265503
Steps:   2%|▏         | 16431/1000000 [8:44:19<2000:11:32,  7.32s/it, lr=1e-5, step_loss=0.0407] Steps:   2%|▏         | 16432/1000000 [8:44:30<2306:31:58,  8.44s/it, lr=1e-5, step_loss=0.0407][RANK-0]: Step: [16432], local_loss=0.022407570853829384, train_loss=0.05829373002052307, time_cost=2.588003635406494
Steps:   2%|▏         | 16432/1000000 [8:44:30<2306:31:58,  8.44s/it, lr=1e-5, step_loss=0.0224]Steps:   2%|▏         | 16433/1000000 [8:44:34<1986:25:58,  7.27s/it, lr=1e-5, step_loss=0.0224][RANK-0]: Step: [16433], local_loss=0.009134144522249699, train_loss=0.1396908015012741, time_cost=1.7355799674987793
Steps:   2%|▏         | 16433/1000000 [8:44:34<1986:25:58,  7.27s/it, lr=1e-5, step_loss=0.00913]Steps:   2%|▏         | 16434/1000000 [8:44:50<2701:03:08,  9.89s/it, lr=1e-5, step_loss=0.00913][RANK-0]: Step: [16434], local_loss=0.022950273007154465, train_loss=0.023635607212781906, time_cost=7.771599054336548
Steps:   2%|▏         | 16434/1000000 [8:44:50<2701:03:08,  9.89s/it, lr=1e-5, step_loss=0.023]  Steps:   2%|▏         | 16435/1000000 [8:45:01<2746:25:47, 10.05s/it, lr=1e-5, step_loss=0.023][RANK-0]: Step: [16435], local_loss=0.011903420090675354, train_loss=0.0888902023434639, time_cost=1.9287757873535156
Steps:   2%|▏         | 16435/1000000 [8:45:01<2746:25:47, 10.05s/it, lr=1e-5, step_loss=0.0119]Steps:   2%|▏         | 16436/1000000 [8:45:05<2308:46:22,  8.45s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [16436], local_loss=0.011723039671778679, train_loss=0.035359255969524384, time_cost=2.0420005321502686
Steps:   2%|▏         | 16436/1000000 [8:45:05<2308:46:22,  8.45s/it, lr=1e-5, step_loss=0.0117]Steps:   2%|▏         | 16437/1000000 [8:45:15<2412:42:32,  8.83s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [16437], local_loss=0.08065425604581833, train_loss=0.026441963389515877, time_cost=6.743354797363281
Steps:   2%|▏         | 16437/1000000 [8:45:15<2412:42:32,  8.83s/it, lr=1e-5, step_loss=0.0807]Steps:   2%|▏         | 16438/1000000 [8:45:20<2122:47:28,  7.77s/it, lr=1e-5, step_loss=0.0807][RANK-0]: Step: [16438], local_loss=0.013731550425291061, train_loss=0.04524971544742584, time_cost=1.6798930168151855
Steps:   2%|▏         | 16438/1000000 [8:45:20<2122:47:28,  7.77s/it, lr=1e-5, step_loss=0.0137]Steps:   2%|▏         | 16439/1000000 [8:45:25<1844:19:25,  6.75s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [16439], local_loss=0.49437904357910156, train_loss=0.12909884750843048, time_cost=1.4940950870513916
Steps:   2%|▏         | 16439/1000000 [8:45:25<1844:19:25,  6.75s/it, lr=1e-5, step_loss=0.494] Steps:   2%|▏         | 16440/1000000 [8:45:30<1713:57:56,  6.27s/it, lr=1e-5, step_loss=0.494][RANK-0]: Step: [16440], local_loss=0.007410291116684675, train_loss=0.10246174037456512, time_cost=1.3485627174377441
Steps:   2%|▏         | 16440/1000000 [8:45:30<1713:57:56,  6.27s/it, lr=1e-5, step_loss=0.00741]Steps:   2%|▏         | 16441/1000000 [8:45:37<1806:47:58,  6.61s/it, lr=1e-5, step_loss=0.00741][RANK-0]: Step: [16441], local_loss=0.07364463806152344, train_loss=0.052813366055488586, time_cost=3.501187324523926
Steps:   2%|▏         | 16441/1000000 [8:45:37<1806:47:58,  6.61s/it, lr=1e-5, step_loss=0.0736] Steps:   2%|▏         | 16442/1000000 [8:45:42<1646:08:09,  6.03s/it, lr=1e-5, step_loss=0.0736][RANK-0]: Step: [16442], local_loss=0.10714557766914368, train_loss=0.040247298777103424, time_cost=1.9612352848052979
Steps:   2%|▏         | 16442/1000000 [8:45:42<1646:08:09,  6.03s/it, lr=1e-5, step_loss=0.107] Steps:   2%|▏         | 16443/1000000 [8:45:46<1505:58:01,  5.51s/it, lr=1e-5, step_loss=0.107][RANK-0]: Step: [16443], local_loss=0.0378849022090435, train_loss=0.022876109927892685, time_cost=1.5107898712158203
Steps:   2%|▏         | 16443/1000000 [8:45:46<1505:58:01,  5.51s/it, lr=1e-5, step_loss=0.0379]Steps:   2%|▏         | 16444/1000000 [8:45:53<1615:22:52,  5.91s/it, lr=1e-5, step_loss=0.0379][RANK-0]: Step: [16444], local_loss=0.0105580510571599, train_loss=0.04221529886126518, time_cost=1.273447036743164
Steps:   2%|▏         | 16444/1000000 [8:45:53<1615:22:52,  5.91s/it, lr=1e-5, step_loss=0.0106]Steps:   2%|▏         | 16445/1000000 [8:46:00<1689:35:43,  6.18s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [16445], local_loss=0.005184152163565159, train_loss=0.06358249485492706, time_cost=2.354124069213867
Steps:   2%|▏         | 16445/1000000 [8:46:00<1689:35:43,  6.18s/it, lr=1e-5, step_loss=0.00518]Steps:   2%|▏         | 16446/1000000 [8:46:09<1948:54:09,  7.13s/it, lr=1e-5, step_loss=0.00518][RANK-0]: Step: [16446], local_loss=0.017773520201444626, train_loss=0.04854521155357361, time_cost=3.7616817951202393
Steps:   2%|▏         | 16446/1000000 [8:46:09<1948:54:09,  7.13s/it, lr=1e-5, step_loss=0.0178] Steps:   2%|▏         | 16447/1000000 [8:46:19<2137:17:42,  7.82s/it, lr=1e-5, step_loss=0.0178][RANK-0]: Step: [16447], local_loss=0.016082432121038437, train_loss=0.06278969347476959, time_cost=3.459272861480713
Steps:   2%|▏         | 16447/1000000 [8:46:19<2137:17:42,  7.82s/it, lr=1e-5, step_loss=0.0161]Steps:   2%|▏         | 16448/1000000 [8:46:29<2316:04:10,  8.48s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [16448], local_loss=0.12560586631298065, train_loss=0.02748054638504982, time_cost=2.1601645946502686
Steps:   2%|▏         | 16448/1000000 [8:46:29<2316:04:10,  8.48s/it, lr=1e-5, step_loss=0.126] Steps:   2%|▏         | 16449/1000000 [8:46:34<2049:47:54,  7.50s/it, lr=1e-5, step_loss=0.126][RANK-0]: Step: [16449], local_loss=0.01275643426924944, train_loss=0.032684992998838425, time_cost=2.6874608993530273
Steps:   2%|▏         | 16449/1000000 [8:46:34<2049:47:54,  7.50s/it, lr=1e-5, step_loss=0.0128]Steps:   2%|▏         | 16450/1000000 [8:46:40<1919:14:01,  7.02s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [16450], local_loss=0.0998590812087059, train_loss=0.04237961024045944, time_cost=3.4075660705566406
Steps:   2%|▏         | 16450/1000000 [8:46:40<1919:14:01,  7.02s/it, lr=1e-5, step_loss=0.0999]Steps:   2%|▏         | 16451/1000000 [8:46:45<1783:37:13,  6.53s/it, lr=1e-5, step_loss=0.0999][RANK-0]: Step: [16451], local_loss=0.04980120807886124, train_loss=0.15407080948352814, time_cost=1.1997897624969482
Steps:   2%|▏         | 16451/1000000 [8:46:45<1783:37:13,  6.53s/it, lr=1e-5, step_loss=0.0498]Steps:   2%|▏         | 16452/1000000 [8:46:59<2352:15:15,  8.61s/it, lr=1e-5, step_loss=0.0498][RANK-0]: Step: [16452], local_loss=0.4614541232585907, train_loss=0.11943823099136353, time_cost=5.1355602741241455
Steps:   2%|▏         | 16452/1000000 [8:46:59<2352:15:15,  8.61s/it, lr=1e-5, step_loss=0.461] Steps:   2%|▏         | 16453/1000000 [8:47:06<2254:02:33,  8.25s/it, lr=1e-5, step_loss=0.461][RANK-0]: Step: [16453], local_loss=0.02238028310239315, train_loss=0.06503133475780487, time_cost=1.5951895713806152
Steps:   2%|▏         | 16453/1000000 [8:47:06<2254:02:33,  8.25s/it, lr=1e-5, step_loss=0.0224]Steps:   2%|▏         | 16454/1000000 [8:47:17<2459:56:44,  9.00s/it, lr=1e-5, step_loss=0.0224][RANK-0]: Step: [16454], local_loss=0.0062059639021754265, train_loss=0.050483208149671555, time_cost=4.21833610534668
Steps:   2%|▏         | 16454/1000000 [8:47:17<2459:56:44,  9.00s/it, lr=1e-5, step_loss=0.00621]Steps:   2%|▏         | 16455/1000000 [8:47:26<2453:57:52,  8.98s/it, lr=1e-5, step_loss=0.00621][RANK-0]: Step: [16455], local_loss=0.07025201618671417, train_loss=0.03481164202094078, time_cost=3.316084146499634
Steps:   2%|▏         | 16455/1000000 [8:47:26<2453:57:52,  8.98s/it, lr=1e-5, step_loss=0.0703] Steps:   2%|▏         | 16456/1000000 [8:47:30<2089:04:42,  7.65s/it, lr=1e-5, step_loss=0.0703][RANK-0]: Step: [16456], local_loss=0.04096288979053497, train_loss=0.030570438131690025, time_cost=1.8055310249328613
Steps:   2%|▏         | 16456/1000000 [8:47:30<2089:04:42,  7.65s/it, lr=1e-5, step_loss=0.041] Steps:   2%|▏         | 16457/1000000 [8:47:35<1872:39:13,  6.85s/it, lr=1e-5, step_loss=0.041][RANK-0]: Step: [16457], local_loss=0.07210349291563034, train_loss=0.05559033900499344, time_cost=2.1594080924987793
Steps:   2%|▏         | 16457/1000000 [8:47:35<1872:39:13,  6.85s/it, lr=1e-5, step_loss=0.0721]Steps:   2%|▏         | 16458/1000000 [8:47:43<1904:22:48,  6.97s/it, lr=1e-5, step_loss=0.0721][RANK-0]: Step: [16458], local_loss=0.07609312981367111, train_loss=0.047139883041381836, time_cost=3.1795949935913086
Steps:   2%|▏         | 16458/1000000 [8:47:43<1904:22:48,  6.97s/it, lr=1e-5, step_loss=0.0761]Steps:   2%|▏         | 16459/1000000 [8:47:56<2445:00:47,  8.95s/it, lr=1e-5, step_loss=0.0761][RANK-0]: Step: [16459], local_loss=0.011335051618516445, train_loss=0.022369693964719772, time_cost=5.7685558795928955
Steps:   2%|▏         | 16459/1000000 [8:47:56<2445:00:47,  8.95s/it, lr=1e-5, step_loss=0.0113]Steps:   2%|▏         | 16460/1000000 [8:48:01<2155:39:44,  7.89s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [16460], local_loss=0.016094978898763657, train_loss=0.02024109475314617, time_cost=1.6465380191802979
Steps:   2%|▏         | 16460/1000000 [8:48:01<2155:39:44,  7.89s/it, lr=1e-5, step_loss=0.0161]Steps:   2%|▏         | 16461/1000000 [8:48:06<1861:36:03,  6.81s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [16461], local_loss=0.008756643161177635, train_loss=0.03671681880950928, time_cost=1.2143406867980957
Steps:   2%|▏         | 16461/1000000 [8:48:06<1861:36:03,  6.81s/it, lr=1e-5, step_loss=0.00876]Steps:   2%|▏         | 16462/1000000 [8:48:15<2043:47:30,  7.48s/it, lr=1e-5, step_loss=0.00876][RANK-0]: Step: [16462], local_loss=0.03792843222618103, train_loss=0.025640912353992462, time_cost=3.908811330795288
Steps:   2%|▏         | 16462/1000000 [8:48:15<2043:47:30,  7.48s/it, lr=1e-5, step_loss=0.0379] Steps:   2%|▏         | 16463/1000000 [8:48:24<2191:00:12,  8.02s/it, lr=1e-5, step_loss=0.0379][RANK-0]: Step: [16463], local_loss=0.04331459477543831, train_loss=0.08524483442306519, time_cost=1.7292187213897705
Steps:   2%|▏         | 16463/1000000 [8:48:24<2191:00:12,  8.02s/it, lr=1e-5, step_loss=0.0433]Steps:   2%|▏         | 16464/1000000 [8:48:36<2543:21:35,  9.31s/it, lr=1e-5, step_loss=0.0433][RANK-0]: Step: [16464], local_loss=0.12325860559940338, train_loss=0.04600208252668381, time_cost=6.393011808395386
Steps:   2%|▏         | 16464/1000000 [8:48:36<2543:21:35,  9.31s/it, lr=1e-5, step_loss=0.123] Steps:   2%|▏         | 16465/1000000 [8:48:45<2521:48:38,  9.23s/it, lr=1e-5, step_loss=0.123][RANK-0]: Step: [16465], local_loss=0.03972385823726654, train_loss=0.06760230660438538, time_cost=1.7348041534423828
Steps:   2%|▏         | 16465/1000000 [8:48:45<2521:48:38,  9.23s/it, lr=1e-5, step_loss=0.0397]Steps:   2%|▏         | 16466/1000000 [8:48:53<2368:38:28,  8.67s/it, lr=1e-5, step_loss=0.0397][RANK-0]: Step: [16466], local_loss=0.005488620605319738, train_loss=0.03469393402338028, time_cost=5.634446859359741
Steps:   2%|▏         | 16466/1000000 [8:48:53<2368:38:28,  8.67s/it, lr=1e-5, step_loss=0.00549]Steps:   2%|▏         | 16467/1000000 [8:49:00<2226:19:06,  8.15s/it, lr=1e-5, step_loss=0.00549][RANK-0]: Step: [16467], local_loss=0.04758286103606224, train_loss=0.04872536659240723, time_cost=4.013003349304199
Steps:   2%|▏         | 16467/1000000 [8:49:00<2226:19:06,  8.15s/it, lr=1e-5, step_loss=0.0476] Steps:   2%|▏         | 16468/1000000 [8:49:09<2276:40:08,  8.33s/it, lr=1e-5, step_loss=0.0476][RANK-0]: Step: [16468], local_loss=0.031553275883197784, train_loss=0.07092258334159851, time_cost=1.4540965557098389
Steps:   2%|▏         | 16468/1000000 [8:49:09<2276:40:08,  8.33s/it, lr=1e-5, step_loss=0.0316]Steps:   2%|▏         | 16469/1000000 [8:49:13<1996:52:42,  7.31s/it, lr=1e-5, step_loss=0.0316][RANK-0]: Step: [16469], local_loss=0.01342517789453268, train_loss=0.016184933483600616, time_cost=1.986187219619751
Steps:   2%|▏         | 16469/1000000 [8:49:13<1996:52:42,  7.31s/it, lr=1e-5, step_loss=0.0134]Steps:   2%|▏         | 16470/1000000 [8:49:21<2027:40:24,  7.42s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [16470], local_loss=0.016032328829169273, train_loss=0.017274394631385803, time_cost=4.14586067199707
Steps:   2%|▏         | 16470/1000000 [8:49:21<2027:40:24,  7.42s/it, lr=1e-5, step_loss=0.016] Steps:   2%|▏         | 16471/1000000 [8:49:30<2128:26:06,  7.79s/it, lr=1e-5, step_loss=0.016][RANK-0]: Step: [16471], local_loss=0.014827472157776356, train_loss=0.03366469964385033, time_cost=2.789182186126709
Steps:   2%|▏         | 16471/1000000 [8:49:30<2128:26:06,  7.79s/it, lr=1e-5, step_loss=0.0148]Steps:   2%|▏         | 16472/1000000 [8:49:42<2509:55:48,  9.19s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [16472], local_loss=0.07709097862243652, train_loss=0.0325363390147686, time_cost=5.596766233444214
Steps:   2%|▏         | 16472/1000000 [8:49:42<2509:55:48,  9.19s/it, lr=1e-5, step_loss=0.0771]Steps:   2%|▏         | 16473/1000000 [8:49:57<2949:23:07, 10.80s/it, lr=1e-5, step_loss=0.0771][RANK-0]: Step: [16473], local_loss=0.005970663391053677, train_loss=0.026548437774181366, time_cost=5.503390550613403
Steps:   2%|▏         | 16473/1000000 [8:49:57<2949:23:07, 10.80s/it, lr=1e-5, step_loss=0.00597]Steps:   2%|▏         | 16474/1000000 [8:50:04<2632:11:23,  9.63s/it, lr=1e-5, step_loss=0.00597][RANK-0]: Step: [16474], local_loss=0.013750873506069183, train_loss=0.019950341433286667, time_cost=3.0221571922302246
Steps:   2%|▏         | 16474/1000000 [8:50:04<2632:11:23,  9.63s/it, lr=1e-5, step_loss=0.0138] Steps:   2%|▏         | 16475/1000000 [8:50:12<2487:00:28,  9.10s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [16475], local_loss=0.006767189595848322, train_loss=0.044257164001464844, time_cost=2.910015344619751
Steps:   2%|▏         | 16475/1000000 [8:50:12<2487:00:28,  9.10s/it, lr=1e-5, step_loss=0.00677]Steps:   2%|▏         | 16476/1000000 [8:50:20<2431:12:28,  8.90s/it, lr=1e-5, step_loss=0.00677][RANK-0]: Step: [16476], local_loss=0.015274266712367535, train_loss=0.10201971977949142, time_cost=2.3887181282043457
Steps:   2%|▏         | 16476/1000000 [8:50:20<2431:12:28,  8.90s/it, lr=1e-5, step_loss=0.0153] Steps:   2%|▏         | 16477/1000000 [8:50:26<2214:21:20,  8.11s/it, lr=1e-5, step_loss=0.0153][RANK-0]: Step: [16477], local_loss=0.026774555444717407, train_loss=0.1729608178138733, time_cost=1.8980329036712646
Steps:   2%|▏         | 16477/1000000 [8:50:26<2214:21:20,  8.11s/it, lr=1e-5, step_loss=0.0268]Steps:   2%|▏         | 16478/1000000 [8:50:33<2131:56:43,  7.80s/it, lr=1e-5, step_loss=0.0268][RANK-0]: Step: [16478], local_loss=0.07173316180706024, train_loss=0.05823889374732971, time_cost=2.7735705375671387
Steps:   2%|▏         | 16478/1000000 [8:50:33<2131:56:43,  7.80s/it, lr=1e-5, step_loss=0.0717]Steps:   2%|▏         | 16479/1000000 [8:50:44<2340:21:02,  8.57s/it, lr=1e-5, step_loss=0.0717][RANK-0]: Step: [16479], local_loss=0.005572345107793808, train_loss=0.02953483909368515, time_cost=2.178823232650757
Steps:   2%|▏         | 16479/1000000 [8:50:44<2340:21:02,  8.57s/it, lr=1e-5, step_loss=0.00557]Steps:   2%|▏         | 16480/1000000 [8:50:56<2686:27:03,  9.83s/it, lr=1e-5, step_loss=0.00557][RANK-0]: Step: [16480], local_loss=0.10220286250114441, train_loss=0.0615852028131485, time_cost=4.226288318634033
Steps:   2%|▏         | 16480/1000000 [8:50:56<2686:27:03,  9.83s/it, lr=1e-5, step_loss=0.102]  Steps:   2%|▏         | 16481/1000000 [8:51:02<2342:41:01,  8.57s/it, lr=1e-5, step_loss=0.102][RANK-0]: Step: [16481], local_loss=0.0588127076625824, train_loss=0.059310801327228546, time_cost=1.7481493949890137
Steps:   2%|▏         | 16481/1000000 [8:51:02<2342:41:01,  8.57s/it, lr=1e-5, step_loss=0.0588]Steps:   2%|▏         | 16482/1000000 [8:51:06<1990:05:34,  7.28s/it, lr=1e-5, step_loss=0.0588][RANK-0]: Step: [16482], local_loss=0.049041006714105606, train_loss=0.06454910337924957, time_cost=1.5754752159118652
Steps:   2%|▏         | 16482/1000000 [8:51:06<1990:05:34,  7.28s/it, lr=1e-5, step_loss=0.049] Steps:   2%|▏         | 16483/1000000 [8:51:11<1749:36:33,  6.40s/it, lr=1e-5, step_loss=0.049][RANK-0]: Step: [16483], local_loss=0.030591268092393875, train_loss=0.047212131321430206, time_cost=1.5513651371002197
Steps:   2%|▏         | 16483/1000000 [8:51:11<1749:36:33,  6.40s/it, lr=1e-5, step_loss=0.0306]Steps:   2%|▏         | 16484/1000000 [8:51:26<2451:39:39,  8.97s/it, lr=1e-5, step_loss=0.0306][RANK-0]: Step: [16484], local_loss=0.019978903234004974, train_loss=6.617186546325684, time_cost=6.47187352180481
Steps:   2%|▏         | 16484/1000000 [8:51:26<2451:39:39,  8.97s/it, lr=1e-5, step_loss=0.02]  Steps:   2%|▏         | 16485/1000000 [8:51:37<2619:36:13,  9.59s/it, lr=1e-5, step_loss=0.02][RANK-0]: Step: [16485], local_loss=0.021483369171619415, train_loss=0.06269483268260956, time_cost=8.08194637298584
Steps:   2%|▏         | 16485/1000000 [8:51:37<2619:36:13,  9.59s/it, lr=1e-5, step_loss=0.0215]Steps:   2%|▏         | 16486/1000000 [8:51:46<2576:05:13,  9.43s/it, lr=1e-5, step_loss=0.0215][RANK-0]: Step: [16486], local_loss=0.03587881848216057, train_loss=0.014533396810293198, time_cost=6.145974159240723
Steps:   2%|▏         | 16486/1000000 [8:51:46<2576:05:13,  9.43s/it, lr=1e-5, step_loss=0.0359]Steps:   2%|▏         | 16487/1000000 [8:51:52<2274:34:46,  8.33s/it, lr=1e-5, step_loss=0.0359][RANK-0]: Step: [16487], local_loss=0.016464103013277054, train_loss=0.02715310826897621, time_cost=1.3466076850891113
Steps:   2%|▏         | 16487/1000000 [8:51:52<2274:34:46,  8.33s/it, lr=1e-5, step_loss=0.0165]Steps:   2%|▏         | 16488/1000000 [8:51:57<2004:21:36,  7.34s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [16488], local_loss=0.038985174149274826, train_loss=0.05842018127441406, time_cost=1.8683855533599854
Steps:   2%|▏         | 16488/1000000 [8:51:57<2004:21:36,  7.34s/it, lr=1e-5, step_loss=0.039] Steps:   2%|▏         | 16489/1000000 [8:52:02<1876:55:46,  6.87s/it, lr=1e-5, step_loss=0.039][RANK-0]: Step: [16489], local_loss=0.03529739752411842, train_loss=0.09066706895828247, time_cost=3.3245270252227783
Steps:   2%|▏         | 16489/1000000 [8:52:02<1876:55:46,  6.87s/it, lr=1e-5, step_loss=0.0353]Steps:   2%|▏         | 16490/1000000 [8:52:15<2344:12:05,  8.58s/it, lr=1e-5, step_loss=0.0353][RANK-0]: Step: [16490], local_loss=0.04665595293045044, train_loss=0.04098084196448326, time_cost=5.343759775161743
Steps:   2%|▏         | 16490/1000000 [8:52:15<2344:12:05,  8.58s/it, lr=1e-5, step_loss=0.0467]Steps:   2%|▏         | 16491/1000000 [8:52:24<2422:58:23,  8.87s/it, lr=1e-5, step_loss=0.0467][RANK-0]: Step: [16491], local_loss=0.03975914046168327, train_loss=0.025774598121643066, time_cost=2.0601911544799805
Steps:   2%|▏         | 16491/1000000 [8:52:24<2422:58:23,  8.87s/it, lr=1e-5, step_loss=0.0398]Steps:   2%|▏         | 16492/1000000 [8:52:33<2427:21:02,  8.88s/it, lr=1e-5, step_loss=0.0398][RANK-0]: Step: [16492], local_loss=0.017164306715130806, train_loss=40.33332061767578, time_cost=3.2345199584960938
Steps:   2%|▏         | 16492/1000000 [8:52:33<2427:21:02,  8.88s/it, lr=1e-5, step_loss=0.0172]Steps:   2%|▏         | 16493/1000000 [8:52:38<2062:56:35,  7.55s/it, lr=1e-5, step_loss=0.0172][RANK-0]: Step: [16493], local_loss=0.1068861335515976, train_loss=0.045828502625226974, time_cost=1.556694507598877
Steps:   2%|▏         | 16493/1000000 [8:52:38<2062:56:35,  7.55s/it, lr=1e-5, step_loss=0.107] Steps:   2%|▏         | 16494/1000000 [8:52:44<1922:55:47,  7.04s/it, lr=1e-5, step_loss=0.107][RANK-0]: Step: [16494], local_loss=0.018165942281484604, train_loss=0.03226889669895172, time_cost=2.2814862728118896
Steps:   2%|▏         | 16494/1000000 [8:52:44<1922:55:47,  7.04s/it, lr=1e-5, step_loss=0.0182]Steps:   2%|▏         | 16495/1000000 [8:52:49<1816:11:38,  6.65s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [16495], local_loss=0.019303523004055023, train_loss=1.0745820999145508, time_cost=2.823395252227783
Steps:   2%|▏         | 16495/1000000 [8:52:49<1816:11:38,  6.65s/it, lr=1e-5, step_loss=0.0193]Steps:   2%|▏         | 16496/1000000 [8:53:01<2222:33:33,  8.14s/it, lr=1e-5, step_loss=0.0193][RANK-0]: Step: [16496], local_loss=0.1575782746076584, train_loss=0.09329397976398468, time_cost=5.612212181091309
Steps:   2%|▏         | 16496/1000000 [8:53:01<2222:33:33,  8.14s/it, lr=1e-5, step_loss=0.158] Steps:   2%|▏         | 16497/1000000 [8:53:12<2455:17:10,  8.99s/it, lr=1e-5, step_loss=0.158][RANK-0]: Step: [16497], local_loss=0.03673650324344635, train_loss=0.1684049367904663, time_cost=2.299375295639038
Steps:   2%|▏         | 16497/1000000 [8:53:12<2455:17:10,  8.99s/it, lr=1e-5, step_loss=0.0367]Steps:   2%|▏         | 16498/1000000 [8:53:17<2150:42:08,  7.87s/it, lr=1e-5, step_loss=0.0367][RANK-0]: Step: [16498], local_loss=0.020414892584085464, train_loss=0.016745675355196, time_cost=1.2301676273345947
Steps:   2%|▏         | 16498/1000000 [8:53:17<2150:42:08,  7.87s/it, lr=1e-5, step_loss=0.0204]Steps:   2%|▏         | 16499/1000000 [8:53:23<1936:48:18,  7.09s/it, lr=1e-5, step_loss=0.0204][RANK-0]: Step: [16499], local_loss=0.017401818186044693, train_loss=0.05047616735100746, time_cost=2.32193922996521
Steps:   2%|▏         | 16499/1000000 [8:53:23<1936:48:18,  7.09s/it, lr=1e-5, step_loss=0.0174]Steps:   2%|▏         | 16500/1000000 [8:53:28<1773:17:46,  6.49s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [16500], local_loss=0.005430304445326328, train_loss=0.02513866499066353, time_cost=1.2279584407806396
Steps:   2%|▏         | 16500/1000000 [8:53:28<1773:17:46,  6.49s/it, lr=1e-5, step_loss=0.00543]Steps:   2%|▏         | 16501/1000000 [8:53:32<1614:16:25,  5.91s/it, lr=1e-5, step_loss=0.00543][RANK-0]: Step: [16501], local_loss=0.07704933732748032, train_loss=0.1524391770362854, time_cost=1.4093420505523682
Steps:   2%|▏         | 16501/1000000 [8:53:32<1614:16:25,  5.91s/it, lr=1e-5, step_loss=0.077]  Steps:   2%|▏         | 16502/1000000 [8:53:42<1941:42:56,  7.11s/it, lr=1e-5, step_loss=0.077][RANK-0]: Step: [16502], local_loss=0.04780537635087967, train_loss=0.06971370428800583, time_cost=2.0773744583129883
Steps:   2%|▏         | 16502/1000000 [8:53:42<1941:42:56,  7.11s/it, lr=1e-5, step_loss=0.0478]Steps:   2%|▏         | 16503/1000000 [8:53:57<2618:07:52,  9.58s/it, lr=1e-5, step_loss=0.0478][RANK-0]: Step: [16503], local_loss=0.007706757169216871, train_loss=0.024552494287490845, time_cost=7.261859655380249
Steps:   2%|▏         | 16503/1000000 [8:53:57<2618:07:52,  9.58s/it, lr=1e-5, step_loss=0.00771]Steps:   2%|▏         | 16504/1000000 [8:54:06<2567:07:35,  9.40s/it, lr=1e-5, step_loss=0.00771][RANK-0]: Step: [16504], local_loss=0.012243427336215973, train_loss=0.07799142599105835, time_cost=1.8255138397216797
Steps:   2%|▏         | 16504/1000000 [8:54:06<2567:07:35,  9.40s/it, lr=1e-5, step_loss=0.0122] Steps:   2%|▏         | 16505/1000000 [8:54:12<2286:58:48,  8.37s/it, lr=1e-5, step_loss=0.0122][RANK-0]: Step: [16505], local_loss=0.013575498946011066, train_loss=0.04206930100917816, time_cost=1.2450270652770996
Steps:   2%|▏         | 16505/1000000 [8:54:12<2286:58:48,  8.37s/it, lr=1e-5, step_loss=0.0136]Steps:   2%|▏         | 16506/1000000 [8:54:21<2294:10:13,  8.40s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [16506], local_loss=0.05850626528263092, train_loss=0.026202553883194923, time_cost=6.868038892745972
Steps:   2%|▏         | 16506/1000000 [8:54:21<2294:10:13,  8.40s/it, lr=1e-5, step_loss=0.0585]Steps:   2%|▏         | 16507/1000000 [8:54:30<2389:15:36,  8.75s/it, lr=1e-5, step_loss=0.0585][RANK-0]: Step: [16507], local_loss=0.07220397144556046, train_loss=0.04422498866915703, time_cost=1.1955673694610596
Steps:   2%|▏         | 16507/1000000 [8:54:30<2389:15:36,  8.75s/it, lr=1e-5, step_loss=0.0722]Steps:   2%|▏         | 16508/1000000 [8:54:41<2501:27:34,  9.16s/it, lr=1e-5, step_loss=0.0722][RANK-0]: Step: [16508], local_loss=0.031026169657707214, train_loss=0.06230216845870018, time_cost=1.2119929790496826
Steps:   2%|▏         | 16508/1000000 [8:54:41<2501:27:34,  9.16s/it, lr=1e-5, step_loss=0.031] Steps:   2%|▏         | 16509/1000000 [8:54:48<2355:46:24,  8.62s/it, lr=1e-5, step_loss=0.031][RANK-0]: Step: [16509], local_loss=0.02064131200313568, train_loss=0.04528876394033432, time_cost=3.1547200679779053
Steps:   2%|▏         | 16509/1000000 [8:54:48<2355:46:24,  8.62s/it, lr=1e-5, step_loss=0.0206]Steps:   2%|▏         | 16510/1000000 [8:54:54<2140:23:23,  7.83s/it, lr=1e-5, step_loss=0.0206][RANK-0]: Step: [16510], local_loss=0.022623470053076744, train_loss=2.66137433052063, time_cost=1.6257331371307373
Steps:   2%|▏         | 16510/1000000 [8:54:54<2140:23:23,  7.83s/it, lr=1e-5, step_loss=0.0226]Steps:   2%|▏         | 16511/1000000 [8:55:08<2657:32:56,  9.73s/it, lr=1e-5, step_loss=0.0226][RANK-0]: Step: [16511], local_loss=0.025956999510526657, train_loss=0.06632622331380844, time_cost=4.722455978393555
Steps:   2%|▏         | 16511/1000000 [8:55:08<2657:32:56,  9.73s/it, lr=1e-5, step_loss=0.026] Steps:   2%|▏         | 16512/1000000 [8:55:23<3087:44:50, 11.30s/it, lr=1e-5, step_loss=0.026][RANK-0]: Step: [16512], local_loss=0.011420536786317825, train_loss=0.029861390590667725, time_cost=1.4454715251922607
Steps:   2%|▏         | 16512/1000000 [8:55:23<3087:44:50, 11.30s/it, lr=1e-5, step_loss=0.0114]Steps:   2%|▏         | 16513/1000000 [8:55:27<2519:39:59,  9.22s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [16513], local_loss=0.025963420048356056, train_loss=0.042038969695568085, time_cost=2.362035036087036
Steps:   2%|▏         | 16513/1000000 [8:55:27<2519:39:59,  9.22s/it, lr=1e-5, step_loss=0.026] Steps:   2%|▏         | 16514/1000000 [8:55:34<2321:19:44,  8.50s/it, lr=1e-5, step_loss=0.026][RANK-0]: Step: [16514], local_loss=0.014544999226927757, train_loss=0.04162786900997162, time_cost=2.4445574283599854
Steps:   2%|▏         | 16514/1000000 [8:55:34<2321:19:44,  8.50s/it, lr=1e-5, step_loss=0.0145]Steps:   2%|▏         | 16515/1000000 [8:55:45<2508:01:35,  9.18s/it, lr=1e-5, step_loss=0.0145][RANK-0]: Step: [16515], local_loss=0.008629035204648972, train_loss=0.02596455067396164, time_cost=1.627058506011963
Steps:   2%|▏         | 16515/1000000 [8:55:45<2508:01:35,  9.18s/it, lr=1e-5, step_loss=0.00863]Steps:   2%|▏         | 16516/1000000 [8:55:52<2310:00:57,  8.46s/it, lr=1e-5, step_loss=0.00863][RANK-0]: Step: [16516], local_loss=0.1046292781829834, train_loss=0.02795344963669777, time_cost=1.2396550178527832
Steps:   2%|▏         | 16516/1000000 [8:55:52<2310:00:57,  8.46s/it, lr=1e-5, step_loss=0.105]  Steps:   2%|▏         | 16517/1000000 [8:56:01<2366:09:04,  8.66s/it, lr=1e-5, step_loss=0.105][RANK-0]: Step: [16517], local_loss=0.02925632894039154, train_loss=0.023528052493929863, time_cost=3.746506452560425
Steps:   2%|▏         | 16517/1000000 [8:56:01<2366:09:04,  8.66s/it, lr=1e-5, step_loss=0.0293]Steps:   2%|▏         | 16518/1000000 [8:56:11<2462:46:40,  9.01s/it, lr=1e-5, step_loss=0.0293][RANK-0]: Step: [16518], local_loss=0.016032012179493904, train_loss=0.15373419225215912, time_cost=1.5418879985809326
Steps:   2%|▏         | 16518/1000000 [8:56:11<2462:46:40,  9.01s/it, lr=1e-5, step_loss=0.016] Steps:   2%|▏         | 16519/1000000 [8:56:22<2688:14:15,  9.84s/it, lr=1e-5, step_loss=0.016][RANK-0]: Step: [16519], local_loss=0.018261101096868515, train_loss=0.032795198261737823, time_cost=8.456051111221313
Steps:   2%|▏         | 16519/1000000 [8:56:22<2688:14:15,  9.84s/it, lr=1e-5, step_loss=0.0183]Steps:   2%|▏         | 16520/1000000 [8:56:34<2803:24:07, 10.26s/it, lr=1e-5, step_loss=0.0183][RANK-0]: Step: [16520], local_loss=0.03307316452264786, train_loss=0.10961587727069855, time_cost=4.285762786865234
Steps:   2%|▏         | 16520/1000000 [8:56:34<2803:24:07, 10.26s/it, lr=1e-5, step_loss=0.0331]Steps:   2%|▏         | 16521/1000000 [8:56:47<3049:42:35, 11.16s/it, lr=1e-5, step_loss=0.0331][RANK-0]: Step: [16521], local_loss=0.017408058047294617, train_loss=0.04787615314126015, time_cost=4.328585147857666
Steps:   2%|▏         | 16521/1000000 [8:56:47<3049:42:35, 11.16s/it, lr=1e-5, step_loss=0.0174]Steps:   2%|▏         | 16522/1000000 [8:57:01<3320:32:55, 12.15s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [16522], local_loss=0.006463341414928436, train_loss=0.029224971309304237, time_cost=5.420140027999878
Steps:   2%|▏         | 16522/1000000 [8:57:01<3320:32:55, 12.15s/it, lr=1e-5, step_loss=0.00646]Steps:   2%|▏         | 16523/1000000 [8:57:06<2719:00:43,  9.95s/it, lr=1e-5, step_loss=0.00646][RANK-0]: Step: [16523], local_loss=0.004456819035112858, train_loss=0.02211599238216877, time_cost=1.2212433815002441
Steps:   2%|▏         | 16523/1000000 [8:57:06<2719:00:43,  9.95s/it, lr=1e-5, step_loss=0.00446]Steps:   2%|▏         | 16524/1000000 [8:57:15<2597:06:34,  9.51s/it, lr=1e-5, step_loss=0.00446][RANK-0]: Step: [16524], local_loss=0.07014691829681396, train_loss=0.05097925662994385, time_cost=2.908005714416504
Steps:   2%|▏         | 16524/1000000 [8:57:15<2597:06:34,  9.51s/it, lr=1e-5, step_loss=0.0701] Steps:   2%|▏         | 16525/1000000 [8:57:24<2557:27:16,  9.36s/it, lr=1e-5, step_loss=0.0701][RANK-0]: Step: [16525], local_loss=0.02765352837741375, train_loss=0.16314075887203217, time_cost=3.447986364364624
Steps:   2%|▏         | 16525/1000000 [8:57:24<2557:27:16,  9.36s/it, lr=1e-5, step_loss=0.0277]Steps:   2%|▏         | 16526/1000000 [8:57:30<2267:55:08,  8.30s/it, lr=1e-5, step_loss=0.0277][RANK-0]: Step: [16526], local_loss=0.00864943116903305, train_loss=0.06787630915641785, time_cost=1.2559187412261963
Steps:   2%|▏         | 16526/1000000 [8:57:30<2267:55:08,  8.30s/it, lr=1e-5, step_loss=0.00865]Steps:   2%|▏         | 16527/1000000 [8:57:41<2520:20:01,  9.23s/it, lr=1e-5, step_loss=0.00865][RANK-0]: Step: [16527], local_loss=0.013282369822263718, train_loss=0.023801488801836967, time_cost=2.7350974082946777
Steps:   2%|▏         | 16527/1000000 [8:57:41<2520:20:01,  9.23s/it, lr=1e-5, step_loss=0.0133] Steps:   2%|▏         | 16528/1000000 [8:57:51<2592:02:31,  9.49s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [16528], local_loss=0.011933885514736176, train_loss=0.050781697034835815, time_cost=4.869368314743042
Steps:   2%|▏         | 16528/1000000 [8:57:51<2592:02:31,  9.49s/it, lr=1e-5, step_loss=0.0119]Steps:   2%|▏         | 16529/1000000 [8:58:01<2608:42:46,  9.55s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [16529], local_loss=0.06960220634937286, train_loss=0.06014690920710564, time_cost=3.497119188308716
Steps:   2%|▏         | 16529/1000000 [8:58:01<2608:42:46,  9.55s/it, lr=1e-5, step_loss=0.0696]Steps:   2%|▏         | 16530/1000000 [8:58:06<2260:24:19,  8.27s/it, lr=1e-5, step_loss=0.0696][RANK-0]: Step: [16530], local_loss=0.005725309252738953, train_loss=0.023978669196367264, time_cost=1.4207043647766113
Steps:   2%|▏         | 16530/1000000 [8:58:06<2260:24:19,  8.27s/it, lr=1e-5, step_loss=0.00573]Steps:   2%|▏         | 16531/1000000 [8:58:19<2677:39:43,  9.80s/it, lr=1e-5, step_loss=0.00573][RANK-0]: Step: [16531], local_loss=0.0072213816456496716, train_loss=0.036650728434324265, time_cost=2.213832378387451
Steps:   2%|▏         | 16531/1000000 [8:58:19<2677:39:43,  9.80s/it, lr=1e-5, step_loss=0.00722]Steps:   2%|▏         | 16532/1000000 [8:58:30<2765:50:20, 10.12s/it, lr=1e-5, step_loss=0.00722][RANK-0]: Step: [16532], local_loss=0.058625396341085434, train_loss=0.02591060847043991, time_cost=4.736733675003052
Steps:   2%|▏         | 16532/1000000 [8:58:30<2765:50:20, 10.12s/it, lr=1e-5, step_loss=0.0586] Steps:   2%|▏         | 16533/1000000 [8:58:36<2382:56:24,  8.72s/it, lr=1e-5, step_loss=0.0586][RANK-0]: Step: [16533], local_loss=0.06426967680454254, train_loss=0.024083111435174942, time_cost=2.7193353176116943
Steps:   2%|▏         | 16533/1000000 [8:58:36<2382:56:24,  8.72s/it, lr=1e-5, step_loss=0.0643]Steps:   2%|▏         | 16534/1000000 [8:58:40<2021:55:51,  7.40s/it, lr=1e-5, step_loss=0.0643][RANK-0]: Step: [16534], local_loss=0.009639411233365536, train_loss=0.07358259707689285, time_cost=1.2093322277069092
Steps:   2%|▏         | 16534/1000000 [8:58:40<2021:55:51,  7.40s/it, lr=1e-5, step_loss=0.00964]Steps:   2%|▏         | 16535/1000000 [8:58:51<2320:53:52,  8.50s/it, lr=1e-5, step_loss=0.00964][RANK-0]: Step: [16535], local_loss=0.023878732696175575, train_loss=0.0235246904194355, time_cost=3.4479072093963623
Steps:   2%|▏         | 16535/1000000 [8:58:51<2320:53:52,  8.50s/it, lr=1e-5, step_loss=0.0239] Steps:   2%|▏         | 16536/1000000 [8:58:57<2069:58:26,  7.58s/it, lr=1e-5, step_loss=0.0239][RANK-0]: Step: [16536], local_loss=0.022280994802713394, train_loss=0.026570376008749008, time_cost=2.9922993183135986
Steps:   2%|▏         | 16536/1000000 [8:58:57<2069:58:26,  7.58s/it, lr=1e-5, step_loss=0.0223]Steps:   2%|▏         | 16537/1000000 [8:59:05<2177:52:16,  7.97s/it, lr=1e-5, step_loss=0.0223][RANK-0]: Step: [16537], local_loss=0.029539624229073524, train_loss=0.16090530157089233, time_cost=1.285654067993164
Steps:   2%|▏         | 16537/1000000 [8:59:05<2177:52:16,  7.97s/it, lr=1e-5, step_loss=0.0295]Steps:   2%|▏         | 16538/1000000 [8:59:15<2342:27:14,  8.57s/it, lr=1e-5, step_loss=0.0295][RANK-0]: Step: [16538], local_loss=0.020757591351866722, train_loss=0.029680486768484116, time_cost=1.3862216472625732
Steps:   2%|▏         | 16538/1000000 [8:59:15<2342:27:14,  8.57s/it, lr=1e-5, step_loss=0.0208]Steps:   2%|▏         | 16539/1000000 [8:59:25<2399:24:25,  8.78s/it, lr=1e-5, step_loss=0.0208][RANK-0]: Step: [16539], local_loss=0.02862659841775894, train_loss=0.05949784815311432, time_cost=1.8604135513305664
Steps:   2%|▏         | 16539/1000000 [8:59:25<2399:24:25,  8.78s/it, lr=1e-5, step_loss=0.0286]Steps:   2%|▏         | 16540/1000000 [8:59:38<2780:15:55, 10.18s/it, lr=1e-5, step_loss=0.0286][RANK-0]: Step: [16540], local_loss=0.029807167127728462, train_loss=0.03198721632361412, time_cost=7.5236616134643555
Steps:   2%|▏         | 16540/1000000 [8:59:38<2780:15:55, 10.18s/it, lr=1e-5, step_loss=0.0298]Steps:   2%|▏         | 16541/1000000 [8:59:50<2931:47:06, 10.73s/it, lr=1e-5, step_loss=0.0298][RANK-0]: Step: [16541], local_loss=0.011953810229897499, train_loss=0.012831094674766064, time_cost=4.637241840362549
Steps:   2%|▏         | 16541/1000000 [8:59:50<2931:47:06, 10.73s/it, lr=1e-5, step_loss=0.012] Steps:   2%|▏         | 16542/1000000 [9:00:00<2866:37:41, 10.49s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [16542], local_loss=0.018142012879252434, train_loss=0.0489528588950634, time_cost=2.2119550704956055
Steps:   2%|▏         | 16542/1000000 [9:00:00<2866:37:41, 10.49s/it, lr=1e-5, step_loss=0.0181]Steps:   2%|▏         | 16543/1000000 [9:00:10<2792:47:13, 10.22s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [16543], local_loss=0.005766153801232576, train_loss=0.027597762644290924, time_cost=2.1034181118011475
Steps:   2%|▏         | 16543/1000000 [9:00:10<2792:47:13, 10.22s/it, lr=1e-5, step_loss=0.00577]Steps:   2%|▏         | 16544/1000000 [9:00:20<2805:32:16, 10.27s/it, lr=1e-5, step_loss=0.00577][RANK-0]: Step: [16544], local_loss=0.007146378979086876, train_loss=0.029526546597480774, time_cost=1.6826138496398926
Steps:   2%|▏         | 16544/1000000 [9:00:20<2805:32:16, 10.27s/it, lr=1e-5, step_loss=0.00715]Steps:   2%|▏         | 16545/1000000 [9:00:31<2861:42:20, 10.48s/it, lr=1e-5, step_loss=0.00715][RANK-0]: Step: [16545], local_loss=0.020864451304078102, train_loss=0.016620784997940063, time_cost=1.234689712524414
Steps:   2%|▏         | 16545/1000000 [9:00:31<2861:42:20, 10.48s/it, lr=1e-5, step_loss=0.0209] Steps:   2%|▏         | 16546/1000000 [9:00:37<2503:15:25,  9.16s/it, lr=1e-5, step_loss=0.0209][RANK-0]: Step: [16546], local_loss=0.10683639347553253, train_loss=0.049053192138671875, time_cost=1.828026533126831
Steps:   2%|▏         | 16546/1000000 [9:00:37<2503:15:25,  9.16s/it, lr=1e-5, step_loss=0.107] Steps:   2%|▏         | 16547/1000000 [9:00:48<2649:33:17,  9.70s/it, lr=1e-5, step_loss=0.107][RANK-0]: Step: [16547], local_loss=0.034382414072752, train_loss=0.026055753231048584, time_cost=3.5869858264923096
Steps:   2%|▏         | 16547/1000000 [9:00:48<2649:33:17,  9.70s/it, lr=1e-5, step_loss=0.0344]Steps:   2%|▏         | 16548/1000000 [9:00:52<2212:28:32,  8.10s/it, lr=1e-5, step_loss=0.0344][RANK-0]: Step: [16548], local_loss=0.2980528175830841, train_loss=0.08251064270734787, time_cost=1.6131713390350342
Steps:   2%|▏         | 16548/1000000 [9:00:52<2212:28:32,  8.10s/it, lr=1e-5, step_loss=0.298] Steps:   2%|▏         | 16549/1000000 [9:00:57<1959:49:21,  7.17s/it, lr=1e-5, step_loss=0.298][RANK-0]: Step: [16549], local_loss=0.05636567249894142, train_loss=0.040541451424360275, time_cost=1.953810453414917
Steps:   2%|▏         | 16549/1000000 [9:00:57<1959:49:21,  7.17s/it, lr=1e-5, step_loss=0.0564]Steps:   2%|▏         | 16550/1000000 [9:01:09<2288:05:50,  8.38s/it, lr=1e-5, step_loss=0.0564][RANK-0]: Step: [16550], local_loss=0.16472847759723663, train_loss=0.06168035417795181, time_cost=2.8597025871276855
Steps:   2%|▏         | 16550/1000000 [9:01:09<2288:05:50,  8.38s/it, lr=1e-5, step_loss=0.165] Steps:   2%|▏         | 16551/1000000 [9:01:20<2507:26:09,  9.18s/it, lr=1e-5, step_loss=0.165][RANK-0]: Step: [16551], local_loss=0.016262978315353394, train_loss=0.09330245107412338, time_cost=3.0314440727233887
Steps:   2%|▏         | 16551/1000000 [9:01:20<2507:26:09,  9.18s/it, lr=1e-5, step_loss=0.0163]Steps:   2%|▏         | 16552/1000000 [9:01:31<2668:09:10,  9.77s/it, lr=1e-5, step_loss=0.0163][RANK-0]: Step: [16552], local_loss=0.027280349284410477, train_loss=11.285633087158203, time_cost=2.8796026706695557
Steps:   2%|▏         | 16552/1000000 [9:01:31<2668:09:10,  9.77s/it, lr=1e-5, step_loss=0.0273]Steps:   2%|▏         | 16553/1000000 [9:01:42<2810:10:03, 10.29s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [16553], local_loss=0.007810753770172596, train_loss=0.03386532515287399, time_cost=4.0428173542022705
Steps:   2%|▏         | 16553/1000000 [9:01:42<2810:10:03, 10.29s/it, lr=1e-5, step_loss=0.00781]Steps:   2%|▏         | 16554/1000000 [9:01:56<3058:13:45, 11.19s/it, lr=1e-5, step_loss=0.00781][RANK-0]: Step: [16554], local_loss=0.024820946156978607, train_loss=0.09633408486843109, time_cost=4.206796646118164
Steps:   2%|▏         | 16554/1000000 [9:01:56<3058:13:45, 11.19s/it, lr=1e-5, step_loss=0.0248] Steps:   2%|▏         | 16555/1000000 [9:02:06<3015:15:42, 11.04s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [16555], local_loss=0.01592695154249668, train_loss=0.03221855312585831, time_cost=3.440464735031128
Steps:   2%|▏         | 16555/1000000 [9:02:06<3015:15:42, 11.04s/it, lr=1e-5, step_loss=0.0159]Steps:   2%|▏         | 16556/1000000 [9:02:13<2661:49:29,  9.74s/it, lr=1e-5, step_loss=0.0159][RANK-0]: Step: [16556], local_loss=0.00890253484249115, train_loss=0.028194498270750046, time_cost=2.1847968101501465
Steps:   2%|▏         | 16556/1000000 [9:02:13<2661:49:29,  9.74s/it, lr=1e-5, step_loss=0.0089]Steps:   2%|▏         | 16557/1000000 [9:02:19<2366:05:24,  8.66s/it, lr=1e-5, step_loss=0.0089][RANK-0]: Step: [16557], local_loss=0.03506670147180557, train_loss=0.04386023432016373, time_cost=2.1978602409362793
Steps:   2%|▏         | 16557/1000000 [9:02:19<2366:05:24,  8.66s/it, lr=1e-5, step_loss=0.0351]Steps:   2%|▏         | 16558/1000000 [9:02:30<2583:08:20,  9.46s/it, lr=1e-5, step_loss=0.0351][RANK-0]: Step: [16558], local_loss=0.02716142125427723, train_loss=0.15003079175949097, time_cost=2.000690221786499
Steps:   2%|▏         | 16558/1000000 [9:02:30<2583:08:20,  9.46s/it, lr=1e-5, step_loss=0.0272]Steps:   2%|▏         | 16559/1000000 [9:02:35<2173:51:36,  7.96s/it, lr=1e-5, step_loss=0.0272][RANK-0]: Step: [16559], local_loss=0.010104052722454071, train_loss=0.152497336268425, time_cost=1.2472434043884277
Steps:   2%|▏         | 16559/1000000 [9:02:35<2173:51:36,  7.96s/it, lr=1e-5, step_loss=0.0101]Steps:   2%|▏         | 16560/1000000 [9:02:44<2255:02:24,  8.25s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [16560], local_loss=0.15011471509933472, train_loss=0.051215216517448425, time_cost=2.8954765796661377
Steps:   2%|▏         | 16560/1000000 [9:02:44<2255:02:24,  8.25s/it, lr=1e-5, step_loss=0.15]  Steps:   2%|▏         | 16561/1000000 [9:02:55<2464:58:42,  9.02s/it, lr=1e-5, step_loss=0.15][RANK-0]: Step: [16561], local_loss=0.010096585378050804, train_loss=0.03330305963754654, time_cost=1.3800530433654785
Steps:   2%|▏         | 16561/1000000 [9:02:55<2464:58:42,  9.02s/it, lr=1e-5, step_loss=0.0101]Steps:   2%|▏         | 16562/1000000 [9:03:01<2227:55:56,  8.16s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [16562], local_loss=0.030331352725625038, train_loss=0.021074680611491203, time_cost=1.9820926189422607
Steps:   2%|▏         | 16562/1000000 [9:03:01<2227:55:56,  8.16s/it, lr=1e-5, step_loss=0.0303]Steps:   2%|▏         | 16563/1000000 [9:03:08<2125:27:31,  7.78s/it, lr=1e-5, step_loss=0.0303][RANK-0]: Step: [16563], local_loss=0.09584031999111176, train_loss=0.03810799494385719, time_cost=1.4542624950408936
Steps:   2%|▏         | 16563/1000000 [9:03:08<2125:27:31,  7.78s/it, lr=1e-5, step_loss=0.0958]Steps:   2%|▏         | 16564/1000000 [9:03:19<2402:26:12,  8.79s/it, lr=1e-5, step_loss=0.0958][RANK-0]: Step: [16564], local_loss=0.01731560006737709, train_loss=0.05784224718809128, time_cost=3.2131330966949463
Steps:   2%|▏         | 16564/1000000 [9:03:19<2402:26:12,  8.79s/it, lr=1e-5, step_loss=0.0173]Steps:   2%|▏         | 16565/1000000 [9:03:25<2179:59:29,  7.98s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [16565], local_loss=0.05288261920213699, train_loss=0.051271431148052216, time_cost=1.3449904918670654
Steps:   2%|▏         | 16565/1000000 [9:03:25<2179:59:29,  7.98s/it, lr=1e-5, step_loss=0.0529]Steps:   2%|▏         | 16566/1000000 [9:03:36<2470:31:16,  9.04s/it, lr=1e-5, step_loss=0.0529][RANK-0]: Step: [16566], local_loss=0.05910228192806244, train_loss=0.025825202465057373, time_cost=2.929262638092041
Steps:   2%|▏         | 16566/1000000 [9:03:36<2470:31:16,  9.04s/it, lr=1e-5, step_loss=0.0591]Steps:   2%|▏         | 16567/1000000 [9:03:47<2609:14:54,  9.55s/it, lr=1e-5, step_loss=0.0591][RANK-0]: Step: [16567], local_loss=0.007132761646062136, train_loss=0.009929566644132137, time_cost=1.520211935043335
Steps:   2%|▏         | 16567/1000000 [9:03:47<2609:14:54,  9.55s/it, lr=1e-5, step_loss=0.00713]Steps:   2%|▏         | 16568/1000000 [9:03:57<2608:23:43,  9.55s/it, lr=1e-5, step_loss=0.00713][RANK-0]: Step: [16568], local_loss=0.048416003584861755, train_loss=0.038419853895902634, time_cost=3.9953863620758057
Steps:   2%|▏         | 16568/1000000 [9:03:57<2608:23:43,  9.55s/it, lr=1e-5, step_loss=0.0484] Steps:   2%|▏         | 16569/1000000 [9:04:07<2633:37:30,  9.64s/it, lr=1e-5, step_loss=0.0484][RANK-0]: Step: [16569], local_loss=0.033714670687913895, train_loss=0.031983185559511185, time_cost=3.5345873832702637
Steps:   2%|▏         | 16569/1000000 [9:04:07<2633:37:30,  9.64s/it, lr=1e-5, step_loss=0.0337]Steps:   2%|▏         | 16570/1000000 [9:04:17<2695:18:26,  9.87s/it, lr=1e-5, step_loss=0.0337][RANK-0]: Step: [16570], local_loss=0.009059589356184006, train_loss=0.018073944374918938, time_cost=5.032722473144531
Steps:   2%|▏         | 16570/1000000 [9:04:17<2695:18:26,  9.87s/it, lr=1e-5, step_loss=0.00906]Steps:   2%|▏         | 16571/1000000 [9:04:22<2295:26:57,  8.40s/it, lr=1e-5, step_loss=0.00906][RANK-0]: Step: [16571], local_loss=0.014067311771214008, train_loss=0.041636236011981964, time_cost=1.9521350860595703
Steps:   2%|▏         | 16571/1000000 [9:04:22<2295:26:57,  8.40s/it, lr=1e-5, step_loss=0.0141] Steps:   2%|▏         | 16572/1000000 [9:04:32<2401:11:08,  8.79s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [16572], local_loss=0.2085777223110199, train_loss=0.059039875864982605, time_cost=2.14787220954895
Steps:   2%|▏         | 16572/1000000 [9:04:32<2401:11:08,  8.79s/it, lr=1e-5, step_loss=0.209] Steps:   2%|▏         | 16573/1000000 [9:04:44<2668:04:51,  9.77s/it, lr=1e-5, step_loss=0.209][RANK-0]: Step: [16573], local_loss=0.0066462317481637, train_loss=0.07010763138532639, time_cost=4.5936667919158936
Steps:   2%|▏         | 16573/1000000 [9:04:44<2668:04:51,  9.77s/it, lr=1e-5, step_loss=0.00665]Steps:   2%|▏         | 16574/1000000 [9:04:55<2779:47:45, 10.18s/it, lr=1e-5, step_loss=0.00665][RANK-0]: Step: [16574], local_loss=0.05511738732457161, train_loss=0.06478306651115417, time_cost=4.236186265945435
Steps:   2%|▏         | 16574/1000000 [9:04:55<2779:47:45, 10.18s/it, lr=1e-5, step_loss=0.0551] Steps:   2%|▏         | 16575/1000000 [9:05:03<2635:15:18,  9.65s/it, lr=1e-5, step_loss=0.0551][RANK-0]: Step: [16575], local_loss=0.13052824139595032, train_loss=0.045800670981407166, time_cost=2.666381359100342
Steps:   2%|▏         | 16575/1000000 [9:05:03<2635:15:18,  9.65s/it, lr=1e-5, step_loss=0.131] Steps:   2%|▏         | 16576/1000000 [9:05:18<3079:02:56, 11.27s/it, lr=1e-5, step_loss=0.131][RANK-0]: Step: [16576], local_loss=0.010658731684088707, train_loss=0.03682821989059448, time_cost=5.384739398956299
Steps:   2%|▏         | 16576/1000000 [9:05:18<3079:02:56, 11.27s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 16577/1000000 [9:05:32<3261:49:10, 11.94s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [16577], local_loss=0.1330166608095169, train_loss=0.03987891972064972, time_cost=5.2435462474823
Steps:   2%|▏         | 16577/1000000 [9:05:32<3261:49:10, 11.94s/it, lr=1e-5, step_loss=0.133] Steps:   2%|▏         | 16578/1000000 [9:05:44<3287:31:12, 12.03s/it, lr=1e-5, step_loss=0.133][RANK-0]: Step: [16578], local_loss=0.013139823451638222, train_loss=0.15892378985881805, time_cost=5.539158344268799
Steps:   2%|▏         | 16578/1000000 [9:05:44<3287:31:12, 12.03s/it, lr=1e-5, step_loss=0.0131]Steps:   2%|▏         | 16579/1000000 [9:05:49<2718:01:19,  9.95s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [16579], local_loss=0.006938554346561432, train_loss=0.012277822941541672, time_cost=2.6047985553741455
Steps:   2%|▏         | 16579/1000000 [9:05:49<2718:01:19,  9.95s/it, lr=1e-5, step_loss=0.00694]Steps:   2%|▏         | 16580/1000000 [9:05:54<2333:37:08,  8.54s/it, lr=1e-5, step_loss=0.00694][RANK-0]: Step: [16580], local_loss=0.023409688845276833, train_loss=0.15581536293029785, time_cost=1.4547407627105713
Steps:   2%|▏         | 16580/1000000 [9:05:54<2333:37:08,  8.54s/it, lr=1e-5, step_loss=0.0234] Steps:   2%|▏         | 16581/1000000 [9:06:00<2053:06:57,  7.52s/it, lr=1e-5, step_loss=0.0234][RANK-0]: Step: [16581], local_loss=0.06666603684425354, train_loss=0.0688629299402237, time_cost=2.165989637374878
Steps:   2%|▏         | 16581/1000000 [9:06:00<2053:06:57,  7.52s/it, lr=1e-5, step_loss=0.0667]Steps:   2%|▏         | 16582/1000000 [9:06:05<1869:13:16,  6.84s/it, lr=1e-5, step_loss=0.0667][RANK-0]: Step: [16582], local_loss=0.006667892914265394, train_loss=0.09920036792755127, time_cost=2.289513111114502
Steps:   2%|▏         | 16582/1000000 [9:06:05<1869:13:16,  6.84s/it, lr=1e-5, step_loss=0.00667]Steps:   2%|▏         | 16583/1000000 [9:06:18<2387:38:35,  8.74s/it, lr=1e-5, step_loss=0.00667][RANK-0]: Step: [16583], local_loss=0.007264938671141863, train_loss=0.08146354556083679, time_cost=6.767140626907349
Steps:   2%|▏         | 16583/1000000 [9:06:18<2387:38:35,  8.74s/it, lr=1e-5, step_loss=0.00726]Steps:   2%|▏         | 16584/1000000 [9:06:23<2044:41:30,  7.49s/it, lr=1e-5, step_loss=0.00726][RANK-0]: Step: [16584], local_loss=0.1504921317100525, train_loss=0.03217952698469162, time_cost=1.4722371101379395
Steps:   2%|▏         | 16584/1000000 [9:06:23<2044:41:30,  7.49s/it, lr=1e-5, step_loss=0.15]   Steps:   2%|▏         | 16585/1000000 [9:06:32<2201:25:19,  8.06s/it, lr=1e-5, step_loss=0.15][RANK-0]: Step: [16585], local_loss=0.38254591822624207, train_loss=0.09887725114822388, time_cost=2.289123296737671
Steps:   2%|▏         | 16585/1000000 [9:06:32<2201:25:19,  8.06s/it, lr=1e-5, step_loss=0.383]Steps:   2%|▏         | 16586/1000000 [9:06:45<2587:01:21,  9.47s/it, lr=1e-5, step_loss=0.383][RANK-0]: Step: [16586], local_loss=0.0025932725984603167, train_loss=0.7296340465545654, time_cost=3.5906665325164795
Steps:   2%|▏         | 16586/1000000 [9:06:45<2587:01:21,  9.47s/it, lr=1e-5, step_loss=0.00259]Steps:   2%|▏         | 16587/1000000 [9:06:49<2169:52:01,  7.94s/it, lr=1e-5, step_loss=0.00259][RANK-0]: Step: [16587], local_loss=0.017503630369901657, train_loss=0.014440642669796944, time_cost=1.410989761352539
Steps:   2%|▏         | 16587/1000000 [9:06:49<2169:52:01,  7.94s/it, lr=1e-5, step_loss=0.0175] Steps:   2%|▏         | 16588/1000000 [9:07:00<2408:49:32,  8.82s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [16588], local_loss=0.03708484396338463, train_loss=0.03950635343790054, time_cost=7.2039079666137695
Steps:   2%|▏         | 16588/1000000 [9:07:00<2408:49:32,  8.82s/it, lr=1e-5, step_loss=0.0371]Steps:   2%|▏         | 16589/1000000 [9:07:13<2744:15:59, 10.05s/it, lr=1e-5, step_loss=0.0371][RANK-0]: Step: [16589], local_loss=0.006414806004613638, train_loss=0.011643560603260994, time_cost=5.734370470046997
Steps:   2%|▏         | 16589/1000000 [9:07:13<2744:15:59, 10.05s/it, lr=1e-5, step_loss=0.00641]Steps:   2%|▏         | 16590/1000000 [9:07:20<2508:40:19,  9.18s/it, lr=1e-5, step_loss=0.00641][RANK-0]: Step: [16590], local_loss=0.007499582599848509, train_loss=0.018173428252339363, time_cost=1.2241246700286865
Steps:   2%|▏         | 16590/1000000 [9:07:20<2508:40:19,  9.18s/it, lr=1e-5, step_loss=0.0075] Steps:   2%|▏         | 16591/1000000 [9:07:27<2363:13:44,  8.65s/it, lr=1e-5, step_loss=0.0075][RANK-0]: Step: [16591], local_loss=0.07371185719966888, train_loss=0.037418365478515625, time_cost=1.9501557350158691
Steps:   2%|▏         | 16591/1000000 [9:07:27<2363:13:44,  8.65s/it, lr=1e-5, step_loss=0.0737]Steps:   2%|▏         | 16592/1000000 [9:07:36<2335:11:31,  8.55s/it, lr=1e-5, step_loss=0.0737][RANK-0]: Step: [16592], local_loss=0.04337455704808235, train_loss=0.14249807596206665, time_cost=4.303277254104614
Steps:   2%|▏         | 16592/1000000 [9:07:36<2335:11:31,  8.55s/it, lr=1e-5, step_loss=0.0434]Steps:   2%|▏         | 16593/1000000 [9:07:41<2040:18:02,  7.47s/it, lr=1e-5, step_loss=0.0434][RANK-0]: Step: [16593], local_loss=0.03773622587323189, train_loss=0.055390097200870514, time_cost=1.8481316566467285
Steps:   2%|▏         | 16593/1000000 [9:07:41<2040:18:02,  7.47s/it, lr=1e-5, step_loss=0.0377]Steps:   2%|▏         | 16594/1000000 [9:07:48<2000:27:23,  7.32s/it, lr=1e-5, step_loss=0.0377][RANK-0]: Step: [16594], local_loss=0.005405053496360779, train_loss=0.017990652471780777, time_cost=2.6173365116119385
Steps:   2%|▏         | 16594/1000000 [9:07:48<2000:27:23,  7.32s/it, lr=1e-5, step_loss=0.00541]Steps:   2%|▏         | 16595/1000000 [9:07:55<1990:17:43,  7.29s/it, lr=1e-5, step_loss=0.00541][RANK-0]: Step: [16595], local_loss=0.024012580513954163, train_loss=0.1060660108923912, time_cost=1.6897785663604736
Steps:   2%|▏         | 16595/1000000 [9:07:55<1990:17:43,  7.29s/it, lr=1e-5, step_loss=0.024]  Steps:   2%|▏         | 16596/1000000 [9:08:08<2469:43:38,  9.04s/it, lr=1e-5, step_loss=0.024][RANK-0]: Step: [16596], local_loss=0.021727493032813072, train_loss=0.1780611276626587, time_cost=4.4066267013549805
Steps:   2%|▏         | 16596/1000000 [9:08:08<2469:43:38,  9.04s/it, lr=1e-5, step_loss=0.0217]Steps:   2%|▏         | 16597/1000000 [9:08:19<2596:04:43,  9.50s/it, lr=1e-5, step_loss=0.0217][RANK-0]: Step: [16597], local_loss=0.017690829932689667, train_loss=0.012943247333168983, time_cost=1.5800511837005615
Steps:   2%|▏         | 16597/1000000 [9:08:19<2596:04:43,  9.50s/it, lr=1e-5, step_loss=0.0177]Steps:   2%|▏         | 16598/1000000 [9:08:24<2239:28:12,  8.20s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [16598], local_loss=0.030843645334243774, train_loss=0.03838493302464485, time_cost=2.1072323322296143
Steps:   2%|▏         | 16598/1000000 [9:08:24<2239:28:12,  8.20s/it, lr=1e-5, step_loss=0.0308]Steps:   2%|▏         | 16599/1000000 [9:08:31<2121:28:23,  7.77s/it, lr=1e-5, step_loss=0.0308][RANK-0]: Step: [16599], local_loss=0.05692361667752266, train_loss=0.043133124709129333, time_cost=2.9639475345611572
Steps:   2%|▏         | 16599/1000000 [9:08:31<2121:28:23,  7.77s/it, lr=1e-5, step_loss=0.0569]Steps:   2%|▏         | 16600/1000000 [9:08:36<1964:50:29,  7.19s/it, lr=1e-5, step_loss=0.0569][RANK-0]: Step: [16600], local_loss=0.004125652369111776, train_loss=2.596796751022339, time_cost=1.79073166847229
Steps:   2%|▏         | 16600/1000000 [9:08:36<1964:50:29,  7.19s/it, lr=1e-5, step_loss=0.00413]Steps:   2%|▏         | 16601/1000000 [9:08:49<2438:05:33,  8.93s/it, lr=1e-5, step_loss=0.00413][RANK-0]: Step: [16601], local_loss=0.004189382307231426, train_loss=0.09160975366830826, time_cost=6.6856982707977295
Steps:   2%|▏         | 16601/1000000 [9:08:49<2438:05:33,  8.93s/it, lr=1e-5, step_loss=0.00419]Steps:   2%|▏         | 16602/1000000 [9:08:57<2327:04:17,  8.52s/it, lr=1e-5, step_loss=0.00419][RANK-0]: Step: [16602], local_loss=0.0102003775537014, train_loss=0.019350629299879074, time_cost=3.0089573860168457
Steps:   2%|▏         | 16602/1000000 [9:08:57<2327:04:17,  8.52s/it, lr=1e-5, step_loss=0.0102] Steps:   2%|▏         | 16603/1000000 [9:09:09<2588:00:47,  9.47s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [16603], local_loss=0.0058608525432646275, train_loss=29.500852584838867, time_cost=1.2130327224731445
Steps:   2%|▏         | 16603/1000000 [9:09:09<2588:00:47,  9.47s/it, lr=1e-5, step_loss=0.00586]Steps:   2%|▏         | 16604/1000000 [9:09:21<2817:21:14, 10.31s/it, lr=1e-5, step_loss=0.00586][RANK-0]: Step: [16604], local_loss=0.009992925450205803, train_loss=0.043974678963422775, time_cost=6.236603021621704
Steps:   2%|▏         | 16604/1000000 [9:09:21<2817:21:14, 10.31s/it, lr=1e-5, step_loss=0.00999]Steps:   2%|▏         | 16605/1000000 [9:09:30<2741:13:43, 10.04s/it, lr=1e-5, step_loss=0.00999][RANK-0]: Step: [16605], local_loss=0.011517305858433247, train_loss=0.02985193207859993, time_cost=3.2151553630828857
Steps:   2%|▏         | 16605/1000000 [9:09:30<2741:13:43, 10.04s/it, lr=1e-5, step_loss=0.0115] Steps:   2%|▏         | 16606/1000000 [9:09:35<2279:47:04,  8.35s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [16606], local_loss=0.06662202626466751, train_loss=0.07039643079042435, time_cost=1.2535033226013184
Steps:   2%|▏         | 16606/1000000 [9:09:35<2279:47:04,  8.35s/it, lr=1e-5, step_loss=0.0666]Steps:   2%|▏         | 16607/1000000 [9:09:42<2221:23:55,  8.13s/it, lr=1e-5, step_loss=0.0666][RANK-0]: Step: [16607], local_loss=0.30198246240615845, train_loss=0.06182170286774635, time_cost=3.421272039413452
Steps:   2%|▏         | 16607/1000000 [9:09:42<2221:23:55,  8.13s/it, lr=1e-5, step_loss=0.302] Steps:   2%|▏         | 16608/1000000 [9:09:53<2464:19:29,  9.02s/it, lr=1e-5, step_loss=0.302][RANK-0]: Step: [16608], local_loss=0.008782129734754562, train_loss=0.024249214679002762, time_cost=2.3010857105255127
Steps:   2%|▏         | 16608/1000000 [9:09:53<2464:19:29,  9.02s/it, lr=1e-5, step_loss=0.00878]Steps:   2%|▏         | 16609/1000000 [9:10:03<2492:49:21,  9.13s/it, lr=1e-5, step_loss=0.00878][RANK-0]: Step: [16609], local_loss=0.009203793480992317, train_loss=0.1345265805721283, time_cost=8.000870704650879
Steps:   2%|▏         | 16609/1000000 [9:10:03<2492:49:21,  9.13s/it, lr=1e-5, step_loss=0.0092] Steps:   2%|▏         | 16610/1000000 [9:10:07<2106:59:31,  7.71s/it, lr=1e-5, step_loss=0.0092][RANK-0]: Step: [16610], local_loss=0.056258972734212875, train_loss=0.08370032906532288, time_cost=1.4058396816253662
Steps:   2%|▏         | 16610/1000000 [9:10:07<2106:59:31,  7.71s/it, lr=1e-5, step_loss=0.0563]Steps:   2%|▏         | 16611/1000000 [9:10:18<2378:28:55,  8.71s/it, lr=1e-5, step_loss=0.0563][RANK-0]: Step: [16611], local_loss=0.04233166202902794, train_loss=0.02504931017756462, time_cost=8.561306715011597
Steps:   2%|▏         | 16611/1000000 [9:10:18<2378:28:55,  8.71s/it, lr=1e-5, step_loss=0.0423]Steps:   2%|▏         | 16612/1000000 [9:10:27<2384:56:15,  8.73s/it, lr=1e-5, step_loss=0.0423][RANK-0]: Step: [16612], local_loss=0.025263654068112373, train_loss=0.01818104088306427, time_cost=5.296993017196655
Steps:   2%|▏         | 16612/1000000 [9:10:27<2384:56:15,  8.73s/it, lr=1e-5, step_loss=0.0253]Steps:   2%|▏         | 16613/1000000 [9:10:32<2075:37:15,  7.60s/it, lr=1e-5, step_loss=0.0253][RANK-0]: Step: [16613], local_loss=0.02501353807747364, train_loss=0.059804871678352356, time_cost=2.2140800952911377
Steps:   2%|▏         | 16613/1000000 [9:10:32<2075:37:15,  7.60s/it, lr=1e-5, step_loss=0.025] Steps:   2%|▏         | 16614/1000000 [9:10:43<2343:05:56,  8.58s/it, lr=1e-5, step_loss=0.025][RANK-0]: Step: [16614], local_loss=0.017290713265538216, train_loss=0.09941120445728302, time_cost=1.9396913051605225
Steps:   2%|▏         | 16614/1000000 [9:10:43<2343:05:56,  8.58s/it, lr=1e-5, step_loss=0.0173]Steps:   2%|▏         | 16615/1000000 [9:10:54<2566:59:12,  9.40s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [16615], local_loss=0.007446499075740576, train_loss=0.03691454976797104, time_cost=4.510180234909058
Steps:   2%|▏         | 16615/1000000 [9:10:54<2566:59:12,  9.40s/it, lr=1e-5, step_loss=0.00745]Steps:   2%|▏         | 16616/1000000 [9:10:59<2198:20:28,  8.05s/it, lr=1e-5, step_loss=0.00745][RANK-0]: Step: [16616], local_loss=0.006581632420420647, train_loss=0.026716426014900208, time_cost=2.167482614517212
Steps:   2%|▏         | 16616/1000000 [9:10:59<2198:20:28,  8.05s/it, lr=1e-5, step_loss=0.00658]Steps:   2%|▏         | 16617/1000000 [9:11:08<2243:51:38,  8.21s/it, lr=1e-5, step_loss=0.00658][RANK-0]: Step: [16617], local_loss=0.005956551060080528, train_loss=0.050109390169382095, time_cost=2.7155580520629883
Steps:   2%|▏         | 16617/1000000 [9:11:08<2243:51:38,  8.21s/it, lr=1e-5, step_loss=0.00596]Steps:   2%|▏         | 16618/1000000 [9:11:19<2475:48:39,  9.06s/it, lr=1e-5, step_loss=0.00596][RANK-0]: Step: [16618], local_loss=0.004511602688580751, train_loss=0.08238524198532104, time_cost=3.543886661529541
Steps:   2%|▏         | 16618/1000000 [9:11:19<2475:48:39,  9.06s/it, lr=1e-5, step_loss=0.00451]Steps:   2%|▏         | 16619/1000000 [9:11:26<2331:31:26,  8.54s/it, lr=1e-5, step_loss=0.00451][RANK-0]: Step: [16619], local_loss=0.009398188441991806, train_loss=0.03518550097942352, time_cost=1.500929594039917
Steps:   2%|▏         | 16619/1000000 [9:11:26<2331:31:26,  8.54s/it, lr=1e-5, step_loss=0.0094] Steps:   2%|▏         | 16620/1000000 [9:11:41<2867:46:57, 10.50s/it, lr=1e-5, step_loss=0.0094][RANK-0]: Step: [16620], local_loss=0.017429815605282784, train_loss=0.10092286765575409, time_cost=6.9320056438446045
Steps:   2%|▏         | 16620/1000000 [9:11:41<2867:46:57, 10.50s/it, lr=1e-5, step_loss=0.0174]Steps:   2%|▏         | 16621/1000000 [9:11:52<2867:55:39, 10.50s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [16621], local_loss=0.007026893552392721, train_loss=0.07602399587631226, time_cost=4.927107095718384
Steps:   2%|▏         | 16621/1000000 [9:11:52<2867:55:39, 10.50s/it, lr=1e-5, step_loss=0.00703]Steps:   2%|▏         | 16622/1000000 [9:12:08<3344:28:23, 12.24s/it, lr=1e-5, step_loss=0.00703][RANK-0]: Step: [16622], local_loss=0.052174344658851624, train_loss=0.04964600130915642, time_cost=8.070544242858887
Steps:   2%|▏         | 16622/1000000 [9:12:08<3344:28:23, 12.24s/it, lr=1e-5, step_loss=0.0522] Steps:   2%|▏         | 16623/1000000 [9:12:17<3073:16:51, 11.25s/it, lr=1e-5, step_loss=0.0522][RANK-0]: Step: [16623], local_loss=0.004992371425032616, train_loss=0.024133581668138504, time_cost=4.812073469161987
Steps:   2%|▏         | 16623/1000000 [9:12:17<3073:16:51, 11.25s/it, lr=1e-5, step_loss=0.00499]Steps:   2%|▏         | 16624/1000000 [9:12:24<2754:44:37, 10.08s/it, lr=1e-5, step_loss=0.00499][RANK-0]: Step: [16624], local_loss=0.025469832122325897, train_loss=0.031152775511145592, time_cost=1.2109792232513428
Steps:   2%|▏         | 16624/1000000 [9:12:24<2754:44:37, 10.08s/it, lr=1e-5, step_loss=0.0255] Steps:   2%|▏         | 16625/1000000 [9:12:33<2631:05:26,  9.63s/it, lr=1e-5, step_loss=0.0255][RANK-0]: Step: [16625], local_loss=269.57611083984375, train_loss=33.77745819091797, time_cost=1.4275588989257812
Steps:   2%|▏         | 16625/1000000 [9:12:33<2631:05:26,  9.63s/it, lr=1e-5, step_loss=270]   Steps:   2%|▏         | 16626/1000000 [9:12:46<2937:26:59, 10.75s/it, lr=1e-5, step_loss=270][RANK-0]: Step: [16626], local_loss=0.0869237557053566, train_loss=0.033627886325120926, time_cost=4.100157260894775
Steps:   2%|▏         | 16626/1000000 [9:12:46<2937:26:59, 10.75s/it, lr=1e-5, step_loss=0.0869]Steps:   2%|▏         | 16627/1000000 [9:12:54<2665:31:32,  9.76s/it, lr=1e-5, step_loss=0.0869][RANK-0]: Step: [16627], local_loss=0.008792960084974766, train_loss=0.13813090324401855, time_cost=3.1124467849731445
Steps:   2%|▏         | 16627/1000000 [9:12:54<2665:31:32,  9.76s/it, lr=1e-5, step_loss=0.00879]Steps:   2%|▏         | 16628/1000000 [9:13:06<2848:17:42, 10.43s/it, lr=1e-5, step_loss=0.00879][RANK-0]: Step: [16628], local_loss=0.03774338588118553, train_loss=0.043251883238554, time_cost=4.743778705596924
Steps:   2%|▏         | 16628/1000000 [9:13:06<2848:17:42, 10.43s/it, lr=1e-5, step_loss=0.0377] Steps:   2%|▏         | 16629/1000000 [9:13:19<3090:44:33, 11.31s/it, lr=1e-5, step_loss=0.0377][RANK-0]: Step: [16629], local_loss=0.018916480243206024, train_loss=0.015213176608085632, time_cost=4.6518473625183105
Steps:   2%|▏         | 16629/1000000 [9:13:19<3090:44:33, 11.31s/it, lr=1e-5, step_loss=0.0189]Steps:   2%|▏         | 16630/1000000 [9:13:26<2753:19:39, 10.08s/it, lr=1e-5, step_loss=0.0189][RANK-0]: Step: [16630], local_loss=0.007431524805724621, train_loss=0.14454299211502075, time_cost=2.739259719848633
Steps:   2%|▏         | 16630/1000000 [9:13:26<2753:19:39, 10.08s/it, lr=1e-5, step_loss=0.00743]Steps:   2%|▏         | 16631/1000000 [9:13:34<2555:03:36,  9.35s/it, lr=1e-5, step_loss=0.00743][RANK-0]: Step: [16631], local_loss=0.04561173543334007, train_loss=0.08726818859577179, time_cost=2.2019879817962646
Steps:   2%|▏         | 16631/1000000 [9:13:34<2555:03:36,  9.35s/it, lr=1e-5, step_loss=0.0456] Steps:   2%|▏         | 16632/1000000 [9:13:45<2682:26:09,  9.82s/it, lr=1e-5, step_loss=0.0456][RANK-0]: Step: [16632], local_loss=0.0636102631688118, train_loss=0.043417803943157196, time_cost=2.633772134780884
Steps:   2%|▏         | 16632/1000000 [9:13:45<2682:26:09,  9.82s/it, lr=1e-5, step_loss=0.0636]Steps:   2%|▏         | 16633/1000000 [9:13:52<2445:25:33,  8.95s/it, lr=1e-5, step_loss=0.0636][RANK-0]: Step: [16633], local_loss=0.00447761919349432, train_loss=0.050428468734025955, time_cost=2.5201263427734375
Steps:   2%|▏         | 16633/1000000 [9:13:52<2445:25:33,  8.95s/it, lr=1e-5, step_loss=0.00448]Steps:   2%|▏         | 16634/1000000 [9:14:03<2645:21:50,  9.68s/it, lr=1e-5, step_loss=0.00448][RANK-0]: Step: [16634], local_loss=0.016546882688999176, train_loss=0.03337008133530617, time_cost=1.2815876007080078
Steps:   2%|▏         | 16634/1000000 [9:14:03<2645:21:50,  9.68s/it, lr=1e-5, step_loss=0.0165] Steps:   2%|▏         | 16635/1000000 [9:14:15<2866:46:12, 10.49s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [16635], local_loss=0.9924830794334412, train_loss=0.1620829850435257, time_cost=4.777709245681763
Steps:   2%|▏         | 16635/1000000 [9:14:15<2866:46:12, 10.49s/it, lr=1e-5, step_loss=0.992] Steps:   2%|▏         | 16636/1000000 [9:14:23<2606:03:27,  9.54s/it, lr=1e-5, step_loss=0.992][RANK-0]: Step: [16636], local_loss=0.05920318141579628, train_loss=0.02939983829855919, time_cost=2.5814452171325684
Steps:   2%|▏         | 16636/1000000 [9:14:23<2606:03:27,  9.54s/it, lr=1e-5, step_loss=0.0592]Steps:   2%|▏         | 16637/1000000 [9:14:31<2503:30:23,  9.17s/it, lr=1e-5, step_loss=0.0592][RANK-0]: Step: [16637], local_loss=0.014471969567239285, train_loss=0.04496479034423828, time_cost=3.628870964050293
Steps:   2%|▏         | 16637/1000000 [9:14:31<2503:30:23,  9.17s/it, lr=1e-5, step_loss=0.0145]Steps:   2%|▏         | 16638/1000000 [9:14:41<2588:26:30,  9.48s/it, lr=1e-5, step_loss=0.0145][RANK-0]: Step: [16638], local_loss=0.006404878571629524, train_loss=0.024493206292390823, time_cost=1.2559418678283691
Steps:   2%|▏         | 16638/1000000 [9:14:41<2588:26:30,  9.48s/it, lr=1e-5, step_loss=0.0064]Steps:   2%|▏         | 16639/1000000 [9:14:46<2172:05:05,  7.95s/it, lr=1e-5, step_loss=0.0064][RANK-0]: Step: [16639], local_loss=0.06711854785680771, train_loss=0.08147920668125153, time_cost=1.824084758758545
Steps:   2%|▏         | 16639/1000000 [9:14:46<2172:05:05,  7.95s/it, lr=1e-5, step_loss=0.0671]Steps:   2%|▏         | 16640/1000000 [9:14:52<2031:20:20,  7.44s/it, lr=1e-5, step_loss=0.0671][RANK-0]: Step: [16640], local_loss=0.015932483598589897, train_loss=0.028220171108841896, time_cost=2.0155930519104004
Steps:   2%|▏         | 16640/1000000 [9:14:52<2031:20:20,  7.44s/it, lr=1e-5, step_loss=0.0159]Steps:   2%|▏         | 16641/1000000 [9:15:05<2526:37:35,  9.25s/it, lr=1e-5, step_loss=0.0159][RANK-0]: Step: [16641], local_loss=0.037950728088617325, train_loss=0.04332253336906433, time_cost=4.374740362167358
Steps:   2%|▏         | 16641/1000000 [9:15:05<2526:37:35,  9.25s/it, lr=1e-5, step_loss=0.038] Steps:   2%|▏         | 16642/1000000 [9:15:14<2484:35:35,  9.10s/it, lr=1e-5, step_loss=0.038][RANK-0]: Step: [16642], local_loss=0.014945205301046371, train_loss=0.10291440039873123, time_cost=2.670234441757202
Steps:   2%|▏         | 16642/1000000 [9:15:14<2484:35:35,  9.10s/it, lr=1e-5, step_loss=0.0149]Steps:   2%|▏         | 16643/1000000 [9:15:25<2607:08:03,  9.54s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [16643], local_loss=0.009873218834400177, train_loss=0.1406514197587967, time_cost=1.5607340335845947
Steps:   2%|▏         | 16643/1000000 [9:15:25<2607:08:03,  9.54s/it, lr=1e-5, step_loss=0.00987]Steps:   2%|▏         | 16644/1000000 [9:15:35<2706:19:32,  9.91s/it, lr=1e-5, step_loss=0.00987][RANK-0]: Step: [16644], local_loss=0.027698736637830734, train_loss=0.04115815460681915, time_cost=1.3065495491027832
Steps:   2%|▏         | 16644/1000000 [9:15:35<2706:19:32,  9.91s/it, lr=1e-5, step_loss=0.0277] Steps:   2%|▏         | 16645/1000000 [9:15:42<2422:25:20,  8.87s/it, lr=1e-5, step_loss=0.0277][RANK-0]: Step: [16645], local_loss=0.013688388280570507, train_loss=0.042582787573337555, time_cost=1.2287611961364746
Steps:   2%|▏         | 16645/1000000 [9:15:42<2422:25:20,  8.87s/it, lr=1e-5, step_loss=0.0137]Steps:   2%|▏         | 16646/1000000 [9:15:52<2563:43:03,  9.39s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [16646], local_loss=0.11416351050138474, train_loss=0.2542450726032257, time_cost=1.2722468376159668
Steps:   2%|▏         | 16646/1000000 [9:15:52<2563:43:03,  9.39s/it, lr=1e-5, step_loss=0.114] Steps:   2%|▏         | 16647/1000000 [9:15:57<2204:31:29,  8.07s/it, lr=1e-5, step_loss=0.114][RANK-0]: Step: [16647], local_loss=0.010883299633860588, train_loss=0.08843208849430084, time_cost=2.201861619949341
Steps:   2%|▏         | 16647/1000000 [9:15:57<2204:31:29,  8.07s/it, lr=1e-5, step_loss=0.0109]Steps:   2%|▏         | 16648/1000000 [9:16:08<2400:28:39,  8.79s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [16648], local_loss=0.006347865331918001, train_loss=0.04862990602850914, time_cost=1.827143669128418
Steps:   2%|▏         | 16648/1000000 [9:16:08<2400:28:39,  8.79s/it, lr=1e-5, step_loss=0.00635]Steps:   2%|▏         | 16649/1000000 [9:16:15<2232:38:48,  8.17s/it, lr=1e-5, step_loss=0.00635][RANK-0]: Step: [16649], local_loss=0.008788447827100754, train_loss=0.02766287699341774, time_cost=2.5632801055908203
Steps:   2%|▏         | 16649/1000000 [9:16:15<2232:38:48,  8.17s/it, lr=1e-5, step_loss=0.00879]Steps:   2%|▏         | 16650/1000000 [9:16:19<1922:46:18,  7.04s/it, lr=1e-5, step_loss=0.00879][RANK-0]: Step: [16650], local_loss=0.03760022297501564, train_loss=0.025507314130663872, time_cost=1.325289249420166
Steps:   2%|▏         | 16650/1000000 [9:16:19<1922:46:18,  7.04s/it, lr=1e-5, step_loss=0.0376] Steps:   2%|▏         | 16651/1000000 [9:16:30<2228:01:59,  8.16s/it, lr=1e-5, step_loss=0.0376][RANK-0]: Step: [16651], local_loss=0.5983874797821045, train_loss=0.11655654013156891, time_cost=2.621293783187866
Steps:   2%|▏         | 16651/1000000 [9:16:30<2228:01:59,  8.16s/it, lr=1e-5, step_loss=0.598] Steps:   2%|▏         | 16652/1000000 [9:16:40<2433:16:45,  8.91s/it, lr=1e-5, step_loss=0.598][RANK-0]: Step: [16652], local_loss=0.03644603118300438, train_loss=14.449850082397461, time_cost=3.157801389694214
Steps:   2%|▏         | 16652/1000000 [9:16:40<2433:16:45,  8.91s/it, lr=1e-5, step_loss=0.0364]Steps:   2%|▏         | 16653/1000000 [9:16:46<2140:22:11,  7.84s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [16653], local_loss=0.010497855953872204, train_loss=0.019856229424476624, time_cost=1.593909740447998
Steps:   2%|▏         | 16653/1000000 [9:16:46<2140:22:11,  7.84s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 16654/1000000 [9:16:54<2151:48:23,  7.88s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [16654], local_loss=0.02931295521557331, train_loss=0.02712557278573513, time_cost=2.00828218460083
Steps:   2%|▏         | 16654/1000000 [9:16:54<2151:48:23,  7.88s/it, lr=1e-5, step_loss=0.0293]Steps:   2%|▏         | 16655/1000000 [9:17:03<2234:30:08,  8.18s/it, lr=1e-5, step_loss=0.0293][RANK-0]: Step: [16655], local_loss=0.07255551964044571, train_loss=0.033743731677532196, time_cost=7.497137784957886
Steps:   2%|▏         | 16655/1000000 [9:17:03<2234:30:08,  8.18s/it, lr=1e-5, step_loss=0.0726]Steps:   2%|▏         | 16656/1000000 [9:17:12<2317:45:31,  8.49s/it, lr=1e-5, step_loss=0.0726][RANK-0]: Step: [16656], local_loss=0.12203739583492279, train_loss=30.880992889404297, time_cost=3.1219210624694824
Steps:   2%|▏         | 16656/1000000 [9:17:12<2317:45:31,  8.49s/it, lr=1e-5, step_loss=0.122] Steps:   2%|▏         | 16657/1000000 [9:17:16<1999:34:59,  7.32s/it, lr=1e-5, step_loss=0.122][RANK-0]: Step: [16657], local_loss=0.007181593216955662, train_loss=0.020518828183412552, time_cost=1.957671880722046
Steps:   2%|▏         | 16657/1000000 [9:17:16<1999:34:59,  7.32s/it, lr=1e-5, step_loss=0.00718]Steps:   2%|▏         | 16658/1000000 [9:17:29<2451:38:25,  8.98s/it, lr=1e-5, step_loss=0.00718][RANK-0]: Step: [16658], local_loss=0.058697499334812164, train_loss=0.024990063160657883, time_cost=4.036667346954346
Steps:   2%|▏         | 16658/1000000 [9:17:29<2451:38:25,  8.98s/it, lr=1e-5, step_loss=0.0587] Steps:   2%|▏         | 16659/1000000 [9:17:35<2208:01:30,  8.08s/it, lr=1e-5, step_loss=0.0587][RANK-0]: Step: [16659], local_loss=0.04540519416332245, train_loss=0.050465114414691925, time_cost=1.7049641609191895
Steps:   2%|▏         | 16659/1000000 [9:17:35<2208:01:30,  8.08s/it, lr=1e-5, step_loss=0.0454]Steps:   2%|▏         | 16660/1000000 [9:17:46<2431:20:55,  8.90s/it, lr=1e-5, step_loss=0.0454][RANK-0]: Step: [16660], local_loss=0.016240393742918968, train_loss=0.06632275879383087, time_cost=3.656306743621826
Steps:   2%|▏         | 16660/1000000 [9:17:46<2431:20:55,  8.90s/it, lr=1e-5, step_loss=0.0162]Steps:   2%|▏         | 16661/1000000 [9:17:53<2295:24:01,  8.40s/it, lr=1e-5, step_loss=0.0162][RANK-0]: Step: [16661], local_loss=0.007026189938187599, train_loss=0.020812558010220528, time_cost=2.742567300796509
Steps:   2%|▏         | 16661/1000000 [9:17:53<2295:24:01,  8.40s/it, lr=1e-5, step_loss=0.00703]Steps:   2%|▏         | 16662/1000000 [9:18:07<2709:32:17,  9.92s/it, lr=1e-5, step_loss=0.00703][RANK-0]: Step: [16662], local_loss=0.04687140882015228, train_loss=0.08885682374238968, time_cost=5.176695346832275
Steps:   2%|▏         | 16662/1000000 [9:18:07<2709:32:17,  9.92s/it, lr=1e-5, step_loss=0.0469] Steps:   2%|▏         | 16663/1000000 [9:18:21<3062:12:54, 11.21s/it, lr=1e-5, step_loss=0.0469][RANK-0]: Step: [16663], local_loss=0.012539751827716827, train_loss=0.029941406100988388, time_cost=7.31307053565979
Steps:   2%|▏         | 16663/1000000 [9:18:21<3062:12:54, 11.21s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 16664/1000000 [9:18:31<2990:37:02, 10.95s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [16664], local_loss=0.011549477465450764, train_loss=0.13319483399391174, time_cost=1.2189013957977295
Steps:   2%|▏         | 16664/1000000 [9:18:31<2990:37:02, 10.95s/it, lr=1e-5, step_loss=0.0115]Steps:   2%|▏         | 16665/1000000 [9:18:37<2570:32:56,  9.41s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [16665], local_loss=0.006568768061697483, train_loss=0.01709633879363537, time_cost=1.829888105392456
Steps:   2%|▏         | 16665/1000000 [9:18:37<2570:32:56,  9.41s/it, lr=1e-5, step_loss=0.00657]Steps:   2%|▏         | 16666/1000000 [9:18:45<2455:10:01,  8.99s/it, lr=1e-5, step_loss=0.00657][RANK-0]: Step: [16666], local_loss=0.01542256586253643, train_loss=0.04278060793876648, time_cost=3.996594190597534
Steps:   2%|▏         | 16666/1000000 [9:18:45<2455:10:01,  8.99s/it, lr=1e-5, step_loss=0.0154] Steps:   2%|▏         | 16667/1000000 [9:18:57<2700:43:05,  9.89s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [16667], local_loss=0.008214760571718216, train_loss=0.07532842457294464, time_cost=3.768545150756836
Steps:   2%|▏         | 16667/1000000 [9:18:57<2700:43:05,  9.89s/it, lr=1e-5, step_loss=0.00821]Steps:   2%|▏         | 16668/1000000 [9:19:07<2677:15:31,  9.80s/it, lr=1e-5, step_loss=0.00821][RANK-0]: Step: [16668], local_loss=0.0034328377805650234, train_loss=0.03329119458794594, time_cost=3.967700719833374
Steps:   2%|▏         | 16668/1000000 [9:19:07<2677:15:31,  9.80s/it, lr=1e-5, step_loss=0.00343]Steps:   2%|▏         | 16669/1000000 [9:19:14<2449:37:06,  8.97s/it, lr=1e-5, step_loss=0.00343][RANK-0]: Step: [16669], local_loss=0.015563743188977242, train_loss=0.039483293890953064, time_cost=2.696890354156494
Steps:   2%|▏         | 16669/1000000 [9:19:14<2449:37:06,  8.97s/it, lr=1e-5, step_loss=0.0156] Steps:   2%|▏         | 16670/1000000 [9:19:26<2684:48:15,  9.83s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [16670], local_loss=0.005835402756929398, train_loss=0.029932746663689613, time_cost=3.19109845161438
Steps:   2%|▏         | 16670/1000000 [9:19:26<2684:48:15,  9.83s/it, lr=1e-5, step_loss=0.00584]Steps:   2%|▏         | 16671/1000000 [9:19:31<2288:39:21,  8.38s/it, lr=1e-5, step_loss=0.00584][RANK-0]: Step: [16671], local_loss=0.008510916493833065, train_loss=0.050636932253837585, time_cost=2.024364709854126
Steps:   2%|▏         | 16671/1000000 [9:19:31<2288:39:21,  8.38s/it, lr=1e-5, step_loss=0.00851]Steps:   2%|▏         | 16672/1000000 [9:19:41<2456:47:07,  8.99s/it, lr=1e-5, step_loss=0.00851][RANK-0]: Step: [16672], local_loss=0.006012219004333019, train_loss=0.03126172348856926, time_cost=1.2610197067260742
Steps:   2%|▏         | 16672/1000000 [9:19:41<2456:47:07,  8.99s/it, lr=1e-5, step_loss=0.00601]Steps:   2%|▏         | 16673/1000000 [9:19:48<2263:40:10,  8.29s/it, lr=1e-5, step_loss=0.00601][RANK-0]: Step: [16673], local_loss=0.008043224923312664, train_loss=0.023389829322695732, time_cost=2.667156219482422
Steps:   2%|▏         | 16673/1000000 [9:19:48<2263:40:10,  8.29s/it, lr=1e-5, step_loss=0.00804]Steps:   2%|▏         | 16674/1000000 [9:19:58<2451:19:51,  8.97s/it, lr=1e-5, step_loss=0.00804][RANK-0]: Step: [16674], local_loss=0.004723475780338049, train_loss=0.0212232805788517, time_cost=1.2583637237548828
Steps:   2%|▏         | 16674/1000000 [9:19:58<2451:19:51,  8.97s/it, lr=1e-5, step_loss=0.00472]Steps:   2%|▏         | 16675/1000000 [9:20:06<2359:09:48,  8.64s/it, lr=1e-5, step_loss=0.00472][RANK-0]: Step: [16675], local_loss=0.017281372100114822, train_loss=0.0243731327354908, time_cost=3.8327410221099854
Steps:   2%|▏         | 16675/1000000 [9:20:06<2359:09:48,  8.64s/it, lr=1e-5, step_loss=0.0173] Steps:   2%|▏         | 16676/1000000 [9:20:17<2512:30:27,  9.20s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [16676], local_loss=0.023665884509682655, train_loss=0.01610809937119484, time_cost=2.0733802318573
Steps:   2%|▏         | 16676/1000000 [9:20:17<2512:30:27,  9.20s/it, lr=1e-5, step_loss=0.0237]Steps:   2%|▏         | 16677/1000000 [9:20:21<2141:52:16,  7.84s/it, lr=1e-5, step_loss=0.0237][RANK-0]: Step: [16677], local_loss=0.006823933683335781, train_loss=0.14760133624076843, time_cost=2.0769100189208984
Steps:   2%|▏         | 16677/1000000 [9:20:21<2141:52:16,  7.84s/it, lr=1e-5, step_loss=0.00682]Steps:   2%|▏         | 16678/1000000 [9:20:30<2178:04:45,  7.97s/it, lr=1e-5, step_loss=0.00682][RANK-0]: Step: [16678], local_loss=0.13406136631965637, train_loss=0.1072646751999855, time_cost=4.211560010910034
Steps:   2%|▏         | 16678/1000000 [9:20:30<2178:04:45,  7.97s/it, lr=1e-5, step_loss=0.134]  Steps:   2%|▏         | 16679/1000000 [9:20:36<2017:31:32,  7.39s/it, lr=1e-5, step_loss=0.134][RANK-0]: Step: [16679], local_loss=0.0405251607298851, train_loss=0.039150699973106384, time_cost=2.4450392723083496
Steps:   2%|▏         | 16679/1000000 [9:20:36<2017:31:32,  7.39s/it, lr=1e-5, step_loss=0.0405]Steps:   2%|▏         | 16680/1000000 [9:20:43<2042:00:58,  7.48s/it, lr=1e-5, step_loss=0.0405][RANK-0]: Step: [16680], local_loss=0.015659818425774574, train_loss=0.022668596357107162, time_cost=4.119824647903442
Steps:   2%|▏         | 16680/1000000 [9:20:43<2042:00:58,  7.48s/it, lr=1e-5, step_loss=0.0157]Steps:   2%|▏         | 16681/1000000 [9:20:57<2521:27:37,  9.23s/it, lr=1e-5, step_loss=0.0157][RANK-0]: Step: [16681], local_loss=0.03395526856184006, train_loss=0.011100495234131813, time_cost=1.2598485946655273
Steps:   2%|▏         | 16681/1000000 [9:20:57<2521:27:37,  9.23s/it, lr=1e-5, step_loss=0.034] Steps:   2%|▏         | 16682/1000000 [9:21:08<2679:13:24,  9.81s/it, lr=1e-5, step_loss=0.034][RANK-0]: Step: [16682], local_loss=0.05743171647191048, train_loss=0.026991846039891243, time_cost=1.5146892070770264
Steps:   2%|▏         | 16682/1000000 [9:21:08<2679:13:24,  9.81s/it, lr=1e-5, step_loss=0.0574]Steps:   2%|▏         | 16683/1000000 [9:21:12<2235:24:42,  8.18s/it, lr=1e-5, step_loss=0.0574][RANK-0]: Step: [16683], local_loss=0.024799806997179985, train_loss=0.015299521386623383, time_cost=1.7258210182189941
Steps:   2%|▏         | 16683/1000000 [9:21:12<2235:24:42,  8.18s/it, lr=1e-5, step_loss=0.0248]Steps:   2%|▏         | 16684/1000000 [9:21:17<1926:07:47,  7.05s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [16684], local_loss=0.007232233881950378, train_loss=0.02401462197303772, time_cost=1.479015588760376
Steps:   2%|▏         | 16684/1000000 [9:21:17<1926:07:47,  7.05s/it, lr=1e-5, step_loss=0.00723]Steps:   2%|▏         | 16685/1000000 [9:21:32<2604:51:42,  9.54s/it, lr=1e-5, step_loss=0.00723][RANK-0]: Step: [16685], local_loss=0.009838748723268509, train_loss=0.033105555921792984, time_cost=1.282691240310669
Steps:   2%|▏         | 16685/1000000 [9:21:32<2604:51:42,  9.54s/it, lr=1e-5, step_loss=0.00984]Steps:   2%|▏         | 16686/1000000 [9:21:36<2194:03:50,  8.03s/it, lr=1e-5, step_loss=0.00984][RANK-0]: Step: [16686], local_loss=0.0071304840967059135, train_loss=0.016102811321616173, time_cost=2.5311551094055176
Steps:   2%|▏         | 16686/1000000 [9:21:36<2194:03:50,  8.03s/it, lr=1e-5, step_loss=0.00713]Steps:   2%|▏         | 16687/1000000 [9:21:42<1981:57:51,  7.26s/it, lr=1e-5, step_loss=0.00713][RANK-0]: Step: [16687], local_loss=0.055742740631103516, train_loss=0.03142732381820679, time_cost=2.1115305423736572
Steps:   2%|▏         | 16687/1000000 [9:21:42<1981:57:51,  7.26s/it, lr=1e-5, step_loss=0.0557] Steps:   2%|▏         | 16688/1000000 [9:21:59<2769:11:28, 10.14s/it, lr=1e-5, step_loss=0.0557][RANK-0]: Step: [16688], local_loss=0.019709084182977676, train_loss=8.473382949829102, time_cost=8.699422836303711
Steps:   2%|▏         | 16688/1000000 [9:21:59<2769:11:28, 10.14s/it, lr=1e-5, step_loss=0.0197]Steps:   2%|▏         | 16689/1000000 [9:22:04<2356:50:12,  8.63s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [16689], local_loss=0.006794329732656479, train_loss=0.041357558220624924, time_cost=2.0918357372283936
Steps:   2%|▏         | 16689/1000000 [9:22:04<2356:50:12,  8.63s/it, lr=1e-5, step_loss=0.00679]Steps:   2%|▏         | 16690/1000000 [9:22:08<2014:14:21,  7.37s/it, lr=1e-5, step_loss=0.00679][RANK-0]: Step: [16690], local_loss=0.043353233486413956, train_loss=0.05283321440219879, time_cost=1.3936622142791748
Steps:   2%|▏         | 16690/1000000 [9:22:08<2014:14:21,  7.37s/it, lr=1e-5, step_loss=0.0434] Steps:   2%|▏         | 16691/1000000 [9:22:15<1943:39:46,  7.12s/it, lr=1e-5, step_loss=0.0434][RANK-0]: Step: [16691], local_loss=0.13679289817810059, train_loss=0.03581196069717407, time_cost=2.4930708408355713
Steps:   2%|▏         | 16691/1000000 [9:22:15<1943:39:46,  7.12s/it, lr=1e-5, step_loss=0.137] Steps:   2%|▏         | 16692/1000000 [9:22:20<1798:35:00,  6.58s/it, lr=1e-5, step_loss=0.137][RANK-0]: Step: [16692], local_loss=0.01828519068658352, train_loss=0.05647584795951843, time_cost=2.429273843765259
Steps:   2%|▏         | 16692/1000000 [9:22:20<1798:35:00,  6.58s/it, lr=1e-5, step_loss=0.0183]Steps:   2%|▏         | 16693/1000000 [9:22:34<2382:34:54,  8.72s/it, lr=1e-5, step_loss=0.0183][RANK-0]: Step: [16693], local_loss=0.29185566306114197, train_loss=0.07592322677373886, time_cost=1.2591965198516846
Steps:   2%|▏         | 16693/1000000 [9:22:34<2382:34:54,  8.72s/it, lr=1e-5, step_loss=0.292] Steps:   2%|▏         | 16694/1000000 [9:22:39<2104:31:12,  7.70s/it, lr=1e-5, step_loss=0.292][RANK-0]: Step: [16694], local_loss=1.032562494277954, train_loss=0.14299504458904266, time_cost=2.4998726844787598
Steps:   2%|▏         | 16694/1000000 [9:22:39<2104:31:12,  7.70s/it, lr=1e-5, step_loss=1.03] Steps:   2%|▏         | 16695/1000000 [9:22:47<2087:58:48,  7.64s/it, lr=1e-5, step_loss=1.03][RANK-0]: Step: [16695], local_loss=0.1211310401558876, train_loss=0.061209797859191895, time_cost=2.0440354347229004
Steps:   2%|▏         | 16695/1000000 [9:22:47<2087:58:48,  7.64s/it, lr=1e-5, step_loss=0.121]Steps:   2%|▏         | 16696/1000000 [9:22:56<2209:12:19,  8.09s/it, lr=1e-5, step_loss=0.121][RANK-0]: Step: [16696], local_loss=0.014704890549182892, train_loss=0.03910192847251892, time_cost=4.701539754867554
Steps:   2%|▏         | 16696/1000000 [9:22:56<2209:12:19,  8.09s/it, lr=1e-5, step_loss=0.0147]Steps:   2%|▏         | 16697/1000000 [9:23:07<2490:41:45,  9.12s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [16697], local_loss=0.03663244843482971, train_loss=0.022177694365382195, time_cost=4.120102405548096
Steps:   2%|▏         | 16697/1000000 [9:23:07<2490:41:45,  9.12s/it, lr=1e-5, step_loss=0.0366]Steps:   2%|▏         | 16698/1000000 [9:23:22<2943:54:07, 10.78s/it, lr=1e-5, step_loss=0.0366][RANK-0]: Step: [16698], local_loss=0.038083720952272415, train_loss=0.03200272470712662, time_cost=6.784924507141113
Steps:   2%|▏         | 16698/1000000 [9:23:22<2943:54:07, 10.78s/it, lr=1e-5, step_loss=0.0381]Steps:   2%|▏         | 16699/1000000 [9:23:34<3005:18:28, 11.00s/it, lr=1e-5, step_loss=0.0381][RANK-0]: Step: [16699], local_loss=0.021118005737662315, train_loss=0.014903565868735313, time_cost=3.041767120361328
Steps:   2%|▏         | 16699/1000000 [9:23:34<3005:18:28, 11.00s/it, lr=1e-5, step_loss=0.0211]Steps:   2%|▏         | 16700/1000000 [9:23:39<2526:05:09,  9.25s/it, lr=1e-5, step_loss=0.0211][RANK-0]: Step: [16700], local_loss=0.0444553904235363, train_loss=0.018810782581567764, time_cost=3.185209035873413
Steps:   2%|▏         | 16700/1000000 [9:23:39<2526:05:09,  9.25s/it, lr=1e-5, step_loss=0.0445]Steps:   2%|▏         | 16701/1000000 [9:23:47<2427:19:37,  8.89s/it, lr=1e-5, step_loss=0.0445][RANK-0]: Step: [16701], local_loss=0.014212939888238907, train_loss=0.11467862129211426, time_cost=4.000442266464233
Steps:   2%|▏         | 16701/1000000 [9:23:47<2427:19:37,  8.89s/it, lr=1e-5, step_loss=0.0142]Steps:   2%|▏         | 16702/1000000 [9:23:51<2060:09:25,  7.54s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [16702], local_loss=0.0665346011519432, train_loss=0.0416659414768219, time_cost=1.869870662689209
Steps:   2%|▏         | 16702/1000000 [9:23:51<2060:09:25,  7.54s/it, lr=1e-5, step_loss=0.0665]Steps:   2%|▏         | 16703/1000000 [9:23:56<1799:36:02,  6.59s/it, lr=1e-5, step_loss=0.0665][RANK-0]: Step: [16703], local_loss=0.4032750129699707, train_loss=0.070750392973423, time_cost=1.4279460906982422
Steps:   2%|▏         | 16703/1000000 [9:23:56<1799:36:02,  6.59s/it, lr=1e-5, step_loss=0.403] Steps:   2%|▏         | 16704/1000000 [9:24:00<1610:37:14,  5.90s/it, lr=1e-5, step_loss=0.403][RANK-0]: Step: [16704], local_loss=0.035276103764772415, train_loss=0.03638884425163269, time_cost=1.7382490634918213
Steps:   2%|▏         | 16704/1000000 [9:24:00<1610:37:14,  5.90s/it, lr=1e-5, step_loss=0.0353]Steps:   2%|▏         | 16705/1000000 [9:24:05<1514:07:53,  5.54s/it, lr=1e-5, step_loss=0.0353][RANK-0]: Step: [16705], local_loss=0.03396954387426376, train_loss=0.02525896392762661, time_cost=2.125235080718994
Steps:   2%|▏         | 16705/1000000 [9:24:05<1514:07:53,  5.54s/it, lr=1e-5, step_loss=0.034] Steps:   2%|▏         | 16706/1000000 [9:24:20<2337:59:56,  8.56s/it, lr=1e-5, step_loss=0.034][RANK-0]: Step: [16706], local_loss=0.03082800656557083, train_loss=0.025267219170928, time_cost=1.456507682800293
Steps:   2%|▏         | 16706/1000000 [9:24:20<2337:59:56,  8.56s/it, lr=1e-5, step_loss=0.0308]Steps:   2%|▏         | 16707/1000000 [9:24:35<2840:39:38, 10.40s/it, lr=1e-5, step_loss=0.0308][RANK-0]: Step: [16707], local_loss=0.01612509787082672, train_loss=0.008804326876997948, time_cost=5.264113426208496
Steps:   2%|▏         | 16707/1000000 [9:24:35<2840:39:38, 10.40s/it, lr=1e-5, step_loss=0.0161]Steps:   2%|▏         | 16708/1000000 [9:24:48<3044:08:43, 11.15s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [16708], local_loss=0.09613532572984695, train_loss=0.028523962944746017, time_cost=5.352964878082275
Steps:   2%|▏         | 16708/1000000 [9:24:48<3044:08:43, 11.15s/it, lr=1e-5, step_loss=0.0961]Steps:   2%|▏         | 16709/1000000 [9:25:01<3183:34:57, 11.66s/it, lr=1e-5, step_loss=0.0961][RANK-0]: Step: [16709], local_loss=0.007534536998718977, train_loss=0.026631375774741173, time_cost=4.388428211212158
Steps:   2%|▏         | 16709/1000000 [9:25:01<3183:34:57, 11.66s/it, lr=1e-5, step_loss=0.00753]Steps:   2%|▏         | 16710/1000000 [9:25:16<3481:44:24, 12.75s/it, lr=1e-5, step_loss=0.00753][RANK-0]: Step: [16710], local_loss=0.008261618204414845, train_loss=0.02705228142440319, time_cost=1.7503230571746826
Steps:   2%|▏         | 16710/1000000 [9:25:16<3481:44:24, 12.75s/it, lr=1e-5, step_loss=0.00826]Steps:   2%|▏         | 16711/1000000 [9:25:23<3006:17:45, 11.01s/it, lr=1e-5, step_loss=0.00826][RANK-0]: Step: [16711], local_loss=0.028068622574210167, train_loss=0.04004736989736557, time_cost=2.378661870956421
Steps:   2%|▏         | 16711/1000000 [9:25:23<3006:17:45, 11.01s/it, lr=1e-5, step_loss=0.0281] Steps:   2%|▏         | 16712/1000000 [9:25:30<2684:26:31,  9.83s/it, lr=1e-5, step_loss=0.0281][RANK-0]: Step: [16712], local_loss=0.008184303529560566, train_loss=0.1159413754940033, time_cost=2.7347331047058105
Steps:   2%|▏         | 16712/1000000 [9:25:30<2684:26:31,  9.83s/it, lr=1e-5, step_loss=0.00818]Steps:   2%|▏         | 16713/1000000 [9:25:44<3050:31:20, 11.17s/it, lr=1e-5, step_loss=0.00818][RANK-0]: Step: [16713], local_loss=0.005856633652001619, train_loss=0.03141357749700546, time_cost=4.05848240852356
Steps:   2%|▏         | 16713/1000000 [9:25:44<3050:31:20, 11.17s/it, lr=1e-5, step_loss=0.00586]Steps:   2%|▏         | 16714/1000000 [9:25:52<2749:00:27, 10.06s/it, lr=1e-5, step_loss=0.00586][RANK-0]: Step: [16714], local_loss=0.015682963654398918, train_loss=0.02035505324602127, time_cost=2.0178418159484863
Steps:   2%|▏         | 16714/1000000 [9:25:52<2749:00:27, 10.06s/it, lr=1e-5, step_loss=0.0157] Steps:   2%|▏         | 16715/1000000 [9:25:59<2498:16:26,  9.15s/it, lr=1e-5, step_loss=0.0157][RANK-0]: Step: [16715], local_loss=0.01441691443324089, train_loss=0.1332802176475525, time_cost=2.5003106594085693
Steps:   2%|▏         | 16715/1000000 [9:25:59<2498:16:26,  9.15s/it, lr=1e-5, step_loss=0.0144]Steps:   2%|▏         | 16716/1000000 [9:26:12<2818:13:20, 10.32s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [16716], local_loss=0.008174619637429714, train_loss=0.059327300637960434, time_cost=4.5684895515441895
Steps:   2%|▏         | 16716/1000000 [9:26:12<2818:13:20, 10.32s/it, lr=1e-5, step_loss=0.00817]Steps:   2%|▏         | 16717/1000000 [9:26:19<2553:16:18,  9.35s/it, lr=1e-5, step_loss=0.00817][RANK-0]: Step: [16717], local_loss=0.0053288135677576065, train_loss=0.1062120720744133, time_cost=2.9463279247283936
Steps:   2%|▏         | 16717/1000000 [9:26:19<2553:16:18,  9.35s/it, lr=1e-5, step_loss=0.00533]Steps:   2%|▏         | 16718/1000000 [9:26:24<2190:27:58,  8.02s/it, lr=1e-5, step_loss=0.00533][RANK-0]: Step: [16718], local_loss=0.02340766042470932, train_loss=0.022602558135986328, time_cost=1.2962751388549805
Steps:   2%|▏         | 16718/1000000 [9:26:24<2190:27:58,  8.02s/it, lr=1e-5, step_loss=0.0234] Steps:   2%|▏         | 16719/1000000 [9:26:31<2114:31:35,  7.74s/it, lr=1e-5, step_loss=0.0234][RANK-0]: Step: [16719], local_loss=0.010685491375625134, train_loss=0.058024048805236816, time_cost=2.322169303894043
Steps:   2%|▏         | 16719/1000000 [9:26:31<2114:31:35,  7.74s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 16720/1000000 [9:26:39<2148:04:32,  7.86s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [16720], local_loss=0.09139060229063034, train_loss=0.030966486781835556, time_cost=1.5492866039276123
Steps:   2%|▏         | 16720/1000000 [9:26:39<2148:04:32,  7.86s/it, lr=1e-5, step_loss=0.0914]Steps:   2%|▏         | 16721/1000000 [9:26:46<2050:29:09,  7.51s/it, lr=1e-5, step_loss=0.0914][RANK-0]: Step: [16721], local_loss=0.06138450652360916, train_loss=0.16666875779628754, time_cost=2.509408712387085
Steps:   2%|▏         | 16721/1000000 [9:26:46<2050:29:09,  7.51s/it, lr=1e-5, step_loss=0.0614]Steps:   2%|▏         | 16722/1000000 [9:26:54<2132:31:43,  7.81s/it, lr=1e-5, step_loss=0.0614][RANK-0]: Step: [16722], local_loss=0.011667544953525066, train_loss=0.02420213259756565, time_cost=4.248555898666382
Steps:   2%|▏         | 16722/1000000 [9:26:54<2132:31:43,  7.81s/it, lr=1e-5, step_loss=0.0117]Steps:   2%|▏         | 16723/1000000 [9:27:06<2435:56:27,  8.92s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [16723], local_loss=0.3933965265750885, train_loss=0.21237170696258545, time_cost=3.2687504291534424
Steps:   2%|▏         | 16723/1000000 [9:27:06<2435:56:27,  8.92s/it, lr=1e-5, step_loss=0.393] Steps:   2%|▏         | 16724/1000000 [9:27:14<2376:40:24,  8.70s/it, lr=1e-5, step_loss=0.393][RANK-0]: Step: [16724], local_loss=0.09985750913619995, train_loss=0.03187238425016403, time_cost=4.411013841629028
Steps:   2%|▏         | 16724/1000000 [9:27:14<2376:40:24,  8.70s/it, lr=1e-5, step_loss=0.0999]Steps:   2%|▏         | 16725/1000000 [9:27:27<2721:14:42,  9.96s/it, lr=1e-5, step_loss=0.0999][RANK-0]: Step: [16725], local_loss=0.005030214320868254, train_loss=0.0896601751446724, time_cost=6.952523231506348
Steps:   2%|▏         | 16725/1000000 [9:27:27<2721:14:42,  9.96s/it, lr=1e-5, step_loss=0.00503]Steps:   2%|▏         | 16726/1000000 [9:27:38<2797:43:00, 10.24s/it, lr=1e-5, step_loss=0.00503][RANK-0]: Step: [16726], local_loss=0.0030211033299565315, train_loss=0.03406774252653122, time_cost=4.900644302368164
Steps:   2%|▏         | 16726/1000000 [9:27:38<2797:43:00, 10.24s/it, lr=1e-5, step_loss=0.00302]Steps:   2%|▏         | 16727/1000000 [9:27:52<3150:57:29, 11.54s/it, lr=1e-5, step_loss=0.00302][RANK-0]: Step: [16727], local_loss=0.006039759144186974, train_loss=0.020573105663061142, time_cost=2.7480974197387695
Steps:   2%|▏         | 16727/1000000 [9:27:52<3150:57:29, 11.54s/it, lr=1e-5, step_loss=0.00604]Steps:   2%|▏         | 16728/1000000 [9:28:03<3072:42:44, 11.25s/it, lr=1e-5, step_loss=0.00604][RANK-0]: Step: [16728], local_loss=0.07444684207439423, train_loss=0.06256435811519623, time_cost=8.231023788452148
Steps:   2%|▏         | 16728/1000000 [9:28:03<3072:42:44, 11.25s/it, lr=1e-5, step_loss=0.0744] Steps:   2%|▏         | 16729/1000000 [9:28:14<3045:29:56, 11.15s/it, lr=1e-5, step_loss=0.0744][RANK-0]: Step: [16729], local_loss=0.10206957161426544, train_loss=0.05103864520788193, time_cost=8.481238603591919
Steps:   2%|▏         | 16729/1000000 [9:28:14<3045:29:56, 11.15s/it, lr=1e-5, step_loss=0.102] Steps:   2%|▏         | 16730/1000000 [9:28:19<2569:26:28,  9.41s/it, lr=1e-5, step_loss=0.102][RANK-0]: Step: [16730], local_loss=0.008682098239660263, train_loss=0.04314976930618286, time_cost=4.300201177597046
Steps:   2%|▏         | 16730/1000000 [9:28:19<2569:26:28,  9.41s/it, lr=1e-5, step_loss=0.00868]Steps:   2%|▏         | 16731/1000000 [9:28:30<2676:45:17,  9.80s/it, lr=1e-5, step_loss=0.00868][RANK-0]: Step: [16731], local_loss=0.0687393993139267, train_loss=17.50156021118164, time_cost=2.726768970489502
Steps:   2%|▏         | 16731/1000000 [9:28:30<2676:45:17,  9.80s/it, lr=1e-5, step_loss=0.0687] Steps:   2%|▏         | 16732/1000000 [9:28:41<2807:46:08, 10.28s/it, lr=1e-5, step_loss=0.0687][RANK-0]: Step: [16732], local_loss=0.0156791303306818, train_loss=0.030095968395471573, time_cost=4.486712455749512
Steps:   2%|▏         | 16732/1000000 [9:28:41<2807:46:08, 10.28s/it, lr=1e-5, step_loss=0.0157]Steps:   2%|▏         | 16733/1000000 [9:28:52<2856:00:52, 10.46s/it, lr=1e-5, step_loss=0.0157][RANK-0]: Step: [16733], local_loss=0.00901174545288086, train_loss=0.024271473288536072, time_cost=2.6341054439544678
Steps:   2%|▏         | 16733/1000000 [9:28:52<2856:00:52, 10.46s/it, lr=1e-5, step_loss=0.00901]Steps:   2%|▏         | 16734/1000000 [9:29:03<2908:28:36, 10.65s/it, lr=1e-5, step_loss=0.00901][RANK-0]: Step: [16734], local_loss=0.024137116968631744, train_loss=0.08021371066570282, time_cost=2.7397620677948
Steps:   2%|▏         | 16734/1000000 [9:29:03<2908:28:36, 10.65s/it, lr=1e-5, step_loss=0.0241] Steps:   2%|▏         | 16735/1000000 [9:29:14<2933:06:29, 10.74s/it, lr=1e-5, step_loss=0.0241][RANK-0]: Step: [16735], local_loss=0.0066161686554551125, train_loss=0.02104203775525093, time_cost=2.158210515975952
Steps:   2%|▏         | 16735/1000000 [9:29:14<2933:06:29, 10.74s/it, lr=1e-5, step_loss=0.00662]Steps:   2%|▏         | 16736/1000000 [9:29:21<2656:44:40,  9.73s/it, lr=1e-5, step_loss=0.00662][RANK-0]: Step: [16736], local_loss=0.013906541280448437, train_loss=0.09249565005302429, time_cost=1.9817430973052979
Steps:   2%|▏         | 16736/1000000 [9:29:21<2656:44:40,  9.73s/it, lr=1e-5, step_loss=0.0139] Steps:   2%|▏         | 16737/1000000 [9:29:33<2814:41:34, 10.31s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [16737], local_loss=0.010257091373205185, train_loss=0.013567986898124218, time_cost=3.274707794189453
Steps:   2%|▏         | 16737/1000000 [9:29:33<2814:41:34, 10.31s/it, lr=1e-5, step_loss=0.0103]Steps:   2%|▏         | 16738/1000000 [9:29:43<2785:00:01, 10.20s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [16738], local_loss=0.024291429668664932, train_loss=0.12123563140630722, time_cost=3.368014097213745
Steps:   2%|▏         | 16738/1000000 [9:29:43<2785:00:01, 10.20s/it, lr=1e-5, step_loss=0.0243]Steps:   2%|▏         | 16739/1000000 [9:29:54<2836:31:37, 10.39s/it, lr=1e-5, step_loss=0.0243][RANK-0]: Step: [16739], local_loss=0.007132077589631081, train_loss=0.04455076530575752, time_cost=4.432434558868408
Steps:   2%|▏         | 16739/1000000 [9:29:54<2836:31:37, 10.39s/it, lr=1e-5, step_loss=0.00713]Steps:   2%|▏         | 16740/1000000 [9:30:08<3166:10:47, 11.59s/it, lr=1e-5, step_loss=0.00713][RANK-0]: Step: [16740], local_loss=0.011640003882348537, train_loss=0.04891073331236839, time_cost=4.334892511367798
Steps:   2%|▏         | 16740/1000000 [9:30:08<3166:10:47, 11.59s/it, lr=1e-5, step_loss=0.0116] Steps:   2%|▏         | 16741/1000000 [9:30:14<2691:20:45,  9.85s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [16741], local_loss=0.01186314970254898, train_loss=0.019286688417196274, time_cost=1.244436264038086
Steps:   2%|▏         | 16741/1000000 [9:30:14<2691:20:45,  9.85s/it, lr=1e-5, step_loss=0.0119]Steps:   2%|▏         | 16742/1000000 [9:30:24<2727:43:40,  9.99s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [16742], local_loss=0.015276273712515831, train_loss=0.15222826600074768, time_cost=1.4362688064575195
Steps:   2%|▏         | 16742/1000000 [9:30:24<2727:43:40,  9.99s/it, lr=1e-5, step_loss=0.0153]Steps:   2%|▏         | 16743/1000000 [9:30:33<2647:00:50,  9.69s/it, lr=1e-5, step_loss=0.0153][RANK-0]: Step: [16743], local_loss=0.055077455937862396, train_loss=9.51279354095459, time_cost=3.0547852516174316
Steps:   2%|▏         | 16743/1000000 [9:30:33<2647:00:50,  9.69s/it, lr=1e-5, step_loss=0.0551]Steps:   2%|▏         | 16744/1000000 [9:30:44<2751:52:52, 10.08s/it, lr=1e-5, step_loss=0.0551][RANK-0]: Step: [16744], local_loss=0.0069600255228579044, train_loss=0.019482556730508804, time_cost=2.1075475215911865
Steps:   2%|▏         | 16744/1000000 [9:30:44<2751:52:52, 10.08s/it, lr=1e-5, step_loss=0.00696]Steps:   2%|▏         | 16745/1000000 [9:30:55<2815:11:54, 10.31s/it, lr=1e-5, step_loss=0.00696][RANK-0]: Step: [16745], local_loss=0.021973662078380585, train_loss=0.028857799246907234, time_cost=3.9704084396362305
Steps:   2%|▏         | 16745/1000000 [9:30:55<2815:11:54, 10.31s/it, lr=1e-5, step_loss=0.022]  Steps:   2%|▏         | 16746/1000000 [9:31:04<2673:17:51,  9.79s/it, lr=1e-5, step_loss=0.022][RANK-0]: Step: [16746], local_loss=0.032423220574855804, train_loss=0.040807321667671204, time_cost=2.8920185565948486
Steps:   2%|▏         | 16746/1000000 [9:31:04<2673:17:51,  9.79s/it, lr=1e-5, step_loss=0.0324]Steps:   2%|▏         | 16747/1000000 [9:31:15<2801:45:02, 10.26s/it, lr=1e-5, step_loss=0.0324][RANK-0]: Step: [16747], local_loss=0.052301209419965744, train_loss=0.15476666390895844, time_cost=4.028530120849609
Steps:   2%|▏         | 16747/1000000 [9:31:15<2801:45:02, 10.26s/it, lr=1e-5, step_loss=0.0523]Steps:   2%|▏         | 16748/1000000 [9:31:20<2373:28:04,  8.69s/it, lr=1e-5, step_loss=0.0523][RANK-0]: Step: [16748], local_loss=0.0537409707903862, train_loss=0.02914291061460972, time_cost=3.724008560180664
Steps:   2%|▏         | 16748/1000000 [9:31:20<2373:28:04,  8.69s/it, lr=1e-5, step_loss=0.0537]Steps:   2%|▏         | 16749/1000000 [9:31:31<2575:31:08,  9.43s/it, lr=1e-5, step_loss=0.0537][RANK-0]: Step: [16749], local_loss=0.10184481739997864, train_loss=0.07576078176498413, time_cost=8.531280994415283
Steps:   2%|▏         | 16749/1000000 [9:31:31<2575:31:08,  9.43s/it, lr=1e-5, step_loss=0.102] Steps:   2%|▏         | 16750/1000000 [9:31:44<2824:17:24, 10.34s/it, lr=1e-5, step_loss=0.102][RANK-0]: Step: [16750], local_loss=0.053282540291547775, train_loss=0.12281282991170883, time_cost=4.231473922729492
Steps:   2%|▏         | 16750/1000000 [9:31:44<2824:17:24, 10.34s/it, lr=1e-5, step_loss=0.0533]Steps:   2%|▏         | 16751/1000000 [9:31:51<2592:13:59,  9.49s/it, lr=1e-5, step_loss=0.0533][RANK-0]: Step: [16751], local_loss=0.011842862702906132, train_loss=0.02328626438975334, time_cost=3.3260385990142822
Steps:   2%|▏         | 16751/1000000 [9:31:51<2592:13:59,  9.49s/it, lr=1e-5, step_loss=0.0118]Steps:   2%|▏         | 16752/1000000 [9:32:02<2660:45:34,  9.74s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [16752], local_loss=0.011230694130063057, train_loss=0.037052348256111145, time_cost=1.919969081878662
Steps:   2%|▏         | 16752/1000000 [9:32:02<2660:45:34,  9.74s/it, lr=1e-5, step_loss=0.0112]Steps:   2%|▏         | 16753/1000000 [9:32:09<2494:10:44,  9.13s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [16753], local_loss=0.00737750343978405, train_loss=0.039951179176568985, time_cost=6.44766640663147
Steps:   2%|▏         | 16753/1000000 [9:32:09<2494:10:44,  9.13s/it, lr=1e-5, step_loss=0.00738]Steps:   2%|▏         | 16754/1000000 [9:32:20<2617:40:05,  9.58s/it, lr=1e-5, step_loss=0.00738][RANK-0]: Step: [16754], local_loss=0.089536152780056, train_loss=0.1233971118927002, time_cost=5.453103065490723
Steps:   2%|▏         | 16754/1000000 [9:32:20<2617:40:05,  9.58s/it, lr=1e-5, step_loss=0.0895] Steps:   2%|▏         | 16755/1000000 [9:32:25<2218:00:34,  8.12s/it, lr=1e-5, step_loss=0.0895][RANK-0]: Step: [16755], local_loss=0.01544836163520813, train_loss=0.030897168442606926, time_cost=1.4669954776763916
Steps:   2%|▏         | 16755/1000000 [9:32:25<2218:00:34,  8.12s/it, lr=1e-5, step_loss=0.0154]Steps:   2%|▏         | 16756/1000000 [9:32:30<1984:30:20,  7.27s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [16756], local_loss=0.1522759646177292, train_loss=0.05794680118560791, time_cost=4.357240915298462
Steps:   2%|▏         | 16756/1000000 [9:32:30<1984:30:20,  7.27s/it, lr=1e-5, step_loss=0.152] Steps:   2%|▏         | 16757/1000000 [9:32:43<2464:16:31,  9.02s/it, lr=1e-5, step_loss=0.152][RANK-0]: Step: [16757], local_loss=0.037405457347631454, train_loss=0.01851118728518486, time_cost=4.444924831390381
Steps:   2%|▏         | 16757/1000000 [9:32:43<2464:16:31,  9.02s/it, lr=1e-5, step_loss=0.0374]Steps:   2%|▏         | 16758/1000000 [9:32:58<2977:38:08, 10.90s/it, lr=1e-5, step_loss=0.0374][RANK-0]: Step: [16758], local_loss=0.006610444746911526, train_loss=0.12567254900932312, time_cost=12.367062091827393
Steps:   2%|▏         | 16758/1000000 [9:32:58<2977:38:08, 10.90s/it, lr=1e-5, step_loss=0.00661]Steps:   2%|▏         | 16759/1000000 [9:33:04<2521:29:51,  9.23s/it, lr=1e-5, step_loss=0.00661][RANK-0]: Step: [16759], local_loss=0.06733182072639465, train_loss=0.02426273003220558, time_cost=2.6668543815612793
Steps:   2%|▏         | 16759/1000000 [9:33:04<2521:29:51,  9.23s/it, lr=1e-5, step_loss=0.0673] Steps:   2%|▏         | 16760/1000000 [9:33:18<2921:27:05, 10.70s/it, lr=1e-5, step_loss=0.0673][RANK-0]: Step: [16760], local_loss=0.004448754247277975, train_loss=0.03104843571782112, time_cost=5.407621145248413
Steps:   2%|▏         | 16760/1000000 [9:33:18<2921:27:05, 10.70s/it, lr=1e-5, step_loss=0.00445]Steps:   2%|▏         | 16761/1000000 [9:33:25<2675:16:29,  9.80s/it, lr=1e-5, step_loss=0.00445][RANK-0]: Step: [16761], local_loss=0.009230563417077065, train_loss=0.02310124598443508, time_cost=3.454090118408203
Steps:   2%|▏         | 16761/1000000 [9:33:25<2675:16:29,  9.80s/it, lr=1e-5, step_loss=0.00923]Steps:   2%|▏         | 16762/1000000 [9:33:39<2999:46:04, 10.98s/it, lr=1e-5, step_loss=0.00923][RANK-0]: Step: [16762], local_loss=0.012850439175963402, train_loss=0.032849930226802826, time_cost=3.313227415084839
Steps:   2%|▏         | 16762/1000000 [9:33:39<2999:46:04, 10.98s/it, lr=1e-5, step_loss=0.0129] Steps:   2%|▏         | 16763/1000000 [9:33:53<3201:00:25, 11.72s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [16763], local_loss=0.019050363451242447, train_loss=0.011683695949614048, time_cost=11.180326700210571
Steps:   2%|▏         | 16763/1000000 [9:33:53<3201:00:25, 11.72s/it, lr=1e-5, step_loss=0.0191]Steps:   2%|▏         | 16764/1000000 [9:33:58<2656:31:26,  9.73s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [16764], local_loss=0.08376634120941162, train_loss=0.05007011443376541, time_cost=2.09238600730896
Steps:   2%|▏         | 16764/1000000 [9:33:58<2656:31:26,  9.73s/it, lr=1e-5, step_loss=0.0838]Steps:   2%|▏         | 16765/1000000 [9:34:09<2759:37:27, 10.10s/it, lr=1e-5, step_loss=0.0838][RANK-0]: Step: [16765], local_loss=0.009986914694309235, train_loss=43.87764358520508, time_cost=2.05995512008667
Steps:   2%|▏         | 16765/1000000 [9:34:09<2759:37:27, 10.10s/it, lr=1e-5, step_loss=0.00999]Steps:   2%|▏         | 16766/1000000 [9:34:14<2354:26:57,  8.62s/it, lr=1e-5, step_loss=0.00999][RANK-0]: Step: [16766], local_loss=0.02410103939473629, train_loss=0.031850527971982956, time_cost=4.007977485656738
Steps:   2%|▏         | 16766/1000000 [9:34:14<2354:26:57,  8.62s/it, lr=1e-5, step_loss=0.0241] Steps:   2%|▏         | 16767/1000000 [9:34:19<2039:12:05,  7.47s/it, lr=1e-5, step_loss=0.0241][RANK-0]: Step: [16767], local_loss=0.06371524930000305, train_loss=0.09755983203649521, time_cost=2.1998162269592285
Steps:   2%|▏         | 16767/1000000 [9:34:19<2039:12:05,  7.47s/it, lr=1e-5, step_loss=0.0637]Steps:   2%|▏         | 16768/1000000 [9:34:29<2311:54:31,  8.46s/it, lr=1e-5, step_loss=0.0637][RANK-0]: Step: [16768], local_loss=0.04489603638648987, train_loss=0.04763661324977875, time_cost=2.4516897201538086
Steps:   2%|▏         | 16768/1000000 [9:34:29<2311:54:31,  8.46s/it, lr=1e-5, step_loss=0.0449]Steps:   2%|▏         | 16769/1000000 [9:34:36<2130:35:05,  7.80s/it, lr=1e-5, step_loss=0.0449][RANK-0]: Step: [16769], local_loss=0.04873829334974289, train_loss=0.0903453528881073, time_cost=1.9340624809265137
Steps:   2%|▏         | 16769/1000000 [9:34:36<2130:35:05,  7.80s/it, lr=1e-5, step_loss=0.0487]Steps:   2%|▏         | 16770/1000000 [9:34:48<2459:18:32,  9.00s/it, lr=1e-5, step_loss=0.0487][RANK-0]: Step: [16770], local_loss=0.40413305163383484, train_loss=0.07151821255683899, time_cost=4.234816074371338
Steps:   2%|▏         | 16770/1000000 [9:34:48<2459:18:32,  9.00s/it, lr=1e-5, step_loss=0.404] Steps:   2%|▏         | 16771/1000000 [9:34:59<2643:54:47,  9.68s/it, lr=1e-5, step_loss=0.404][RANK-0]: Step: [16771], local_loss=0.008672993630170822, train_loss=0.01835986226797104, time_cost=2.2397801876068115
Steps:   2%|▏         | 16771/1000000 [9:34:59<2643:54:47,  9.68s/it, lr=1e-5, step_loss=0.00867]Steps:   2%|▏         | 16772/1000000 [9:35:12<2963:27:42, 10.85s/it, lr=1e-5, step_loss=0.00867][RANK-0]: Step: [16772], local_loss=0.11770961433649063, train_loss=0.032119378447532654, time_cost=4.0818493366241455
Steps:   2%|▏         | 16772/1000000 [9:35:12<2963:27:42, 10.85s/it, lr=1e-5, step_loss=0.118]  Steps:   2%|▏         | 16773/1000000 [9:35:19<2641:10:57,  9.67s/it, lr=1e-5, step_loss=0.118][RANK-0]: Step: [16773], local_loss=0.013976259157061577, train_loss=0.0390009805560112, time_cost=1.304187536239624
Steps:   2%|▏         | 16773/1000000 [9:35:19<2641:10:57,  9.67s/it, lr=1e-5, step_loss=0.014]Steps:   2%|▏         | 16774/1000000 [9:35:24<2228:10:03,  8.16s/it, lr=1e-5, step_loss=0.014][RANK-0]: Step: [16774], local_loss=0.006537248380482197, train_loss=0.06293796747922897, time_cost=1.6636426448822021
Steps:   2%|▏         | 16774/1000000 [9:35:24<2228:10:03,  8.16s/it, lr=1e-5, step_loss=0.00654]Steps:   2%|▏         | 16775/1000000 [9:35:36<2573:05:02,  9.42s/it, lr=1e-5, step_loss=0.00654][RANK-0]: Step: [16775], local_loss=0.4793643355369568, train_loss=0.10251877456903458, time_cost=5.002204656600952
Steps:   2%|▏         | 16775/1000000 [9:35:36<2573:05:02,  9.42s/it, lr=1e-5, step_loss=0.479]  Steps:   2%|▏         | 16776/1000000 [9:35:47<2700:28:12,  9.89s/it, lr=1e-5, step_loss=0.479][RANK-0]: Step: [16776], local_loss=0.006803826428949833, train_loss=0.07682362198829651, time_cost=3.4191577434539795
Steps:   2%|▏         | 16776/1000000 [9:35:47<2700:28:12,  9.89s/it, lr=1e-5, step_loss=0.0068]Steps:   2%|▏         | 16777/1000000 [9:35:52<2302:03:23,  8.43s/it, lr=1e-5, step_loss=0.0068][RANK-0]: Step: [16777], local_loss=0.04838457331061363, train_loss=0.028587885200977325, time_cost=2.156806468963623
Steps:   2%|▏         | 16777/1000000 [9:35:52<2302:03:23,  8.43s/it, lr=1e-5, step_loss=0.0484]Steps:   2%|▏         | 16778/1000000 [9:36:00<2219:46:35,  8.13s/it, lr=1e-5, step_loss=0.0484][RANK-0]: Step: [16778], local_loss=0.035841744393110275, train_loss=0.03181330859661102, time_cost=1.3159241676330566
Steps:   2%|▏         | 16778/1000000 [9:36:00<2219:46:35,  8.13s/it, lr=1e-5, step_loss=0.0358]Steps:   2%|▏         | 16779/1000000 [9:36:11<2507:26:11,  9.18s/it, lr=1e-5, step_loss=0.0358][RANK-0]: Step: [16779], local_loss=0.0057127755135297775, train_loss=0.031987421214580536, time_cost=3.8200299739837646
Steps:   2%|▏         | 16779/1000000 [9:36:11<2507:26:11,  9.18s/it, lr=1e-5, step_loss=0.00571]Steps:   2%|▏         | 16780/1000000 [9:36:23<2694:20:30,  9.87s/it, lr=1e-5, step_loss=0.00571][RANK-0]: Step: [16780], local_loss=0.005707768257707357, train_loss=0.010255116969347, time_cost=3.2578444480895996
Steps:   2%|▏         | 16780/1000000 [9:36:23<2694:20:30,  9.87s/it, lr=1e-5, step_loss=0.00571]Steps:   2%|▏         | 16781/1000000 [9:36:38<3162:13:09, 11.58s/it, lr=1e-5, step_loss=0.00571][RANK-0]: Step: [16781], local_loss=0.012376256287097931, train_loss=0.17261992394924164, time_cost=2.318288564682007
Steps:   2%|▏         | 16781/1000000 [9:36:38<3162:13:09, 11.58s/it, lr=1e-5, step_loss=0.0124] Steps:   2%|▏         | 16782/1000000 [9:36:54<3494:23:04, 12.79s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [16782], local_loss=0.021863162517547607, train_loss=0.04524286091327667, time_cost=6.258480548858643
Steps:   2%|▏         | 16782/1000000 [9:36:54<3494:23:04, 12.79s/it, lr=1e-5, step_loss=0.0219]Steps:   2%|▏         | 16783/1000000 [9:37:05<3371:34:29, 12.34s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [16783], local_loss=0.00971001386642456, train_loss=0.14414313435554504, time_cost=5.468006134033203
Steps:   2%|▏         | 16783/1000000 [9:37:05<3371:34:29, 12.34s/it, lr=1e-5, step_loss=0.00971]Steps:   2%|▏         | 16784/1000000 [9:37:14<3065:16:22, 11.22s/it, lr=1e-5, step_loss=0.00971][RANK-0]: Step: [16784], local_loss=0.006958866026252508, train_loss=0.03687169402837753, time_cost=1.2752981185913086
Steps:   2%|▏         | 16784/1000000 [9:37:14<3065:16:22, 11.22s/it, lr=1e-5, step_loss=0.00696]Steps:   2%|▏         | 16785/1000000 [9:37:19<2573:36:16,  9.42s/it, lr=1e-5, step_loss=0.00696][RANK-0]: Step: [16785], local_loss=0.04270552471280098, train_loss=0.028163665905594826, time_cost=2.105879545211792
Steps:   2%|▏         | 16785/1000000 [9:37:19<2573:36:16,  9.42s/it, lr=1e-5, step_loss=0.0427] Steps:   2%|▏         | 16786/1000000 [9:37:34<3043:19:29, 11.14s/it, lr=1e-5, step_loss=0.0427][RANK-0]: Step: [16786], local_loss=0.010109258815646172, train_loss=0.030748898163437843, time_cost=6.7390522956848145
Steps:   2%|▏         | 16786/1000000 [9:37:34<3043:19:29, 11.14s/it, lr=1e-5, step_loss=0.0101]Steps:   2%|▏         | 16787/1000000 [9:37:48<3272:07:06, 11.98s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [16787], local_loss=0.00830857828259468, train_loss=0.07654915004968643, time_cost=5.111815452575684
Steps:   2%|▏         | 16787/1000000 [9:37:48<3272:07:06, 11.98s/it, lr=1e-5, step_loss=0.00831]Steps:   2%|▏         | 16788/1000000 [9:38:01<3371:00:26, 12.34s/it, lr=1e-5, step_loss=0.00831][RANK-0]: Step: [16788], local_loss=0.005601187236607075, train_loss=0.04219575226306915, time_cost=4.158313512802124
Steps:   2%|▏         | 16788/1000000 [9:38:01<3371:00:26, 12.34s/it, lr=1e-5, step_loss=0.0056] Steps:   2%|▏         | 16789/1000000 [9:38:07<2779:21:08, 10.18s/it, lr=1e-5, step_loss=0.0056][RANK-0]: Step: [16789], local_loss=0.012659751810133457, train_loss=0.035357631742954254, time_cost=2.3114840984344482
Steps:   2%|▏         | 16789/1000000 [9:38:07<2779:21:08, 10.18s/it, lr=1e-5, step_loss=0.0127]Steps:   2%|▏         | 16790/1000000 [9:38:18<2901:51:51, 10.63s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [16790], local_loss=0.01799001917243004, train_loss=0.04773147404193878, time_cost=4.796350002288818
Steps:   2%|▏         | 16790/1000000 [9:38:18<2901:51:51, 10.63s/it, lr=1e-5, step_loss=0.018] Steps:   2%|▏         | 16791/1000000 [9:38:23<2427:48:08,  8.89s/it, lr=1e-5, step_loss=0.018][RANK-0]: Step: [16791], local_loss=0.0037626554258167744, train_loss=0.023886650800704956, time_cost=2.0054354667663574
Steps:   2%|▏         | 16791/1000000 [9:38:23<2427:48:08,  8.89s/it, lr=1e-5, step_loss=0.00376]Steps:   2%|▏         | 16792/1000000 [9:38:32<2421:20:50,  8.87s/it, lr=1e-5, step_loss=0.00376][RANK-0]: Step: [16792], local_loss=0.05571672320365906, train_loss=0.08401212841272354, time_cost=3.043674945831299
Steps:   2%|▏         | 16792/1000000 [9:38:32<2421:20:50,  8.87s/it, lr=1e-5, step_loss=0.0557] Steps:   2%|▏         | 16793/1000000 [9:38:39<2287:27:36,  8.38s/it, lr=1e-5, step_loss=0.0557][RANK-0]: Step: [16793], local_loss=0.011570636183023453, train_loss=0.019228797405958176, time_cost=2.707183837890625
Steps:   2%|▏         | 16793/1000000 [9:38:39<2287:27:36,  8.38s/it, lr=1e-5, step_loss=0.0116]Steps:   2%|▏         | 16794/1000000 [9:38:47<2259:33:27,  8.27s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [16794], local_loss=0.005961504764854908, train_loss=0.051545076072216034, time_cost=1.8397631645202637
Steps:   2%|▏         | 16794/1000000 [9:38:47<2259:33:27,  8.27s/it, lr=1e-5, step_loss=0.00596]Steps:   2%|▏         | 16795/1000000 [9:38:55<2222:06:20,  8.14s/it, lr=1e-5, step_loss=0.00596][RANK-0]: Step: [16795], local_loss=0.09182555973529816, train_loss=0.07961658388376236, time_cost=1.8553595542907715
Steps:   2%|▏         | 16795/1000000 [9:38:55<2222:06:20,  8.14s/it, lr=1e-5, step_loss=0.0918] Steps:   2%|▏         | 16796/1000000 [9:39:01<2086:45:16,  7.64s/it, lr=1e-5, step_loss=0.0918][RANK-0]: Step: [16796], local_loss=0.007601594086736441, train_loss=0.06365078687667847, time_cost=2.8927555084228516
Steps:   2%|▏         | 16796/1000000 [9:39:01<2086:45:16,  7.64s/it, lr=1e-5, step_loss=0.0076]Steps:   2%|▏         | 16797/1000000 [9:39:16<2637:28:32,  9.66s/it, lr=1e-5, step_loss=0.0076][RANK-0]: Step: [16797], local_loss=0.05989541485905647, train_loss=0.05645989626646042, time_cost=5.453205585479736
Steps:   2%|▏         | 16797/1000000 [9:39:16<2637:28:32,  9.66s/it, lr=1e-5, step_loss=0.0599]Steps:   2%|▏         | 16798/1000000 [9:39:25<2613:21:43,  9.57s/it, lr=1e-5, step_loss=0.0599][RANK-0]: Step: [16798], local_loss=0.011922143399715424, train_loss=0.03014635294675827, time_cost=3.4666144847869873
Steps:   2%|▏         | 16798/1000000 [9:39:25<2613:21:43,  9.57s/it, lr=1e-5, step_loss=0.0119]Steps:   2%|▏         | 16799/1000000 [9:39:36<2751:35:52, 10.08s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [16799], local_loss=0.023921573534607887, train_loss=0.026847202330827713, time_cost=5.258177042007446
Steps:   2%|▏         | 16799/1000000 [9:39:36<2751:35:52, 10.08s/it, lr=1e-5, step_loss=0.0239]Steps:   2%|▏         | 16800/1000000 [9:39:44<2508:47:48,  9.19s/it, lr=1e-5, step_loss=0.0239][RANK-0]: Step: [16800], local_loss=0.3324013948440552, train_loss=0.08026222139596939, time_cost=2.961400032043457
Steps:   2%|▏         | 16800/1000000 [9:39:44<2508:47:48,  9.19s/it, lr=1e-5, step_loss=0.332] Steps:   2%|▏         | 16801/1000000 [9:39:51<2382:42:51,  8.72s/it, lr=1e-5, step_loss=0.332][RANK-0]: Step: [16801], local_loss=0.011392779648303986, train_loss=0.040711693465709686, time_cost=6.427207946777344
Steps:   2%|▏         | 16801/1000000 [9:39:51<2382:42:51,  8.72s/it, lr=1e-5, step_loss=0.0114]Steps:   2%|▏         | 16802/1000000 [9:39:56<2045:23:30,  7.49s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [16802], local_loss=0.08959644287824631, train_loss=0.03522532060742378, time_cost=1.6509325504302979
Steps:   2%|▏         | 16802/1000000 [9:39:56<2045:23:30,  7.49s/it, lr=1e-5, step_loss=0.0896]Steps:   2%|▏         | 16803/1000000 [9:40:01<1883:55:54,  6.90s/it, lr=1e-5, step_loss=0.0896][RANK-0]: Step: [16803], local_loss=0.04277504235506058, train_loss=20.42205238342285, time_cost=2.7533226013183594
Steps:   2%|▏         | 16803/1000000 [9:40:01<1883:55:54,  6.90s/it, lr=1e-5, step_loss=0.0428]Steps:   2%|▏         | 16804/1000000 [9:40:12<2212:05:19,  8.10s/it, lr=1e-5, step_loss=0.0428][RANK-0]: Step: [16804], local_loss=0.025109801441431046, train_loss=0.054257266223430634, time_cost=1.5202417373657227
Steps:   2%|▏         | 16804/1000000 [9:40:12<2212:05:19,  8.10s/it, lr=1e-5, step_loss=0.0251]Steps:   2%|▏         | 16805/1000000 [9:40:22<2378:16:38,  8.71s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [16805], local_loss=0.008786258287727833, train_loss=0.02910982444882393, time_cost=1.9382569789886475
Steps:   2%|▏         | 16805/1000000 [9:40:22<2378:16:38,  8.71s/it, lr=1e-5, step_loss=0.00879]Steps:   2%|▏         | 16806/1000000 [9:40:34<2610:49:58,  9.56s/it, lr=1e-5, step_loss=0.00879][RANK-0]: Step: [16806], local_loss=0.11010289192199707, train_loss=0.08191250264644623, time_cost=4.094695568084717
Steps:   2%|▏         | 16806/1000000 [9:40:34<2610:49:58,  9.56s/it, lr=1e-5, step_loss=0.11]   Steps:   2%|▏         | 16807/1000000 [9:40:49<3053:01:07, 11.18s/it, lr=1e-5, step_loss=0.11][RANK-0]: Step: [16807], local_loss=0.005603412631899118, train_loss=0.05159187316894531, time_cost=1.3556382656097412
Steps:   2%|▏         | 16807/1000000 [9:40:49<3053:01:07, 11.18s/it, lr=1e-5, step_loss=0.0056]Steps:   2%|▏         | 16808/1000000 [9:40:55<2644:13:50,  9.68s/it, lr=1e-5, step_loss=0.0056][RANK-0]: Step: [16808], local_loss=0.08757942169904709, train_loss=0.0426873154938221, time_cost=1.9650661945343018
Steps:   2%|▏         | 16808/1000000 [9:40:55<2644:13:50,  9.68s/it, lr=1e-5, step_loss=0.0876]Steps:   2%|▏         | 16809/1000000 [9:41:04<2569:34:00,  9.41s/it, lr=1e-5, step_loss=0.0876][RANK-0]: Step: [16809], local_loss=0.021530376747250557, train_loss=0.1506900191307068, time_cost=2.1955230236053467
Steps:   2%|▏         | 16809/1000000 [9:41:04<2569:34:00,  9.41s/it, lr=1e-5, step_loss=0.0215]Steps:   2%|▏         | 16810/1000000 [9:41:11<2351:47:48,  8.61s/it, lr=1e-5, step_loss=0.0215][RANK-0]: Step: [16810], local_loss=0.0260374266654253, train_loss=0.031175315380096436, time_cost=2.144820213317871
Steps:   2%|▏         | 16810/1000000 [9:41:11<2351:47:48,  8.61s/it, lr=1e-5, step_loss=0.026] Steps:   2%|▏         | 16811/1000000 [9:41:21<2521:27:52,  9.23s/it, lr=1e-5, step_loss=0.026][RANK-0]: Step: [16811], local_loss=0.027981620281934738, train_loss=0.03276568651199341, time_cost=1.5657477378845215
Steps:   2%|▏         | 16811/1000000 [9:41:21<2521:27:52,  9.23s/it, lr=1e-5, step_loss=0.028]Steps:   2%|▏         | 16812/1000000 [9:41:35<2863:55:11, 10.49s/it, lr=1e-5, step_loss=0.028][RANK-0]: Step: [16812], local_loss=0.00960454810410738, train_loss=0.021926168352365494, time_cost=4.013867378234863
Steps:   2%|▏         | 16812/1000000 [9:41:35<2863:55:11, 10.49s/it, lr=1e-5, step_loss=0.0096]Steps:   2%|▏         | 16813/1000000 [9:41:43<2708:04:27,  9.92s/it, lr=1e-5, step_loss=0.0096][RANK-0]: Step: [16813], local_loss=0.0185324028134346, train_loss=0.028521373867988586, time_cost=6.6307079792022705
Steps:   2%|▏         | 16813/1000000 [9:41:43<2708:04:27,  9.92s/it, lr=1e-5, step_loss=0.0185]Steps:   2%|▏         | 16814/1000000 [9:41:59<3151:36:55, 11.54s/it, lr=1e-5, step_loss=0.0185][RANK-0]: Step: [16814], local_loss=0.04021584987640381, train_loss=0.1581101268529892, time_cost=5.753091812133789
Steps:   2%|▏         | 16814/1000000 [9:41:59<3151:36:55, 11.54s/it, lr=1e-5, step_loss=0.0402]Steps:   2%|▏         | 16815/1000000 [9:42:06<2817:22:15, 10.32s/it, lr=1e-5, step_loss=0.0402][RANK-0]: Step: [16815], local_loss=0.05369049310684204, train_loss=0.025822903960943222, time_cost=1.8541150093078613
Steps:   2%|▏         | 16815/1000000 [9:42:06<2817:22:15, 10.32s/it, lr=1e-5, step_loss=0.0537]Steps:   2%|▏         | 16816/1000000 [9:42:11<2342:51:02,  8.58s/it, lr=1e-5, step_loss=0.0537][RANK-0]: Step: [16816], local_loss=0.2819383144378662, train_loss=0.18477892875671387, time_cost=2.035111665725708
Steps:   2%|▏         | 16816/1000000 [9:42:11<2342:51:02,  8.58s/it, lr=1e-5, step_loss=0.282] Steps:   2%|▏         | 16817/1000000 [9:42:19<2375:04:07,  8.70s/it, lr=1e-5, step_loss=0.282][RANK-0]: Step: [16817], local_loss=0.00845531839877367, train_loss=0.026363667100667953, time_cost=1.5282249450683594
Steps:   2%|▏         | 16817/1000000 [9:42:19<2375:04:07,  8.70s/it, lr=1e-5, step_loss=0.00846]Steps:   2%|▏         | 16818/1000000 [9:42:31<2568:36:28,  9.41s/it, lr=1e-5, step_loss=0.00846][RANK-0]: Step: [16818], local_loss=0.48241209983825684, train_loss=0.10144326835870743, time_cost=1.3145701885223389
Steps:   2%|▏         | 16818/1000000 [9:42:31<2568:36:28,  9.41s/it, lr=1e-5, step_loss=0.482]  Steps:   2%|▏         | 16819/1000000 [9:42:42<2728:07:44,  9.99s/it, lr=1e-5, step_loss=0.482][RANK-0]: Step: [16819], local_loss=0.031051596626639366, train_loss=0.1451377272605896, time_cost=3.426945447921753
Steps:   2%|▏         | 16819/1000000 [9:42:42<2728:07:44,  9.99s/it, lr=1e-5, step_loss=0.0311]Steps:   2%|▏         | 16820/1000000 [9:42:49<2475:06:12,  9.06s/it, lr=1e-5, step_loss=0.0311][RANK-0]: Step: [16820], local_loss=0.021993456408381462, train_loss=0.15743917226791382, time_cost=2.438875436782837
Steps:   2%|▏         | 16820/1000000 [9:42:49<2475:06:12,  9.06s/it, lr=1e-5, step_loss=0.022] Steps:   2%|▏         | 16821/1000000 [9:42:55<2218:13:38,  8.12s/it, lr=1e-5, step_loss=0.022][RANK-0]: Step: [16821], local_loss=0.00481280405074358, train_loss=0.07127887010574341, time_cost=2.200249671936035
Steps:   2%|▏         | 16821/1000000 [9:42:55<2218:13:38,  8.12s/it, lr=1e-5, step_loss=0.00481]Steps:   2%|▏         | 16822/1000000 [9:43:08<2603:19:44,  9.53s/it, lr=1e-5, step_loss=0.00481][RANK-0]: Step: [16822], local_loss=0.029355734586715698, train_loss=0.0256043653935194, time_cost=5.225265741348267
Steps:   2%|▏         | 16822/1000000 [9:43:08<2603:19:44,  9.53s/it, lr=1e-5, step_loss=0.0294] Steps:   2%|▏         | 16823/1000000 [9:43:22<3021:03:21, 11.06s/it, lr=1e-5, step_loss=0.0294][RANK-0]: Step: [16823], local_loss=0.018413037061691284, train_loss=0.059719666838645935, time_cost=5.767308235168457
Steps:   2%|▏         | 16823/1000000 [9:43:22<3021:03:21, 11.06s/it, lr=1e-5, step_loss=0.0184]Steps:   2%|▏         | 16824/1000000 [9:43:34<3061:50:11, 11.21s/it, lr=1e-5, step_loss=0.0184][RANK-0]: Step: [16824], local_loss=0.01877656579017639, train_loss=0.03849131613969803, time_cost=4.042956590652466
Steps:   2%|▏         | 16824/1000000 [9:43:34<3061:50:11, 11.21s/it, lr=1e-5, step_loss=0.0188]Steps:   2%|▏         | 16825/1000000 [9:43:39<2572:44:58,  9.42s/it, lr=1e-5, step_loss=0.0188][RANK-0]: Step: [16825], local_loss=0.007430835627019405, train_loss=0.04268375039100647, time_cost=1.7605128288269043
Steps:   2%|▏         | 16825/1000000 [9:43:39<2572:44:58,  9.42s/it, lr=1e-5, step_loss=0.00743]Steps:   2%|▏         | 16826/1000000 [9:43:46<2410:08:46,  8.83s/it, lr=1e-5, step_loss=0.00743][RANK-0]: Step: [16826], local_loss=0.005725751630961895, train_loss=0.01788106933236122, time_cost=3.360121250152588
Steps:   2%|▏         | 16826/1000000 [9:43:46<2410:08:46,  8.83s/it, lr=1e-5, step_loss=0.00573]Steps:   2%|▏         | 16827/1000000 [9:43:52<2138:09:57,  7.83s/it, lr=1e-5, step_loss=0.00573][RANK-0]: Step: [16827], local_loss=0.013350785709917545, train_loss=0.032263558357954025, time_cost=2.995133638381958
Steps:   2%|▏         | 16827/1000000 [9:43:52<2138:09:57,  7.83s/it, lr=1e-5, step_loss=0.0134] Steps:   2%|▏         | 16828/1000000 [9:44:05<2569:32:48,  9.41s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [16828], local_loss=0.033674515783786774, train_loss=0.03736069053411484, time_cost=3.0437803268432617
Steps:   2%|▏         | 16828/1000000 [9:44:05<2569:32:48,  9.41s/it, lr=1e-5, step_loss=0.0337]Steps:   2%|▏         | 16829/1000000 [9:44:12<2389:48:43,  8.75s/it, lr=1e-5, step_loss=0.0337][RANK-0]: Step: [16829], local_loss=0.00837252289056778, train_loss=0.02343188226222992, time_cost=1.8829305171966553
Steps:   2%|▏         | 16829/1000000 [9:44:12<2389:48:43,  8.75s/it, lr=1e-5, step_loss=0.00837]Steps:   2%|▏         | 16830/1000000 [9:44:29<3007:53:37, 11.01s/it, lr=1e-5, step_loss=0.00837][RANK-0]: Step: [16830], local_loss=0.08464410901069641, train_loss=0.037526685744524, time_cost=8.726388216018677
Steps:   2%|▏         | 16830/1000000 [9:44:29<3007:53:37, 11.01s/it, lr=1e-5, step_loss=0.0846] Steps:   2%|▏         | 16831/1000000 [9:44:41<3095:55:15, 11.34s/it, lr=1e-5, step_loss=0.0846][RANK-0]: Step: [16831], local_loss=0.025796102359890938, train_loss=0.031265731900930405, time_cost=9.143645763397217
Steps:   2%|▏         | 16831/1000000 [9:44:41<3095:55:15, 11.34s/it, lr=1e-5, step_loss=0.0258]Steps:   2%|▏         | 16832/1000000 [9:44:52<3087:56:12, 11.31s/it, lr=1e-5, step_loss=0.0258][RANK-0]: Step: [16832], local_loss=0.04379289597272873, train_loss=0.05948416143655777, time_cost=4.154433250427246
Steps:   2%|▏         | 16832/1000000 [9:44:52<3087:56:12, 11.31s/it, lr=1e-5, step_loss=0.0438]Steps:   2%|▏         | 16833/1000000 [9:44:59<2753:42:04, 10.08s/it, lr=1e-5, step_loss=0.0438][RANK-0]: Step: [16833], local_loss=0.02130870148539543, train_loss=0.0411200113594532, time_cost=3.613234281539917
Steps:   2%|▏         | 16833/1000000 [9:44:59<2753:42:04, 10.08s/it, lr=1e-5, step_loss=0.0213]Steps:   2%|▏         | 16834/1000000 [9:45:08<2668:54:52,  9.77s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [16834], local_loss=0.004011925775557756, train_loss=0.04002797603607178, time_cost=3.5627026557922363
Steps:   2%|▏         | 16834/1000000 [9:45:08<2668:54:52,  9.77s/it, lr=1e-5, step_loss=0.00401]Steps:   2%|▏         | 16835/1000000 [9:45:16<2474:23:35,  9.06s/it, lr=1e-5, step_loss=0.00401][RANK-0]: Step: [16835], local_loss=0.004012772347778082, train_loss=4.78753662109375, time_cost=1.8745543956756592
Steps:   2%|▏         | 16835/1000000 [9:45:16<2474:23:35,  9.06s/it, lr=1e-5, step_loss=0.00401]Steps:   2%|▏         | 16836/1000000 [9:45:23<2343:03:12,  8.58s/it, lr=1e-5, step_loss=0.00401][RANK-0]: Step: [16836], local_loss=0.051347240805625916, train_loss=0.09170135110616684, time_cost=1.448800802230835
Steps:   2%|▏         | 16836/1000000 [9:45:23<2343:03:12,  8.58s/it, lr=1e-5, step_loss=0.0513] Steps:   2%|▏         | 16837/1000000 [9:45:29<2121:37:13,  7.77s/it, lr=1e-5, step_loss=0.0513][RANK-0]: Step: [16837], local_loss=0.015141066163778305, train_loss=0.021987877786159515, time_cost=1.2713675498962402
Steps:   2%|▏         | 16837/1000000 [9:45:29<2121:37:13,  7.77s/it, lr=1e-5, step_loss=0.0151]Steps:   2%|▏         | 16838/1000000 [9:45:40<2389:46:34,  8.75s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [16838], local_loss=0.027295999228954315, train_loss=0.04938770830631256, time_cost=3.148534059524536
Steps:   2%|▏         | 16838/1000000 [9:45:40<2389:46:34,  8.75s/it, lr=1e-5, step_loss=0.0273]Steps:   2%|▏         | 16839/1000000 [9:45:49<2406:43:41,  8.81s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [16839], local_loss=170.931884765625, train_loss=21.45111656188965, time_cost=3.0836100578308105
Steps:   2%|▏         | 16839/1000000 [9:45:49<2406:43:41,  8.81s/it, lr=1e-5, step_loss=171]   Steps:   2%|▏         | 16840/1000000 [9:45:59<2527:53:38,  9.26s/it, lr=1e-5, step_loss=171][RANK-0]: Step: [16840], local_loss=0.02854694426059723, train_loss=0.06500832736492157, time_cost=4.700765132904053
Steps:   2%|▏         | 16840/1000000 [9:45:59<2527:53:38,  9.26s/it, lr=1e-5, step_loss=0.0285]Steps:   2%|▏         | 16841/1000000 [9:46:08<2508:14:04,  9.18s/it, lr=1e-5, step_loss=0.0285][RANK-0]: Step: [16841], local_loss=0.03218662366271019, train_loss=0.034185826778411865, time_cost=3.1751554012298584
Steps:   2%|▏         | 16841/1000000 [9:46:08<2508:14:04,  9.18s/it, lr=1e-5, step_loss=0.0322]Steps:   2%|▏         | 16842/1000000 [9:46:18<2566:36:16,  9.40s/it, lr=1e-5, step_loss=0.0322][RANK-0]: Step: [16842], local_loss=0.010663144290447235, train_loss=0.029430285096168518, time_cost=3.668519973754883
Steps:   2%|▏         | 16842/1000000 [9:46:18<2566:36:16,  9.40s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 16843/1000000 [9:46:25<2389:32:39,  8.75s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [16843], local_loss=0.04512270912528038, train_loss=0.048517532646656036, time_cost=1.4021046161651611
Steps:   2%|▏         | 16843/1000000 [9:46:25<2389:32:39,  8.75s/it, lr=1e-5, step_loss=0.0451]Steps:   2%|▏         | 16844/1000000 [9:46:30<2090:18:39,  7.65s/it, lr=1e-5, step_loss=0.0451][RANK-0]: Step: [16844], local_loss=0.017505407333374023, train_loss=0.01906895637512207, time_cost=3.8089826107025146
Steps:   2%|▏         | 16844/1000000 [9:46:30<2090:18:39,  7.65s/it, lr=1e-5, step_loss=0.0175]Steps:   2%|▏         | 16845/1000000 [9:46:36<1893:59:15,  6.94s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [16845], local_loss=0.029879160225391388, train_loss=0.04277973249554634, time_cost=2.216287612915039
Steps:   2%|▏         | 16845/1000000 [9:46:36<1893:59:15,  6.94s/it, lr=1e-5, step_loss=0.0299]Steps:   2%|▏         | 16846/1000000 [9:46:51<2558:33:27,  9.37s/it, lr=1e-5, step_loss=0.0299][RANK-0]: Step: [16846], local_loss=52.886451721191406, train_loss=6.629560470581055, time_cost=6.795530319213867
Steps:   2%|▏         | 16846/1000000 [9:46:51<2558:33:27,  9.37s/it, lr=1e-5, step_loss=52.9]  Steps:   2%|▏         | 16847/1000000 [9:46:55<2167:15:53,  7.94s/it, lr=1e-5, step_loss=52.9][RANK-0]: Step: [16847], local_loss=0.009143337607383728, train_loss=0.027794163674116135, time_cost=2.0056350231170654
Steps:   2%|▏         | 16847/1000000 [9:46:55<2167:15:53,  7.94s/it, lr=1e-5, step_loss=0.00914]Steps:   2%|▏         | 16848/1000000 [9:47:12<2867:58:08, 10.50s/it, lr=1e-5, step_loss=0.00914][RANK-0]: Step: [16848], local_loss=0.019628874957561493, train_loss=0.051183588802814484, time_cost=6.825024366378784
Steps:   2%|▏         | 16848/1000000 [9:47:12<2867:58:08, 10.50s/it, lr=1e-5, step_loss=0.0196] Steps:   2%|▏         | 16849/1000000 [9:47:20<2713:15:06,  9.94s/it, lr=1e-5, step_loss=0.0196][RANK-0]: Step: [16849], local_loss=0.04522543400526047, train_loss=0.020490597933530807, time_cost=6.14904522895813
Steps:   2%|▏         | 16849/1000000 [9:47:20<2713:15:06,  9.94s/it, lr=1e-5, step_loss=0.0452]Steps:   2%|▏         | 16850/1000000 [9:47:33<2962:46:35, 10.85s/it, lr=1e-5, step_loss=0.0452][RANK-0]: Step: [16850], local_loss=0.020612619817256927, train_loss=0.03838159143924713, time_cost=4.009426116943359
Steps:   2%|▏         | 16850/1000000 [9:47:33<2962:46:35, 10.85s/it, lr=1e-5, step_loss=0.0206]Steps:   2%|▏         | 16851/1000000 [9:47:38<2483:32:46,  9.09s/it, lr=1e-5, step_loss=0.0206][RANK-0]: Step: [16851], local_loss=0.03452795743942261, train_loss=0.03365089371800423, time_cost=2.4661507606506348
Steps:   2%|▏         | 16851/1000000 [9:47:38<2483:32:46,  9.09s/it, lr=1e-5, step_loss=0.0345]Steps:   2%|▏         | 16852/1000000 [9:47:49<2616:10:02,  9.58s/it, lr=1e-5, step_loss=0.0345][RANK-0]: Step: [16852], local_loss=0.004831231664866209, train_loss=0.03692338615655899, time_cost=1.614769458770752
Steps:   2%|▏         | 16852/1000000 [9:47:49<2616:10:02,  9.58s/it, lr=1e-5, step_loss=0.00483]Steps:   2%|▏         | 16853/1000000 [9:48:03<2959:26:26, 10.84s/it, lr=1e-5, step_loss=0.00483][RANK-0]: Step: [16853], local_loss=0.010134914889931679, train_loss=0.020482193678617477, time_cost=5.618640661239624
Steps:   2%|▏         | 16853/1000000 [9:48:03<2959:26:26, 10.84s/it, lr=1e-5, step_loss=0.0101] Steps:   2%|▏         | 16854/1000000 [9:48:15<3086:12:54, 11.30s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [16854], local_loss=0.007224433124065399, train_loss=0.0160696841776371, time_cost=8.71878981590271
Steps:   2%|▏         | 16854/1000000 [9:48:15<3086:12:54, 11.30s/it, lr=1e-5, step_loss=0.00722]Steps:   2%|▏         | 16855/1000000 [9:48:27<3122:07:14, 11.43s/it, lr=1e-5, step_loss=0.00722][RANK-0]: Step: [16855], local_loss=0.1981453150510788, train_loss=0.06649823486804962, time_cost=2.9005184173583984
Steps:   2%|▏         | 16855/1000000 [9:48:27<3122:07:14, 11.43s/it, lr=1e-5, step_loss=0.198]  Steps:   2%|▏         | 16856/1000000 [9:48:42<3440:18:00, 12.60s/it, lr=1e-5, step_loss=0.198][RANK-0]: Step: [16856], local_loss=0.00821330863982439, train_loss=0.016429714858531952, time_cost=6.076308727264404
Steps:   2%|▏         | 16856/1000000 [9:48:42<3440:18:00, 12.60s/it, lr=1e-5, step_loss=0.00821]Steps:   2%|▏         | 16857/1000000 [9:48:53<3293:11:20, 12.06s/it, lr=1e-5, step_loss=0.00821][RANK-0]: Step: [16857], local_loss=0.014148414134979248, train_loss=0.015206672251224518, time_cost=1.489661693572998
Steps:   2%|▏         | 16857/1000000 [9:48:53<3293:11:20, 12.06s/it, lr=1e-5, step_loss=0.0141] Steps:   2%|▏         | 16858/1000000 [9:49:02<3040:34:40, 11.13s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [16858], local_loss=0.021900424733757973, train_loss=0.023979410529136658, time_cost=2.6817128658294678
Steps:   2%|▏         | 16858/1000000 [9:49:02<3040:34:40, 11.13s/it, lr=1e-5, step_loss=0.0219]Steps:   2%|▏         | 16859/1000000 [9:49:07<2538:31:07,  9.30s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [16859], local_loss=0.00392699521034956, train_loss=0.03106461837887764, time_cost=3.7970292568206787
Steps:   2%|▏         | 16859/1000000 [9:49:07<2538:31:07,  9.30s/it, lr=1e-5, step_loss=0.00393]Steps:   2%|▏         | 16860/1000000 [9:49:14<2380:08:03,  8.72s/it, lr=1e-5, step_loss=0.00393][RANK-0]: Step: [16860], local_loss=0.023158259689807892, train_loss=0.0281795933842659, time_cost=5.46075177192688
Steps:   2%|▏         | 16860/1000000 [9:49:14<2380:08:03,  8.72s/it, lr=1e-5, step_loss=0.0232] Steps:   2%|▏         | 16861/1000000 [9:49:26<2578:38:10,  9.44s/it, lr=1e-5, step_loss=0.0232][RANK-0]: Step: [16861], local_loss=0.055632948875427246, train_loss=0.03614193573594093, time_cost=4.642180442810059
Steps:   2%|▏         | 16861/1000000 [9:49:26<2578:38:10,  9.44s/it, lr=1e-5, step_loss=0.0556]Steps:   2%|▏         | 16862/1000000 [9:49:40<2953:38:54, 10.82s/it, lr=1e-5, step_loss=0.0556][RANK-0]: Step: [16862], local_loss=0.3921395540237427, train_loss=0.06163328140974045, time_cost=5.152036666870117
Steps:   2%|▏         | 16862/1000000 [9:49:40<2953:38:54, 10.82s/it, lr=1e-5, step_loss=0.392] Steps:   2%|▏         | 16863/1000000 [9:49:46<2604:55:31,  9.54s/it, lr=1e-5, step_loss=0.392][RANK-0]: Step: [16863], local_loss=0.014069970697164536, train_loss=0.07852346450090408, time_cost=1.2273006439208984
Steps:   2%|▏         | 16863/1000000 [9:49:46<2604:55:31,  9.54s/it, lr=1e-5, step_loss=0.0141]Steps:   2%|▏         | 16864/1000000 [9:49:52<2313:13:15,  8.47s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [16864], local_loss=0.0075039733201265335, train_loss=0.04404452443122864, time_cost=1.632190227508545
Steps:   2%|▏         | 16864/1000000 [9:49:52<2313:13:15,  8.47s/it, lr=1e-5, step_loss=0.0075]Steps:   2%|▏         | 16865/1000000 [9:50:04<2609:07:42,  9.55s/it, lr=1e-5, step_loss=0.0075][RANK-0]: Step: [16865], local_loss=0.010401898995041847, train_loss=0.057674430310726166, time_cost=5.265295743942261
Steps:   2%|▏         | 16865/1000000 [9:50:04<2609:07:42,  9.55s/it, lr=1e-5, step_loss=0.0104]Steps:   2%|▏         | 16866/1000000 [9:50:11<2413:34:29,  8.84s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [16866], local_loss=0.03416110575199127, train_loss=0.03597057983279228, time_cost=1.3939368724822998
Steps:   2%|▏         | 16866/1000000 [9:50:11<2413:34:29,  8.84s/it, lr=1e-5, step_loss=0.0342]Steps:   2%|▏         | 16867/1000000 [9:50:20<2393:10:25,  8.76s/it, lr=1e-5, step_loss=0.0342][RANK-0]: Step: [16867], local_loss=0.018306812271475792, train_loss=0.19290317595005035, time_cost=1.2359473705291748
Steps:   2%|▏         | 16867/1000000 [9:50:20<2393:10:25,  8.76s/it, lr=1e-5, step_loss=0.0183]Steps:   2%|▏         | 16868/1000000 [9:50:30<2456:05:33,  8.99s/it, lr=1e-5, step_loss=0.0183][RANK-0]: Step: [16868], local_loss=0.004973333328962326, train_loss=0.03236265480518341, time_cost=3.1873931884765625
Steps:   2%|▏         | 16868/1000000 [9:50:30<2456:05:33,  8.99s/it, lr=1e-5, step_loss=0.00497]Steps:   2%|▏         | 16869/1000000 [9:50:40<2558:38:54,  9.37s/it, lr=1e-5, step_loss=0.00497][RANK-0]: Step: [16869], local_loss=0.014814160764217377, train_loss=0.04245396703481674, time_cost=2.5796525478363037
Steps:   2%|▏         | 16869/1000000 [9:50:40<2558:38:54,  9.37s/it, lr=1e-5, step_loss=0.0148] Steps:   2%|▏         | 16870/1000000 [9:50:44<2134:33:23,  7.82s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [16870], local_loss=0.005035326350480318, train_loss=0.034070782363414764, time_cost=1.6015634536743164
Steps:   2%|▏         | 16870/1000000 [9:50:44<2134:33:23,  7.82s/it, lr=1e-5, step_loss=0.00504]Steps:   2%|▏         | 16871/1000000 [9:50:56<2520:30:07,  9.23s/it, lr=1e-5, step_loss=0.00504][RANK-0]: Step: [16871], local_loss=0.005238727200776339, train_loss=0.06129710003733635, time_cost=4.917575120925903
Steps:   2%|▏         | 16871/1000000 [9:50:56<2520:30:07,  9.23s/it, lr=1e-5, step_loss=0.00524]Steps:   2%|▏         | 16872/1000000 [9:51:04<2402:14:12,  8.80s/it, lr=1e-5, step_loss=0.00524][RANK-0]: Step: [16872], local_loss=0.040414948016405106, train_loss=0.05163487046957016, time_cost=1.2130708694458008
Steps:   2%|▏         | 16872/1000000 [9:51:04<2402:14:12,  8.80s/it, lr=1e-5, step_loss=0.0404] Steps:   2%|▏         | 16873/1000000 [9:51:09<2104:44:25,  7.71s/it, lr=1e-5, step_loss=0.0404][RANK-0]: Step: [16873], local_loss=0.0714605525135994, train_loss=0.07454252243041992, time_cost=1.5736477375030518
Steps:   2%|▏         | 16873/1000000 [9:51:09<2104:44:25,  7.71s/it, lr=1e-5, step_loss=0.0715]Steps:   2%|▏         | 16874/1000000 [9:51:19<2259:48:49,  8.27s/it, lr=1e-5, step_loss=0.0715][RANK-0]: Step: [16874], local_loss=0.004982516635209322, train_loss=0.06357777118682861, time_cost=4.766327857971191
Steps:   2%|▏         | 16874/1000000 [9:51:19<2259:48:49,  8.27s/it, lr=1e-5, step_loss=0.00498]Steps:   2%|▏         | 16875/1000000 [9:51:30<2450:45:29,  8.97s/it, lr=1e-5, step_loss=0.00498][RANK-0]: Step: [16875], local_loss=0.007898683659732342, train_loss=0.014168348163366318, time_cost=1.5174312591552734
Steps:   2%|▏         | 16875/1000000 [9:51:30<2450:45:29,  8.97s/it, lr=1e-5, step_loss=0.0079] Steps:   2%|▏         | 16876/1000000 [9:51:34<2081:57:39,  7.62s/it, lr=1e-5, step_loss=0.0079][RANK-0]: Step: [16876], local_loss=0.007854444906115532, train_loss=0.06436655670404434, time_cost=1.838360071182251
Steps:   2%|▏         | 16876/1000000 [9:51:34<2081:57:39,  7.62s/it, lr=1e-5, step_loss=0.00785]Steps:   2%|▏         | 16877/1000000 [9:51:41<2028:50:24,  7.43s/it, lr=1e-5, step_loss=0.00785][RANK-0]: Step: [16877], local_loss=0.01504949014633894, train_loss=0.05447465181350708, time_cost=1.2668004035949707
Steps:   2%|▏         | 16877/1000000 [9:51:41<2028:50:24,  7.43s/it, lr=1e-5, step_loss=0.015]  Steps:   2%|▏         | 16878/1000000 [9:51:46<1831:35:56,  6.71s/it, lr=1e-5, step_loss=0.015][RANK-0]: Step: [16878], local_loss=0.010496236383914948, train_loss=0.025349173694849014, time_cost=2.284853935241699
Steps:   2%|▏         | 16878/1000000 [9:51:46<1831:35:56,  6.71s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 16879/1000000 [9:51:53<1882:58:45,  6.90s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [16879], local_loss=0.005326290614902973, train_loss=0.04488619044423103, time_cost=4.680625915527344
Steps:   2%|▏         | 16879/1000000 [9:51:53<1882:58:45,  6.90s/it, lr=1e-5, step_loss=0.00533]Steps:   2%|▏         | 16880/1000000 [9:52:04<2182:25:07,  7.99s/it, lr=1e-5, step_loss=0.00533][RANK-0]: Step: [16880], local_loss=0.0094703184440732, train_loss=0.05746385455131531, time_cost=5.318007230758667
Steps:   2%|▏         | 16880/1000000 [9:52:04<2182:25:07,  7.99s/it, lr=1e-5, step_loss=0.00947]Steps:   2%|▏         | 16881/1000000 [9:52:14<2368:27:08,  8.67s/it, lr=1e-5, step_loss=0.00947][RANK-0]: Step: [16881], local_loss=0.007111517246812582, train_loss=0.04211118817329407, time_cost=2.192270278930664
Steps:   2%|▏         | 16881/1000000 [9:52:14<2368:27:08,  8.67s/it, lr=1e-5, step_loss=0.00711]Steps:   2%|▏         | 16882/1000000 [9:52:20<2146:45:33,  7.86s/it, lr=1e-5, step_loss=0.00711][RANK-0]: Step: [16882], local_loss=0.01312874536961317, train_loss=0.15125684440135956, time_cost=1.583341121673584
Steps:   2%|▏         | 16882/1000000 [9:52:20<2146:45:33,  7.86s/it, lr=1e-5, step_loss=0.0131] Steps:   2%|▏         | 16883/1000000 [9:52:28<2100:31:16,  7.69s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [16883], local_loss=0.04646027088165283, train_loss=0.0566142275929451, time_cost=5.416013240814209
Steps:   2%|▏         | 16883/1000000 [9:52:28<2100:31:16,  7.69s/it, lr=1e-5, step_loss=0.0465]Steps:   2%|▏         | 16884/1000000 [9:52:32<1824:35:44,  6.68s/it, lr=1e-5, step_loss=0.0465][RANK-0]: Step: [16884], local_loss=0.06151527538895607, train_loss=0.1261001080274582, time_cost=1.725050926208496
Steps:   2%|▏         | 16884/1000000 [9:52:32<1824:35:44,  6.68s/it, lr=1e-5, step_loss=0.0615]Steps:   2%|▏         | 16885/1000000 [9:52:45<2331:21:38,  8.54s/it, lr=1e-5, step_loss=0.0615][RANK-0]: Step: [16885], local_loss=0.01733083836734295, train_loss=0.06725699454545975, time_cost=4.497185230255127
Steps:   2%|▏         | 16885/1000000 [9:52:45<2331:21:38,  8.54s/it, lr=1e-5, step_loss=0.0173]Steps:   2%|▏         | 16886/1000000 [9:52:58<2724:56:36,  9.98s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [16886], local_loss=0.008848311379551888, train_loss=0.017240438610315323, time_cost=1.3299202919006348
Steps:   2%|▏         | 16886/1000000 [9:52:58<2724:56:36,  9.98s/it, lr=1e-5, step_loss=0.00885]Steps:   2%|▏         | 16887/1000000 [9:53:05<2513:09:22,  9.20s/it, lr=1e-5, step_loss=0.00885][RANK-0]: Step: [16887], local_loss=0.036924682557582855, train_loss=0.029020866379141808, time_cost=1.9462482929229736
Steps:   2%|▏         | 16887/1000000 [9:53:05<2513:09:22,  9.20s/it, lr=1e-5, step_loss=0.0369] Steps:   2%|▏         | 16888/1000000 [9:53:16<2642:51:10,  9.68s/it, lr=1e-5, step_loss=0.0369][RANK-0]: Step: [16888], local_loss=0.013914113864302635, train_loss=0.025608476251363754, time_cost=5.956508159637451
Steps:   2%|▏         | 16888/1000000 [9:53:16<2642:51:10,  9.68s/it, lr=1e-5, step_loss=0.0139]Steps:   2%|▏         | 16889/1000000 [9:53:22<2349:28:23,  8.60s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [16889], local_loss=0.023053674027323723, train_loss=0.026504958048462868, time_cost=2.110142707824707
Steps:   2%|▏         | 16889/1000000 [9:53:22<2349:28:23,  8.60s/it, lr=1e-5, step_loss=0.0231]Steps:   2%|▏         | 16890/1000000 [9:53:37<2848:58:32, 10.43s/it, lr=1e-5, step_loss=0.0231][RANK-0]: Step: [16890], local_loss=0.028266532346606255, train_loss=0.022986605763435364, time_cost=3.2244131565093994
Steps:   2%|▏         | 16890/1000000 [9:53:37<2848:58:32, 10.43s/it, lr=1e-5, step_loss=0.0283]Steps:   2%|▏         | 16891/1000000 [9:53:46<2736:14:40, 10.02s/it, lr=1e-5, step_loss=0.0283][RANK-0]: Step: [16891], local_loss=0.006639075465500355, train_loss=0.030163871124386787, time_cost=3.888038158416748
Steps:   2%|▏         | 16891/1000000 [9:53:46<2736:14:40, 10.02s/it, lr=1e-5, step_loss=0.00664]Steps:   2%|▏         | 16892/1000000 [9:53:52<2362:30:15,  8.65s/it, lr=1e-5, step_loss=0.00664][RANK-0]: Step: [16892], local_loss=0.03168387711048126, train_loss=0.04056629538536072, time_cost=1.783351182937622
Steps:   2%|▏         | 16892/1000000 [9:53:52<2362:30:15,  8.65s/it, lr=1e-5, step_loss=0.0317] /home/image_data/hxy/Open-Sora-Plan/opensora/utils/utils.py:369: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.
  caption = BeautifulSoup(caption, features='html.parser').text
Steps:   2%|▏         | 16893/1000000 [9:54:03<2563:56:45,  9.39s/it, lr=1e-5, step_loss=0.0317][RANK-0]: Step: [16893], local_loss=0.012530133128166199, train_loss=0.02922319620847702, time_cost=1.9262630939483643
Steps:   2%|▏         | 16893/1000000 [9:54:03<2563:56:45,  9.39s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 16894/1000000 [9:54:18<3054:07:41, 11.18s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [16894], local_loss=0.0967797338962555, train_loss=0.05058060213923454, time_cost=7.799904108047485
Steps:   2%|▏         | 16894/1000000 [9:54:18<3054:07:41, 11.18s/it, lr=1e-5, step_loss=0.0968]Steps:   2%|▏         | 16895/1000000 [9:54:29<3052:58:48, 11.18s/it, lr=1e-5, step_loss=0.0968][RANK-0]: Step: [16895], local_loss=0.04476756975054741, train_loss=0.021468836814165115, time_cost=3.865584373474121
Steps:   2%|▏         | 16895/1000000 [9:54:29<3052:58:48, 11.18s/it, lr=1e-5, step_loss=0.0448]Steps:   2%|▏         | 16896/1000000 [9:54:39<2921:54:42, 10.70s/it, lr=1e-5, step_loss=0.0448][RANK-0]: Step: [16896], local_loss=0.011538650840520859, train_loss=0.038902610540390015, time_cost=4.384485960006714
Steps:   2%|▏         | 16896/1000000 [9:54:39<2921:54:42, 10.70s/it, lr=1e-5, step_loss=0.0115]Steps:   2%|▏         | 16897/1000000 [9:54:50<2933:10:07, 10.74s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [16897], local_loss=0.004901539534330368, train_loss=0.013323131948709488, time_cost=4.6193528175354
Steps:   2%|▏         | 16897/1000000 [9:54:50<2933:10:07, 10.74s/it, lr=1e-5, step_loss=0.0049]Steps:   2%|▏         | 16898/1000000 [9:54:56<2609:59:21,  9.56s/it, lr=1e-5, step_loss=0.0049][RANK-0]: Step: [16898], local_loss=0.022280031815171242, train_loss=0.0535908006131649, time_cost=2.1326711177825928
Steps:   2%|▏         | 16898/1000000 [9:54:56<2609:59:21,  9.56s/it, lr=1e-5, step_loss=0.0223]Steps:   2%|▏         | 16899/1000000 [9:55:02<2290:18:42,  8.39s/it, lr=1e-5, step_loss=0.0223][RANK-0]: Step: [16899], local_loss=0.005996644031256437, train_loss=0.049926720559597015, time_cost=4.469437837600708
Steps:   2%|▏         | 16899/1000000 [9:55:02<2290:18:42,  8.39s/it, lr=1e-5, step_loss=0.006] Steps:   2%|▏         | 16900/1000000 [9:55:11<2371:30:26,  8.68s/it, lr=1e-5, step_loss=0.006][RANK-0]: Step: [16900], local_loss=0.0634877160191536, train_loss=0.02842779830098152, time_cost=3.779961347579956
Steps:   2%|▏         | 16900/1000000 [9:55:11<2371:30:26,  8.68s/it, lr=1e-5, step_loss=0.0635]Steps:   2%|▏         | 16901/1000000 [9:55:19<2273:21:52,  8.32s/it, lr=1e-5, step_loss=0.0635][RANK-0]: Step: [16901], local_loss=0.014493877999484539, train_loss=0.045488204807043076, time_cost=3.926111936569214
Steps:   2%|▏         | 16901/1000000 [9:55:19<2273:21:52,  8.32s/it, lr=1e-5, step_loss=0.0145]Steps:   2%|▏         | 16902/1000000 [9:55:34<2863:56:45, 10.49s/it, lr=1e-5, step_loss=0.0145][RANK-0]: Step: [16902], local_loss=0.030121654272079468, train_loss=0.018798604607582092, time_cost=12.2548828125
Steps:   2%|▏         | 16902/1000000 [9:55:34<2863:56:45, 10.49s/it, lr=1e-5, step_loss=0.0301]Steps:   2%|▏         | 16903/1000000 [9:55:46<2941:09:11, 10.77s/it, lr=1e-5, step_loss=0.0301][RANK-0]: Step: [16903], local_loss=0.01518678106367588, train_loss=0.01811130903661251, time_cost=2.8539693355560303
Steps:   2%|▏         | 16903/1000000 [9:55:46<2941:09:11, 10.77s/it, lr=1e-5, step_loss=0.0152]Steps:   2%|▏         | 16904/1000000 [9:55:50<2433:53:39,  8.91s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [16904], local_loss=0.02434595301747322, train_loss=0.015188589692115784, time_cost=1.8773887157440186
Steps:   2%|▏         | 16904/1000000 [9:55:50<2433:53:39,  8.91s/it, lr=1e-5, step_loss=0.0243]Steps:   2%|▏         | 16905/1000000 [9:55:56<2140:40:19,  7.84s/it, lr=1e-5, step_loss=0.0243][RANK-0]: Step: [16905], local_loss=0.0148770147934556, train_loss=0.02097538858652115, time_cost=1.7404499053955078
Steps:   2%|▏         | 16905/1000000 [9:55:56<2140:40:19,  7.84s/it, lr=1e-5, step_loss=0.0149]Steps:   2%|▏         | 16906/1000000 [9:56:08<2538:48:35,  9.30s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [16906], local_loss=0.039507847279310226, train_loss=0.1965041309595108, time_cost=5.956130027770996
Steps:   2%|▏         | 16906/1000000 [9:56:09<2538:48:35,  9.30s/it, lr=1e-5, step_loss=0.0395]Steps:   2%|▏         | 16907/1000000 [9:56:21<2806:16:28, 10.28s/it, lr=1e-5, step_loss=0.0395][RANK-0]: Step: [16907], local_loss=0.04088054969906807, train_loss=0.024403348565101624, time_cost=1.1884722709655762
Steps:   2%|▏         | 16907/1000000 [9:56:21<2806:16:28, 10.28s/it, lr=1e-5, step_loss=0.0409]Steps:   2%|▏         | 16908/1000000 [9:56:36<3214:58:53, 11.77s/it, lr=1e-5, step_loss=0.0409][RANK-0]: Step: [16908], local_loss=0.02316349744796753, train_loss=0.017910756170749664, time_cost=7.70176887512207
Steps:   2%|▏         | 16908/1000000 [9:56:36<3214:58:53, 11.77s/it, lr=1e-5, step_loss=0.0232]Steps:   2%|▏         | 16909/1000000 [9:56:41<2666:15:28,  9.76s/it, lr=1e-5, step_loss=0.0232][RANK-0]: Step: [16909], local_loss=0.005215676501393318, train_loss=0.04737866297364235, time_cost=2.931572198867798
Steps:   2%|▏         | 16909/1000000 [9:56:41<2666:15:28,  9.76s/it, lr=1e-5, step_loss=0.00522]Steps:   2%|▏         | 16910/1000000 [9:56:47<2290:42:37,  8.39s/it, lr=1e-5, step_loss=0.00522][RANK-0]: Step: [16910], local_loss=0.03831646963953972, train_loss=0.02327214926481247, time_cost=1.7869873046875
Steps:   2%|▏         | 16910/1000000 [9:56:47<2290:42:37,  8.39s/it, lr=1e-5, step_loss=0.0383] Steps:   2%|▏         | 16911/1000000 [9:56:56<2379:07:13,  8.71s/it, lr=1e-5, step_loss=0.0383][RANK-0]: Step: [16911], local_loss=0.005871286615729332, train_loss=26.70825958251953, time_cost=3.6944141387939453
Steps:   2%|▏         | 16911/1000000 [9:56:56<2379:07:13,  8.71s/it, lr=1e-5, step_loss=0.00587]Steps:   2%|▏         | 16912/1000000 [9:57:04<2318:35:41,  8.49s/it, lr=1e-5, step_loss=0.00587][RANK-0]: Step: [16912], local_loss=0.013582433573901653, train_loss=0.0307847261428833, time_cost=1.1962921619415283
Steps:   2%|▏         | 16912/1000000 [9:57:04<2318:35:41,  8.49s/it, lr=1e-5, step_loss=0.0136] Steps:   2%|▏         | 16913/1000000 [9:57:09<2044:46:50,  7.49s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [16913], local_loss=0.05397747829556465, train_loss=0.026350781321525574, time_cost=4.3944103717803955
Steps:   2%|▏         | 16913/1000000 [9:57:09<2044:46:50,  7.49s/it, lr=1e-5, step_loss=0.054] Steps:   2%|▏         | 16914/1000000 [9:57:18<2186:28:32,  8.01s/it, lr=1e-5, step_loss=0.054][RANK-0]: Step: [16914], local_loss=0.14307451248168945, train_loss=0.045683518052101135, time_cost=3.6703741550445557
Steps:   2%|▏         | 16914/1000000 [9:57:18<2186:28:32,  8.01s/it, lr=1e-5, step_loss=0.143]Steps:   2%|▏         | 16915/1000000 [9:57:25<2109:06:47,  7.72s/it, lr=1e-5, step_loss=0.143][RANK-0]: Step: [16915], local_loss=0.04799384996294975, train_loss=0.06251519173383713, time_cost=1.6848962306976318
Steps:   2%|▏         | 16915/1000000 [9:57:25<2109:06:47,  7.72s/it, lr=1e-5, step_loss=0.048]Steps:   2%|▏         | 16916/1000000 [9:57:39<2583:24:13,  9.46s/it, lr=1e-5, step_loss=0.048][RANK-0]: Step: [16916], local_loss=0.020271368324756622, train_loss=0.05673827975988388, time_cost=3.8025310039520264
Steps:   2%|▏         | 16916/1000000 [9:57:39<2583:24:13,  9.46s/it, lr=1e-5, step_loss=0.0203]Steps:   2%|▏         | 16917/1000000 [9:57:50<2738:16:21, 10.03s/it, lr=1e-5, step_loss=0.0203][RANK-0]: Step: [16917], local_loss=0.00519444840028882, train_loss=0.06046123057603836, time_cost=4.665292739868164
Steps:   2%|▏         | 16917/1000000 [9:57:50<2738:16:21, 10.03s/it, lr=1e-5, step_loss=0.00519]Steps:   2%|▏         | 16918/1000000 [9:57:59<2643:46:37,  9.68s/it, lr=1e-5, step_loss=0.00519][RANK-0]: Step: [16918], local_loss=0.08972971886396408, train_loss=0.16220255196094513, time_cost=2.790803909301758
Steps:   2%|▏         | 16918/1000000 [9:57:59<2643:46:37,  9.68s/it, lr=1e-5, step_loss=0.0897] Steps:   2%|▏         | 16919/1000000 [9:58:05<2350:11:32,  8.61s/it, lr=1e-5, step_loss=0.0897][RANK-0]: Step: [16919], local_loss=0.04714680463075638, train_loss=0.031719870865345, time_cost=2.596656084060669
Steps:   2%|▏         | 16919/1000000 [9:58:05<2350:11:32,  8.61s/it, lr=1e-5, step_loss=0.0471]Steps:   2%|▏         | 16920/1000000 [9:58:20<2816:24:59, 10.31s/it, lr=1e-5, step_loss=0.0471][RANK-0]: Step: [16920], local_loss=0.01969633810222149, train_loss=0.03035275638103485, time_cost=1.988886833190918
Steps:   2%|▏         | 16920/1000000 [9:58:20<2816:24:59, 10.31s/it, lr=1e-5, step_loss=0.0197]Steps:   2%|▏         | 16921/1000000 [9:58:24<2324:27:07,  8.51s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [16921], local_loss=0.05496100336313248, train_loss=0.04265356808900833, time_cost=1.3778448104858398
Steps:   2%|▏         | 16921/1000000 [9:58:24<2324:27:07,  8.51s/it, lr=1e-5, step_loss=0.055] Steps:   2%|▏         | 16922/1000000 [9:58:37<2712:24:22,  9.93s/it, lr=1e-5, step_loss=0.055][RANK-0]: Step: [16922], local_loss=0.1654180884361267, train_loss=0.04376446455717087, time_cost=1.8658685684204102
Steps:   2%|▏         | 16922/1000000 [9:58:37<2712:24:22,  9.93s/it, lr=1e-5, step_loss=0.165]Steps:   2%|▏         | 16923/1000000 [9:58:42<2291:10:50,  8.39s/it, lr=1e-5, step_loss=0.165][RANK-0]: Step: [16923], local_loss=0.004288474563509226, train_loss=0.13036730885505676, time_cost=1.873732566833496
Steps:   2%|▏         | 16923/1000000 [9:58:42<2291:10:50,  8.39s/it, lr=1e-5, step_loss=0.00429]Steps:   2%|▏         | 16924/1000000 [9:58:57<2804:09:36, 10.27s/it, lr=1e-5, step_loss=0.00429][RANK-0]: Step: [16924], local_loss=0.00795456487685442, train_loss=0.019172193482518196, time_cost=5.620039224624634
Steps:   2%|▏         | 16924/1000000 [9:58:57<2804:09:36, 10.27s/it, lr=1e-5, step_loss=0.00795]Steps:   2%|▏         | 16925/1000000 [9:59:10<3053:26:38, 11.18s/it, lr=1e-5, step_loss=0.00795][RANK-0]: Step: [16925], local_loss=0.010545270517468452, train_loss=0.023267341777682304, time_cost=10.051693677902222
Steps:   2%|▏         | 16925/1000000 [9:59:10<3053:26:38, 11.18s/it, lr=1e-5, step_loss=0.0105] Steps:   2%|▏         | 16926/1000000 [9:59:21<3066:28:11, 11.23s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [16926], local_loss=0.2940763235092163, train_loss=0.05556964874267578, time_cost=2.0753166675567627
Steps:   2%|▏         | 16926/1000000 [9:59:21<3066:28:11, 11.23s/it, lr=1e-5, step_loss=0.294] Steps:   2%|▏         | 16927/1000000 [9:59:34<3173:34:44, 11.62s/it, lr=1e-5, step_loss=0.294][RANK-0]: Step: [16927], local_loss=0.09342624247074127, train_loss=0.03793967142701149, time_cost=6.175010681152344
Steps:   2%|▏         | 16927/1000000 [9:59:34<3173:34:44, 11.62s/it, lr=1e-5, step_loss=0.0934]Steps:   2%|▏         | 16928/1000000 [9:59:47<3309:23:00, 12.12s/it, lr=1e-5, step_loss=0.0934][RANK-0]: Step: [16928], local_loss=0.01797153428196907, train_loss=0.10692138969898224, time_cost=6.546281814575195
Steps:   2%|▏         | 16928/1000000 [9:59:47<3309:23:00, 12.12s/it, lr=1e-5, step_loss=0.018] Steps:   2%|▏         | 16929/1000000 [9:59:55<2966:34:34, 10.86s/it, lr=1e-5, step_loss=0.018][RANK-0]: Step: [16929], local_loss=0.022424669936299324, train_loss=0.011408008635044098, time_cost=4.548857688903809
Steps:   2%|▏         | 16929/1000000 [9:59:55<2966:34:34, 10.86s/it, lr=1e-5, step_loss=0.0224]Steps:   2%|▏         | 16930/1000000 [10:00:04<2816:21:20, 10.31s/it, lr=1e-5, step_loss=0.0224][RANK-0]: Step: [16930], local_loss=0.9853650331497192, train_loss=0.13626058399677277, time_cost=2.9011828899383545
Steps:   2%|▏         | 16930/1000000 [10:00:04<2816:21:20, 10.31s/it, lr=1e-5, step_loss=0.985] Steps:   2%|▏         | 16931/1000000 [10:00:08<2326:45:50,  8.52s/it, lr=1e-5, step_loss=0.985][RANK-0]: Step: [16931], local_loss=0.22833919525146484, train_loss=0.17915299534797668, time_cost=1.732717514038086
Steps:   2%|▏         | 16931/1000000 [10:00:08<2326:45:50,  8.52s/it, lr=1e-5, step_loss=0.228]Steps:   2%|▏         | 16932/1000000 [10:00:20<2573:18:58,  9.42s/it, lr=1e-5, step_loss=0.228][RANK-0]: Step: [16932], local_loss=0.08339173346757889, train_loss=0.025294940918684006, time_cost=8.315983295440674
Steps:   2%|▏         | 16932/1000000 [10:00:20<2573:18:58,  9.42s/it, lr=1e-5, step_loss=0.0834]Steps:   2%|▏         | 16933/1000000 [10:00:32<2828:50:41, 10.36s/it, lr=1e-5, step_loss=0.0834][RANK-0]: Step: [16933], local_loss=0.006290892604738474, train_loss=0.03325963020324707, time_cost=3.8125252723693848
Steps:   2%|▏         | 16933/1000000 [10:00:32<2828:50:41, 10.36s/it, lr=1e-5, step_loss=0.00629]Steps:   2%|▏         | 16934/1000000 [10:00:39<2496:03:34,  9.14s/it, lr=1e-5, step_loss=0.00629][RANK-0]: Step: [16934], local_loss=0.008451610803604126, train_loss=0.029879257082939148, time_cost=2.6175732612609863
Steps:   2%|▏         | 16934/1000000 [10:00:39<2496:03:34,  9.14s/it, lr=1e-5, step_loss=0.00845]Steps:   2%|▏         | 16935/1000000 [10:00:46<2319:28:34,  8.49s/it, lr=1e-5, step_loss=0.00845][RANK-0]: Step: [16935], local_loss=0.022581921890378, train_loss=0.024741891771554947, time_cost=2.371865749359131
Steps:   2%|▏         | 16935/1000000 [10:00:46<2319:28:34,  8.49s/it, lr=1e-5, step_loss=0.0226] Steps:   2%|▏         | 16936/1000000 [10:00:52<2111:16:21,  7.73s/it, lr=1e-5, step_loss=0.0226][RANK-0]: Step: [16936], local_loss=0.006044288165867329, train_loss=0.02204989641904831, time_cost=2.4032294750213623
Steps:   2%|▏         | 16936/1000000 [10:00:52<2111:16:21,  7.73s/it, lr=1e-5, step_loss=0.00604]Steps:   2%|▏         | 16937/1000000 [10:01:06<2626:36:19,  9.62s/it, lr=1e-5, step_loss=0.00604][RANK-0]: Step: [16937], local_loss=0.9903552532196045, train_loss=0.1439492404460907, time_cost=2.622979164123535
Steps:   2%|▏         | 16937/1000000 [10:01:06<2626:36:19,  9.62s/it, lr=1e-5, step_loss=0.99]   Steps:   2%|▏         | 16938/1000000 [10:01:15<2611:54:56,  9.56s/it, lr=1e-5, step_loss=0.99][RANK-0]: Step: [16938], local_loss=0.9999889135360718, train_loss=0.1486106961965561, time_cost=3.9156813621520996
Steps:   2%|▏         | 16938/1000000 [10:01:15<2611:54:56,  9.56s/it, lr=1e-5, step_loss=1]   Steps:   2%|▏         | 16939/1000000 [10:01:26<2747:06:17, 10.06s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [16939], local_loss=0.02408078871667385, train_loss=0.030920952558517456, time_cost=2.407726526260376
Steps:   2%|▏         | 16939/1000000 [10:01:26<2747:06:17, 10.06s/it, lr=1e-5, step_loss=0.0241]Steps:   2%|▏         | 16940/1000000 [10:01:36<2694:54:52,  9.87s/it, lr=1e-5, step_loss=0.0241][RANK-0]: Step: [16940], local_loss=0.00331237749196589, train_loss=0.01186673529446125, time_cost=2.221776247024536
Steps:   2%|▏         | 16940/1000000 [10:01:36<2694:54:52,  9.87s/it, lr=1e-5, step_loss=0.00331]Steps:   2%|▏         | 16941/1000000 [10:01:46<2743:12:35, 10.05s/it, lr=1e-5, step_loss=0.00331][RANK-0]: Step: [16941], local_loss=0.009857213124632835, train_loss=7.1513590812683105, time_cost=2.1735236644744873
Steps:   2%|▏         | 16941/1000000 [10:01:46<2743:12:35, 10.05s/it, lr=1e-5, step_loss=0.00986]Steps:   2%|▏         | 16942/1000000 [10:01:57<2807:25:35, 10.28s/it, lr=1e-5, step_loss=0.00986][RANK-0]: Step: [16942], local_loss=0.07924185693264008, train_loss=0.03576327860355377, time_cost=1.9430019855499268
Steps:   2%|▏         | 16942/1000000 [10:01:57<2807:25:35, 10.28s/it, lr=1e-5, step_loss=0.0792] Steps:   2%|▏         | 16943/1000000 [10:02:03<2427:20:47,  8.89s/it, lr=1e-5, step_loss=0.0792][RANK-0]: Step: [16943], local_loss=0.011565967462956905, train_loss=0.030280787497758865, time_cost=1.2880828380584717
Steps:   2%|▏         | 16943/1000000 [10:02:03<2427:20:47,  8.89s/it, lr=1e-5, step_loss=0.0116]Steps:   2%|▏         | 16944/1000000 [10:02:07<2078:17:12,  7.61s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [16944], local_loss=0.01822158880531788, train_loss=0.042174819856882095, time_cost=1.9504146575927734
Steps:   2%|▏         | 16944/1000000 [10:02:07<2078:17:12,  7.61s/it, lr=1e-5, step_loss=0.0182]Steps:   2%|▏         | 16945/1000000 [10:02:15<2065:53:33,  7.57s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [16945], local_loss=0.033981770277023315, train_loss=0.03954920545220375, time_cost=5.218738794326782
Steps:   2%|▏         | 16945/1000000 [10:02:15<2065:53:33,  7.57s/it, lr=1e-5, step_loss=0.034] Steps:   2%|▏         | 16946/1000000 [10:02:30<2709:50:50,  9.92s/it, lr=1e-5, step_loss=0.034][RANK-0]: Step: [16946], local_loss=0.005565114319324493, train_loss=0.1577294021844864, time_cost=7.951881408691406
Steps:   2%|▏         | 16946/1000000 [10:02:30<2709:50:50,  9.92s/it, lr=1e-5, step_loss=0.00557]Steps:   2%|▏         | 16947/1000000 [10:02:40<2718:40:38,  9.96s/it, lr=1e-5, step_loss=0.00557][RANK-0]: Step: [16947], local_loss=0.00796005129814148, train_loss=0.06924330443143845, time_cost=1.2089097499847412
Steps:   2%|▏         | 16947/1000000 [10:02:40<2718:40:38,  9.96s/it, lr=1e-5, step_loss=0.00796]Steps:   2%|▏         | 16948/1000000 [10:02:52<2835:39:43, 10.38s/it, lr=1e-5, step_loss=0.00796][RANK-0]: Step: [16948], local_loss=0.07762607932090759, train_loss=0.08128741383552551, time_cost=2.216914415359497
Steps:   2%|▏         | 16948/1000000 [10:02:52<2835:39:43, 10.38s/it, lr=1e-5, step_loss=0.0776] Steps:   2%|▏         | 16949/1000000 [10:02:59<2613:36:20,  9.57s/it, lr=1e-5, step_loss=0.0776][RANK-0]: Step: [16949], local_loss=0.02373199164867401, train_loss=0.02209293283522129, time_cost=2.4772257804870605
Steps:   2%|▏         | 16949/1000000 [10:02:59<2613:36:20,  9.57s/it, lr=1e-5, step_loss=0.0237]Steps:   2%|▏         | 16950/1000000 [10:03:11<2760:10:24, 10.11s/it, lr=1e-5, step_loss=0.0237][RANK-0]: Step: [16950], local_loss=0.1513897031545639, train_loss=0.052216216921806335, time_cost=3.616481065750122
Steps:   2%|▏         | 16950/1000000 [10:03:11<2760:10:24, 10.11s/it, lr=1e-5, step_loss=0.151] Steps:   2%|▏         | 16951/1000000 [10:03:16<2354:04:31,  8.62s/it, lr=1e-5, step_loss=0.151][RANK-0]: Step: [16951], local_loss=0.08068841695785522, train_loss=0.030960317701101303, time_cost=1.2713587284088135
Steps:   2%|▏         | 16951/1000000 [10:03:16<2354:04:31,  8.62s/it, lr=1e-5, step_loss=0.0807]Steps:   2%|▏         | 16952/1000000 [10:03:30<2817:26:35, 10.32s/it, lr=1e-5, step_loss=0.0807][RANK-0]: Step: [16952], local_loss=0.023022310808300972, train_loss=0.027003740891814232, time_cost=5.21203351020813
Steps:   2%|▏         | 16952/1000000 [10:03:30<2817:26:35, 10.32s/it, lr=1e-5, step_loss=0.023] Steps:   2%|▏         | 16953/1000000 [10:03:42<2951:16:36, 10.81s/it, lr=1e-5, step_loss=0.023][RANK-0]: Step: [16953], local_loss=0.00661213556304574, train_loss=0.060466937720775604, time_cost=3.1174168586730957
Steps:   2%|▏         | 16953/1000000 [10:03:42<2951:16:36, 10.81s/it, lr=1e-5, step_loss=0.00661]Steps:   2%|▏         | 16954/1000000 [10:03:47<2459:48:35,  9.01s/it, lr=1e-5, step_loss=0.00661][RANK-0]: Step: [16954], local_loss=0.022185832262039185, train_loss=0.042826030403375626, time_cost=2.528249979019165
Steps:   2%|▏         | 16954/1000000 [10:03:47<2459:48:35,  9.01s/it, lr=1e-5, step_loss=0.0222] Steps:   2%|▏         | 16955/1000000 [10:03:52<2137:21:42,  7.83s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [16955], local_loss=0.02417066879570484, train_loss=0.04861386865377426, time_cost=3.8310515880584717
Steps:   2%|▏         | 16955/1000000 [10:03:52<2137:21:42,  7.83s/it, lr=1e-5, step_loss=0.0242]Steps:   2%|▏         | 16956/1000000 [10:03:59<2062:56:05,  7.55s/it, lr=1e-5, step_loss=0.0242][RANK-0]: Step: [16956], local_loss=0.015432419255375862, train_loss=0.0346885547041893, time_cost=1.5753741264343262
Steps:   2%|▏         | 16956/1000000 [10:03:59<2062:56:05,  7.55s/it, lr=1e-5, step_loss=0.0154]Steps:   2%|▏         | 16957/1000000 [10:04:08<2156:36:55,  7.90s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [16957], local_loss=0.022749798372387886, train_loss=0.07206814736127853, time_cost=1.1988158226013184
Steps:   2%|▏         | 16957/1000000 [10:04:08<2156:36:55,  7.90s/it, lr=1e-5, step_loss=0.0227]Steps:   2%|▏         | 16958/1000000 [10:04:12<1878:00:56,  6.88s/it, lr=1e-5, step_loss=0.0227][RANK-0]: Step: [16958], local_loss=0.05522514134645462, train_loss=0.06934119760990143, time_cost=1.6372706890106201
Steps:   2%|▏         | 16958/1000000 [10:04:12<1878:00:56,  6.88s/it, lr=1e-5, step_loss=0.0552]Steps:   2%|▏         | 16959/1000000 [10:04:16<1662:07:52,  6.09s/it, lr=1e-5, step_loss=0.0552][RANK-0]: Step: [16959], local_loss=0.018012627959251404, train_loss=0.045883215963840485, time_cost=1.4389123916625977
Steps:   2%|▏         | 16959/1000000 [10:04:16<1662:07:52,  6.09s/it, lr=1e-5, step_loss=0.018] Steps:   2%|▏         | 16960/1000000 [10:04:29<2203:33:14,  8.07s/it, lr=1e-5, step_loss=0.018][RANK-0]: Step: [16960], local_loss=1.019602656364441, train_loss=0.17567838728427887, time_cost=1.193474531173706
Steps:   2%|▏         | 16960/1000000 [10:04:29<2203:33:14,  8.07s/it, lr=1e-5, step_loss=1.02] Steps:   2%|▏         | 16961/1000000 [10:04:37<2171:52:38,  7.95s/it, lr=1e-5, step_loss=1.02][RANK-0]: Step: [16961], local_loss=0.005667855031788349, train_loss=0.021630477160215378, time_cost=3.9845967292785645
Steps:   2%|▏         | 16961/1000000 [10:04:37<2171:52:38,  7.95s/it, lr=1e-5, step_loss=0.00567]Steps:   2%|▏         | 16962/1000000 [10:04:44<2130:43:07,  7.80s/it, lr=1e-5, step_loss=0.00567][RANK-0]: Step: [16962], local_loss=0.025258611887693405, train_loss=0.058094605803489685, time_cost=3.0305328369140625
Steps:   2%|▏         | 16962/1000000 [10:04:44<2130:43:07,  7.80s/it, lr=1e-5, step_loss=0.0253] Steps:   2%|▏         | 16963/1000000 [10:04:48<1823:39:32,  6.68s/it, lr=1e-5, step_loss=0.0253][RANK-0]: Step: [16963], local_loss=0.04873114451766014, train_loss=0.09168240427970886, time_cost=1.3624906539916992
Steps:   2%|▏         | 16963/1000000 [10:04:48<1823:39:32,  6.68s/it, lr=1e-5, step_loss=0.0487]Steps:   2%|▏         | 16964/1000000 [10:05:02<2402:23:31,  8.80s/it, lr=1e-5, step_loss=0.0487][RANK-0]: Step: [16964], local_loss=0.03478807210922241, train_loss=0.03314162790775299, time_cost=9.752309322357178
Steps:   2%|▏         | 16964/1000000 [10:05:02<2402:23:31,  8.80s/it, lr=1e-5, step_loss=0.0348]Steps:   2%|▏         | 16965/1000000 [10:05:08<2146:39:10,  7.86s/it, lr=1e-5, step_loss=0.0348][RANK-0]: Step: [16965], local_loss=0.04365193843841553, train_loss=0.07912140339612961, time_cost=1.2876386642456055
Steps:   2%|▏         | 16965/1000000 [10:05:08<2146:39:10,  7.86s/it, lr=1e-5, step_loss=0.0437]Steps:   2%|▏         | 16966/1000000 [10:05:22<2671:46:49,  9.78s/it, lr=1e-5, step_loss=0.0437][RANK-0]: Step: [16966], local_loss=0.0651305764913559, train_loss=0.06883548945188522, time_cost=5.819165945053101
Steps:   2%|▏         | 16966/1000000 [10:05:22<2671:46:49,  9.78s/it, lr=1e-5, step_loss=0.0651]Steps:   2%|▏         | 16967/1000000 [10:05:36<3046:55:07, 11.16s/it, lr=1e-5, step_loss=0.0651][RANK-0]: Step: [16967], local_loss=0.023353077471256256, train_loss=0.025528857484459877, time_cost=8.927243709564209
Steps:   2%|▏         | 16967/1000000 [10:05:36<3046:55:07, 11.16s/it, lr=1e-5, step_loss=0.0234]Steps:   2%|▏         | 16968/1000000 [10:05:50<3232:31:02, 11.84s/it, lr=1e-5, step_loss=0.0234][RANK-0]: Step: [16968], local_loss=0.013552075251936913, train_loss=0.019338458776474, time_cost=2.4516923427581787
Steps:   2%|▏         | 16968/1000000 [10:05:50<3232:31:02, 11.84s/it, lr=1e-5, step_loss=0.0136]Steps:   2%|▏         | 16969/1000000 [10:06:01<3182:32:53, 11.65s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [16969], local_loss=0.005732052493840456, train_loss=0.008740484714508057, time_cost=3.459278106689453
Steps:   2%|▏         | 16969/1000000 [10:06:01<3182:32:53, 11.65s/it, lr=1e-5, step_loss=0.00573]Steps:   2%|▏         | 16970/1000000 [10:06:14<3306:41:51, 12.11s/it, lr=1e-5, step_loss=0.00573][RANK-0]: Step: [16970], local_loss=0.012480362318456173, train_loss=0.02934947982430458, time_cost=1.2816269397735596
Steps:   2%|▏         | 16970/1000000 [10:06:14<3306:41:51, 12.11s/it, lr=1e-5, step_loss=0.0125] Steps:   2%|▏         | 16971/1000000 [10:06:23<3047:11:24, 11.16s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [16971], local_loss=0.06877107918262482, train_loss=5.525625705718994, time_cost=3.2532382011413574
Steps:   2%|▏         | 16971/1000000 [10:06:23<3047:11:24, 11.16s/it, lr=1e-5, step_loss=0.0688]Steps:   2%|▏         | 16972/1000000 [10:06:34<3004:40:43, 11.00s/it, lr=1e-5, step_loss=0.0688][RANK-0]: Step: [16972], local_loss=0.043528392910957336, train_loss=0.03267799690365791, time_cost=1.3365068435668945
Steps:   2%|▏         | 16972/1000000 [10:06:34<3004:40:43, 11.00s/it, lr=1e-5, step_loss=0.0435]Steps:   2%|▏         | 16973/1000000 [10:06:45<3051:12:27, 11.17s/it, lr=1e-5, step_loss=0.0435][RANK-0]: Step: [16973], local_loss=0.01609361357986927, train_loss=0.04351959377527237, time_cost=5.31736421585083
Steps:   2%|▏         | 16973/1000000 [10:06:45<3051:12:27, 11.17s/it, lr=1e-5, step_loss=0.0161]Steps:   2%|▏         | 16974/1000000 [10:06:51<2594:02:53,  9.50s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [16974], local_loss=0.08690910786390305, train_loss=0.028812184929847717, time_cost=2.0309932231903076
Steps:   2%|▏         | 16974/1000000 [10:06:51<2594:02:53,  9.50s/it, lr=1e-5, step_loss=0.0869]Steps:   2%|▏         | 16975/1000000 [10:07:04<2907:40:25, 10.65s/it, lr=1e-5, step_loss=0.0869][RANK-0]: Step: [16975], local_loss=0.0387265719473362, train_loss=0.07040584087371826, time_cost=11.276785612106323
Steps:   2%|▏         | 16975/1000000 [10:07:04<2907:40:25, 10.65s/it, lr=1e-5, step_loss=0.0387]Steps:   2%|▏         | 16976/1000000 [10:07:09<2424:40:14,  8.88s/it, lr=1e-5, step_loss=0.0387][RANK-0]: Step: [16976], local_loss=0.33022540807724, train_loss=0.08049185574054718, time_cost=2.492464542388916
Steps:   2%|▏         | 16976/1000000 [10:07:09<2424:40:14,  8.88s/it, lr=1e-5, step_loss=0.33]  Steps:   2%|▏         | 16977/1000000 [10:07:14<2116:41:49,  7.75s/it, lr=1e-5, step_loss=0.33][RANK-0]: Step: [16977], local_loss=0.9766656756401062, train_loss=0.21946586668491364, time_cost=2.467515468597412
Steps:   2%|▏         | 16977/1000000 [10:07:14<2116:41:49,  7.75s/it, lr=1e-5, step_loss=0.977]Steps:   2%|▏         | 16978/1000000 [10:07:19<1891:07:40,  6.93s/it, lr=1e-5, step_loss=0.977][RANK-0]: Step: [16978], local_loss=0.04031319543719292, train_loss=0.15366405248641968, time_cost=4.151828289031982
Steps:   2%|▏         | 16978/1000000 [10:07:19<1891:07:40,  6.93s/it, lr=1e-5, step_loss=0.0403]Steps:   2%|▏         | 16979/1000000 [10:07:33<2510:38:40,  9.19s/it, lr=1e-5, step_loss=0.0403][RANK-0]: Step: [16979], local_loss=0.03634532541036606, train_loss=0.022054173052310944, time_cost=6.629252910614014
Steps:   2%|▏         | 16979/1000000 [10:07:33<2510:38:40,  9.19s/it, lr=1e-5, step_loss=0.0363]Steps:   2%|▏         | 16980/1000000 [10:07:39<2244:40:08,  8.22s/it, lr=1e-5, step_loss=0.0363][RANK-0]: Step: [16980], local_loss=0.006145508028566837, train_loss=0.01978078857064247, time_cost=4.252540588378906
Steps:   2%|▏         | 16980/1000000 [10:07:39<2244:40:08,  8.22s/it, lr=1e-5, step_loss=0.00615]Steps:   2%|▏         | 16981/1000000 [10:07:54<2747:44:49, 10.06s/it, lr=1e-5, step_loss=0.00615][RANK-0]: Step: [16981], local_loss=0.027203481644392014, train_loss=0.02567155286669731, time_cost=6.201105356216431
Steps:   2%|▏         | 16981/1000000 [10:07:54<2747:44:49, 10.06s/it, lr=1e-5, step_loss=0.0272] Steps:   2%|▏         | 16982/1000000 [10:08:04<2760:33:30, 10.11s/it, lr=1e-5, step_loss=0.0272][RANK-0]: Step: [16982], local_loss=0.044068437069654465, train_loss=0.05490998923778534, time_cost=1.2907941341400146
Steps:   2%|▏         | 16982/1000000 [10:08:04<2760:33:30, 10.11s/it, lr=1e-5, step_loss=0.0441]Steps:   2%|▏         | 16983/1000000 [10:08:15<2863:28:37, 10.49s/it, lr=1e-5, step_loss=0.0441][RANK-0]: Step: [16983], local_loss=0.06268516927957535, train_loss=0.030176108703017235, time_cost=1.9355123043060303
Steps:   2%|▏         | 16983/1000000 [10:08:15<2863:28:37, 10.49s/it, lr=1e-5, step_loss=0.0627]Steps:   2%|▏         | 16984/1000000 [10:08:22<2587:00:11,  9.47s/it, lr=1e-5, step_loss=0.0627][RANK-0]: Step: [16984], local_loss=0.004665303509682417, train_loss=0.04780847579240799, time_cost=3.6116721630096436
Steps:   2%|▏         | 16984/1000000 [10:08:22<2587:00:11,  9.47s/it, lr=1e-5, step_loss=0.00467]Steps:   2%|▏         | 16985/1000000 [10:08:33<2656:09:24,  9.73s/it, lr=1e-5, step_loss=0.00467][RANK-0]: Step: [16985], local_loss=0.007129145786166191, train_loss=0.15815570950508118, time_cost=3.704897403717041
Steps:   2%|▏         | 16985/1000000 [10:08:33<2656:09:24,  9.73s/it, lr=1e-5, step_loss=0.00713]Steps:   2%|▏         | 16986/1000000 [10:08:43<2699:09:18,  9.88s/it, lr=1e-5, step_loss=0.00713][RANK-0]: Step: [16986], local_loss=0.009582838043570518, train_loss=0.026912033557891846, time_cost=1.5762689113616943
Steps:   2%|▏         | 16986/1000000 [10:08:43<2699:09:18,  9.88s/it, lr=1e-5, step_loss=0.00958]Steps:   2%|▏         | 16987/1000000 [10:08:54<2759:40:46, 10.11s/it, lr=1e-5, step_loss=0.00958][RANK-0]: Step: [16987], local_loss=0.009001071564853191, train_loss=0.1354983150959015, time_cost=1.5422286987304688
Steps:   2%|▏         | 16987/1000000 [10:08:54<2759:40:46, 10.11s/it, lr=1e-5, step_loss=0.009]  Steps:   2%|▏         | 16988/1000000 [10:09:05<2871:36:39, 10.52s/it, lr=1e-5, step_loss=0.009][RANK-0]: Step: [16988], local_loss=0.005725904367864132, train_loss=0.03588515520095825, time_cost=8.303779363632202
Steps:   2%|▏         | 16988/1000000 [10:09:05<2871:36:39, 10.52s/it, lr=1e-5, step_loss=0.00573]Steps:   2%|▏         | 16989/1000000 [10:09:11<2475:00:44,  9.06s/it, lr=1e-5, step_loss=0.00573][RANK-0]: Step: [16989], local_loss=0.06213373318314552, train_loss=0.024782374501228333, time_cost=2.888181209564209
Steps:   2%|▏         | 16989/1000000 [10:09:11<2475:00:44,  9.06s/it, lr=1e-5, step_loss=0.0621] Steps:   2%|▏         | 16990/1000000 [10:09:17<2234:18:28,  8.18s/it, lr=1e-5, step_loss=0.0621][RANK-0]: Step: [16990], local_loss=0.06452228128910065, train_loss=0.046877019107341766, time_cost=1.7363412380218506
Steps:   2%|▏         | 16990/1000000 [10:09:17<2234:18:28,  8.18s/it, lr=1e-5, step_loss=0.0645]Steps:   2%|▏         | 16991/1000000 [10:09:27<2426:01:43,  8.88s/it, lr=1e-5, step_loss=0.0645][RANK-0]: Step: [16991], local_loss=0.0050713177770376205, train_loss=0.06623139977455139, time_cost=2.190692663192749
Steps:   2%|▏         | 16991/1000000 [10:09:27<2426:01:43,  8.88s/it, lr=1e-5, step_loss=0.00507]Steps:   2%|▏         | 16992/1000000 [10:09:36<2375:27:52,  8.70s/it, lr=1e-5, step_loss=0.00507][RANK-0]: Step: [16992], local_loss=0.013284281827509403, train_loss=0.02337595820426941, time_cost=3.2945239543914795
Steps:   2%|▏         | 16992/1000000 [10:09:36<2375:27:52,  8.70s/it, lr=1e-5, step_loss=0.0133] Steps:   2%|▏         | 16993/1000000 [10:09:41<2099:48:30,  7.69s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [16993], local_loss=0.03885376453399658, train_loss=0.029813066124916077, time_cost=1.1939818859100342
Steps:   2%|▏         | 16993/1000000 [10:09:41<2099:48:30,  7.69s/it, lr=1e-5, step_loss=0.0389]Steps:   2%|▏         | 16994/1000000 [10:09:54<2535:37:39,  9.29s/it, lr=1e-5, step_loss=0.0389][RANK-0]: Step: [16994], local_loss=0.013058827258646488, train_loss=0.021664034575223923, time_cost=5.589549541473389
Steps:   2%|▏         | 16994/1000000 [10:09:54<2535:37:39,  9.29s/it, lr=1e-5, step_loss=0.0131]Steps:   2%|▏         | 16995/1000000 [10:10:02<2406:08:55,  8.81s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [16995], local_loss=0.0395885705947876, train_loss=0.05782051756978035, time_cost=1.8647572994232178
Steps:   2%|▏         | 16995/1000000 [10:10:02<2406:08:55,  8.81s/it, lr=1e-5, step_loss=0.0396]Steps:   2%|▏         | 16996/1000000 [10:10:06<2057:12:04,  7.53s/it, lr=1e-5, step_loss=0.0396][RANK-0]: Step: [16996], local_loss=0.03815441578626633, train_loss=0.1322508454322815, time_cost=1.7731428146362305
Steps:   2%|▏         | 16996/1000000 [10:10:06<2057:12:04,  7.53s/it, lr=1e-5, step_loss=0.0382]Steps:   2%|▏         | 16997/1000000 [10:10:12<1878:23:24,  6.88s/it, lr=1e-5, step_loss=0.0382][RANK-0]: Step: [16997], local_loss=0.037505120038986206, train_loss=0.07899881899356842, time_cost=2.9516499042510986
Steps:   2%|▏         | 16997/1000000 [10:10:12<1878:23:24,  6.88s/it, lr=1e-5, step_loss=0.0375]Steps:   2%|▏         | 16998/1000000 [10:10:22<2132:51:59,  7.81s/it, lr=1e-5, step_loss=0.0375][RANK-0]: Step: [16998], local_loss=0.028437847271561623, train_loss=0.057584136724472046, time_cost=1.5583269596099854
Steps:   2%|▏         | 16998/1000000 [10:10:22<2132:51:59,  7.81s/it, lr=1e-5, step_loss=0.0284]Steps:   2%|▏         | 16999/1000000 [10:10:35<2562:31:36,  9.38s/it, lr=1e-5, step_loss=0.0284][RANK-0]: Step: [16999], local_loss=0.017332209274172783, train_loss=0.01810310035943985, time_cost=1.2047786712646484
Steps:   2%|▏         | 16999/1000000 [10:10:35<2562:31:36,  9.38s/it, lr=1e-5, step_loss=0.0173]Steps:   2%|▏         | 17000/1000000 [10:10:39<2164:13:51,  7.93s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [17000], local_loss=0.010467816144227982, train_loss=0.025796040892601013, time_cost=2.458712577819824
09/18/2024 19:34:42 - INFO - accelerate.accelerator - Saving current state to /home/save_dir/runs/allinpaint_stage1/checkpoint-17000
09/18/2024 19:34:42 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-18 19:34:42,630] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-09-18 19:34:42,659] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/mp_rank_00_model_states.pt
[2024-09-18 19:34:42,660] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 19:35:00,395] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 19:35:00,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-18 19:35:00,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt...
[2024-09-18 19:35:00,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2024-09-18 19:35:00,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
[2024-09-18 19:35:00,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-09-18 19:35:00,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt...
[2024-09-18 19:35:00,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt...
[2024-09-18 19:35:00,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2024-09-18 19:35:35,415] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt.
[2024-09-18 19:35:35,415] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt
[2024-09-18 19:35:35,415] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 19:35:35,591] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt.
[2024-09-18 19:35:35,591] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt
[2024-09-18 19:35:35,591] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 19:35:35,686] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt.
[2024-09-18 19:35:35,686] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt
[2024-09-18 19:35:35,687] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 19:35:36,151] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-18 19:35:36,210] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-18 19:35:36,211] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 19:35:36,280] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
[2024-09-18 19:35:36,280] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
[2024-09-18 19:35:36,281] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 19:35:36,462] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2024-09-18 19:35:36,463] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[2024-09-18 19:35:36,463] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 19:35:36,608] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2024-09-18 19:35:36,608] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[2024-09-18 19:35:36,608] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 19:35:36,620] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-09-18 19:35:36,620] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-09-18 19:35:36,620] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/18/2024 19:35:36 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/pytorch_model
{'norm_num_groups', 'dropout', 'use_additional_conditions'} was not found in config. Values will be initialized to default values.
Configuration saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/model_ema/config.json
Model weights saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/model_ema/diffusion_pytorch_model.safetensors
Configuration saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/model/config.json
Model weights saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/model/diffusion_pytorch_model.safetensors
09/18/2024 19:36:39 - INFO - accelerate.checkpointing - Scheduler state saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/scheduler.bin
09/18/2024 19:36:39 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/sampler.bin
09/18/2024 19:36:39 - INFO - accelerate.checkpointing - Random states saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-17000/random_states_0.pkl
09/18/2024 19:36:39 - INFO - __main__ - Saved state to /home/save_dir/runs/allinpaint_stage1/checkpoint-17000
Steps:   2%|▏         | 17000/1000000 [10:12:36<2164:13:51,  7.93s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 17001/1000000 [10:12:43<11624:03:22, 42.57s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [17001], local_loss=0.16729380190372467, train_loss=0.040026433765888214, time_cost=1.2185585498809814
Steps:   2%|▏         | 17001/1000000 [10:12:43<11624:03:22, 42.57s/it, lr=1e-5, step_loss=0.167] Steps:   2%|▏         | 17002/1000000 [10:12:50<8776:02:22, 32.14s/it, lr=1e-5, step_loss=0.167] [RANK-0]: Step: [17002], local_loss=0.014310137368738651, train_loss=0.03296928480267525, time_cost=3.7338662147521973
Steps:   2%|▏         | 17002/1000000 [10:12:50<8776:02:22, 32.14s/it, lr=1e-5, step_loss=0.0143]Steps:   2%|▏         | 17003/1000000 [10:13:02<7094:58:08, 25.98s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [17003], local_loss=0.3650026321411133, train_loss=0.07945461571216583, time_cost=2.9234795570373535
Steps:   2%|▏         | 17003/1000000 [10:13:02<7094:58:08, 25.98s/it, lr=1e-5, step_loss=0.365] Steps:   2%|▏         | 17004/1000000 [10:13:16<6132:17:52, 22.46s/it, lr=1e-5, step_loss=0.365][RANK-0]: Step: [17004], local_loss=0.024287329986691475, train_loss=0.02627602592110634, time_cost=6.571466445922852
Steps:   2%|▏         | 17004/1000000 [10:13:16<6132:17:52, 22.46s/it, lr=1e-5, step_loss=0.0243]Steps:   2%|▏         | 17005/1000000 [10:13:29<5295:28:43, 19.39s/it, lr=1e-5, step_loss=0.0243][RANK-0]: Step: [17005], local_loss=0.0056488998234272, train_loss=0.008736910298466682, time_cost=5.432394981384277
Steps:   2%|▏         | 17005/1000000 [10:13:29<5295:28:43, 19.39s/it, lr=1e-5, step_loss=0.00565]Steps:   2%|▏         | 17006/1000000 [10:13:43<4891:30:46, 17.91s/it, lr=1e-5, step_loss=0.00565][RANK-0]: Step: [17006], local_loss=0.24337923526763916, train_loss=5.432071685791016, time_cost=7.699734449386597
Steps:   2%|▏         | 17006/1000000 [10:13:43<4891:30:46, 17.91s/it, lr=1e-5, step_loss=0.243]  Steps:   2%|▏         | 17007/1000000 [10:13:58<4628:31:06, 16.95s/it, lr=1e-5, step_loss=0.243][RANK-0]: Step: [17007], local_loss=0.007492171134799719, train_loss=0.021486900746822357, time_cost=2.821817398071289
Steps:   2%|▏         | 17007/1000000 [10:13:58<4628:31:06, 16.95s/it, lr=1e-5, step_loss=0.00749]Steps:   2%|▏         | 17008/1000000 [10:14:05<3803:43:57, 13.93s/it, lr=1e-5, step_loss=0.00749][RANK-0]: Step: [17008], local_loss=0.01994553580880165, train_loss=0.019243977963924408, time_cost=2.849259853363037
Steps:   2%|▏         | 17008/1000000 [10:14:05<3803:43:57, 13.93s/it, lr=1e-5, step_loss=0.0199] Steps:   2%|▏         | 17009/1000000 [10:14:18<3774:33:53, 13.82s/it, lr=1e-5, step_loss=0.0199][RANK-0]: Step: [17009], local_loss=0.05582321435213089, train_loss=0.021249083802103996, time_cost=4.934828519821167
Steps:   2%|▏         | 17009/1000000 [10:14:18<3774:33:53, 13.82s/it, lr=1e-5, step_loss=0.0558]Steps:   2%|▏         | 17010/1000000 [10:14:23<3050:47:55, 11.17s/it, lr=1e-5, step_loss=0.0558][RANK-0]: Step: [17010], local_loss=0.009395998902618885, train_loss=0.026475384831428528, time_cost=2.6838924884796143
Steps:   2%|▏         | 17010/1000000 [10:14:23<3050:47:55, 11.17s/it, lr=1e-5, step_loss=0.0094]Steps:   2%|▏         | 17011/1000000 [10:14:32<2843:05:36, 10.41s/it, lr=1e-5, step_loss=0.0094][RANK-0]: Step: [17011], local_loss=0.07386559247970581, train_loss=0.04007510468363762, time_cost=1.9882135391235352
Steps:   2%|▏         | 17011/1000000 [10:14:32<2843:05:36, 10.41s/it, lr=1e-5, step_loss=0.0739]Steps:   2%|▏         | 17012/1000000 [10:14:39<2553:04:56,  9.35s/it, lr=1e-5, step_loss=0.0739][RANK-0]: Step: [17012], local_loss=0.10174945741891861, train_loss=0.072031170129776, time_cost=2.6873836517333984
Steps:   2%|▏         | 17012/1000000 [10:14:39<2553:04:56,  9.35s/it, lr=1e-5, step_loss=0.102] Steps:   2%|▏         | 17013/1000000 [10:14:50<2693:51:41,  9.87s/it, lr=1e-5, step_loss=0.102][RANK-0]: Step: [17013], local_loss=0.009217701852321625, train_loss=0.04372020810842514, time_cost=1.8832461833953857
Steps:   2%|▏         | 17013/1000000 [10:14:50<2693:51:41,  9.87s/it, lr=1e-5, step_loss=0.00922]Steps:   2%|▏         | 17014/1000000 [10:14:56<2365:40:40,  8.66s/it, lr=1e-5, step_loss=0.00922][RANK-0]: Step: [17014], local_loss=0.008174596354365349, train_loss=0.03054795227944851, time_cost=3.1648924350738525
Steps:   2%|▏         | 17014/1000000 [10:14:56<2365:40:40,  8.66s/it, lr=1e-5, step_loss=0.00817]Steps:   2%|▏         | 17015/1000000 [10:15:00<2009:28:37,  7.36s/it, lr=1e-5, step_loss=0.00817][RANK-0]: Step: [17015], local_loss=0.04274656996130943, train_loss=0.06954493373632431, time_cost=3.2361862659454346
Steps:   2%|▏         | 17015/1000000 [10:15:00<2009:28:37,  7.36s/it, lr=1e-5, step_loss=0.0427] Steps:   2%|▏         | 17016/1000000 [10:15:05<1784:37:55,  6.54s/it, lr=1e-5, step_loss=0.0427][RANK-0]: Step: [17016], local_loss=0.08971323072910309, train_loss=0.04827580228447914, time_cost=1.9536457061767578
Steps:   2%|▏         | 17016/1000000 [10:15:05<1784:37:55,  6.54s/it, lr=1e-5, step_loss=0.0897]Steps:   2%|▏         | 17017/1000000 [10:15:13<1956:08:41,  7.16s/it, lr=1e-5, step_loss=0.0897][RANK-0]: Step: [17017], local_loss=0.01414811797440052, train_loss=0.040951184928417206, time_cost=2.0652544498443604
Steps:   2%|▏         | 17017/1000000 [10:15:13<1956:08:41,  7.16s/it, lr=1e-5, step_loss=0.0141]Steps:   2%|▏         | 17018/1000000 [10:15:23<2161:38:17,  7.92s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [17018], local_loss=0.020506415516138077, train_loss=0.03863615542650223, time_cost=4.838881254196167
Steps:   2%|▏         | 17018/1000000 [10:15:23<2161:38:17,  7.92s/it, lr=1e-5, step_loss=0.0205]Steps:   2%|▏         | 17019/1000000 [10:15:36<2609:44:36,  9.56s/it, lr=1e-5, step_loss=0.0205][RANK-0]: Step: [17019], local_loss=0.004572460427880287, train_loss=0.01665356755256653, time_cost=1.839611530303955
Steps:   2%|▏         | 17019/1000000 [10:15:36<2609:44:36,  9.56s/it, lr=1e-5, step_loss=0.00457]Steps:   2%|▏         | 17020/1000000 [10:15:43<2345:40:41,  8.59s/it, lr=1e-5, step_loss=0.00457][RANK-0]: Step: [17020], local_loss=0.03745537996292114, train_loss=0.023091644048690796, time_cost=1.9580888748168945
Steps:   2%|▏         | 17020/1000000 [10:15:43<2345:40:41,  8.59s/it, lr=1e-5, step_loss=0.0375] Steps:   2%|▏         | 17021/1000000 [10:15:49<2207:24:03,  8.08s/it, lr=1e-5, step_loss=0.0375][RANK-0]: Step: [17021], local_loss=0.0065335496328771114, train_loss=0.07693533599376678, time_cost=1.572727918624878
Steps:   2%|▏         | 17021/1000000 [10:15:49<2207:24:03,  8.08s/it, lr=1e-5, step_loss=0.00653]Steps:   2%|▏         | 17022/1000000 [10:15:55<1960:43:31,  7.18s/it, lr=1e-5, step_loss=0.00653][RANK-0]: Step: [17022], local_loss=0.004518147557973862, train_loss=0.025952113792300224, time_cost=2.3593649864196777
Steps:   2%|▏         | 17022/1000000 [10:15:55<1960:43:31,  7.18s/it, lr=1e-5, step_loss=0.00452]Steps:   2%|▏         | 17023/1000000 [10:16:04<2110:36:02,  7.73s/it, lr=1e-5, step_loss=0.00452][RANK-0]: Step: [17023], local_loss=0.02569216676056385, train_loss=0.14195960760116577, time_cost=3.052978992462158
Steps:   2%|▏         | 17023/1000000 [10:16:04<2110:36:02,  7.73s/it, lr=1e-5, step_loss=0.0257] Steps:   2%|▏         | 17024/1000000 [10:16:08<1868:30:54,  6.84s/it, lr=1e-5, step_loss=0.0257][RANK-0]: Step: [17024], local_loss=0.01020748633891344, train_loss=0.038323014974594116, time_cost=2.0481576919555664
Steps:   2%|▏         | 17024/1000000 [10:16:08<1868:30:54,  6.84s/it, lr=1e-5, step_loss=0.0102]Steps:   2%|▏         | 17025/1000000 [10:16:21<2369:14:39,  8.68s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [17025], local_loss=0.05221980810165405, train_loss=0.044524431228637695, time_cost=2.909327507019043
Steps:   2%|▏         | 17025/1000000 [10:16:21<2369:14:39,  8.68s/it, lr=1e-5, step_loss=0.0522]Steps:   2%|▏         | 17026/1000000 [10:16:27<2137:37:37,  7.83s/it, lr=1e-5, step_loss=0.0522][RANK-0]: Step: [17026], local_loss=0.010027221404016018, train_loss=0.02155633457005024, time_cost=2.048107147216797
Steps:   2%|▏         | 17026/1000000 [10:16:27<2137:37:37,  7.83s/it, lr=1e-5, step_loss=0.01]  Steps:   2%|▏         | 17027/1000000 [10:16:37<2326:46:28,  8.52s/it, lr=1e-5, step_loss=0.01][RANK-0]: Step: [17027], local_loss=0.01682356372475624, train_loss=0.049988530576229095, time_cost=4.816103458404541
Steps:   2%|▏         | 17027/1000000 [10:16:37<2326:46:28,  8.52s/it, lr=1e-5, step_loss=0.0168]Steps:   2%|▏         | 17028/1000000 [10:16:42<2043:21:30,  7.48s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [17028], local_loss=0.13665904104709625, train_loss=0.04363662004470825, time_cost=2.0197064876556396
Steps:   2%|▏         | 17028/1000000 [10:16:42<2043:21:30,  7.48s/it, lr=1e-5, step_loss=0.137] Steps:   2%|▏         | 17029/1000000 [10:16:49<1988:24:49,  7.28s/it, lr=1e-5, step_loss=0.137][RANK-0]: Step: [17029], local_loss=0.03544684126973152, train_loss=0.08063122630119324, time_cost=2.223586320877075
Steps:   2%|▏         | 17029/1000000 [10:16:49<1988:24:49,  7.28s/it, lr=1e-5, step_loss=0.0354]Steps:   2%|▏         | 17030/1000000 [10:16:54<1811:28:15,  6.63s/it, lr=1e-5, step_loss=0.0354][RANK-0]: Step: [17030], local_loss=0.03812282159924507, train_loss=0.0251470897346735, time_cost=2.120861530303955
Steps:   2%|▏         | 17030/1000000 [10:16:54<1811:28:15,  6.63s/it, lr=1e-5, step_loss=0.0381]Steps:   2%|▏         | 17031/1000000 [10:16:59<1649:56:44,  6.04s/it, lr=1e-5, step_loss=0.0381][RANK-0]: Step: [17031], local_loss=0.008001661859452724, train_loss=0.09258247911930084, time_cost=1.8013203144073486
Steps:   2%|▏         | 17031/1000000 [10:16:59<1649:56:44,  6.04s/it, lr=1e-5, step_loss=0.008] Steps:   2%|▏         | 17032/1000000 [10:17:13<2321:50:49,  8.50s/it, lr=1e-5, step_loss=0.008][RANK-0]: Step: [17032], local_loss=0.021294081583619118, train_loss=0.07609344273805618, time_cost=5.155463457107544
Steps:   2%|▏         | 17032/1000000 [10:17:13<2321:50:49,  8.50s/it, lr=1e-5, step_loss=0.0213]Steps:   2%|▏         | 17033/1000000 [10:17:19<2107:24:37,  7.72s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [17033], local_loss=0.008264526724815369, train_loss=0.0216110497713089, time_cost=1.667039155960083
Steps:   2%|▏         | 17033/1000000 [10:17:19<2107:24:37,  7.72s/it, lr=1e-5, step_loss=0.00826]Steps:   2%|▏         | 17034/1000000 [10:17:30<2400:02:51,  8.79s/it, lr=1e-5, step_loss=0.00826][RANK-0]: Step: [17034], local_loss=0.02181442454457283, train_loss=0.0950622707605362, time_cost=3.1636316776275635
Steps:   2%|▏         | 17034/1000000 [10:17:30<2400:02:51,  8.79s/it, lr=1e-5, step_loss=0.0218] Steps:   2%|▏         | 17035/1000000 [10:17:40<2443:45:03,  8.95s/it, lr=1e-5, step_loss=0.0218][RANK-0]: Step: [17035], local_loss=0.06964204460382462, train_loss=0.01811233162879944, time_cost=2.1837499141693115
Steps:   2%|▏         | 17035/1000000 [10:17:40<2443:45:03,  8.95s/it, lr=1e-5, step_loss=0.0696]Steps:   2%|▏         | 17036/1000000 [10:17:50<2580:50:57,  9.45s/it, lr=1e-5, step_loss=0.0696][RANK-0]: Step: [17036], local_loss=0.008123046718537807, train_loss=0.03549238294363022, time_cost=1.5178306102752686
Steps:   2%|▏         | 17036/1000000 [10:17:50<2580:50:57,  9.45s/it, lr=1e-5, step_loss=0.00812]Steps:   2%|▏         | 17037/1000000 [10:17:56<2282:11:33,  8.36s/it, lr=1e-5, step_loss=0.00812][RANK-0]: Step: [17037], local_loss=0.011182689107954502, train_loss=0.023621022701263428, time_cost=1.7580585479736328
Steps:   2%|▏         | 17037/1000000 [10:17:56<2282:11:33,  8.36s/it, lr=1e-5, step_loss=0.0112] Steps:   2%|▏         | 17038/1000000 [10:18:01<1966:50:01,  7.20s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [17038], local_loss=0.023985425010323524, train_loss=0.04145105928182602, time_cost=1.8924241065979004
Steps:   2%|▏         | 17038/1000000 [10:18:01<1966:50:01,  7.20s/it, lr=1e-5, step_loss=0.024] Steps:   2%|▏         | 17039/1000000 [10:18:13<2430:08:41,  8.90s/it, lr=1e-5, step_loss=0.024][RANK-0]: Step: [17039], local_loss=0.00828513503074646, train_loss=0.03431126847863197, time_cost=4.703451633453369
Steps:   2%|▏         | 17039/1000000 [10:18:13<2430:08:41,  8.90s/it, lr=1e-5, step_loss=0.00829]Steps:   2%|▏         | 17040/1000000 [10:18:18<2065:09:22,  7.56s/it, lr=1e-5, step_loss=0.00829][RANK-0]: Step: [17040], local_loss=217.28854370117188, train_loss=27.167818069458008, time_cost=1.4279425144195557
Steps:   2%|▏         | 17040/1000000 [10:18:18<2065:09:22,  7.56s/it, lr=1e-5, step_loss=217]    Steps:   2%|▏         | 17041/1000000 [10:18:23<1829:02:12,  6.70s/it, lr=1e-5, step_loss=217][RANK-0]: Step: [17041], local_loss=0.23120467364788055, train_loss=0.056637972593307495, time_cost=4.049082517623901
Steps:   2%|▏         | 17041/1000000 [10:18:23<1829:02:12,  6.70s/it, lr=1e-5, step_loss=0.231]Steps:   2%|▏         | 17042/1000000 [10:18:32<2083:48:17,  7.63s/it, lr=1e-5, step_loss=0.231][RANK-0]: Step: [17042], local_loss=0.018355675041675568, train_loss=0.06239573284983635, time_cost=1.2126598358154297
Steps:   2%|▏         | 17042/1000000 [10:18:32<2083:48:17,  7.63s/it, lr=1e-5, step_loss=0.0184]Steps:   2%|▏         | 17043/1000000 [10:18:38<1931:11:40,  7.07s/it, lr=1e-5, step_loss=0.0184][RANK-0]: Step: [17043], local_loss=0.012962582521140575, train_loss=0.035104572772979736, time_cost=2.861264944076538
Steps:   2%|▏         | 17043/1000000 [10:18:38<1931:11:40,  7.07s/it, lr=1e-5, step_loss=0.013] Steps:   2%|▏         | 17044/1000000 [10:18:45<1904:14:09,  6.97s/it, lr=1e-5, step_loss=0.013][RANK-0]: Step: [17044], local_loss=0.01475436333566904, train_loss=0.05589974299073219, time_cost=1.1971018314361572
Steps:   2%|▏         | 17044/1000000 [10:18:45<1904:14:09,  6.97s/it, lr=1e-5, step_loss=0.0148]Steps:   2%|▏         | 17045/1000000 [10:18:55<2180:27:52,  7.99s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [17045], local_loss=0.0037623175885528326, train_loss=0.02047348953783512, time_cost=8.155667066574097
Steps:   2%|▏         | 17045/1000000 [10:18:55<2180:27:52,  7.99s/it, lr=1e-5, step_loss=0.00376]Steps:   2%|▏         | 17046/1000000 [10:19:06<2425:17:59,  8.88s/it, lr=1e-5, step_loss=0.00376][RANK-0]: Step: [17046], local_loss=0.0913219004869461, train_loss=0.05411882326006889, time_cost=9.211600303649902
Steps:   2%|▏         | 17046/1000000 [10:19:06<2425:17:59,  8.88s/it, lr=1e-5, step_loss=0.0913] Steps:   2%|▏         | 17047/1000000 [10:19:12<2187:16:17,  8.01s/it, lr=1e-5, step_loss=0.0913][RANK-0]: Step: [17047], local_loss=0.010656215250492096, train_loss=0.05836912989616394, time_cost=2.320749521255493
Steps:   2%|▏         | 17047/1000000 [10:19:12<2187:16:17,  8.01s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 17048/1000000 [10:19:27<2750:54:44, 10.08s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [17048], local_loss=0.027633780613541603, train_loss=0.034164972603321075, time_cost=5.011379241943359
Steps:   2%|▏         | 17048/1000000 [10:19:27<2750:54:44, 10.08s/it, lr=1e-5, step_loss=0.0276]Steps:   2%|▏         | 17049/1000000 [10:19:38<2806:29:35, 10.28s/it, lr=1e-5, step_loss=0.0276][RANK-0]: Step: [17049], local_loss=0.013317900709807873, train_loss=0.018373243510723114, time_cost=3.491133689880371
Steps:   2%|▏         | 17049/1000000 [10:19:38<2806:29:35, 10.28s/it, lr=1e-5, step_loss=0.0133]Steps:   2%|▏         | 17050/1000000 [10:19:44<2458:51:44,  9.01s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [17050], local_loss=0.010539736598730087, train_loss=0.026859130710363388, time_cost=1.706376314163208
Steps:   2%|▏         | 17050/1000000 [10:19:44<2458:51:44,  9.01s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 17051/1000000 [10:19:55<2612:11:01,  9.57s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [17051], local_loss=0.013653445057570934, train_loss=0.04327967390418053, time_cost=3.1823229789733887
Steps:   2%|▏         | 17051/1000000 [10:19:55<2612:11:01,  9.57s/it, lr=1e-5, step_loss=0.0137]Steps:   2%|▏         | 17052/1000000 [10:20:04<2575:51:56,  9.43s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [17052], local_loss=0.02377752587199211, train_loss=0.016080014407634735, time_cost=2.3989760875701904
Steps:   2%|▏         | 17052/1000000 [10:20:04<2575:51:56,  9.43s/it, lr=1e-5, step_loss=0.0238]Steps:   2%|▏         | 17053/1000000 [10:20:09<2247:29:25,  8.23s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [17053], local_loss=0.007768424227833748, train_loss=0.03281796723604202, time_cost=1.1913602352142334
Steps:   2%|▏         | 17053/1000000 [10:20:09<2247:29:25,  8.23s/it, lr=1e-5, step_loss=0.00777]Steps:   2%|▏         | 17054/1000000 [10:20:15<2050:50:04,  7.51s/it, lr=1e-5, step_loss=0.00777][RANK-0]: Step: [17054], local_loss=0.056104376912117004, train_loss=0.12552843987941742, time_cost=1.2372794151306152
Steps:   2%|▏         | 17054/1000000 [10:20:15<2050:50:04,  7.51s/it, lr=1e-5, step_loss=0.0561] Steps:   2%|▏         | 17055/1000000 [10:20:19<1791:02:20,  6.56s/it, lr=1e-5, step_loss=0.0561][RANK-0]: Step: [17055], local_loss=0.004002873320132494, train_loss=0.03742249682545662, time_cost=1.3046696186065674
Steps:   2%|▏         | 17055/1000000 [10:20:19<1791:02:20,  6.56s/it, lr=1e-5, step_loss=0.004] Steps:   2%|▏         | 17056/1000000 [10:20:25<1744:55:59,  6.39s/it, lr=1e-5, step_loss=0.004][RANK-0]: Step: [17056], local_loss=0.006754414178431034, train_loss=0.030748941004276276, time_cost=1.805302381515503
Steps:   2%|▏         | 17056/1000000 [10:20:25<1744:55:59,  6.39s/it, lr=1e-5, step_loss=0.00675]Steps:   2%|▏         | 17057/1000000 [10:20:32<1787:01:50,  6.54s/it, lr=1e-5, step_loss=0.00675][RANK-0]: Step: [17057], local_loss=0.0045179040171206, train_loss=0.027827220037579536, time_cost=1.6811225414276123
Steps:   2%|▏         | 17057/1000000 [10:20:32<1787:01:50,  6.54s/it, lr=1e-5, step_loss=0.00452]Steps:   2%|▏         | 17058/1000000 [10:20:46<2400:53:43,  8.79s/it, lr=1e-5, step_loss=0.00452][RANK-0]: Step: [17058], local_loss=0.027017006650567055, train_loss=0.0343392938375473, time_cost=1.2097713947296143
Steps:   2%|▏         | 17058/1000000 [10:20:46<2400:53:43,  8.79s/it, lr=1e-5, step_loss=0.027]  Steps:   2%|▏         | 17059/1000000 [10:20:56<2435:58:33,  8.92s/it, lr=1e-5, step_loss=0.027][RANK-0]: Step: [17059], local_loss=0.02262757159769535, train_loss=0.04767153784632683, time_cost=1.820549726486206
Steps:   2%|▏         | 17059/1000000 [10:20:56<2435:58:33,  8.92s/it, lr=1e-5, step_loss=0.0226]Steps:   2%|▏         | 17060/1000000 [10:21:09<2779:51:13, 10.18s/it, lr=1e-5, step_loss=0.0226][RANK-0]: Step: [17060], local_loss=0.026640478521585464, train_loss=0.04087529331445694, time_cost=4.051220417022705
Steps:   2%|▏         | 17060/1000000 [10:21:09<2779:51:13, 10.18s/it, lr=1e-5, step_loss=0.0266]Steps:   2%|▏         | 17061/1000000 [10:21:18<2678:31:10,  9.81s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [17061], local_loss=0.01843699999153614, train_loss=0.012620381079614162, time_cost=3.2662792205810547
Steps:   2%|▏         | 17061/1000000 [10:21:18<2678:31:10,  9.81s/it, lr=1e-5, step_loss=0.0184]Steps:   2%|▏         | 17062/1000000 [10:21:23<2288:10:12,  8.38s/it, lr=1e-5, step_loss=0.0184][RANK-0]: Step: [17062], local_loss=0.011787229217588902, train_loss=0.01749703288078308, time_cost=2.136343240737915
Steps:   2%|▏         | 17062/1000000 [10:21:23<2288:10:12,  8.38s/it, lr=1e-5, step_loss=0.0118]Steps:   2%|▏         | 17063/1000000 [10:21:33<2402:52:52,  8.80s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [17063], local_loss=0.006451945751905441, train_loss=0.06308436393737793, time_cost=1.2171967029571533
Steps:   2%|▏         | 17063/1000000 [10:21:33<2402:52:52,  8.80s/it, lr=1e-5, step_loss=0.00645]Steps:   2%|▏         | 17064/1000000 [10:21:38<2106:03:38,  7.71s/it, lr=1e-5, step_loss=0.00645][RANK-0]: Step: [17064], local_loss=0.05452749505639076, train_loss=0.06825768947601318, time_cost=2.837646961212158
Steps:   2%|▏         | 17064/1000000 [10:21:38<2106:03:38,  7.71s/it, lr=1e-5, step_loss=0.0545] Steps:   2%|▏         | 17065/1000000 [10:21:51<2579:52:04,  9.45s/it, lr=1e-5, step_loss=0.0545][RANK-0]: Step: [17065], local_loss=0.05535423010587692, train_loss=0.045638810843229294, time_cost=5.069146156311035
Steps:   2%|▏         | 17065/1000000 [10:21:51<2579:52:04,  9.45s/it, lr=1e-5, step_loss=0.0554]Steps:   2%|▏         | 17066/1000000 [10:21:57<2243:24:03,  8.22s/it, lr=1e-5, step_loss=0.0554][RANK-0]: Step: [17066], local_loss=0.027827154844999313, train_loss=0.024214791133999825, time_cost=3.4502508640289307
Steps:   2%|▏         | 17066/1000000 [10:21:57<2243:24:03,  8.22s/it, lr=1e-5, step_loss=0.0278]Steps:   2%|▏         | 17067/1000000 [10:22:10<2683:47:02,  9.83s/it, lr=1e-5, step_loss=0.0278][RANK-0]: Step: [17067], local_loss=0.061876922845840454, train_loss=0.028765130788087845, time_cost=4.003878831863403
Steps:   2%|▏         | 17067/1000000 [10:22:10<2683:47:02,  9.83s/it, lr=1e-5, step_loss=0.0619]Steps:   2%|▏         | 17068/1000000 [10:22:17<2465:41:49,  9.03s/it, lr=1e-5, step_loss=0.0619][RANK-0]: Step: [17068], local_loss=0.9953207969665527, train_loss=0.1452087014913559, time_cost=3.1157546043395996
Steps:   2%|▏         | 17068/1000000 [10:22:17<2465:41:49,  9.03s/it, lr=1e-5, step_loss=0.995] Steps:   2%|▏         | 17069/1000000 [10:22:30<2798:11:04, 10.25s/it, lr=1e-5, step_loss=0.995][RANK-0]: Step: [17069], local_loss=0.007730227895081043, train_loss=0.03830719739198685, time_cost=5.172710180282593
Steps:   2%|▏         | 17069/1000000 [10:22:30<2798:11:04, 10.25s/it, lr=1e-5, step_loss=0.00773]Steps:   2%|▏         | 17070/1000000 [10:22:38<2562:19:14,  9.38s/it, lr=1e-5, step_loss=0.00773][RANK-0]: Step: [17070], local_loss=0.006284655537456274, train_loss=0.048874299973249435, time_cost=2.9931273460388184
Steps:   2%|▏         | 17070/1000000 [10:22:38<2562:19:14,  9.38s/it, lr=1e-5, step_loss=0.00628]Steps:   2%|▏         | 17071/1000000 [10:22:54<3130:49:55, 11.47s/it, lr=1e-5, step_loss=0.00628][RANK-0]: Step: [17071], local_loss=0.02051355130970478, train_loss=0.03242572396993637, time_cost=6.959258079528809
Steps:   2%|▏         | 17071/1000000 [10:22:54<3130:49:55, 11.47s/it, lr=1e-5, step_loss=0.0205] Steps:   2%|▏         | 17072/1000000 [10:22:59<2599:12:58,  9.52s/it, lr=1e-5, step_loss=0.0205][RANK-0]: Step: [17072], local_loss=0.05499086529016495, train_loss=0.017716161906719208, time_cost=1.2321975231170654
Steps:   2%|▏         | 17072/1000000 [10:22:59<2599:12:58,  9.52s/it, lr=1e-5, step_loss=0.055] Steps:   2%|▏         | 17073/1000000 [10:23:08<2516:59:29,  9.22s/it, lr=1e-5, step_loss=0.055][RANK-0]: Step: [17073], local_loss=0.004170609172433615, train_loss=0.048622552305459976, time_cost=2.2054989337921143
Steps:   2%|▏         | 17073/1000000 [10:23:08<2516:59:29,  9.22s/it, lr=1e-5, step_loss=0.00417]Steps:   2%|▏         | 17074/1000000 [10:23:14<2273:28:11,  8.33s/it, lr=1e-5, step_loss=0.00417][RANK-0]: Step: [17074], local_loss=0.018853534013032913, train_loss=0.0272950641810894, time_cost=2.6289665699005127
Steps:   2%|▏         | 17074/1000000 [10:23:14<2273:28:11,  8.33s/it, lr=1e-5, step_loss=0.0189] Steps:   2%|▏         | 17075/1000000 [10:23:29<2807:51:35, 10.28s/it, lr=1e-5, step_loss=0.0189][RANK-0]: Step: [17075], local_loss=0.011946111917495728, train_loss=0.029367543756961823, time_cost=5.694402456283569
Steps:   2%|▏         | 17075/1000000 [10:23:29<2807:51:35, 10.28s/it, lr=1e-5, step_loss=0.0119]Steps:   2%|▏         | 17076/1000000 [10:23:36<2553:22:52,  9.35s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [17076], local_loss=0.030453503131866455, train_loss=0.013341376557946205, time_cost=3.3968088626861572
Steps:   2%|▏         | 17076/1000000 [10:23:36<2553:22:52,  9.35s/it, lr=1e-5, step_loss=0.0305]Steps:   2%|▏         | 17077/1000000 [10:23:47<2667:06:37,  9.77s/it, lr=1e-5, step_loss=0.0305][RANK-0]: Step: [17077], local_loss=0.025900553911924362, train_loss=0.02443017065525055, time_cost=2.7009503841400146
Steps:   2%|▏         | 17077/1000000 [10:23:47<2667:06:37,  9.77s/it, lr=1e-5, step_loss=0.0259]Steps:   2%|▏         | 17078/1000000 [10:24:00<2989:13:57, 10.95s/it, lr=1e-5, step_loss=0.0259][RANK-0]: Step: [17078], local_loss=0.016340207308530807, train_loss=0.05744945630431175, time_cost=4.242282152175903
Steps:   2%|▏         | 17078/1000000 [10:24:00<2989:13:57, 10.95s/it, lr=1e-5, step_loss=0.0163]Steps:   2%|▏         | 17079/1000000 [10:24:14<3180:02:39, 11.65s/it, lr=1e-5, step_loss=0.0163][RANK-0]: Step: [17079], local_loss=0.034918349236249924, train_loss=0.018303124234080315, time_cost=5.919290065765381
Steps:   2%|▏         | 17079/1000000 [10:24:14<3180:02:39, 11.65s/it, lr=1e-5, step_loss=0.0349]Steps:   2%|▏         | 17080/1000000 [10:24:21<2799:25:27, 10.25s/it, lr=1e-5, step_loss=0.0349][RANK-0]: Step: [17080], local_loss=0.022627482190728188, train_loss=0.02942259982228279, time_cost=1.7373194694519043
Steps:   2%|▏         | 17080/1000000 [10:24:21<2799:25:27, 10.25s/it, lr=1e-5, step_loss=0.0226]Steps:   2%|▏         | 17081/1000000 [10:24:31<2849:56:31, 10.44s/it, lr=1e-5, step_loss=0.0226][RANK-0]: Step: [17081], local_loss=0.009917911142110825, train_loss=0.06406739354133606, time_cost=3.4599058628082275
Steps:   2%|▏         | 17081/1000000 [10:24:31<2849:56:31, 10.44s/it, lr=1e-5, step_loss=0.00992]Steps:   2%|▏         | 17082/1000000 [10:24:36<2354:25:02,  8.62s/it, lr=1e-5, step_loss=0.00992][RANK-0]: Step: [17082], local_loss=0.062414880841970444, train_loss=0.026574524119496346, time_cost=1.9491181373596191
Steps:   2%|▏         | 17082/1000000 [10:24:36<2354:25:02,  8.62s/it, lr=1e-5, step_loss=0.0624] Steps:   2%|▏         | 17083/1000000 [10:24:47<2565:50:58,  9.40s/it, lr=1e-5, step_loss=0.0624][RANK-0]: Step: [17083], local_loss=0.010323893278837204, train_loss=0.05153757333755493, time_cost=1.2712445259094238
Steps:   2%|▏         | 17083/1000000 [10:24:47<2565:50:58,  9.40s/it, lr=1e-5, step_loss=0.0103]Steps:   2%|▏         | 17084/1000000 [10:24:53<2269:17:58,  8.31s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [17084], local_loss=0.025615325197577477, train_loss=0.019817005842924118, time_cost=3.1970255374908447
Steps:   2%|▏         | 17084/1000000 [10:24:53<2269:17:58,  8.31s/it, lr=1e-5, step_loss=0.0256]Steps:   2%|▏         | 17085/1000000 [10:25:06<2627:56:53,  9.63s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [17085], local_loss=0.03696546331048012, train_loss=0.029480069875717163, time_cost=3.481982946395874
Steps:   2%|▏         | 17085/1000000 [10:25:06<2627:56:53,  9.63s/it, lr=1e-5, step_loss=0.037] Steps:   2%|▏         | 17086/1000000 [10:25:13<2437:06:14,  8.93s/it, lr=1e-5, step_loss=0.037][RANK-0]: Step: [17086], local_loss=0.009769631549715996, train_loss=0.016736947000026703, time_cost=1.4460463523864746
Steps:   2%|▏         | 17086/1000000 [10:25:13<2437:06:14,  8.93s/it, lr=1e-5, step_loss=0.00977]Steps:   2%|▏         | 17087/1000000 [10:25:18<2114:02:12,  7.74s/it, lr=1e-5, step_loss=0.00977][RANK-0]: Step: [17087], local_loss=0.016131140291690826, train_loss=0.02335335500538349, time_cost=1.243837833404541
Steps:   2%|▏         | 17087/1000000 [10:25:18<2114:02:12,  7.74s/it, lr=1e-5, step_loss=0.0161] Steps:   2%|▏         | 17088/1000000 [10:25:29<2393:04:37,  8.76s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [17088], local_loss=0.06097079813480377, train_loss=0.07244427502155304, time_cost=2.4268717765808105
Steps:   2%|▏         | 17088/1000000 [10:25:29<2393:04:37,  8.76s/it, lr=1e-5, step_loss=0.061] Steps:   2%|▏         | 17089/1000000 [10:25:34<2111:53:05,  7.73s/it, lr=1e-5, step_loss=0.061][RANK-0]: Step: [17089], local_loss=0.012160531245172024, train_loss=0.028521068394184113, time_cost=1.767665147781372
Steps:   2%|▏         | 17089/1000000 [10:25:34<2111:53:05,  7.73s/it, lr=1e-5, step_loss=0.0122]Steps:   2%|▏         | 17090/1000000 [10:25:42<2085:32:12,  7.64s/it, lr=1e-5, step_loss=0.0122][RANK-0]: Step: [17090], local_loss=0.013313534669578075, train_loss=0.16352711617946625, time_cost=2.1236393451690674
Steps:   2%|▏         | 17090/1000000 [10:25:42<2085:32:12,  7.64s/it, lr=1e-5, step_loss=0.0133]Steps:   2%|▏         | 17091/1000000 [10:25:47<1928:54:18,  7.06s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [17091], local_loss=0.005564291961491108, train_loss=0.04193637892603874, time_cost=3.018935203552246
Steps:   2%|▏         | 17091/1000000 [10:25:47<1928:54:18,  7.06s/it, lr=1e-5, step_loss=0.00556]Steps:   2%|▏         | 17092/1000000 [10:25:58<2180:12:20,  7.99s/it, lr=1e-5, step_loss=0.00556][RANK-0]: Step: [17092], local_loss=0.018645048141479492, train_loss=0.15143685042858124, time_cost=2.2827582359313965
Steps:   2%|▏         | 17092/1000000 [10:25:58<2180:12:20,  7.99s/it, lr=1e-5, step_loss=0.0186] Steps:   2%|▏         | 17093/1000000 [10:26:07<2313:45:27,  8.47s/it, lr=1e-5, step_loss=0.0186][RANK-0]: Step: [17093], local_loss=0.010770758613944054, train_loss=0.014527013525366783, time_cost=7.342333078384399
Steps:   2%|▏         | 17093/1000000 [10:26:07<2313:45:27,  8.47s/it, lr=1e-5, step_loss=0.0108]Steps:   2%|▏         | 17094/1000000 [10:26:14<2198:12:02,  8.05s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [17094], local_loss=0.030701909214258194, train_loss=0.05898623913526535, time_cost=1.479090929031372
Steps:   2%|▏         | 17094/1000000 [10:26:14<2198:12:02,  8.05s/it, lr=1e-5, step_loss=0.0307]Steps:   2%|▏         | 17095/1000000 [10:26:19<1905:31:47,  6.98s/it, lr=1e-5, step_loss=0.0307][RANK-0]: Step: [17095], local_loss=0.007715380750596523, train_loss=0.07811996340751648, time_cost=1.5310094356536865
Steps:   2%|▏         | 17095/1000000 [10:26:19<1905:31:47,  6.98s/it, lr=1e-5, step_loss=0.00772]Steps:   2%|▏         | 17096/1000000 [10:26:32<2388:57:01,  8.75s/it, lr=1e-5, step_loss=0.00772][RANK-0]: Step: [17096], local_loss=0.023798100650310516, train_loss=0.06823917478322983, time_cost=3.7151966094970703
Steps:   2%|▏         | 17096/1000000 [10:26:32<2388:57:01,  8.75s/it, lr=1e-5, step_loss=0.0238] Steps:   2%|▏         | 17097/1000000 [10:26:39<2319:07:37,  8.49s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [17097], local_loss=0.013394953683018684, train_loss=0.04315163567662239, time_cost=1.4909603595733643
Steps:   2%|▏         | 17097/1000000 [10:26:39<2319:07:37,  8.49s/it, lr=1e-5, step_loss=0.0134]Steps:   2%|▏         | 17098/1000000 [10:26:53<2722:44:52,  9.97s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [17098], local_loss=0.0168361384421587, train_loss=0.09085961431264877, time_cost=6.528135061264038
Steps:   2%|▏         | 17098/1000000 [10:26:53<2722:44:52,  9.97s/it, lr=1e-5, step_loss=0.0168]Steps:   2%|▏         | 17099/1000000 [10:26:59<2395:13:34,  8.77s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [17099], local_loss=0.02224777452647686, train_loss=0.02013300731778145, time_cost=3.204885482788086
Steps:   2%|▏         | 17099/1000000 [10:26:59<2395:13:34,  8.77s/it, lr=1e-5, step_loss=0.0222]Steps:   2%|▏         | 17100/1000000 [10:27:09<2524:20:28,  9.25s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [17100], local_loss=0.047431811690330505, train_loss=0.0389510914683342, time_cost=2.422595739364624
Steps:   2%|▏         | 17100/1000000 [10:27:09<2524:20:28,  9.25s/it, lr=1e-5, step_loss=0.0474]Steps:   2%|▏         | 17101/1000000 [10:27:15<2227:45:47,  8.16s/it, lr=1e-5, step_loss=0.0474][RANK-0]: Step: [17101], local_loss=0.008371138013899326, train_loss=0.04870928078889847, time_cost=2.4199299812316895
Steps:   2%|▏         | 17101/1000000 [10:27:15<2227:45:47,  8.16s/it, lr=1e-5, step_loss=0.00837]Steps:   2%|▏         | 17102/1000000 [10:27:25<2352:45:44,  8.62s/it, lr=1e-5, step_loss=0.00837][RANK-0]: Step: [17102], local_loss=0.008475162088871002, train_loss=0.0380842499434948, time_cost=3.5780279636383057
Steps:   2%|▏         | 17102/1000000 [10:27:25<2352:45:44,  8.62s/it, lr=1e-5, step_loss=0.00848]Steps:   2%|▏         | 17103/1000000 [10:27:30<2075:29:42,  7.60s/it, lr=1e-5, step_loss=0.00848][RANK-0]: Step: [17103], local_loss=0.0033923794981092215, train_loss=0.011446196585893631, time_cost=1.684288501739502
Steps:   2%|▏         | 17103/1000000 [10:27:30<2075:29:42,  7.60s/it, lr=1e-5, step_loss=0.00339]Steps:   2%|▏         | 17104/1000000 [10:27:41<2346:54:56,  8.60s/it, lr=1e-5, step_loss=0.00339][RANK-0]: Step: [17104], local_loss=0.015494677238166332, train_loss=0.06258359551429749, time_cost=1.8795270919799805
Steps:   2%|▏         | 17104/1000000 [10:27:41<2346:54:56,  8.60s/it, lr=1e-5, step_loss=0.0155] Steps:   2%|▏         | 17105/1000000 [10:27:49<2320:24:05,  8.50s/it, lr=1e-5, step_loss=0.0155][RANK-0]: Step: [17105], local_loss=1.0119497776031494, train_loss=0.19561299681663513, time_cost=3.5167367458343506
Steps:   2%|▏         | 17105/1000000 [10:27:49<2320:24:05,  8.50s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 17106/1000000 [10:27:56<2195:23:03,  8.04s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [17106], local_loss=0.08052906394004822, train_loss=0.026947928592562675, time_cost=2.8517966270446777
Steps:   2%|▏         | 17106/1000000 [10:27:56<2195:23:03,  8.04s/it, lr=1e-5, step_loss=0.0805]Steps:   2%|▏         | 17107/1000000 [10:28:04<2197:09:54,  8.05s/it, lr=1e-5, step_loss=0.0805][RANK-0]: Step: [17107], local_loss=0.029280779883265495, train_loss=0.02352266013622284, time_cost=1.7102937698364258
Steps:   2%|▏         | 17107/1000000 [10:28:04<2197:09:54,  8.05s/it, lr=1e-5, step_loss=0.0293]Steps:   2%|▏         | 17108/1000000 [10:28:13<2300:31:27,  8.43s/it, lr=1e-5, step_loss=0.0293][RANK-0]: Step: [17108], local_loss=0.17559760808944702, train_loss=0.1052403599023819, time_cost=1.745103120803833
Steps:   2%|▏         | 17108/1000000 [10:28:13<2300:31:27,  8.43s/it, lr=1e-5, step_loss=0.176] Steps:   2%|▏         | 17109/1000000 [10:28:20<2145:08:03,  7.86s/it, lr=1e-5, step_loss=0.176][RANK-0]: Step: [17109], local_loss=0.006674581207334995, train_loss=0.03349587693810463, time_cost=1.7437434196472168
Steps:   2%|▏         | 17109/1000000 [10:28:20<2145:08:03,  7.86s/it, lr=1e-5, step_loss=0.00667]Steps:   2%|▏         | 17110/1000000 [10:28:26<1978:05:06,  7.25s/it, lr=1e-5, step_loss=0.00667][RANK-0]: Step: [17110], local_loss=0.03741637244820595, train_loss=21.119070053100586, time_cost=2.244131565093994
Steps:   2%|▏         | 17110/1000000 [10:28:26<1978:05:06,  7.25s/it, lr=1e-5, step_loss=0.0374] Steps:   2%|▏         | 17111/1000000 [10:28:33<1981:31:35,  7.26s/it, lr=1e-5, step_loss=0.0374][RANK-0]: Step: [17111], local_loss=0.018283206969499588, train_loss=0.0573887974023819, time_cost=1.833521842956543
Steps:   2%|▏         | 17111/1000000 [10:28:33<1981:31:35,  7.26s/it, lr=1e-5, step_loss=0.0183]Steps:   2%|▏         | 17112/1000000 [10:28:42<2154:49:43,  7.89s/it, lr=1e-5, step_loss=0.0183][RANK-0]: Step: [17112], local_loss=0.007564044091850519, train_loss=0.04200679808855057, time_cost=2.288390874862671
Steps:   2%|▏         | 17112/1000000 [10:28:42<2154:49:43,  7.89s/it, lr=1e-5, step_loss=0.00756]Steps:   2%|▏         | 17113/1000000 [10:28:56<2627:55:04,  9.63s/it, lr=1e-5, step_loss=0.00756][RANK-0]: Step: [17113], local_loss=0.004767666570842266, train_loss=0.1422896832227707, time_cost=5.812268257141113
Steps:   2%|▏         | 17113/1000000 [10:28:56<2627:55:04,  9.63s/it, lr=1e-5, step_loss=0.00477]Steps:   2%|▏         | 17114/1000000 [10:29:05<2556:31:13,  9.36s/it, lr=1e-5, step_loss=0.00477][RANK-0]: Step: [17114], local_loss=0.03426910564303398, train_loss=0.022020023316144943, time_cost=1.3018684387207031
Steps:   2%|▏         | 17114/1000000 [10:29:05<2556:31:13,  9.36s/it, lr=1e-5, step_loss=0.0343] Steps:   2%|▏         | 17115/1000000 [10:29:11<2284:31:02,  8.37s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [17115], local_loss=0.010281167924404144, train_loss=0.042847033590078354, time_cost=2.8983922004699707
Steps:   2%|▏         | 17115/1000000 [10:29:11<2284:31:02,  8.37s/it, lr=1e-5, step_loss=0.0103]Steps:   2%|▏         | 17116/1000000 [10:29:24<2669:38:04,  9.78s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [17116], local_loss=0.11659227311611176, train_loss=0.07768339663743973, time_cost=1.300832986831665
Steps:   2%|▏         | 17116/1000000 [10:29:24<2669:38:04,  9.78s/it, lr=1e-5, step_loss=0.117] Steps:   2%|▏         | 17117/1000000 [10:29:34<2729:50:08, 10.00s/it, lr=1e-5, step_loss=0.117][RANK-0]: Step: [17117], local_loss=0.05238935351371765, train_loss=0.04478283226490021, time_cost=5.267875909805298
Steps:   2%|▏         | 17117/1000000 [10:29:34<2729:50:08, 10.00s/it, lr=1e-5, step_loss=0.0524]Steps:   2%|▏         | 17118/1000000 [10:29:39<2329:16:55,  8.53s/it, lr=1e-5, step_loss=0.0524][RANK-0]: Step: [17118], local_loss=0.07344929128885269, train_loss=0.02826605550944805, time_cost=2.723808765411377
Steps:   2%|▏         | 17118/1000000 [10:29:39<2329:16:55,  8.53s/it, lr=1e-5, step_loss=0.0734]Steps:   2%|▏         | 17119/1000000 [10:29:44<2013:56:14,  7.38s/it, lr=1e-5, step_loss=0.0734][RANK-0]: Step: [17119], local_loss=0.006358189042657614, train_loss=0.0297941155731678, time_cost=2.3531789779663086
Steps:   2%|▏         | 17119/1000000 [10:29:44<2013:56:14,  7.38s/it, lr=1e-5, step_loss=0.00636]Steps:   2%|▏         | 17120/1000000 [10:29:51<1961:44:18,  7.19s/it, lr=1e-5, step_loss=0.00636][RANK-0]: Step: [17120], local_loss=0.005625964142382145, train_loss=0.020977813750505447, time_cost=2.7232275009155273
Steps:   2%|▏         | 17120/1000000 [10:29:51<1961:44:18,  7.19s/it, lr=1e-5, step_loss=0.00563]Steps:   2%|▏         | 17121/1000000 [10:30:02<2312:42:58,  8.47s/it, lr=1e-5, step_loss=0.00563][RANK-0]: Step: [17121], local_loss=0.003548691514879465, train_loss=0.035916902124881744, time_cost=4.457494258880615
Steps:   2%|▏         | 17121/1000000 [10:30:02<2312:42:58,  8.47s/it, lr=1e-5, step_loss=0.00355]Steps:   2%|▏         | 17122/1000000 [10:30:21<3143:46:34, 11.51s/it, lr=1e-5, step_loss=0.00355][RANK-0]: Step: [17122], local_loss=0.02704804390668869, train_loss=0.040191344916820526, time_cost=15.11713719367981
Steps:   2%|▏         | 17122/1000000 [10:30:21<3143:46:34, 11.51s/it, lr=1e-5, step_loss=0.027]  Steps:   2%|▏         | 17123/1000000 [10:30:28<2783:30:04, 10.20s/it, lr=1e-5, step_loss=0.027][RANK-0]: Step: [17123], local_loss=0.018052099272608757, train_loss=0.1473543494939804, time_cost=2.549639940261841
Steps:   2%|▏         | 17123/1000000 [10:30:28<2783:30:04, 10.20s/it, lr=1e-5, step_loss=0.0181]Steps:   2%|▏         | 17124/1000000 [10:30:33<2355:32:51,  8.63s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [17124], local_loss=0.017276672646403313, train_loss=0.0424175001680851, time_cost=1.781468391418457
Steps:   2%|▏         | 17124/1000000 [10:30:33<2355:32:51,  8.63s/it, lr=1e-5, step_loss=0.0173]Steps:   2%|▏         | 17125/1000000 [10:30:39<2173:59:45,  7.96s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [17125], local_loss=0.0121476324275136, train_loss=0.02822267636656761, time_cost=1.2953858375549316
Steps:   2%|▏         | 17125/1000000 [10:30:39<2173:59:45,  7.96s/it, lr=1e-5, step_loss=0.0121]Steps:   2%|▏         | 17126/1000000 [10:30:50<2365:13:39,  8.66s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [17126], local_loss=0.10015150159597397, train_loss=0.07835046947002411, time_cost=1.3395969867706299
Steps:   2%|▏         | 17126/1000000 [10:30:50<2365:13:39,  8.66s/it, lr=1e-5, step_loss=0.1]   Steps:   2%|▏         | 17127/1000000 [10:30:56<2158:28:55,  7.91s/it, lr=1e-5, step_loss=0.1][RANK-0]: Step: [17127], local_loss=0.01068396121263504, train_loss=0.09895104169845581, time_cost=2.1416385173797607
Steps:   2%|▏         | 17127/1000000 [10:30:56<2158:28:55,  7.91s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 17128/1000000 [10:31:07<2426:56:00,  8.89s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [17128], local_loss=0.14021694660186768, train_loss=6.508214473724365, time_cost=2.259843111038208
Steps:   2%|▏         | 17128/1000000 [10:31:07<2426:56:00,  8.89s/it, lr=1e-5, step_loss=0.14]  Steps:   2%|▏         | 17129/1000000 [10:31:18<2592:47:53,  9.50s/it, lr=1e-5, step_loss=0.14][RANK-0]: Step: [17129], local_loss=0.007361278869211674, train_loss=0.012461073696613312, time_cost=2.998835802078247
Steps:   2%|▏         | 17129/1000000 [10:31:18<2592:47:53,  9.50s/it, lr=1e-5, step_loss=0.00736]Steps:   2%|▏         | 17130/1000000 [10:31:30<2836:56:22, 10.39s/it, lr=1e-5, step_loss=0.00736][RANK-0]: Step: [17130], local_loss=0.003973466344177723, train_loss=0.011820184998214245, time_cost=10.372739553451538
Steps:   2%|▏         | 17130/1000000 [10:31:30<2836:56:22, 10.39s/it, lr=1e-5, step_loss=0.00397]Steps:   2%|▏         | 17131/1000000 [10:31:40<2732:58:37, 10.01s/it, lr=1e-5, step_loss=0.00397][RANK-0]: Step: [17131], local_loss=0.02471802569925785, train_loss=0.15202587842941284, time_cost=2.0711405277252197
Steps:   2%|▏         | 17131/1000000 [10:31:40<2732:58:37, 10.01s/it, lr=1e-5, step_loss=0.0247] Steps:   2%|▏         | 17132/1000000 [10:31:47<2512:28:14,  9.20s/it, lr=1e-5, step_loss=0.0247][RANK-0]: Step: [17132], local_loss=0.017853910103440285, train_loss=0.034645065665245056, time_cost=3.0714752674102783
Steps:   2%|▏         | 17132/1000000 [10:31:47<2512:28:14,  9.20s/it, lr=1e-5, step_loss=0.0179]Steps:   2%|▏         | 17133/1000000 [10:31:54<2337:22:52,  8.56s/it, lr=1e-5, step_loss=0.0179][RANK-0]: Step: [17133], local_loss=0.015421630814671516, train_loss=0.0794316828250885, time_cost=5.3080384731292725
Steps:   2%|▏         | 17133/1000000 [10:31:54<2337:22:52,  8.56s/it, lr=1e-5, step_loss=0.0154]Steps:   2%|▏         | 17134/1000000 [10:31:59<2039:26:43,  7.47s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [17134], local_loss=0.036404091864824295, train_loss=0.03085879050195217, time_cost=3.8838295936584473
Steps:   2%|▏         | 17134/1000000 [10:31:59<2039:26:43,  7.47s/it, lr=1e-5, step_loss=0.0364]Steps:   2%|▏         | 17135/1000000 [10:32:04<1838:47:52,  6.74s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [17135], local_loss=0.019062010571360588, train_loss=6.44851016998291, time_cost=1.9871718883514404
Steps:   2%|▏         | 17135/1000000 [10:32:04<1838:47:52,  6.74s/it, lr=1e-5, step_loss=0.0191]Steps:   2%|▏         | 17136/1000000 [10:32:15<2224:34:42,  8.15s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [17136], local_loss=0.04590502753853798, train_loss=0.051072217524051666, time_cost=1.2245895862579346
Steps:   2%|▏         | 17136/1000000 [10:32:15<2224:34:42,  8.15s/it, lr=1e-5, step_loss=0.0459]Steps:   2%|▏         | 17137/1000000 [10:32:20<1975:53:00,  7.24s/it, lr=1e-5, step_loss=0.0459][RANK-0]: Step: [17137], local_loss=0.010789016261696815, train_loss=0.026286941021680832, time_cost=2.151676654815674
Steps:   2%|▏         | 17137/1000000 [10:32:20<1975:53:00,  7.24s/it, lr=1e-5, step_loss=0.0108]Steps:   2%|▏         | 17138/1000000 [10:32:29<2080:37:04,  7.62s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [17138], local_loss=0.03109882026910782, train_loss=0.030759019777178764, time_cost=1.7947866916656494
Steps:   2%|▏         | 17138/1000000 [10:32:29<2080:37:04,  7.62s/it, lr=1e-5, step_loss=0.0311]Steps:   2%|▏         | 17139/1000000 [10:32:39<2314:57:43,  8.48s/it, lr=1e-5, step_loss=0.0311][RANK-0]: Step: [17139], local_loss=0.010712006129324436, train_loss=0.06345026940107346, time_cost=4.297187089920044
Steps:   2%|▏         | 17139/1000000 [10:32:39<2314:57:43,  8.48s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 17140/1000000 [10:32:46<2172:37:40,  7.96s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [17140], local_loss=0.04723839834332466, train_loss=0.07370564341545105, time_cost=3.1183364391326904
Steps:   2%|▏         | 17140/1000000 [10:32:46<2172:37:40,  7.96s/it, lr=1e-5, step_loss=0.0472]Steps:   2%|▏         | 17141/1000000 [10:32:57<2384:57:29,  8.74s/it, lr=1e-5, step_loss=0.0472][RANK-0]: Step: [17141], local_loss=0.11890839785337448, train_loss=0.08284083008766174, time_cost=1.9019420146942139
Steps:   2%|▏         | 17141/1000000 [10:32:57<2384:57:29,  8.74s/it, lr=1e-5, step_loss=0.119] Steps:   2%|▏         | 17142/1000000 [10:33:03<2159:33:20,  7.91s/it, lr=1e-5, step_loss=0.119][RANK-0]: Step: [17142], local_loss=0.011283145286142826, train_loss=0.02681908570230007, time_cost=1.5543851852416992
Steps:   2%|▏         | 17142/1000000 [10:33:03<2159:33:20,  7.91s/it, lr=1e-5, step_loss=0.0113]Steps:   2%|▏         | 17143/1000000 [10:33:09<1998:39:40,  7.32s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [17143], local_loss=0.010634428821504116, train_loss=0.0458163321018219, time_cost=2.174447536468506
Steps:   2%|▏         | 17143/1000000 [10:33:09<1998:39:40,  7.32s/it, lr=1e-5, step_loss=0.0106]Steps:   2%|▏         | 17144/1000000 [10:33:13<1758:45:15,  6.44s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [17144], local_loss=0.006663517095148563, train_loss=0.15899938344955444, time_cost=1.4077284336090088
Steps:   2%|▏         | 17144/1000000 [10:33:13<1758:45:15,  6.44s/it, lr=1e-5, step_loss=0.00666]Steps:   2%|▏         | 17145/1000000 [10:33:18<1651:26:04,  6.05s/it, lr=1e-5, step_loss=0.00666][RANK-0]: Step: [17145], local_loss=0.04465483874082565, train_loss=0.029335957020521164, time_cost=2.1370298862457275
Steps:   2%|▏         | 17145/1000000 [10:33:18<1651:26:04,  6.05s/it, lr=1e-5, step_loss=0.0447] Steps:   2%|▏         | 17146/1000000 [10:33:28<1985:14:40,  7.27s/it, lr=1e-5, step_loss=0.0447][RANK-0]: Step: [17146], local_loss=0.01747104898095131, train_loss=0.02711649239063263, time_cost=3.2970056533813477
Steps:   2%|▏         | 17146/1000000 [10:33:28<1985:14:40,  7.27s/it, lr=1e-5, step_loss=0.0175]Steps:   2%|▏         | 17147/1000000 [10:33:40<2325:27:35,  8.52s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [17147], local_loss=0.02131481282413006, train_loss=0.05192849785089493, time_cost=3.785869598388672
Steps:   2%|▏         | 17147/1000000 [10:33:40<2325:27:35,  8.52s/it, lr=1e-5, step_loss=0.0213]Steps:   2%|▏         | 17148/1000000 [10:33:46<2117:43:25,  7.76s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [17148], local_loss=1.005928635597229, train_loss=0.13603658974170685, time_cost=1.66654372215271
Steps:   2%|▏         | 17148/1000000 [10:33:46<2117:43:25,  7.76s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 17149/1000000 [10:33:53<2091:42:50,  7.66s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [17149], local_loss=0.054496195167303085, train_loss=0.035998594015836716, time_cost=1.8794808387756348
Steps:   2%|▏         | 17149/1000000 [10:33:53<2091:42:50,  7.66s/it, lr=1e-5, step_loss=0.0545]Steps:   2%|▏         | 17150/1000000 [10:33:58<1828:50:59,  6.70s/it, lr=1e-5, step_loss=0.0545][RANK-0]: Step: [17150], local_loss=0.03264959156513214, train_loss=0.03687714785337448, time_cost=1.5945394039154053
Steps:   2%|▏         | 17150/1000000 [10:33:58<1828:50:59,  6.70s/it, lr=1e-5, step_loss=0.0326]Steps:   2%|▏         | 17151/1000000 [10:34:07<2046:21:11,  7.50s/it, lr=1e-5, step_loss=0.0326][RANK-0]: Step: [17151], local_loss=0.03531739115715027, train_loss=0.03220415860414505, time_cost=2.1598262786865234
Steps:   2%|▏         | 17151/1000000 [10:34:07<2046:21:11,  7.50s/it, lr=1e-5, step_loss=0.0353]Steps:   2%|▏         | 17152/1000000 [10:34:20<2465:50:22,  9.03s/it, lr=1e-5, step_loss=0.0353][RANK-0]: Step: [17152], local_loss=0.021234722808003426, train_loss=0.02876708284020424, time_cost=5.495088815689087
Steps:   2%|▏         | 17152/1000000 [10:34:20<2465:50:22,  9.03s/it, lr=1e-5, step_loss=0.0212]Steps:   2%|▏         | 17153/1000000 [10:34:25<2206:50:20,  8.08s/it, lr=1e-5, step_loss=0.0212][RANK-0]: Step: [17153], local_loss=0.025993939489126205, train_loss=0.043110065162181854, time_cost=1.3480477333068848
Steps:   2%|▏         | 17153/1000000 [10:34:25<2206:50:20,  8.08s/it, lr=1e-5, step_loss=0.026] Steps:   2%|▏         | 17154/1000000 [10:34:31<1996:17:37,  7.31s/it, lr=1e-5, step_loss=0.026][RANK-0]: Step: [17154], local_loss=0.006469164043664932, train_loss=0.02858629822731018, time_cost=2.3053410053253174
Steps:   2%|▏         | 17154/1000000 [10:34:31<1996:17:37,  7.31s/it, lr=1e-5, step_loss=0.00647]Steps:   2%|▏         | 17155/1000000 [10:34:40<2115:44:01,  7.75s/it, lr=1e-5, step_loss=0.00647][RANK-0]: Step: [17155], local_loss=0.010326666757464409, train_loss=0.035195332020521164, time_cost=2.9304139614105225
Steps:   2%|▏         | 17155/1000000 [10:34:40<2115:44:01,  7.75s/it, lr=1e-5, step_loss=0.0103] Steps:   2%|▏         | 17156/1000000 [10:34:47<2102:29:11,  7.70s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [17156], local_loss=0.01678105816245079, train_loss=0.07221725583076477, time_cost=1.5422124862670898
Steps:   2%|▏         | 17156/1000000 [10:34:47<2102:29:11,  7.70s/it, lr=1e-5, step_loss=0.0168]Steps:   2%|▏         | 17157/1000000 [10:34:55<2071:27:46,  7.59s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [17157], local_loss=0.004215781576931477, train_loss=0.018153898417949677, time_cost=1.9524903297424316
Steps:   2%|▏         | 17157/1000000 [10:34:55<2071:27:46,  7.59s/it, lr=1e-5, step_loss=0.00422]Steps:   2%|▏         | 17158/1000000 [10:35:02<2066:27:52,  7.57s/it, lr=1e-5, step_loss=0.00422][RANK-0]: Step: [17158], local_loss=0.045482661575078964, train_loss=0.1538550853729248, time_cost=2.295433521270752
Steps:   2%|▏         | 17158/1000000 [10:35:02<2066:27:52,  7.57s/it, lr=1e-5, step_loss=0.0455] Steps:   2%|▏         | 17159/1000000 [10:35:07<1833:45:41,  6.72s/it, lr=1e-5, step_loss=0.0455][RANK-0]: Step: [17159], local_loss=0.03381654992699623, train_loss=0.032146621495485306, time_cost=1.2330467700958252
Steps:   2%|▏         | 17159/1000000 [10:35:07<1833:45:41,  6.72s/it, lr=1e-5, step_loss=0.0338]Steps:   2%|▏         | 17160/1000000 [10:35:15<1929:42:39,  7.07s/it, lr=1e-5, step_loss=0.0338][RANK-0]: Step: [17160], local_loss=0.044187143445014954, train_loss=0.029678404331207275, time_cost=2.990926504135132
Steps:   2%|▏         | 17160/1000000 [10:35:15<1929:42:39,  7.07s/it, lr=1e-5, step_loss=0.0442]Steps:   2%|▏         | 17161/1000000 [10:35:25<2156:16:08,  7.90s/it, lr=1e-5, step_loss=0.0442][RANK-0]: Step: [17161], local_loss=0.01995261386036873, train_loss=0.07378056645393372, time_cost=1.7687296867370605
Steps:   2%|▏         | 17161/1000000 [10:35:25<2156:16:08,  7.90s/it, lr=1e-5, step_loss=0.02]  Steps:   2%|▏         | 17162/1000000 [10:35:30<1936:06:14,  7.09s/it, lr=1e-5, step_loss=0.02][RANK-0]: Step: [17162], local_loss=0.012438500300049782, train_loss=0.06986457109451294, time_cost=1.7939167022705078
Steps:   2%|▏         | 17162/1000000 [10:35:30<1936:06:14,  7.09s/it, lr=1e-5, step_loss=0.0124]Steps:   2%|▏         | 17163/1000000 [10:35:44<2543:49:15,  9.32s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [17163], local_loss=0.09580973535776138, train_loss=0.04698414355516434, time_cost=4.632310152053833
Steps:   2%|▏         | 17163/1000000 [10:35:44<2543:49:15,  9.32s/it, lr=1e-5, step_loss=0.0958]Steps:   2%|▏         | 17164/1000000 [10:35:52<2381:34:00,  8.72s/it, lr=1e-5, step_loss=0.0958][RANK-0]: Step: [17164], local_loss=0.009722741320729256, train_loss=0.13331668078899384, time_cost=2.271346092224121
Steps:   2%|▏         | 17164/1000000 [10:35:52<2381:34:00,  8.72s/it, lr=1e-5, step_loss=0.00972]Steps:   2%|▏         | 17165/1000000 [10:36:03<2569:16:48,  9.41s/it, lr=1e-5, step_loss=0.00972][RANK-0]: Step: [17165], local_loss=0.012271569110453129, train_loss=0.014836407266557217, time_cost=3.332444190979004
Steps:   2%|▏         | 17165/1000000 [10:36:03<2569:16:48,  9.41s/it, lr=1e-5, step_loss=0.0123] Steps:   2%|▏         | 17166/1000000 [10:36:07<2188:12:25,  8.02s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [17166], local_loss=0.005667452234774828, train_loss=0.021166017279028893, time_cost=1.2597241401672363
Steps:   2%|▏         | 17166/1000000 [10:36:07<2188:12:25,  8.02s/it, lr=1e-5, step_loss=0.00567]Steps:   2%|▏         | 17167/1000000 [10:36:21<2610:11:55,  9.56s/it, lr=1e-5, step_loss=0.00567][RANK-0]: Step: [17167], local_loss=0.04693833738565445, train_loss=0.04164819046854973, time_cost=3.277423620223999
Steps:   2%|▏         | 17167/1000000 [10:36:21<2610:11:55,  9.56s/it, lr=1e-5, step_loss=0.0469] Steps:   2%|▏         | 17168/1000000 [10:36:26<2229:53:36,  8.17s/it, lr=1e-5, step_loss=0.0469][RANK-0]: Step: [17168], local_loss=0.013906270265579224, train_loss=0.06684263795614243, time_cost=1.264786958694458
Steps:   2%|▏         | 17168/1000000 [10:36:26<2229:53:36,  8.17s/it, lr=1e-5, step_loss=0.0139]Steps:   2%|▏         | 17169/1000000 [10:36:37<2479:52:00,  9.08s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [17169], local_loss=0.009114840067923069, train_loss=0.086735300719738, time_cost=4.375071048736572
Steps:   2%|▏         | 17169/1000000 [10:36:37<2479:52:00,  9.08s/it, lr=1e-5, step_loss=0.00911]Steps:   2%|▏         | 17170/1000000 [10:36:51<2902:58:04, 10.63s/it, lr=1e-5, step_loss=0.00911][RANK-0]: Step: [17170], local_loss=0.04048430919647217, train_loss=0.056893400847911835, time_cost=1.2203137874603271
Steps:   2%|▏         | 17170/1000000 [10:36:51<2902:58:04, 10.63s/it, lr=1e-5, step_loss=0.0405] Steps:   2%|▏         | 17171/1000000 [10:36:58<2609:24:22,  9.56s/it, lr=1e-5, step_loss=0.0405][RANK-0]: Step: [17171], local_loss=0.2174765169620514, train_loss=0.04437441751360893, time_cost=4.264864206314087
Steps:   2%|▏         | 17171/1000000 [10:36:58<2609:24:22,  9.56s/it, lr=1e-5, step_loss=0.217] Steps:   2%|▏         | 17172/1000000 [10:37:02<2169:36:17,  7.95s/it, lr=1e-5, step_loss=0.217][RANK-0]: Step: [17172], local_loss=0.0111435167491436, train_loss=0.17268989980220795, time_cost=2.85172438621521
Steps:   2%|▏         | 17172/1000000 [10:37:02<2169:36:17,  7.95s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 17173/1000000 [10:37:08<1950:24:44,  7.14s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [17173], local_loss=0.07049018144607544, train_loss=0.043620914220809937, time_cost=2.297714948654175
Steps:   2%|▏         | 17173/1000000 [10:37:08<1950:24:44,  7.14s/it, lr=1e-5, step_loss=0.0705]Steps:   2%|▏         | 17174/1000000 [10:37:16<2097:00:17,  7.68s/it, lr=1e-5, step_loss=0.0705][RANK-0]: Step: [17174], local_loss=0.008387453854084015, train_loss=0.028782369568943977, time_cost=2.705216407775879
Steps:   2%|▏         | 17174/1000000 [10:37:16<2097:00:17,  7.68s/it, lr=1e-5, step_loss=0.00839]Steps:   2%|▏         | 17175/1000000 [10:37:27<2356:23:25,  8.63s/it, lr=1e-5, step_loss=0.00839][RANK-0]: Step: [17175], local_loss=0.03666770085692406, train_loss=0.0397975854575634, time_cost=2.052076578140259
Steps:   2%|▏         | 17175/1000000 [10:37:27<2356:23:25,  8.63s/it, lr=1e-5, step_loss=0.0367] Steps:   2%|▏         | 17176/1000000 [10:37:38<2516:33:51,  9.22s/it, lr=1e-5, step_loss=0.0367][RANK-0]: Step: [17176], local_loss=0.05951488018035889, train_loss=0.027213457971811295, time_cost=2.0954995155334473
Steps:   2%|▏         | 17176/1000000 [10:37:38<2516:33:51,  9.22s/it, lr=1e-5, step_loss=0.0595]Steps:   2%|▏         | 17177/1000000 [10:37:48<2609:11:56,  9.56s/it, lr=1e-5, step_loss=0.0595][RANK-0]: Step: [17177], local_loss=0.15201084315776825, train_loss=0.03334590792655945, time_cost=1.6840770244598389
Steps:   2%|▏         | 17177/1000000 [10:37:48<2609:11:56,  9.56s/it, lr=1e-5, step_loss=0.152] Steps:   2%|▏         | 17178/1000000 [10:38:01<2889:29:08, 10.58s/it, lr=1e-5, step_loss=0.152][RANK-0]: Step: [17178], local_loss=0.005231970921158791, train_loss=0.017936773598194122, time_cost=6.029926538467407
Steps:   2%|▏         | 17178/1000000 [10:38:01<2889:29:08, 10.58s/it, lr=1e-5, step_loss=0.00523]Steps:   2%|▏         | 17179/1000000 [10:38:12<2888:14:01, 10.58s/it, lr=1e-5, step_loss=0.00523][RANK-0]: Step: [17179], local_loss=0.00969714391976595, train_loss=0.032207563519477844, time_cost=2.5171432495117188
Steps:   2%|▏         | 17179/1000000 [10:38:12<2888:14:01, 10.58s/it, lr=1e-5, step_loss=0.0097] Steps:   2%|▏         | 17180/1000000 [10:38:24<3053:55:58, 11.19s/it, lr=1e-5, step_loss=0.0097][RANK-0]: Step: [17180], local_loss=0.005392559804022312, train_loss=0.013281162828207016, time_cost=9.026897668838501
Steps:   2%|▏         | 17180/1000000 [10:38:24<3053:55:58, 11.19s/it, lr=1e-5, step_loss=0.00539]Steps:   2%|▏         | 17181/1000000 [10:38:35<2971:57:49, 10.89s/it, lr=1e-5, step_loss=0.00539][RANK-0]: Step: [17181], local_loss=0.01163970772176981, train_loss=0.01947803795337677, time_cost=1.8031127452850342
Steps:   2%|▏         | 17181/1000000 [10:38:35<2971:57:49, 10.89s/it, lr=1e-5, step_loss=0.0116] Steps:   2%|▏         | 17182/1000000 [10:38:48<3206:24:06, 11.74s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [17182], local_loss=0.029792573302984238, train_loss=0.148351788520813, time_cost=4.750248193740845
Steps:   2%|▏         | 17182/1000000 [10:38:48<3206:24:06, 11.74s/it, lr=1e-5, step_loss=0.0298]Steps:   2%|▏         | 17183/1000000 [10:38:57<2937:49:59, 10.76s/it, lr=1e-5, step_loss=0.0298][RANK-0]: Step: [17183], local_loss=0.007362802047282457, train_loss=0.018342966213822365, time_cost=4.8404905796051025
Steps:   2%|▏         | 17183/1000000 [10:38:57<2937:49:59, 10.76s/it, lr=1e-5, step_loss=0.00736]Steps:   2%|▏         | 17184/1000000 [10:39:04<2624:19:53,  9.61s/it, lr=1e-5, step_loss=0.00736][RANK-0]: Step: [17184], local_loss=0.014157315716147423, train_loss=0.0372760072350502, time_cost=1.5361273288726807
Steps:   2%|▏         | 17184/1000000 [10:39:04<2624:19:53,  9.61s/it, lr=1e-5, step_loss=0.0142] Steps:   2%|▏         | 17185/1000000 [10:39:17<2903:20:18, 10.63s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [17185], local_loss=0.054207123816013336, train_loss=0.020422134548425674, time_cost=3.7649736404418945
Steps:   2%|▏         | 17185/1000000 [10:39:17<2903:20:18, 10.63s/it, lr=1e-5, step_loss=0.0542]Steps:   2%|▏         | 17186/1000000 [10:39:26<2774:29:32, 10.16s/it, lr=1e-5, step_loss=0.0542][RANK-0]: Step: [17186], local_loss=0.01367775909602642, train_loss=0.012489606626331806, time_cost=3.8016653060913086
Steps:   2%|▏         | 17186/1000000 [10:39:26<2774:29:32, 10.16s/it, lr=1e-5, step_loss=0.0137]Steps:   2%|▏         | 17187/1000000 [10:39:36<2810:23:41, 10.29s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [17187], local_loss=0.0036925440654158592, train_loss=0.015272160060703754, time_cost=7.4581756591796875
Steps:   2%|▏         | 17187/1000000 [10:39:36<2810:23:41, 10.29s/it, lr=1e-5, step_loss=0.00369]Steps:   2%|▏         | 17188/1000000 [10:39:43<2526:19:18,  9.25s/it, lr=1e-5, step_loss=0.00369][RANK-0]: Step: [17188], local_loss=0.0841456800699234, train_loss=0.04154965654015541, time_cost=1.2604436874389648
Steps:   2%|▏         | 17188/1000000 [10:39:43<2526:19:18,  9.25s/it, lr=1e-5, step_loss=0.0841] Steps:   2%|▏         | 17189/1000000 [10:39:54<2649:13:22,  9.70s/it, lr=1e-5, step_loss=0.0841][RANK-0]: Step: [17189], local_loss=0.006834344007074833, train_loss=0.14528526365756989, time_cost=1.6482620239257812
Steps:   2%|▏         | 17189/1000000 [10:39:54<2649:13:22,  9.70s/it, lr=1e-5, step_loss=0.00683]Steps:   2%|▏         | 17190/1000000 [10:40:07<2885:28:50, 10.57s/it, lr=1e-5, step_loss=0.00683][RANK-0]: Step: [17190], local_loss=0.009467190131545067, train_loss=0.024949925020337105, time_cost=3.405730962753296
Steps:   2%|▏         | 17190/1000000 [10:40:07<2885:28:50, 10.57s/it, lr=1e-5, step_loss=0.00947]Steps:   2%|▏         | 17191/1000000 [10:40:21<3238:46:10, 11.86s/it, lr=1e-5, step_loss=0.00947][RANK-0]: Step: [17191], local_loss=0.0337352529168129, train_loss=0.017070025205612183, time_cost=6.458819627761841
Steps:   2%|▏         | 17191/1000000 [10:40:21<3238:46:10, 11.86s/it, lr=1e-5, step_loss=0.0337] Steps:   2%|▏         | 17192/1000000 [10:40:28<2794:39:44, 10.24s/it, lr=1e-5, step_loss=0.0337][RANK-0]: Step: [17192], local_loss=0.03738969564437866, train_loss=0.08958041667938232, time_cost=1.3469326496124268
Steps:   2%|▏         | 17192/1000000 [10:40:28<2794:39:44, 10.24s/it, lr=1e-5, step_loss=0.0374]Steps:   2%|▏         | 17193/1000000 [10:40:34<2438:51:11,  8.93s/it, lr=1e-5, step_loss=0.0374][RANK-0]: Step: [17193], local_loss=0.030188167467713356, train_loss=0.02437460795044899, time_cost=1.7685399055480957
Steps:   2%|▏         | 17193/1000000 [10:40:34<2438:51:11,  8.93s/it, lr=1e-5, step_loss=0.0302]Steps:   2%|▏         | 17194/1000000 [10:40:41<2331:42:41,  8.54s/it, lr=1e-5, step_loss=0.0302][RANK-0]: Step: [17194], local_loss=0.021422071382403374, train_loss=0.03460949659347534, time_cost=3.8639261722564697
Steps:   2%|▏         | 17194/1000000 [10:40:41<2331:42:41,  8.54s/it, lr=1e-5, step_loss=0.0214]Steps:   2%|▏         | 17195/1000000 [10:40:51<2387:08:57,  8.74s/it, lr=1e-5, step_loss=0.0214][RANK-0]: Step: [17195], local_loss=0.07569482177495956, train_loss=0.09611541032791138, time_cost=2.5704550743103027
Steps:   2%|▏         | 17195/1000000 [10:40:51<2387:08:57,  8.74s/it, lr=1e-5, step_loss=0.0757]Steps:   2%|▏         | 17196/1000000 [10:41:04<2723:02:03,  9.97s/it, lr=1e-5, step_loss=0.0757][RANK-0]: Step: [17196], local_loss=0.047608423978090286, train_loss=0.05698137730360031, time_cost=10.796110391616821
Steps:   2%|▏         | 17196/1000000 [10:41:04<2723:02:03,  9.97s/it, lr=1e-5, step_loss=0.0476]Steps:   2%|▏         | 17197/1000000 [10:41:14<2774:52:29, 10.16s/it, lr=1e-5, step_loss=0.0476][RANK-0]: Step: [17197], local_loss=0.05598749592900276, train_loss=0.0315110981464386, time_cost=3.5741512775421143
Steps:   2%|▏         | 17197/1000000 [10:41:14<2774:52:29, 10.16s/it, lr=1e-5, step_loss=0.056] Steps:   2%|▏         | 17198/1000000 [10:41:31<3346:19:55, 12.26s/it, lr=1e-5, step_loss=0.056][RANK-0]: Step: [17198], local_loss=0.07149379700422287, train_loss=0.03474005311727524, time_cost=8.961509227752686
Steps:   2%|▏         | 17198/1000000 [10:41:31<3346:19:55, 12.26s/it, lr=1e-5, step_loss=0.0715]Steps:   2%|▏         | 17199/1000000 [10:41:36<2702:04:08,  9.90s/it, lr=1e-5, step_loss=0.0715][RANK-0]: Step: [17199], local_loss=0.03125695511698723, train_loss=0.021849194541573524, time_cost=1.3388237953186035
Steps:   2%|▏         | 17199/1000000 [10:41:36<2702:04:08,  9.90s/it, lr=1e-5, step_loss=0.0313]Steps:   2%|▏         | 17200/1000000 [10:41:43<2495:04:47,  9.14s/it, lr=1e-5, step_loss=0.0313][RANK-0]: Step: [17200], local_loss=0.018809083849191666, train_loss=0.024094657972455025, time_cost=1.494460105895996
Steps:   2%|▏         | 17200/1000000 [10:41:43<2495:04:47,  9.14s/it, lr=1e-5, step_loss=0.0188]Steps:   2%|▏         | 17201/1000000 [10:41:54<2639:23:05,  9.67s/it, lr=1e-5, step_loss=0.0188][RANK-0]: Step: [17201], local_loss=0.004660391714423895, train_loss=0.014869846403598785, time_cost=1.3113114833831787
Steps:   2%|▏         | 17201/1000000 [10:41:54<2639:23:05,  9.67s/it, lr=1e-5, step_loss=0.00466]Steps:   2%|▏         | 17202/1000000 [10:42:03<2582:08:03,  9.46s/it, lr=1e-5, step_loss=0.00466][RANK-0]: Step: [17202], local_loss=0.014660771004855633, train_loss=0.05650632455945015, time_cost=3.0844836235046387
Steps:   2%|▏         | 17202/1000000 [10:42:03<2582:08:03,  9.46s/it, lr=1e-5, step_loss=0.0147] Steps:   2%|▏         | 17203/1000000 [10:42:16<2887:24:40, 10.58s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [17203], local_loss=0.01290002278983593, train_loss=0.03550099581480026, time_cost=1.9366438388824463
Steps:   2%|▏         | 17203/1000000 [10:42:16<2887:24:40, 10.58s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 17204/1000000 [10:42:21<2440:31:41,  8.94s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [17204], local_loss=0.02579433284699917, train_loss=0.17038720846176147, time_cost=2.446298837661743
Steps:   2%|▏         | 17204/1000000 [10:42:21<2440:31:41,  8.94s/it, lr=1e-5, step_loss=0.0258]Steps:   2%|▏         | 17205/1000000 [10:42:30<2425:48:36,  8.89s/it, lr=1e-5, step_loss=0.0258][RANK-0]: Step: [17205], local_loss=0.006436466239392757, train_loss=0.12666015326976776, time_cost=1.2379429340362549
Steps:   2%|▏         | 17205/1000000 [10:42:30<2425:48:36,  8.89s/it, lr=1e-5, step_loss=0.00644]Steps:   2%|▏         | 17206/1000000 [10:42:37<2269:45:52,  8.31s/it, lr=1e-5, step_loss=0.00644][RANK-0]: Step: [17206], local_loss=0.08348391950130463, train_loss=0.05453087389469147, time_cost=2.271657705307007
Steps:   2%|▏         | 17206/1000000 [10:42:37<2269:45:52,  8.31s/it, lr=1e-5, step_loss=0.0835] Steps:   2%|▏         | 17207/1000000 [10:42:44<2139:44:06,  7.84s/it, lr=1e-5, step_loss=0.0835][RANK-0]: Step: [17207], local_loss=0.004723673220723867, train_loss=0.129514679312706, time_cost=2.4125308990478516
Steps:   2%|▏         | 17207/1000000 [10:42:44<2139:44:06,  7.84s/it, lr=1e-5, step_loss=0.00472]Steps:   2%|▏         | 17208/1000000 [10:42:56<2467:16:39,  9.04s/it, lr=1e-5, step_loss=0.00472][RANK-0]: Step: [17208], local_loss=0.013101750984787941, train_loss=0.04044877737760544, time_cost=4.396544933319092
Steps:   2%|▏         | 17208/1000000 [10:42:56<2467:16:39,  9.04s/it, lr=1e-5, step_loss=0.0131] Steps:   2%|▏         | 17209/1000000 [10:43:03<2315:34:47,  8.48s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [17209], local_loss=0.01772073283791542, train_loss=0.04193387180566788, time_cost=1.3682959079742432
Steps:   2%|▏         | 17209/1000000 [10:43:03<2315:34:47,  8.48s/it, lr=1e-5, step_loss=0.0177]Steps:   2%|▏         | 17210/1000000 [10:43:08<2054:04:11,  7.52s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [17210], local_loss=0.03790836036205292, train_loss=0.0676174908876419, time_cost=4.122992277145386
Steps:   2%|▏         | 17210/1000000 [10:43:08<2054:04:11,  7.52s/it, lr=1e-5, step_loss=0.0379]Steps:   2%|▏         | 17211/1000000 [10:43:15<1992:11:24,  7.30s/it, lr=1e-5, step_loss=0.0379][RANK-0]: Step: [17211], local_loss=0.18272314965724945, train_loss=0.05009394884109497, time_cost=1.2444441318511963
Steps:   2%|▏         | 17211/1000000 [10:43:15<1992:11:24,  7.30s/it, lr=1e-5, step_loss=0.183] Steps:   2%|▏         | 17212/1000000 [10:43:25<2273:37:10,  8.33s/it, lr=1e-5, step_loss=0.183][RANK-0]: Step: [17212], local_loss=0.01952371560037136, train_loss=0.03496863320469856, time_cost=3.152812957763672
Steps:   2%|▏         | 17212/1000000 [10:43:25<2273:37:10,  8.33s/it, lr=1e-5, step_loss=0.0195]Steps:   2%|▏         | 17213/1000000 [10:43:36<2434:07:01,  8.92s/it, lr=1e-5, step_loss=0.0195][RANK-0]: Step: [17213], local_loss=0.04278959706425667, train_loss=0.15117602050304413, time_cost=3.8602795600891113
Steps:   2%|▏         | 17213/1000000 [10:43:36<2434:07:01,  8.92s/it, lr=1e-5, step_loss=0.0428]Steps:   2%|▏         | 17214/1000000 [10:43:43<2323:58:46,  8.51s/it, lr=1e-5, step_loss=0.0428][RANK-0]: Step: [17214], local_loss=0.00882762111723423, train_loss=0.019108686596155167, time_cost=1.8000202178955078
Steps:   2%|▏         | 17214/1000000 [10:43:43<2323:58:46,  8.51s/it, lr=1e-5, step_loss=0.00883]Steps:   2%|▏         | 17215/1000000 [10:43:51<2269:56:27,  8.31s/it, lr=1e-5, step_loss=0.00883][RANK-0]: Step: [17215], local_loss=0.05308259278535843, train_loss=0.03863246738910675, time_cost=2.0281429290771484
Steps:   2%|▏         | 17215/1000000 [10:43:51<2269:56:27,  8.31s/it, lr=1e-5, step_loss=0.0531] Steps:   2%|▏         | 17216/1000000 [10:44:02<2465:20:01,  9.03s/it, lr=1e-5, step_loss=0.0531][RANK-0]: Step: [17216], local_loss=0.037714675068855286, train_loss=0.018437212333083153, time_cost=2.7985823154449463
Steps:   2%|▏         | 17216/1000000 [10:44:02<2465:20:01,  9.03s/it, lr=1e-5, step_loss=0.0377]Steps:   2%|▏         | 17217/1000000 [10:44:14<2712:09:51,  9.93s/it, lr=1e-5, step_loss=0.0377][RANK-0]: Step: [17217], local_loss=0.007807186339050531, train_loss=0.04614616930484772, time_cost=4.390766859054565
Steps:   2%|▏         | 17217/1000000 [10:44:14<2712:09:51,  9.93s/it, lr=1e-5, step_loss=0.00781]Steps:   2%|▏         | 17218/1000000 [10:44:28<3039:46:05, 11.13s/it, lr=1e-5, step_loss=0.00781][RANK-0]: Step: [17218], local_loss=0.08547161519527435, train_loss=0.07360392063856125, time_cost=9.943005084991455
Steps:   2%|▏         | 17218/1000000 [10:44:28<3039:46:05, 11.13s/it, lr=1e-5, step_loss=0.0855] Steps:   2%|▏         | 17219/1000000 [10:44:41<3175:08:02, 11.63s/it, lr=1e-5, step_loss=0.0855][RANK-0]: Step: [17219], local_loss=0.07305267453193665, train_loss=0.02993040531873703, time_cost=6.314693450927734
Steps:   2%|▏         | 17219/1000000 [10:44:41<3175:08:02, 11.63s/it, lr=1e-5, step_loss=0.0731]Steps:   2%|▏         | 17220/1000000 [10:44:49<2929:40:44, 10.73s/it, lr=1e-5, step_loss=0.0731][RANK-0]: Step: [17220], local_loss=0.035747602581977844, train_loss=0.05436035245656967, time_cost=1.616375207901001
Steps:   2%|▏         | 17220/1000000 [10:44:49<2929:40:44, 10.73s/it, lr=1e-5, step_loss=0.0357]Steps:   2%|▏         | 17221/1000000 [10:45:01<2984:35:00, 10.93s/it, lr=1e-5, step_loss=0.0357][RANK-0]: Step: [17221], local_loss=0.0074629997834563255, train_loss=0.04448316991329193, time_cost=2.6933350563049316
Steps:   2%|▏         | 17221/1000000 [10:45:01<2984:35:00, 10.93s/it, lr=1e-5, step_loss=0.00746]Steps:   2%|▏         | 17222/1000000 [10:45:15<3284:12:53, 12.03s/it, lr=1e-5, step_loss=0.00746][RANK-0]: Step: [17222], local_loss=0.009371291846036911, train_loss=0.14332342147827148, time_cost=5.20168924331665
Steps:   2%|▏         | 17222/1000000 [10:45:15<3284:12:53, 12.03s/it, lr=1e-5, step_loss=0.00937]Steps:   2%|▏         | 17223/1000000 [10:45:23<2964:21:08, 10.86s/it, lr=1e-5, step_loss=0.00937][RANK-0]: Step: [17223], local_loss=0.005994494538754225, train_loss=0.16727611422538757, time_cost=4.569934606552124
Steps:   2%|▏         | 17223/1000000 [10:45:23<2964:21:08, 10.86s/it, lr=1e-5, step_loss=0.00599]Steps:   2%|▏         | 17224/1000000 [10:45:30<2610:46:32,  9.56s/it, lr=1e-5, step_loss=0.00599][RANK-0]: Step: [17224], local_loss=0.006823324598371983, train_loss=0.0587661974132061, time_cost=2.718822956085205
Steps:   2%|▏         | 17224/1000000 [10:45:30<2610:46:32,  9.56s/it, lr=1e-5, step_loss=0.00682]Steps:   2%|▏         | 17225/1000000 [10:45:40<2631:03:40,  9.64s/it, lr=1e-5, step_loss=0.00682][RANK-0]: Step: [17225], local_loss=0.15718020498752594, train_loss=0.06575068831443787, time_cost=1.4935071468353271
Steps:   2%|▏         | 17225/1000000 [10:45:40<2631:03:40,  9.64s/it, lr=1e-5, step_loss=0.157]  Steps:   2%|▏         | 17226/1000000 [10:45:58<3303:34:49, 12.10s/it, lr=1e-5, step_loss=0.157][RANK-0]: Step: [17226], local_loss=0.03449335694313049, train_loss=0.04089930281043053, time_cost=1.1864745616912842
Steps:   2%|▏         | 17226/1000000 [10:45:58<3303:34:49, 12.10s/it, lr=1e-5, step_loss=0.0345]Steps:   2%|▏         | 17227/1000000 [10:46:02<2711:10:30,  9.93s/it, lr=1e-5, step_loss=0.0345][RANK-0]: Step: [17227], local_loss=0.02605224959552288, train_loss=0.019092679023742676, time_cost=1.1925148963928223
Steps:   2%|▏         | 17227/1000000 [10:46:02<2711:10:30,  9.93s/it, lr=1e-5, step_loss=0.0261]Steps:   2%|▏         | 17228/1000000 [10:46:08<2318:33:33,  8.49s/it, lr=1e-5, step_loss=0.0261][RANK-0]: Step: [17228], local_loss=0.46380066871643066, train_loss=0.07954530417919159, time_cost=2.4741430282592773
Steps:   2%|▏         | 17228/1000000 [10:46:08<2318:33:33,  8.49s/it, lr=1e-5, step_loss=0.464] Steps:   2%|▏         | 17229/1000000 [10:46:19<2565:11:39,  9.40s/it, lr=1e-5, step_loss=0.464][RANK-0]: Step: [17229], local_loss=0.02556890994310379, train_loss=0.038736578077077866, time_cost=1.7865338325500488
Steps:   2%|▏         | 17229/1000000 [10:46:19<2565:11:39,  9.40s/it, lr=1e-5, step_loss=0.0256]Steps:   2%|▏         | 17230/1000000 [10:46:24<2180:28:23,  7.99s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [17230], local_loss=0.020075278356671333, train_loss=0.009708295576274395, time_cost=1.3765389919281006
Steps:   2%|▏         | 17230/1000000 [10:46:24<2180:28:23,  7.99s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 17231/1000000 [10:46:31<2099:59:18,  7.69s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [17231], local_loss=0.010650907643139362, train_loss=0.0464550219476223, time_cost=1.8289711475372314
Steps:   2%|▏         | 17231/1000000 [10:46:31<2099:59:18,  7.69s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 17232/1000000 [10:46:36<1927:22:18,  7.06s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [17232], local_loss=0.01962130330502987, train_loss=0.03756435215473175, time_cost=1.9088637828826904
Steps:   2%|▏         | 17232/1000000 [10:46:36<1927:22:18,  7.06s/it, lr=1e-5, step_loss=0.0196]Steps:   2%|▏         | 17233/1000000 [10:46:45<2093:17:07,  7.67s/it, lr=1e-5, step_loss=0.0196][RANK-0]: Step: [17233], local_loss=0.07600877434015274, train_loss=0.04997146129608154, time_cost=1.7875642776489258
Steps:   2%|▏         | 17233/1000000 [10:46:45<2093:17:07,  7.67s/it, lr=1e-5, step_loss=0.076] Steps:   2%|▏         | 17234/1000000 [10:46:52<1969:02:34,  7.21s/it, lr=1e-5, step_loss=0.076][RANK-0]: Step: [17234], local_loss=0.020855290815234184, train_loss=0.025988321751356125, time_cost=5.061002969741821
Steps:   2%|▏         | 17234/1000000 [10:46:52<1969:02:34,  7.21s/it, lr=1e-5, step_loss=0.0209]Steps:   2%|▏         | 17235/1000000 [10:46:59<2009:56:05,  7.36s/it, lr=1e-5, step_loss=0.0209][RANK-0]: Step: [17235], local_loss=0.04897994548082352, train_loss=0.03083367459475994, time_cost=3.615191698074341
Steps:   2%|▏         | 17235/1000000 [10:46:59<2009:56:05,  7.36s/it, lr=1e-5, step_loss=0.049] Steps:   2%|▏         | 17236/1000000 [10:47:05<1887:37:13,  6.91s/it, lr=1e-5, step_loss=0.049][RANK-0]: Step: [17236], local_loss=0.007251456845551729, train_loss=0.057096004486083984, time_cost=2.4236931800842285
Steps:   2%|▏         | 17236/1000000 [10:47:05<1887:37:13,  6.91s/it, lr=1e-5, step_loss=0.00725]Steps:   2%|▏         | 17237/1000000 [10:47:11<1758:17:10,  6.44s/it, lr=1e-5, step_loss=0.00725][RANK-0]: Step: [17237], local_loss=0.10191881656646729, train_loss=0.06743036955595016, time_cost=2.2998740673065186
Steps:   2%|▏         | 17237/1000000 [10:47:11<1758:17:10,  6.44s/it, lr=1e-5, step_loss=0.102]  Steps:   2%|▏         | 17238/1000000 [10:47:19<1944:53:49,  7.12s/it, lr=1e-5, step_loss=0.102][RANK-0]: Step: [17238], local_loss=0.006880210712552071, train_loss=0.03165416792035103, time_cost=2.826871871948242
Steps:   2%|▏         | 17238/1000000 [10:47:19<1944:53:49,  7.12s/it, lr=1e-5, step_loss=0.00688]Steps:   2%|▏         | 17239/1000000 [10:47:28<2068:42:57,  7.58s/it, lr=1e-5, step_loss=0.00688][RANK-0]: Step: [17239], local_loss=0.11875706166028976, train_loss=0.025719091296195984, time_cost=6.414544343948364
Steps:   2%|▏         | 17239/1000000 [10:47:28<2068:42:57,  7.58s/it, lr=1e-5, step_loss=0.119]  Steps:   2%|▏         | 17240/1000000 [10:47:41<2521:26:06,  9.24s/it, lr=1e-5, step_loss=0.119][RANK-0]: Step: [17240], local_loss=0.05528301000595093, train_loss=0.042456064373254776, time_cost=7.46587610244751
Steps:   2%|▏         | 17240/1000000 [10:47:41<2521:26:06,  9.24s/it, lr=1e-5, step_loss=0.0553]Steps:   2%|▏         | 17241/1000000 [10:47:53<2716:27:09,  9.95s/it, lr=1e-5, step_loss=0.0553][RANK-0]: Step: [17241], local_loss=0.03431050851941109, train_loss=0.015810750424861908, time_cost=2.1844077110290527
Steps:   2%|▏         | 17241/1000000 [10:47:53<2716:27:09,  9.95s/it, lr=1e-5, step_loss=0.0343]Steps:   2%|▏         | 17242/1000000 [10:48:04<2847:36:19, 10.43s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [17242], local_loss=0.014644458889961243, train_loss=0.028601400554180145, time_cost=2.3966856002807617
Steps:   2%|▏         | 17242/1000000 [10:48:04<2847:36:19, 10.43s/it, lr=1e-5, step_loss=0.0146]Steps:   2%|▏         | 17243/1000000 [10:48:15<2891:02:32, 10.59s/it, lr=1e-5, step_loss=0.0146][RANK-0]: Step: [17243], local_loss=0.0092959338799119, train_loss=0.04118834435939789, time_cost=8.169363498687744
Steps:   2%|▏         | 17243/1000000 [10:48:15<2891:02:32, 10.59s/it, lr=1e-5, step_loss=0.0093]Steps:   2%|▏         | 17244/1000000 [10:48:26<2916:35:13, 10.68s/it, lr=1e-5, step_loss=0.0093][RANK-0]: Step: [17244], local_loss=0.012646697461605072, train_loss=0.04403994232416153, time_cost=2.6937415599823
Steps:   2%|▏         | 17244/1000000 [10:48:26<2916:35:13, 10.68s/it, lr=1e-5, step_loss=0.0126]Steps:   2%|▏         | 17245/1000000 [10:48:31<2482:16:06,  9.09s/it, lr=1e-5, step_loss=0.0126][RANK-0]: Step: [17245], local_loss=0.013942037709057331, train_loss=0.014631612226366997, time_cost=2.1321325302124023
Steps:   2%|▏         | 17245/1000000 [10:48:31<2482:16:06,  9.09s/it, lr=1e-5, step_loss=0.0139]Steps:   2%|▏         | 17246/1000000 [10:48:40<2437:32:07,  8.93s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [17246], local_loss=0.012542585842311382, train_loss=0.024389872327446938, time_cost=1.9521660804748535
Steps:   2%|▏         | 17246/1000000 [10:48:40<2437:32:07,  8.93s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 17247/1000000 [10:48:48<2324:29:07,  8.52s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [17247], local_loss=0.02182924561202526, train_loss=0.033825479447841644, time_cost=1.568244218826294
Steps:   2%|▏         | 17247/1000000 [10:48:48<2324:29:07,  8.52s/it, lr=1e-5, step_loss=0.0218]/home/image_data/hxy/Open-Sora-Plan/opensora/utils/utils.py:369: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.
  caption = BeautifulSoup(caption, features='html.parser').text
Steps:   2%|▏         | 17248/1000000 [10:49:01<2718:54:51,  9.96s/it, lr=1e-5, step_loss=0.0218][RANK-0]: Step: [17248], local_loss=0.019034380093216896, train_loss=0.03327096626162529, time_cost=5.745054721832275
Steps:   2%|▏         | 17248/1000000 [10:49:01<2718:54:51,  9.96s/it, lr=1e-5, step_loss=0.019] Steps:   2%|▏         | 17249/1000000 [10:49:10<2681:21:22,  9.82s/it, lr=1e-5, step_loss=0.019][RANK-0]: Step: [17249], local_loss=0.012372353114187717, train_loss=0.020777426660060883, time_cost=3.3379721641540527
Steps:   2%|▏         | 17249/1000000 [10:49:10<2681:21:22,  9.82s/it, lr=1e-5, step_loss=0.0124]Steps:   2%|▏         | 17250/1000000 [10:49:15<2278:38:06,  8.35s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [17250], local_loss=0.029677197337150574, train_loss=0.022345880046486855, time_cost=1.9449462890625
Steps:   2%|▏         | 17250/1000000 [10:49:15<2278:38:06,  8.35s/it, lr=1e-5, step_loss=0.0297]Steps:   2%|▏         | 17251/1000000 [10:49:22<2171:02:33,  7.95s/it, lr=1e-5, step_loss=0.0297][RANK-0]: Step: [17251], local_loss=0.0303975697606802, train_loss=0.03205427527427673, time_cost=2.4987995624542236
Steps:   2%|▏         | 17251/1000000 [10:49:22<2171:02:33,  7.95s/it, lr=1e-5, step_loss=0.0304]Steps:   2%|▏         | 17252/1000000 [10:49:29<2067:19:21,  7.57s/it, lr=1e-5, step_loss=0.0304][RANK-0]: Step: [17252], local_loss=0.07049378007650375, train_loss=0.03699316456913948, time_cost=2.2414703369140625
Steps:   2%|▏         | 17252/1000000 [10:49:29<2067:19:21,  7.57s/it, lr=1e-5, step_loss=0.0705]Steps:   2%|▏         | 17253/1000000 [10:49:42<2542:11:59,  9.31s/it, lr=1e-5, step_loss=0.0705][RANK-0]: Step: [17253], local_loss=0.012351304292678833, train_loss=0.07403793931007385, time_cost=5.837366580963135
Steps:   2%|▏         | 17253/1000000 [10:49:42<2542:11:59,  9.31s/it, lr=1e-5, step_loss=0.0124]Steps:   2%|▏         | 17254/1000000 [10:49:48<2210:21:52,  8.10s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [17254], local_loss=0.04726635292172432, train_loss=0.029535768553614616, time_cost=2.725313186645508
Steps:   2%|▏         | 17254/1000000 [10:49:48<2210:21:52,  8.10s/it, lr=1e-5, step_loss=0.0473]Steps:   2%|▏         | 17255/1000000 [10:49:59<2463:51:42,  9.03s/it, lr=1e-5, step_loss=0.0473][RANK-0]: Step: [17255], local_loss=0.051482684910297394, train_loss=0.024073190987110138, time_cost=4.82099723815918
Steps:   2%|▏         | 17255/1000000 [10:49:59<2463:51:42,  9.03s/it, lr=1e-5, step_loss=0.0515]Steps:   2%|▏         | 17256/1000000 [10:50:07<2376:26:16,  8.71s/it, lr=1e-5, step_loss=0.0515][RANK-0]: Step: [17256], local_loss=0.22776681184768677, train_loss=0.05506696179509163, time_cost=2.536060333251953
Steps:   2%|▏         | 17256/1000000 [10:50:07<2376:26:16,  8.71s/it, lr=1e-5, step_loss=0.228] Steps:   2%|▏         | 17257/1000000 [10:50:17<2490:48:03,  9.12s/it, lr=1e-5, step_loss=0.228][RANK-0]: Step: [17257], local_loss=0.006890744436532259, train_loss=0.15824748575687408, time_cost=8.429982423782349
Steps:   2%|▏         | 17257/1000000 [10:50:17<2490:48:03,  9.12s/it, lr=1e-5, step_loss=0.00689]Steps:   2%|▏         | 17258/1000000 [10:50:27<2593:44:19,  9.50s/it, lr=1e-5, step_loss=0.00689][RANK-0]: Step: [17258], local_loss=0.07660700380802155, train_loss=0.04036322236061096, time_cost=1.1994845867156982
Steps:   2%|▏         | 17258/1000000 [10:50:27<2593:44:19,  9.50s/it, lr=1e-5, step_loss=0.0766] Steps:   2%|▏         | 17259/1000000 [10:50:32<2168:00:52,  7.94s/it, lr=1e-5, step_loss=0.0766][RANK-0]: Step: [17259], local_loss=0.22678576409816742, train_loss=0.17049072682857513, time_cost=1.6530985832214355
Steps:   2%|▏         | 17259/1000000 [10:50:32<2168:00:52,  7.94s/it, lr=1e-5, step_loss=0.227] Steps:   2%|▏         | 17260/1000000 [10:50:38<2082:48:56,  7.63s/it, lr=1e-5, step_loss=0.227][RANK-0]: Step: [17260], local_loss=0.008745983242988586, train_loss=0.02068878710269928, time_cost=2.9854848384857178
Steps:   2%|▏         | 17260/1000000 [10:50:38<2082:48:56,  7.63s/it, lr=1e-5, step_loss=0.00875]Steps:   2%|▏         | 17261/1000000 [10:50:45<1958:31:41,  7.17s/it, lr=1e-5, step_loss=0.00875][RANK-0]: Step: [17261], local_loss=0.005050759296864271, train_loss=0.046952467411756516, time_cost=2.372483015060425
Steps:   2%|▏         | 17261/1000000 [10:50:45<1958:31:41,  7.17s/it, lr=1e-5, step_loss=0.00505]Steps:   2%|▏         | 17262/1000000 [10:50:50<1792:40:50,  6.57s/it, lr=1e-5, step_loss=0.00505][RANK-0]: Step: [17262], local_loss=0.0298022348433733, train_loss=0.044067129492759705, time_cost=2.0883195400238037
Steps:   2%|▏         | 17262/1000000 [10:50:50<1792:40:50,  6.57s/it, lr=1e-5, step_loss=0.0298] Steps:   2%|▏         | 17263/1000000 [10:50:57<1818:56:00,  6.66s/it, lr=1e-5, step_loss=0.0298][RANK-0]: Step: [17263], local_loss=0.08243875950574875, train_loss=0.03530234843492508, time_cost=2.978034496307373
Steps:   2%|▏         | 17263/1000000 [10:50:57<1818:56:00,  6.66s/it, lr=1e-5, step_loss=0.0824]Steps:   2%|▏         | 17264/1000000 [10:51:07<2104:31:34,  7.71s/it, lr=1e-5, step_loss=0.0824][RANK-0]: Step: [17264], local_loss=0.008226354606449604, train_loss=0.06035088002681732, time_cost=7.566737651824951
Steps:   2%|▏         | 17264/1000000 [10:51:07<2104:31:34,  7.71s/it, lr=1e-5, step_loss=0.00823]Steps:   2%|▏         | 17265/1000000 [10:51:14<2100:30:54,  7.69s/it, lr=1e-5, step_loss=0.00823][RANK-0]: Step: [17265], local_loss=0.1396181732416153, train_loss=0.1021081805229187, time_cost=1.8088769912719727
Steps:   2%|▏         | 17265/1000000 [10:51:14<2100:30:54,  7.69s/it, lr=1e-5, step_loss=0.14]   Steps:   2%|▏         | 17266/1000000 [10:51:20<1936:32:52,  7.09s/it, lr=1e-5, step_loss=0.14][RANK-0]: Step: [17266], local_loss=0.007904568687081337, train_loss=0.1583622246980667, time_cost=3.4156415462493896
Steps:   2%|▏         | 17266/1000000 [10:51:20<1936:32:52,  7.09s/it, lr=1e-5, step_loss=0.0079]Steps:   2%|▏         | 17267/1000000 [10:51:28<2003:08:26,  7.34s/it, lr=1e-5, step_loss=0.0079][RANK-0]: Step: [17267], local_loss=0.00684161065146327, train_loss=0.04306165128946304, time_cost=5.701264142990112
Steps:   2%|▏         | 17267/1000000 [10:51:28<2003:08:26,  7.34s/it, lr=1e-5, step_loss=0.00684]Steps:   2%|▏         | 17268/1000000 [10:51:41<2493:03:56,  9.13s/it, lr=1e-5, step_loss=0.00684][RANK-0]: Step: [17268], local_loss=0.10247280448675156, train_loss=0.021208882331848145, time_cost=1.2892513275146484
Steps:   2%|▏         | 17268/1000000 [10:51:41<2493:03:56,  9.13s/it, lr=1e-5, step_loss=0.102]  Steps:   2%|▏         | 17269/1000000 [10:51:47<2181:34:35,  7.99s/it, lr=1e-5, step_loss=0.102][RANK-0]: Step: [17269], local_loss=0.016197672113776207, train_loss=0.02061314508318901, time_cost=2.273017168045044
Steps:   2%|▏         | 17269/1000000 [10:51:47<2181:34:35,  7.99s/it, lr=1e-5, step_loss=0.0162]Steps:   2%|▏         | 17270/1000000 [10:51:57<2398:16:05,  8.79s/it, lr=1e-5, step_loss=0.0162][RANK-0]: Step: [17270], local_loss=0.01860019750893116, train_loss=8.868375778198242, time_cost=7.900351524353027
Steps:   2%|▏         | 17270/1000000 [10:51:57<2398:16:05,  8.79s/it, lr=1e-5, step_loss=0.0186]Steps:   2%|▏         | 17271/1000000 [10:52:09<2650:33:23,  9.71s/it, lr=1e-5, step_loss=0.0186][RANK-0]: Step: [17271], local_loss=0.01959860883653164, train_loss=0.04990151524543762, time_cost=5.688867807388306
Steps:   2%|▏         | 17271/1000000 [10:52:09<2650:33:23,  9.71s/it, lr=1e-5, step_loss=0.0196]Steps:   2%|▏         | 17272/1000000 [10:52:14<2267:19:21,  8.31s/it, lr=1e-5, step_loss=0.0196][RANK-0]: Step: [17272], local_loss=0.02803031913936138, train_loss=0.07601945102214813, time_cost=2.1411640644073486
Steps:   2%|▏         | 17272/1000000 [10:52:14<2267:19:21,  8.31s/it, lr=1e-5, step_loss=0.028] Steps:   2%|▏         | 17273/1000000 [10:52:25<2442:33:54,  8.95s/it, lr=1e-5, step_loss=0.028][RANK-0]: Step: [17273], local_loss=0.007786482572555542, train_loss=0.01705111935734749, time_cost=1.9848127365112305
Steps:   2%|▏         | 17273/1000000 [10:52:25<2442:33:54,  8.95s/it, lr=1e-5, step_loss=0.00779]Steps:   2%|▏         | 17274/1000000 [10:52:35<2583:03:40,  9.46s/it, lr=1e-5, step_loss=0.00779][RANK-0]: Step: [17274], local_loss=0.040537748485803604, train_loss=0.01567113772034645, time_cost=3.390974521636963
Steps:   2%|▏         | 17274/1000000 [10:52:35<2583:03:40,  9.46s/it, lr=1e-5, step_loss=0.0405] Steps:   2%|▏         | 17275/1000000 [10:52:48<2867:51:52, 10.51s/it, lr=1e-5, step_loss=0.0405][RANK-0]: Step: [17275], local_loss=0.05334533005952835, train_loss=0.030306510627269745, time_cost=4.715341567993164
Steps:   2%|▏         | 17275/1000000 [10:52:48<2867:51:52, 10.51s/it, lr=1e-5, step_loss=0.0533]Steps:   2%|▏         | 17276/1000000 [10:52:59<2857:47:49, 10.47s/it, lr=1e-5, step_loss=0.0533][RANK-0]: Step: [17276], local_loss=0.0106071000918746, train_loss=0.023505104705691338, time_cost=1.2310519218444824
Steps:   2%|▏         | 17276/1000000 [10:52:59<2857:47:49, 10.47s/it, lr=1e-5, step_loss=0.0106]Steps:   2%|▏         | 17277/1000000 [10:53:10<2936:52:58, 10.76s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [17277], local_loss=0.7758089303970337, train_loss=0.1308344602584839, time_cost=1.2623679637908936
Steps:   2%|▏         | 17277/1000000 [10:53:10<2936:52:58, 10.76s/it, lr=1e-5, step_loss=0.776] Steps:   2%|▏         | 17278/1000000 [10:53:26<3343:54:09, 12.25s/it, lr=1e-5, step_loss=0.776][RANK-0]: Step: [17278], local_loss=0.05438621714711189, train_loss=0.030798714607954025, time_cost=7.373033046722412
Steps:   2%|▏         | 17278/1000000 [10:53:26<3343:54:09, 12.25s/it, lr=1e-5, step_loss=0.0544]Steps:   2%|▏         | 17279/1000000 [10:53:33<2906:14:14, 10.65s/it, lr=1e-5, step_loss=0.0544][RANK-0]: Step: [17279], local_loss=0.017707932740449905, train_loss=0.021304896101355553, time_cost=3.313566207885742
Steps:   2%|▏         | 17279/1000000 [10:53:33<2906:14:14, 10.65s/it, lr=1e-5, step_loss=0.0177]Steps:   2%|▏         | 17280/1000000 [10:53:43<2862:36:01, 10.49s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [17280], local_loss=0.006715518422424793, train_loss=0.08822204172611237, time_cost=2.3687500953674316
Steps:   2%|▏         | 17280/1000000 [10:53:43<2862:36:01, 10.49s/it, lr=1e-5, step_loss=0.00672]Steps:   2%|▏         | 17281/1000000 [10:53:50<2625:05:57,  9.62s/it, lr=1e-5, step_loss=0.00672][RANK-0]: Step: [17281], local_loss=0.01808828115463257, train_loss=0.028107672929763794, time_cost=2.1581530570983887
Steps:   2%|▏         | 17281/1000000 [10:53:50<2625:05:57,  9.62s/it, lr=1e-5, step_loss=0.0181] Steps:   2%|▏         | 17282/1000000 [10:54:04<2960:11:52, 10.84s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [17282], local_loss=0.010459034703671932, train_loss=0.02622830681502819, time_cost=5.166303396224976
Steps:   2%|▏         | 17282/1000000 [10:54:04<2960:11:52, 10.84s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 17283/1000000 [10:54:11<2644:04:29,  9.69s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [17283], local_loss=0.00935191847383976, train_loss=0.06505617499351501, time_cost=2.7683424949645996
Steps:   2%|▏         | 17283/1000000 [10:54:11<2644:04:29,  9.69s/it, lr=1e-5, step_loss=0.00935]Steps:   2%|▏         | 17284/1000000 [10:54:16<2263:37:53,  8.29s/it, lr=1e-5, step_loss=0.00935][RANK-0]: Step: [17284], local_loss=0.01312632579356432, train_loss=0.03960629552602768, time_cost=2.140169858932495
Steps:   2%|▏         | 17284/1000000 [10:54:16<2263:37:53,  8.29s/it, lr=1e-5, step_loss=0.0131] Steps:   2%|▏         | 17285/1000000 [10:54:32<2856:16:40, 10.46s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [17285], local_loss=0.06365285813808441, train_loss=0.051582809537649155, time_cost=3.74609637260437
Steps:   2%|▏         | 17285/1000000 [10:54:32<2856:16:40, 10.46s/it, lr=1e-5, step_loss=0.0637]Steps:   2%|▏         | 17286/1000000 [10:54:38<2550:15:29,  9.34s/it, lr=1e-5, step_loss=0.0637][RANK-0]: Step: [17286], local_loss=0.010205688886344433, train_loss=0.03852035850286484, time_cost=2.9600071907043457
Steps:   2%|▏         | 17286/1000000 [10:54:38<2550:15:29,  9.34s/it, lr=1e-5, step_loss=0.0102]Steps:   2%|▏         | 17287/1000000 [10:54:52<2884:38:42, 10.57s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [17287], local_loss=0.011506144888699055, train_loss=0.016250813379883766, time_cost=1.9080865383148193
Steps:   2%|▏         | 17287/1000000 [10:54:52<2884:38:42, 10.57s/it, lr=1e-5, step_loss=0.0115]Steps:   2%|▏         | 17288/1000000 [10:55:03<2918:06:08, 10.69s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [17288], local_loss=0.04796355590224266, train_loss=0.14903442561626434, time_cost=3.0525851249694824
Steps:   2%|▏         | 17288/1000000 [10:55:03<2918:06:08, 10.69s/it, lr=1e-5, step_loss=0.048] Steps:   2%|▏         | 17289/1000000 [10:55:16<3095:50:33, 11.34s/it, lr=1e-5, step_loss=0.048][RANK-0]: Step: [17289], local_loss=0.0560726523399353, train_loss=0.03540930151939392, time_cost=4.388364315032959
Steps:   2%|▏         | 17289/1000000 [10:55:16<3095:50:33, 11.34s/it, lr=1e-5, step_loss=0.0561]Steps:   2%|▏         | 17290/1000000 [10:55:27<3067:59:09, 11.24s/it, lr=1e-5, step_loss=0.0561][RANK-0]: Step: [17290], local_loss=0.01983060874044895, train_loss=0.039163827896118164, time_cost=5.295308589935303
Steps:   2%|▏         | 17290/1000000 [10:55:27<3067:59:09, 11.24s/it, lr=1e-5, step_loss=0.0198]Steps:   2%|▏         | 17291/1000000 [10:55:34<2772:12:29, 10.16s/it, lr=1e-5, step_loss=0.0198][RANK-0]: Step: [17291], local_loss=0.020541805773973465, train_loss=0.011915445327758789, time_cost=1.5221202373504639
Steps:   2%|▏         | 17291/1000000 [10:55:34<2772:12:29, 10.16s/it, lr=1e-5, step_loss=0.0205]Steps:   2%|▏         | 17292/1000000 [10:55:40<2444:44:29,  8.96s/it, lr=1e-5, step_loss=0.0205][RANK-0]: Step: [17292], local_loss=0.00898787286132574, train_loss=0.18466198444366455, time_cost=2.0541129112243652
Steps:   2%|▏         | 17292/1000000 [10:55:40<2444:44:29,  8.96s/it, lr=1e-5, step_loss=0.00899]Steps:   2%|▏         | 17293/1000000 [10:55:56<2969:21:31, 10.88s/it, lr=1e-5, step_loss=0.00899][RANK-0]: Step: [17293], local_loss=0.009603308513760567, train_loss=0.17065873742103577, time_cost=7.800736427307129
Steps:   2%|▏         | 17293/1000000 [10:55:56<2969:21:31, 10.88s/it, lr=1e-5, step_loss=0.0096] Steps:   2%|▏         | 17294/1000000 [10:56:02<2544:42:46,  9.32s/it, lr=1e-5, step_loss=0.0096][RANK-0]: Step: [17294], local_loss=0.025173276662826538, train_loss=0.1414976716041565, time_cost=2.939785957336426
Steps:   2%|▏         | 17294/1000000 [10:56:02<2544:42:46,  9.32s/it, lr=1e-5, step_loss=0.0252]Steps:   2%|▏         | 17295/1000000 [10:56:13<2712:37:11,  9.94s/it, lr=1e-5, step_loss=0.0252][RANK-0]: Step: [17295], local_loss=0.016827359795570374, train_loss=0.03881393373012543, time_cost=4.864094257354736
Steps:   2%|▏         | 17295/1000000 [10:56:13<2712:37:11,  9.94s/it, lr=1e-5, step_loss=0.0168]Steps:   2%|▏         | 17296/1000000 [10:56:24<2796:49:32, 10.25s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [17296], local_loss=0.1319464147090912, train_loss=0.06939397007226944, time_cost=3.2091546058654785
Steps:   2%|▏         | 17296/1000000 [10:56:24<2796:49:32, 10.25s/it, lr=1e-5, step_loss=0.132] Steps:   2%|▏         | 17297/1000000 [10:56:39<3182:26:39, 11.66s/it, lr=1e-5, step_loss=0.132][RANK-0]: Step: [17297], local_loss=0.024842508137226105, train_loss=0.05036531388759613, time_cost=5.334615230560303
Steps:   2%|▏         | 17297/1000000 [10:56:39<3182:26:39, 11.66s/it, lr=1e-5, step_loss=0.0248]Steps:   2%|▏         | 17298/1000000 [10:56:46<2816:29:25, 10.32s/it, lr=1e-5, step_loss=0.0248][RANK-0]: Step: [17298], local_loss=0.024490617215633392, train_loss=0.02159389853477478, time_cost=2.8652403354644775
Steps:   2%|▏         | 17298/1000000 [10:56:46<2816:29:25, 10.32s/it, lr=1e-5, step_loss=0.0245]Steps:   2%|▏         | 17299/1000000 [10:56:55<2732:18:21, 10.01s/it, lr=1e-5, step_loss=0.0245][RANK-0]: Step: [17299], local_loss=0.00963553972542286, train_loss=0.02783949300646782, time_cost=1.4584360122680664
Steps:   2%|▏         | 17299/1000000 [10:56:55<2732:18:21, 10.01s/it, lr=1e-5, step_loss=0.00964]Steps:   2%|▏         | 17300/1000000 [10:57:06<2785:53:06, 10.21s/it, lr=1e-5, step_loss=0.00964][RANK-0]: Step: [17300], local_loss=0.05467582866549492, train_loss=0.038537465035915375, time_cost=1.3101730346679688
Steps:   2%|▏         | 17300/1000000 [10:57:06<2785:53:06, 10.21s/it, lr=1e-5, step_loss=0.0547] Steps:   2%|▏         | 17301/1000000 [10:57:15<2694:59:15,  9.87s/it, lr=1e-5, step_loss=0.0547][RANK-0]: Step: [17301], local_loss=0.005576318129897118, train_loss=0.020967336371541023, time_cost=7.206344127655029
Steps:   2%|▏         | 17301/1000000 [10:57:15<2694:59:15,  9.87s/it, lr=1e-5, step_loss=0.00558]Steps:   2%|▏         | 17302/1000000 [10:57:19<2249:00:48,  8.24s/it, lr=1e-5, step_loss=0.00558][RANK-0]: Step: [17302], local_loss=0.01145640853792429, train_loss=6.217714786529541, time_cost=1.7741584777832031
Steps:   2%|▏         | 17302/1000000 [10:57:19<2249:00:48,  8.24s/it, lr=1e-5, step_loss=0.0115] Steps:   2%|▏         | 17303/1000000 [10:57:30<2413:05:44,  8.84s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [17303], local_loss=0.09363914281129837, train_loss=0.04127102345228195, time_cost=1.2173900604248047
Steps:   2%|▏         | 17303/1000000 [10:57:30<2413:05:44,  8.84s/it, lr=1e-5, step_loss=0.0936]Steps:   2%|▏         | 17304/1000000 [10:57:39<2464:19:07,  9.03s/it, lr=1e-5, step_loss=0.0936][RANK-0]: Step: [17304], local_loss=0.008316216990351677, train_loss=0.03236885741353035, time_cost=7.681309461593628
Steps:   2%|▏         | 17304/1000000 [10:57:39<2464:19:07,  9.03s/it, lr=1e-5, step_loss=0.00832]Steps:   2%|▏         | 17305/1000000 [10:57:53<2875:27:26, 10.53s/it, lr=1e-5, step_loss=0.00832][RANK-0]: Step: [17305], local_loss=0.035548266023397446, train_loss=0.03630628064274788, time_cost=5.257446050643921
Steps:   2%|▏         | 17305/1000000 [10:57:53<2875:27:26, 10.53s/it, lr=1e-5, step_loss=0.0355] Steps:   2%|▏         | 17306/1000000 [10:57:59<2512:29:57,  9.20s/it, lr=1e-5, step_loss=0.0355][RANK-0]: Step: [17306], local_loss=0.009482862427830696, train_loss=0.04131466895341873, time_cost=1.503211259841919
Steps:   2%|▏         | 17306/1000000 [10:57:59<2512:29:57,  9.20s/it, lr=1e-5, step_loss=0.00948]Steps:   2%|▏         | 17307/1000000 [10:58:10<2594:50:18,  9.51s/it, lr=1e-5, step_loss=0.00948][RANK-0]: Step: [17307], local_loss=0.007802105508744717, train_loss=0.029243700206279755, time_cost=1.869194507598877
Steps:   2%|▏         | 17307/1000000 [10:58:10<2594:50:18,  9.51s/it, lr=1e-5, step_loss=0.0078] Steps:   2%|▏         | 17308/1000000 [10:58:24<2970:49:58, 10.88s/it, lr=1e-5, step_loss=0.0078][RANK-0]: Step: [17308], local_loss=0.024975048378109932, train_loss=0.052263982594013214, time_cost=8.276031970977783
Steps:   2%|▏         | 17308/1000000 [10:58:24<2970:49:58, 10.88s/it, lr=1e-5, step_loss=0.025] Steps:   2%|▏         | 17309/1000000 [10:58:36<3118:57:46, 11.43s/it, lr=1e-5, step_loss=0.025][RANK-0]: Step: [17309], local_loss=0.006908544804900885, train_loss=0.059640951454639435, time_cost=5.866860389709473
Steps:   2%|▏         | 17309/1000000 [10:58:36<3118:57:46, 11.43s/it, lr=1e-5, step_loss=0.00691]Steps:   2%|▏         | 17310/1000000 [10:58:50<3331:11:58, 12.20s/it, lr=1e-5, step_loss=0.00691][RANK-0]: Step: [17310], local_loss=0.06705830246210098, train_loss=0.17194116115570068, time_cost=4.658435821533203
Steps:   2%|▏         | 17310/1000000 [10:58:50<3331:11:58, 12.20s/it, lr=1e-5, step_loss=0.0671] Steps:   2%|▏         | 17311/1000000 [10:58:58<2928:37:26, 10.73s/it, lr=1e-5, step_loss=0.0671][RANK-0]: Step: [17311], local_loss=0.010250001214444637, train_loss=0.022230587899684906, time_cost=2.994203567504883
Steps:   2%|▏         | 17311/1000000 [10:58:58<2928:37:26, 10.73s/it, lr=1e-5, step_loss=0.0103]Steps:   2%|▏         | 17312/1000000 [10:59:05<2631:02:55,  9.64s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [17312], local_loss=0.007061176933348179, train_loss=0.07968113571405411, time_cost=1.4298737049102783
Steps:   2%|▏         | 17312/1000000 [10:59:05<2631:02:55,  9.64s/it, lr=1e-5, step_loss=0.00706]Steps:   2%|▏         | 17313/1000000 [10:59:16<2755:24:09, 10.09s/it, lr=1e-5, step_loss=0.00706][RANK-0]: Step: [17313], local_loss=0.05172533169388771, train_loss=0.07447436451911926, time_cost=2.10699725151062
Steps:   2%|▏         | 17313/1000000 [10:59:16<2755:24:09, 10.09s/it, lr=1e-5, step_loss=0.0517] Steps:   2%|▏         | 17314/1000000 [10:59:30<3114:22:29, 11.41s/it, lr=1e-5, step_loss=0.0517][RANK-0]: Step: [17314], local_loss=0.014946339651942253, train_loss=0.031088463962078094, time_cost=2.7474348545074463
Steps:   2%|▏         | 17314/1000000 [10:59:30<3114:22:29, 11.41s/it, lr=1e-5, step_loss=0.0149]Steps:   2%|▏         | 17315/1000000 [10:59:41<3087:50:44, 11.31s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [17315], local_loss=0.010495657101273537, train_loss=0.01848091557621956, time_cost=1.8926072120666504
Steps:   2%|▏         | 17315/1000000 [10:59:41<3087:50:44, 11.31s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 17316/1000000 [10:59:52<3009:39:00, 11.03s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [17316], local_loss=0.009595717303454876, train_loss=0.0282377228140831, time_cost=1.216360092163086
Steps:   2%|▏         | 17316/1000000 [10:59:52<3009:39:00, 11.03s/it, lr=1e-5, step_loss=0.0096]Steps:   2%|▏         | 17317/1000000 [11:00:03<3031:34:34, 11.11s/it, lr=1e-5, step_loss=0.0096][RANK-0]: Step: [17317], local_loss=0.05293256416916847, train_loss=0.042864859104156494, time_cost=3.863431692123413
Steps:   2%|▏         | 17317/1000000 [11:00:03<3031:34:34, 11.11s/it, lr=1e-5, step_loss=0.0529]Steps:   2%|▏         | 17318/1000000 [11:00:15<3060:41:46, 11.21s/it, lr=1e-5, step_loss=0.0529][RANK-0]: Step: [17318], local_loss=0.006442921236157417, train_loss=0.02292047068476677, time_cost=2.4061851501464844
Steps:   2%|▏         | 17318/1000000 [11:00:15<3060:41:46, 11.21s/it, lr=1e-5, step_loss=0.00644]Steps:   2%|▏         | 17319/1000000 [11:00:24<2908:30:00, 10.66s/it, lr=1e-5, step_loss=0.00644][RANK-0]: Step: [17319], local_loss=0.0317673459649086, train_loss=0.02756493166089058, time_cost=2.555394411087036
Steps:   2%|▏         | 17319/1000000 [11:00:24<2908:30:00, 10.66s/it, lr=1e-5, step_loss=0.0318] Steps:   2%|▏         | 17320/1000000 [11:00:33<2783:16:19, 10.20s/it, lr=1e-5, step_loss=0.0318][RANK-0]: Step: [17320], local_loss=0.044653359800577164, train_loss=0.02252158522605896, time_cost=6.811448097229004
Steps:   2%|▏         | 17320/1000000 [11:00:33<2783:16:19, 10.20s/it, lr=1e-5, step_loss=0.0447]Steps:   2%|▏         | 17321/1000000 [11:00:45<2890:10:48, 10.59s/it, lr=1e-5, step_loss=0.0447][RANK-0]: Step: [17321], local_loss=0.05387319251894951, train_loss=0.1739889532327652, time_cost=4.034418106079102
Steps:   2%|▏         | 17321/1000000 [11:00:45<2890:10:48, 10.59s/it, lr=1e-5, step_loss=0.0539]Steps:   2%|▏         | 17322/1000000 [11:00:55<2920:50:40, 10.70s/it, lr=1e-5, step_loss=0.0539][RANK-0]: Step: [17322], local_loss=0.010534994304180145, train_loss=0.029857492074370384, time_cost=1.8609435558319092
Steps:   2%|▏         | 17322/1000000 [11:00:55<2920:50:40, 10.70s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 17323/1000000 [11:01:02<2606:28:50,  9.55s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [17323], local_loss=0.014060728251934052, train_loss=0.1428953856229782, time_cost=5.209434747695923
Steps:   2%|▏         | 17323/1000000 [11:01:02<2606:28:50,  9.55s/it, lr=1e-5, step_loss=0.0141]Steps:   2%|▏         | 17324/1000000 [11:01:13<2698:57:22,  9.89s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [17324], local_loss=0.02470851130783558, train_loss=0.028311386704444885, time_cost=4.334564685821533
Steps:   2%|▏         | 17324/1000000 [11:01:13<2698:57:22,  9.89s/it, lr=1e-5, step_loss=0.0247]Steps:   2%|▏         | 17325/1000000 [11:01:27<3041:46:27, 11.14s/it, lr=1e-5, step_loss=0.0247][RANK-0]: Step: [17325], local_loss=0.07498618960380554, train_loss=0.016550280153751373, time_cost=6.707385778427124
Steps:   2%|▏         | 17325/1000000 [11:01:27<3041:46:27, 11.14s/it, lr=1e-5, step_loss=0.075] Steps:   2%|▏         | 17326/1000000 [11:01:33<2605:36:34,  9.55s/it, lr=1e-5, step_loss=0.075][RANK-0]: Step: [17326], local_loss=0.006138961296528578, train_loss=0.027835801243782043, time_cost=1.4080052375793457
Steps:   2%|▏         | 17326/1000000 [11:01:33<2605:36:34,  9.55s/it, lr=1e-5, step_loss=0.00614]Steps:   2%|▏         | 17327/1000000 [11:01:41<2465:48:24,  9.03s/it, lr=1e-5, step_loss=0.00614][RANK-0]: Step: [17327], local_loss=0.007857950404286385, train_loss=0.04412205144762993, time_cost=6.822038173675537
Steps:   2%|▏         | 17327/1000000 [11:01:41<2465:48:24,  9.03s/it, lr=1e-5, step_loss=0.00786]Steps:   2%|▏         | 17328/1000000 [11:01:48<2321:28:28,  8.50s/it, lr=1e-5, step_loss=0.00786][RANK-0]: Step: [17328], local_loss=0.03486942499876022, train_loss=0.08669055998325348, time_cost=1.2610015869140625
Steps:   2%|▏         | 17328/1000000 [11:01:48<2321:28:28,  8.50s/it, lr=1e-5, step_loss=0.0349] Steps:   2%|▏         | 17329/1000000 [11:01:55<2235:51:52,  8.19s/it, lr=1e-5, step_loss=0.0349][RANK-0]: Step: [17329], local_loss=0.21306408941745758, train_loss=0.03911276161670685, time_cost=3.622577667236328
Steps:   2%|▏         | 17329/1000000 [11:01:55<2235:51:52,  8.19s/it, lr=1e-5, step_loss=0.213] Steps:   2%|▏         | 17330/1000000 [11:02:03<2141:02:07,  7.84s/it, lr=1e-5, step_loss=0.213][RANK-0]: Step: [17330], local_loss=0.005268592853099108, train_loss=0.035892996937036514, time_cost=2.6952898502349854
Steps:   2%|▏         | 17330/1000000 [11:02:03<2141:02:07,  7.84s/it, lr=1e-5, step_loss=0.00527]Steps:   2%|▏         | 17331/1000000 [11:02:18<2800:45:30, 10.26s/it, lr=1e-5, step_loss=0.00527][RANK-0]: Step: [17331], local_loss=138.58412170410156, train_loss=17.377016067504883, time_cost=13.022039413452148
Steps:   2%|▏         | 17331/1000000 [11:02:18<2800:45:30, 10.26s/it, lr=1e-5, step_loss=139]    Steps:   2%|▏         | 17332/1000000 [11:02:29<2805:11:48, 10.28s/it, lr=1e-5, step_loss=139][RANK-0]: Step: [17332], local_loss=0.013269511982798576, train_loss=0.13594062626361847, time_cost=3.122128963470459
Steps:   2%|▏         | 17332/1000000 [11:02:29<2805:11:48, 10.28s/it, lr=1e-5, step_loss=0.0133]Steps:   2%|▏         | 17333/1000000 [11:02:34<2385:21:19,  8.74s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [17333], local_loss=0.007510068826377392, train_loss=0.05513594672083855, time_cost=1.601057529449463
Steps:   2%|▏         | 17333/1000000 [11:02:34<2385:21:19,  8.74s/it, lr=1e-5, step_loss=0.00751]Steps:   2%|▏         | 17334/1000000 [11:02:41<2250:41:58,  8.25s/it, lr=1e-5, step_loss=0.00751][RANK-0]: Step: [17334], local_loss=0.008056624792516232, train_loss=0.04729112982749939, time_cost=1.2311615943908691
Steps:   2%|▏         | 17334/1000000 [11:02:41<2250:41:58,  8.25s/it, lr=1e-5, step_loss=0.00806]Steps:   2%|▏         | 17335/1000000 [11:02:46<2024:38:34,  7.42s/it, lr=1e-5, step_loss=0.00806][RANK-0]: Step: [17335], local_loss=0.04571472108364105, train_loss=0.04245381057262421, time_cost=2.410261631011963
Steps:   2%|▏         | 17335/1000000 [11:02:46<2024:38:34,  7.42s/it, lr=1e-5, step_loss=0.0457] Steps:   2%|▏         | 17336/1000000 [11:02:59<2456:54:31,  9.00s/it, lr=1e-5, step_loss=0.0457][RANK-0]: Step: [17336], local_loss=0.054984334856271744, train_loss=0.027400821447372437, time_cost=3.449490547180176
Steps:   2%|▏         | 17336/1000000 [11:02:59<2456:54:31,  9.00s/it, lr=1e-5, step_loss=0.055] Steps:   2%|▏         | 17337/1000000 [11:03:14<2960:06:42, 10.84s/it, lr=1e-5, step_loss=0.055][RANK-0]: Step: [17337], local_loss=0.023496858775615692, train_loss=0.030367769300937653, time_cost=12.461142778396606
Steps:   2%|▏         | 17337/1000000 [11:03:14<2960:06:42, 10.84s/it, lr=1e-5, step_loss=0.0235]Steps:   2%|▏         | 17338/1000000 [11:03:22<2682:02:06,  9.83s/it, lr=1e-5, step_loss=0.0235][RANK-0]: Step: [17338], local_loss=0.045988649129867554, train_loss=0.055033303797245026, time_cost=2.343726873397827
Steps:   2%|▏         | 17338/1000000 [11:03:22<2682:02:06,  9.83s/it, lr=1e-5, step_loss=0.046] Steps:   2%|▏         | 17339/1000000 [11:03:38<3187:00:42, 11.68s/it, lr=1e-5, step_loss=0.046][RANK-0]: Step: [17339], local_loss=0.04638556018471718, train_loss=0.036352191120386124, time_cost=7.715432405471802
Steps:   2%|▏         | 17339/1000000 [11:03:38<3187:00:42, 11.68s/it, lr=1e-5, step_loss=0.0464]Steps:   2%|▏         | 17340/1000000 [11:03:51<3292:10:52, 12.06s/it, lr=1e-5, step_loss=0.0464][RANK-0]: Step: [17340], local_loss=0.009767716750502586, train_loss=0.016933759674429893, time_cost=4.973973035812378
Steps:   2%|▏         | 17340/1000000 [11:03:51<3292:10:52, 12.06s/it, lr=1e-5, step_loss=0.00977]Steps:   2%|▏         | 17341/1000000 [11:04:05<3477:20:39, 12.74s/it, lr=1e-5, step_loss=0.00977][RANK-0]: Step: [17341], local_loss=0.006014786660671234, train_loss=0.04104229062795639, time_cost=6.986429452896118
Steps:   2%|▏         | 17341/1000000 [11:04:05<3477:20:39, 12.74s/it, lr=1e-5, step_loss=0.00601]Steps:   2%|▏         | 17342/1000000 [11:04:12<3034:28:34, 11.12s/it, lr=1e-5, step_loss=0.00601][RANK-0]: Step: [17342], local_loss=0.005389883648604155, train_loss=0.1734190136194229, time_cost=3.6445388793945312
Steps:   2%|▏         | 17342/1000000 [11:04:12<3034:28:34, 11.12s/it, lr=1e-5, step_loss=0.00539]Steps:   2%|▏         | 17343/1000000 [11:04:18<2567:47:46,  9.41s/it, lr=1e-5, step_loss=0.00539][RANK-0]: Step: [17343], local_loss=0.0069984933361411095, train_loss=0.026202648878097534, time_cost=2.3446638584136963
Steps:   2%|▏         | 17343/1000000 [11:04:18<2567:47:46,  9.41s/it, lr=1e-5, step_loss=0.007]  Steps:   2%|▏         | 17344/1000000 [11:04:23<2207:00:45,  8.09s/it, lr=1e-5, step_loss=0.007][RANK-0]: Step: [17344], local_loss=0.01868753880262375, train_loss=15.121793746948242, time_cost=3.8308818340301514
Steps:   2%|▏         | 17344/1000000 [11:04:23<2207:00:45,  8.09s/it, lr=1e-5, step_loss=0.0187]Steps:   2%|▏         | 17345/1000000 [11:04:28<1950:36:02,  7.15s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [17345], local_loss=0.025475408881902695, train_loss=0.029368901625275612, time_cost=1.9898271560668945
Steps:   2%|▏         | 17345/1000000 [11:04:28<1950:36:02,  7.15s/it, lr=1e-5, step_loss=0.0255]Steps:   2%|▏         | 17346/1000000 [11:04:38<2227:16:09,  8.16s/it, lr=1e-5, step_loss=0.0255][RANK-0]: Step: [17346], local_loss=0.08680284768342972, train_loss=0.021109091117978096, time_cost=1.8450992107391357
Steps:   2%|▏         | 17346/1000000 [11:04:38<2227:16:09,  8.16s/it, lr=1e-5, step_loss=0.0868]Steps:   2%|▏         | 17347/1000000 [11:04:53<2728:22:54, 10.00s/it, lr=1e-5, step_loss=0.0868][RANK-0]: Step: [17347], local_loss=0.037513889372348785, train_loss=0.014213372021913528, time_cost=3.34504771232605
Steps:   2%|▏         | 17347/1000000 [11:04:53<2728:22:54, 10.00s/it, lr=1e-5, step_loss=0.0375]Steps:   2%|▏         | 17348/1000000 [11:04:57<2303:12:59,  8.44s/it, lr=1e-5, step_loss=0.0375][RANK-0]: Step: [17348], local_loss=0.005239053629338741, train_loss=0.030042579397559166, time_cost=1.2153148651123047
Steps:   2%|▏         | 17348/1000000 [11:04:57<2303:12:59,  8.44s/it, lr=1e-5, step_loss=0.00524]Steps:   2%|▏         | 17349/1000000 [11:05:05<2276:25:07,  8.34s/it, lr=1e-5, step_loss=0.00524][RANK-0]: Step: [17349], local_loss=1.0019217729568481, train_loss=0.27256080508232117, time_cost=3.1115715503692627
Steps:   2%|▏         | 17349/1000000 [11:05:05<2276:25:07,  8.34s/it, lr=1e-5, step_loss=1]      Steps:   2%|▏         | 17350/1000000 [11:05:20<2748:03:10, 10.07s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [17350], local_loss=0.011172044090926647, train_loss=0.025658030062913895, time_cost=6.427321910858154
Steps:   2%|▏         | 17350/1000000 [11:05:20<2748:03:10, 10.07s/it, lr=1e-5, step_loss=0.0112]Steps:   2%|▏         | 17351/1000000 [11:05:24<2269:53:25,  8.32s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [17351], local_loss=0.006149829365313053, train_loss=0.043714843690395355, time_cost=1.732923984527588
Steps:   2%|▏         | 17351/1000000 [11:05:24<2269:53:25,  8.32s/it, lr=1e-5, step_loss=0.00615]Steps:   2%|▏         | 17352/1000000 [11:05:35<2477:14:01,  9.08s/it, lr=1e-5, step_loss=0.00615][RANK-0]: Step: [17352], local_loss=0.02816462703049183, train_loss=0.12823371589183807, time_cost=2.969561815261841
Steps:   2%|▏         | 17352/1000000 [11:05:35<2477:14:01,  9.08s/it, lr=1e-5, step_loss=0.0282] Steps:   2%|▏         | 17353/1000000 [11:05:40<2138:33:00,  7.83s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [17353], local_loss=0.035471271723508835, train_loss=0.04580741003155708, time_cost=1.333132266998291
Steps:   2%|▏         | 17353/1000000 [11:05:40<2138:33:00,  7.83s/it, lr=1e-5, step_loss=0.0355]Steps:   2%|▏         | 17354/1000000 [11:05:53<2630:03:37,  9.64s/it, lr=1e-5, step_loss=0.0355][RANK-0]: Step: [17354], local_loss=0.006503335200250149, train_loss=0.05597051978111267, time_cost=1.288498878479004
Steps:   2%|▏         | 17354/1000000 [11:05:53<2630:03:37,  9.64s/it, lr=1e-5, step_loss=0.0065]Steps:   2%|▏         | 17355/1000000 [11:06:05<2757:12:31, 10.10s/it, lr=1e-5, step_loss=0.0065][RANK-0]: Step: [17355], local_loss=0.021213123574852943, train_loss=0.025600306689739227, time_cost=2.763679265975952
Steps:   2%|▏         | 17355/1000000 [11:06:05<2757:12:31, 10.10s/it, lr=1e-5, step_loss=0.0212]Steps:   2%|▏         | 17356/1000000 [11:06:11<2484:16:37,  9.10s/it, lr=1e-5, step_loss=0.0212][RANK-0]: Step: [17356], local_loss=0.009343559853732586, train_loss=0.029498878866434097, time_cost=2.089801549911499
Steps:   2%|▏         | 17356/1000000 [11:06:11<2484:16:37,  9.10s/it, lr=1e-5, step_loss=0.00934]Steps:   2%|▏         | 17357/1000000 [11:06:27<2982:44:58, 10.93s/it, lr=1e-5, step_loss=0.00934][RANK-0]: Step: [17357], local_loss=0.018014388158917427, train_loss=0.06562113761901855, time_cost=6.996169805526733
Steps:   2%|▏         | 17357/1000000 [11:06:27<2982:44:58, 10.93s/it, lr=1e-5, step_loss=0.018]  Steps:   2%|▏         | 17358/1000000 [11:06:34<2690:45:58,  9.86s/it, lr=1e-5, step_loss=0.018][RANK-0]: Step: [17358], local_loss=0.04173225536942482, train_loss=0.021927548572421074, time_cost=1.6952362060546875
Steps:   2%|▏         | 17358/1000000 [11:06:34<2690:45:58,  9.86s/it, lr=1e-5, step_loss=0.0417]Steps:   2%|▏         | 17359/1000000 [11:06:48<2996:54:34, 10.98s/it, lr=1e-5, step_loss=0.0417][RANK-0]: Step: [17359], local_loss=0.04533549025654793, train_loss=0.05369056761264801, time_cost=4.358886480331421
Steps:   2%|▏         | 17359/1000000 [11:06:48<2996:54:34, 10.98s/it, lr=1e-5, step_loss=0.0453]Steps:   2%|▏         | 17360/1000000 [11:06:57<2840:15:30, 10.41s/it, lr=1e-5, step_loss=0.0453][RANK-0]: Step: [17360], local_loss=0.0065612695179879665, train_loss=0.02164066582918167, time_cost=2.7628390789031982
Steps:   2%|▏         | 17360/1000000 [11:06:57<2840:15:30, 10.41s/it, lr=1e-5, step_loss=0.00656]Steps:   2%|▏         | 17361/1000000 [11:07:02<2424:35:43,  8.88s/it, lr=1e-5, step_loss=0.00656][RANK-0]: Step: [17361], local_loss=0.010813294909894466, train_loss=0.03362574428319931, time_cost=2.9642696380615234
Steps:   2%|▏         | 17361/1000000 [11:07:02<2424:35:43,  8.88s/it, lr=1e-5, step_loss=0.0108] Steps:   2%|▏         | 17362/1000000 [11:07:15<2754:07:32, 10.09s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [17362], local_loss=0.014731692150235176, train_loss=0.03992946445941925, time_cost=5.45080041885376
Steps:   2%|▏         | 17362/1000000 [11:07:15<2754:07:32, 10.09s/it, lr=1e-5, step_loss=0.0147]Steps:   2%|▏         | 17363/1000000 [11:07:25<2781:35:00, 10.19s/it, lr=1e-5, step_loss=0.0147][RANK-0]: Step: [17363], local_loss=0.005899642128497362, train_loss=0.020667152479290962, time_cost=3.0522470474243164
Steps:   2%|▏         | 17363/1000000 [11:07:25<2781:35:00, 10.19s/it, lr=1e-5, step_loss=0.0059]Steps:   2%|▏         | 17364/1000000 [11:07:35<2785:56:50, 10.21s/it, lr=1e-5, step_loss=0.0059][RANK-0]: Step: [17364], local_loss=0.012455666437745094, train_loss=0.07523640245199203, time_cost=5.036905288696289
Steps:   2%|▏         | 17364/1000000 [11:07:35<2785:56:50, 10.21s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 17365/1000000 [11:07:40<2356:14:31,  8.63s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [17365], local_loss=0.007641876116394997, train_loss=0.08091753721237183, time_cost=2.046428680419922
Steps:   2%|▏         | 17365/1000000 [11:07:40<2356:14:31,  8.63s/it, lr=1e-5, step_loss=0.00764]Steps:   2%|▏         | 17366/1000000 [11:07:55<2854:40:30, 10.46s/it, lr=1e-5, step_loss=0.00764][RANK-0]: Step: [17366], local_loss=0.06410139799118042, train_loss=0.04810480773448944, time_cost=5.27775239944458
Steps:   2%|▏         | 17366/1000000 [11:07:55<2854:40:30, 10.46s/it, lr=1e-5, step_loss=0.0641] Steps:   2%|▏         | 17367/1000000 [11:08:03<2621:18:58,  9.60s/it, lr=1e-5, step_loss=0.0641][RANK-0]: Step: [17367], local_loss=0.008694487623870373, train_loss=0.07350838929414749, time_cost=3.049382209777832
Steps:   2%|▏         | 17367/1000000 [11:08:03<2621:18:58,  9.60s/it, lr=1e-5, step_loss=0.00869]Steps:   2%|▏         | 17368/1000000 [11:08:14<2774:00:16, 10.16s/it, lr=1e-5, step_loss=0.00869][RANK-0]: Step: [17368], local_loss=0.012096554972231388, train_loss=0.06864065676927567, time_cost=1.6176698207855225
Steps:   2%|▏         | 17368/1000000 [11:08:14<2774:00:16, 10.16s/it, lr=1e-5, step_loss=0.0121] Steps:   2%|▏         | 17369/1000000 [11:08:19<2352:02:59,  8.62s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [17369], local_loss=0.007764636538922787, train_loss=0.019054781645536423, time_cost=2.273555278778076
Steps:   2%|▏         | 17369/1000000 [11:08:19<2352:02:59,  8.62s/it, lr=1e-5, step_loss=0.00776]Steps:   2%|▏         | 17370/1000000 [11:08:32<2731:00:02, 10.01s/it, lr=1e-5, step_loss=0.00776][RANK-0]: Step: [17370], local_loss=0.0098233912140131, train_loss=0.017084863036870956, time_cost=3.997570276260376
Steps:   2%|▏         | 17370/1000000 [11:08:33<2731:00:02, 10.01s/it, lr=1e-5, step_loss=0.00982]Steps:   2%|▏         | 17371/1000000 [11:08:48<3178:44:11, 11.65s/it, lr=1e-5, step_loss=0.00982][RANK-0]: Step: [17371], local_loss=0.0037484019994735718, train_loss=0.011957069858908653, time_cost=8.171746730804443
Steps:   2%|▏         | 17371/1000000 [11:08:48<3178:44:11, 11.65s/it, lr=1e-5, step_loss=0.00375]Steps:   2%|▏         | 17372/1000000 [11:09:03<3454:26:28, 12.66s/it, lr=1e-5, step_loss=0.00375][RANK-0]: Step: [17372], local_loss=0.006681107450276613, train_loss=0.01097111590206623, time_cost=6.932158470153809
Steps:   2%|▏         | 17372/1000000 [11:09:03<3454:26:28, 12.66s/it, lr=1e-5, step_loss=0.00668]Steps:   2%|▏         | 17373/1000000 [11:09:16<3451:33:59, 12.65s/it, lr=1e-5, step_loss=0.00668][RANK-0]: Step: [17373], local_loss=0.06544532626867294, train_loss=0.03280789032578468, time_cost=1.2025158405303955
Steps:   2%|▏         | 17373/1000000 [11:09:16<3451:33:59, 12.65s/it, lr=1e-5, step_loss=0.0654] Steps:   2%|▏         | 17374/1000000 [11:09:21<2816:53:11, 10.32s/it, lr=1e-5, step_loss=0.0654][RANK-0]: Step: [17374], local_loss=0.03328147903084755, train_loss=0.0647803395986557, time_cost=2.4029738903045654
Steps:   2%|▏         | 17374/1000000 [11:09:21<2816:53:11, 10.32s/it, lr=1e-5, step_loss=0.0333]Steps:   2%|▏         | 17375/1000000 [11:09:28<2602:03:02,  9.53s/it, lr=1e-5, step_loss=0.0333][RANK-0]: Step: [17375], local_loss=0.02981221117079258, train_loss=0.032188381999731064, time_cost=1.2465262413024902
Steps:   2%|▏         | 17375/1000000 [11:09:28<2602:03:02,  9.53s/it, lr=1e-5, step_loss=0.0298]Steps:   2%|▏         | 17376/1000000 [11:09:44<3116:42:57, 11.42s/it, lr=1e-5, step_loss=0.0298][RANK-0]: Step: [17376], local_loss=0.01639474742114544, train_loss=0.0513470396399498, time_cost=14.288827180862427
Steps:   2%|▏         | 17376/1000000 [11:09:44<3116:42:57, 11.42s/it, lr=1e-5, step_loss=0.0164]Steps:   2%|▏         | 17377/1000000 [11:09:52<2855:47:56, 10.46s/it, lr=1e-5, step_loss=0.0164][RANK-0]: Step: [17377], local_loss=0.0350492000579834, train_loss=0.03429686650633812, time_cost=1.19966459274292
Steps:   2%|▏         | 17377/1000000 [11:09:52<2855:47:56, 10.46s/it, lr=1e-5, step_loss=0.035] Steps:   2%|▏         | 17378/1000000 [11:09:59<2559:48:50,  9.38s/it, lr=1e-5, step_loss=0.035][RANK-0]: Step: [17378], local_loss=0.03797324374318123, train_loss=0.06971284747123718, time_cost=1.4571292400360107
Steps:   2%|▏         | 17378/1000000 [11:09:59<2559:48:50,  9.38s/it, lr=1e-5, step_loss=0.038]Steps:   2%|▏         | 17379/1000000 [11:10:06<2379:45:44,  8.72s/it, lr=1e-5, step_loss=0.038][RANK-0]: Step: [17379], local_loss=0.011478631757199764, train_loss=0.026952333748340607, time_cost=2.705545663833618
Steps:   2%|▏         | 17379/1000000 [11:10:06<2379:45:44,  8.72s/it, lr=1e-5, step_loss=0.0115]Steps:   2%|▏         | 17380/1000000 [11:10:11<2047:36:02,  7.50s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [17380], local_loss=0.0156076205894351, train_loss=0.027249429374933243, time_cost=2.003328323364258
Steps:   2%|▏         | 17380/1000000 [11:10:11<2047:36:02,  7.50s/it, lr=1e-5, step_loss=0.0156]Steps:   2%|▏         | 17381/1000000 [11:10:18<2016:47:49,  7.39s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [17381], local_loss=0.24208606779575348, train_loss=0.10720647126436234, time_cost=2.9131484031677246
Steps:   2%|▏         | 17381/1000000 [11:10:18<2016:47:49,  7.39s/it, lr=1e-5, step_loss=0.242] Steps:   2%|▏         | 17382/1000000 [11:10:29<2279:11:43,  8.35s/it, lr=1e-5, step_loss=0.242][RANK-0]: Step: [17382], local_loss=0.04104664549231529, train_loss=0.02920149452984333, time_cost=7.570236921310425
Steps:   2%|▏         | 17382/1000000 [11:10:29<2279:11:43,  8.35s/it, lr=1e-5, step_loss=0.041]Steps:   2%|▏         | 17383/1000000 [11:10:35<2100:10:41,  7.69s/it, lr=1e-5, step_loss=0.041][RANK-0]: Step: [17383], local_loss=0.04744546487927437, train_loss=0.03195478767156601, time_cost=2.6030824184417725
Steps:   2%|▏         | 17383/1000000 [11:10:35<2100:10:41,  7.69s/it, lr=1e-5, step_loss=0.0474]Steps:   2%|▏         | 17384/1000000 [11:10:45<2334:13:42,  8.55s/it, lr=1e-5, step_loss=0.0474][RANK-0]: Step: [17384], local_loss=0.06026295945048332, train_loss=0.06433333456516266, time_cost=3.847146987915039
Steps:   2%|▏         | 17384/1000000 [11:10:45<2334:13:42,  8.55s/it, lr=1e-5, step_loss=0.0603]Steps:   2%|▏         | 17385/1000000 [11:10:56<2505:33:45,  9.18s/it, lr=1e-5, step_loss=0.0603][RANK-0]: Step: [17385], local_loss=0.0021748612634837627, train_loss=0.16384321451187134, time_cost=1.6888294219970703
Steps:   2%|▏         | 17385/1000000 [11:10:56<2505:33:45,  9.18s/it, lr=1e-5, step_loss=0.00217]Steps:   2%|▏         | 17386/1000000 [11:11:02<2244:34:31,  8.22s/it, lr=1e-5, step_loss=0.00217][RANK-0]: Step: [17386], local_loss=0.009016958065330982, train_loss=0.02119375765323639, time_cost=1.5481936931610107
Steps:   2%|▏         | 17386/1000000 [11:11:02<2244:34:31,  8.22s/it, lr=1e-5, step_loss=0.00902]Steps:   2%|▏         | 17387/1000000 [11:11:09<2131:19:30,  7.81s/it, lr=1e-5, step_loss=0.00902][RANK-0]: Step: [17387], local_loss=0.0669899582862854, train_loss=0.08138494938611984, time_cost=1.183501958847046
Steps:   2%|▏         | 17387/1000000 [11:11:09<2131:19:30,  7.81s/it, lr=1e-5, step_loss=0.067]  Steps:   2%|▏         | 17388/1000000 [11:11:16<2074:21:34,  7.60s/it, lr=1e-5, step_loss=0.067][RANK-0]: Step: [17388], local_loss=0.008748062886297703, train_loss=0.04624816030263901, time_cost=1.7990691661834717
Steps:   2%|▏         | 17388/1000000 [11:11:16<2074:21:34,  7.60s/it, lr=1e-5, step_loss=0.00875]Steps:   2%|▏         | 17389/1000000 [11:11:26<2312:41:48,  8.47s/it, lr=1e-5, step_loss=0.00875][RANK-0]: Step: [17389], local_loss=0.01419675350189209, train_loss=0.06028713285923004, time_cost=3.0677692890167236
Steps:   2%|▏         | 17389/1000000 [11:11:26<2312:41:48,  8.47s/it, lr=1e-5, step_loss=0.0142] Steps:   2%|▏         | 17390/1000000 [11:11:31<1972:57:25,  7.23s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [17390], local_loss=0.006142450496554375, train_loss=0.06297871470451355, time_cost=1.6109719276428223
Steps:   2%|▏         | 17390/1000000 [11:11:31<1972:57:25,  7.23s/it, lr=1e-5, step_loss=0.00614]Steps:   2%|▏         | 17391/1000000 [11:11:42<2282:56:45,  8.36s/it, lr=1e-5, step_loss=0.00614][RANK-0]: Step: [17391], local_loss=0.009191970340907574, train_loss=0.024542152881622314, time_cost=3.9272007942199707
Steps:   2%|▏         | 17391/1000000 [11:11:42<2282:56:45,  8.36s/it, lr=1e-5, step_loss=0.00919]Steps:   2%|▏         | 17392/1000000 [11:11:46<1959:59:28,  7.18s/it, lr=1e-5, step_loss=0.00919][RANK-0]: Step: [17392], local_loss=0.01263448316603899, train_loss=0.01910148188471794, time_cost=1.7713541984558105
Steps:   2%|▏         | 17392/1000000 [11:11:46<1959:59:28,  7.18s/it, lr=1e-5, step_loss=0.0126] Steps:   2%|▏         | 17393/1000000 [11:11:56<2191:29:23,  8.03s/it, lr=1e-5, step_loss=0.0126][RANK-0]: Step: [17393], local_loss=0.003688706085085869, train_loss=0.06628917902708054, time_cost=1.426302433013916
Steps:   2%|▏         | 17393/1000000 [11:11:56<2191:29:23,  8.03s/it, lr=1e-5, step_loss=0.00369]Steps:   2%|▏         | 17394/1000000 [11:12:09<2585:29:58,  9.47s/it, lr=1e-5, step_loss=0.00369][RANK-0]: Step: [17394], local_loss=0.011642560362815857, train_loss=0.052545879036188126, time_cost=3.193269968032837
Steps:   2%|▏         | 17394/1000000 [11:12:09<2585:29:58,  9.47s/it, lr=1e-5, step_loss=0.0116] Steps:   2%|▏         | 17395/1000000 [11:12:23<2977:45:48, 10.91s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [17395], local_loss=0.02212587371468544, train_loss=0.017191968858242035, time_cost=5.66984224319458
Steps:   2%|▏         | 17395/1000000 [11:12:23<2977:45:48, 10.91s/it, lr=1e-5, step_loss=0.0221]Steps:   2%|▏         | 17396/1000000 [11:12:38<3260:16:25, 11.94s/it, lr=1e-5, step_loss=0.0221][RANK-0]: Step: [17396], local_loss=0.0053992304019629955, train_loss=0.030138414353132248, time_cost=4.7041175365448
Steps:   2%|▏         | 17396/1000000 [11:12:38<3260:16:25, 11.94s/it, lr=1e-5, step_loss=0.0054]Steps:   2%|▏         | 17397/1000000 [11:12:45<2847:27:39, 10.43s/it, lr=1e-5, step_loss=0.0054][RANK-0]: Step: [17397], local_loss=0.01506267674267292, train_loss=0.017285872250795364, time_cost=1.4695613384246826
Steps:   2%|▏         | 17397/1000000 [11:12:45<2847:27:39, 10.43s/it, lr=1e-5, step_loss=0.0151]Steps:   2%|▏         | 17398/1000000 [11:12:52<2566:04:09,  9.40s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [17398], local_loss=0.1827675700187683, train_loss=0.09163139760494232, time_cost=5.315770149230957
Steps:   2%|▏         | 17398/1000000 [11:12:52<2566:04:09,  9.40s/it, lr=1e-5, step_loss=0.183] Steps:   2%|▏         | 17399/1000000 [11:13:05<2866:08:02, 10.50s/it, lr=1e-5, step_loss=0.183][RANK-0]: Step: [17399], local_loss=0.07382399588823318, train_loss=0.24868136644363403, time_cost=9.36182165145874
Steps:   2%|▏         | 17399/1000000 [11:13:05<2866:08:02, 10.50s/it, lr=1e-5, step_loss=0.0738]Steps:   2%|▏         | 17400/1000000 [11:13:18<3131:12:30, 11.47s/it, lr=1e-5, step_loss=0.0738][RANK-0]: Step: [17400], local_loss=0.08069074153900146, train_loss=0.24213652312755585, time_cost=5.591170787811279
Steps:   2%|▏         | 17400/1000000 [11:13:18<3131:12:30, 11.47s/it, lr=1e-5, step_loss=0.0807]Steps:   2%|▏         | 17401/1000000 [11:13:31<3206:03:42, 11.75s/it, lr=1e-5, step_loss=0.0807][RANK-0]: Step: [17401], local_loss=0.1776122897863388, train_loss=0.06667456775903702, time_cost=2.6719634532928467
Steps:   2%|▏         | 17401/1000000 [11:13:31<3206:03:42, 11.75s/it, lr=1e-5, step_loss=0.178] Steps:   2%|▏         | 17402/1000000 [11:13:38<2796:55:31, 10.25s/it, lr=1e-5, step_loss=0.178][RANK-0]: Step: [17402], local_loss=0.005563200917094946, train_loss=0.012385141104459763, time_cost=1.2137222290039062
Steps:   2%|▏         | 17402/1000000 [11:13:38<2796:55:31, 10.25s/it, lr=1e-5, step_loss=0.00556]Steps:   2%|▏         | 17403/1000000 [11:13:52<3178:30:42, 11.65s/it, lr=1e-5, step_loss=0.00556][RANK-0]: Step: [17403], local_loss=0.057420749217271805, train_loss=0.030929680913686752, time_cost=6.498483419418335
Steps:   2%|▏         | 17403/1000000 [11:13:52<3178:30:42, 11.65s/it, lr=1e-5, step_loss=0.0574] Steps:   2%|▏         | 17404/1000000 [11:14:07<3399:59:02, 12.46s/it, lr=1e-5, step_loss=0.0574][RANK-0]: Step: [17404], local_loss=0.024512842297554016, train_loss=0.031053895130753517, time_cost=8.76484227180481
Steps:   2%|▏         | 17404/1000000 [11:14:07<3399:59:02, 12.46s/it, lr=1e-5, step_loss=0.0245]Steps:   2%|▏         | 17405/1000000 [11:14:18<3259:45:07, 11.94s/it, lr=1e-5, step_loss=0.0245][RANK-0]: Step: [17405], local_loss=0.013077120296657085, train_loss=0.07842683047056198, time_cost=4.7698283195495605
Steps:   2%|▏         | 17405/1000000 [11:14:18<3259:45:07, 11.94s/it, lr=1e-5, step_loss=0.0131]Steps:   2%|▏         | 17406/1000000 [11:14:23<2768:38:31, 10.14s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [17406], local_loss=0.01020286325365305, train_loss=0.013286137022078037, time_cost=1.4032421112060547
Steps:   2%|▏         | 17406/1000000 [11:14:23<2768:38:31, 10.14s/it, lr=1e-5, step_loss=0.0102]Steps:   2%|▏         | 17407/1000000 [11:14:42<3430:42:35, 12.57s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [17407], local_loss=0.04450215399265289, train_loss=0.14477261900901794, time_cost=10.727150201797485
Steps:   2%|▏         | 17407/1000000 [11:14:42<3430:42:35, 12.57s/it, lr=1e-5, step_loss=0.0445]Steps:   2%|▏         | 17408/1000000 [11:14:50<3049:18:56, 11.17s/it, lr=1e-5, step_loss=0.0445][RANK-0]: Step: [17408], local_loss=0.029197493568062782, train_loss=0.031077371910214424, time_cost=7.088535308837891
Steps:   2%|▏         | 17408/1000000 [11:14:50<3049:18:56, 11.17s/it, lr=1e-5, step_loss=0.0292]Steps:   2%|▏         | 17409/1000000 [11:15:01<3088:25:15, 11.32s/it, lr=1e-5, step_loss=0.0292][RANK-0]: Step: [17409], local_loss=0.05925673618912697, train_loss=0.061802566051483154, time_cost=2.915313720703125
Steps:   2%|▏         | 17409/1000000 [11:15:01<3088:25:15, 11.32s/it, lr=1e-5, step_loss=0.0593]Steps:   2%|▏         | 17410/1000000 [11:15:06<2528:22:41,  9.26s/it, lr=1e-5, step_loss=0.0593][RANK-0]: Step: [17410], local_loss=0.00424245186150074, train_loss=0.015898557379841805, time_cost=1.717071533203125
Steps:   2%|▏         | 17410/1000000 [11:15:06<2528:22:41,  9.26s/it, lr=1e-5, step_loss=0.00424]Steps:   2%|▏         | 17411/1000000 [11:15:11<2195:56:04,  8.05s/it, lr=1e-5, step_loss=0.00424][RANK-0]: Step: [17411], local_loss=0.12084189802408218, train_loss=0.03487864136695862, time_cost=2.0415749549865723
Steps:   2%|▏         | 17411/1000000 [11:15:11<2195:56:04,  8.05s/it, lr=1e-5, step_loss=0.121]  Steps:   2%|▏         | 17412/1000000 [11:15:20<2240:58:42,  8.21s/it, lr=1e-5, step_loss=0.121][RANK-0]: Step: [17412], local_loss=0.020182261243462563, train_loss=0.024893298745155334, time_cost=1.3001854419708252
Steps:   2%|▏         | 17412/1000000 [11:15:20<2240:58:42,  8.21s/it, lr=1e-5, step_loss=0.0202]Steps:   2%|▏         | 17413/1000000 [11:15:33<2658:08:09,  9.74s/it, lr=1e-5, step_loss=0.0202][RANK-0]: Step: [17413], local_loss=0.005963364616036415, train_loss=0.055947445333004, time_cost=4.549715757369995
Steps:   2%|▏         | 17413/1000000 [11:15:33<2658:08:09,  9.74s/it, lr=1e-5, step_loss=0.00596]Steps:   2%|▏         | 17414/1000000 [11:15:44<2774:55:02, 10.17s/it, lr=1e-5, step_loss=0.00596][RANK-0]: Step: [17414], local_loss=0.009399129077792168, train_loss=0.03467747941613197, time_cost=2.960620403289795
Steps:   2%|▏         | 17414/1000000 [11:15:44<2774:55:02, 10.17s/it, lr=1e-5, step_loss=0.0094] Steps:   2%|▏         | 17415/1000000 [11:15:48<2300:21:50,  8.43s/it, lr=1e-5, step_loss=0.0094][RANK-0]: Step: [17415], local_loss=0.024183884263038635, train_loss=0.023971127346158028, time_cost=1.6626813411712646
Steps:   2%|▏         | 17415/1000000 [11:15:48<2300:21:50,  8.43s/it, lr=1e-5, step_loss=0.0242]Steps:   2%|▏         | 17416/1000000 [11:15:56<2200:18:23,  8.06s/it, lr=1e-5, step_loss=0.0242][RANK-0]: Step: [17416], local_loss=0.04470426216721535, train_loss=0.07374785840511322, time_cost=2.828707695007324
Steps:   2%|▏         | 17416/1000000 [11:15:56<2200:18:23,  8.06s/it, lr=1e-5, step_loss=0.0447]Steps:   2%|▏         | 17417/1000000 [11:16:00<1930:10:47,  7.07s/it, lr=1e-5, step_loss=0.0447][RANK-0]: Step: [17417], local_loss=0.026739396154880524, train_loss=0.0516851469874382, time_cost=1.8207554817199707
Steps:   2%|▏         | 17417/1000000 [11:16:00<1930:10:47,  7.07s/it, lr=1e-5, step_loss=0.0267]Steps:   2%|▏         | 17418/1000000 [11:16:07<1906:42:54,  6.99s/it, lr=1e-5, step_loss=0.0267][RANK-0]: Step: [17418], local_loss=0.00490780733525753, train_loss=0.0374576710164547, time_cost=2.3035829067230225
Steps:   2%|▏         | 17418/1000000 [11:16:07<1906:42:54,  6.99s/it, lr=1e-5, step_loss=0.00491]Steps:   2%|▏         | 17419/1000000 [11:16:14<1911:32:45,  7.00s/it, lr=1e-5, step_loss=0.00491][RANK-0]: Step: [17419], local_loss=0.0157607551664114, train_loss=9.2701416015625, time_cost=1.6676130294799805
Steps:   2%|▏         | 17419/1000000 [11:16:14<1911:32:45,  7.00s/it, lr=1e-5, step_loss=0.0158] Steps:   2%|▏         | 17420/1000000 [11:16:24<2135:42:07,  7.82s/it, lr=1e-5, step_loss=0.0158][RANK-0]: Step: [17420], local_loss=0.02496497333049774, train_loss=0.29719114303588867, time_cost=1.2351415157318115
Steps:   2%|▏         | 17420/1000000 [11:16:24<2135:42:07,  7.82s/it, lr=1e-5, step_loss=0.025] Steps:   2%|▏         | 17421/1000000 [11:16:29<1938:29:57,  7.10s/it, lr=1e-5, step_loss=0.025][RANK-0]: Step: [17421], local_loss=0.02100820094347, train_loss=0.14686466753482819, time_cost=1.194505214691162
Steps:   2%|▏         | 17421/1000000 [11:16:29<1938:29:57,  7.10s/it, lr=1e-5, step_loss=0.021]Steps:   2%|▏         | 17422/1000000 [11:16:35<1787:10:29,  6.55s/it, lr=1e-5, step_loss=0.021][RANK-0]: Step: [17422], local_loss=0.008274574764072895, train_loss=0.036017559468746185, time_cost=2.555863380432129
Steps:   2%|▏         | 17422/1000000 [11:16:35<1787:10:29,  6.55s/it, lr=1e-5, step_loss=0.00827]Steps:   2%|▏         | 17423/1000000 [11:16:44<2004:51:22,  7.35s/it, lr=1e-5, step_loss=0.00827][RANK-0]: Step: [17423], local_loss=0.004670299123972654, train_loss=0.07062286883592606, time_cost=2.5779218673706055
Steps:   2%|▏         | 17423/1000000 [11:16:44<2004:51:22,  7.35s/it, lr=1e-5, step_loss=0.00467]Steps:   2%|▏         | 17424/1000000 [11:16:51<2024:34:38,  7.42s/it, lr=1e-5, step_loss=0.00467][RANK-0]: Step: [17424], local_loss=0.06301707774400711, train_loss=0.0555817075073719, time_cost=2.0280141830444336
Steps:   2%|▏         | 17424/1000000 [11:16:51<2024:34:38,  7.42s/it, lr=1e-5, step_loss=0.063]  Steps:   2%|▏         | 17425/1000000 [11:16:59<2030:30:39,  7.44s/it, lr=1e-5, step_loss=0.063][RANK-0]: Step: [17425], local_loss=0.17042173445224762, train_loss=0.041071005165576935, time_cost=3.093034505844116
Steps:   2%|▏         | 17425/1000000 [11:16:59<2030:30:39,  7.44s/it, lr=1e-5, step_loss=0.17] Steps:   2%|▏         | 17426/1000000 [11:17:11<2377:32:07,  8.71s/it, lr=1e-5, step_loss=0.17][RANK-0]: Step: [17426], local_loss=0.03140115365386009, train_loss=0.02424512803554535, time_cost=8.769848823547363
Steps:   2%|▏         | 17426/1000000 [11:17:11<2377:32:07,  8.71s/it, lr=1e-5, step_loss=0.0314]Steps:   2%|▏         | 17427/1000000 [11:17:21<2537:26:21,  9.30s/it, lr=1e-5, step_loss=0.0314][RANK-0]: Step: [17427], local_loss=0.015939027070999146, train_loss=0.02297675982117653, time_cost=2.2135000228881836
Steps:   2%|▏         | 17427/1000000 [11:17:21<2537:26:21,  9.30s/it, lr=1e-5, step_loss=0.0159]Steps:   2%|▏         | 17428/1000000 [11:17:35<2880:26:26, 10.55s/it, lr=1e-5, step_loss=0.0159][RANK-0]: Step: [17428], local_loss=0.009817596524953842, train_loss=0.016126487404108047, time_cost=4.10724949836731
Steps:   2%|▏         | 17428/1000000 [11:17:35<2880:26:26, 10.55s/it, lr=1e-5, step_loss=0.00982]Steps:   2%|▏         | 17429/1000000 [11:17:51<3348:18:42, 12.27s/it, lr=1e-5, step_loss=0.00982][RANK-0]: Step: [17429], local_loss=0.009198220446705818, train_loss=0.052767571061849594, time_cost=8.713555812835693
Steps:   2%|▏         | 17429/1000000 [11:17:51<3348:18:42, 12.27s/it, lr=1e-5, step_loss=0.0092] Steps:   2%|▏         | 17430/1000000 [11:17:58<2954:31:35, 10.82s/it, lr=1e-5, step_loss=0.0092][RANK-0]: Step: [17430], local_loss=0.027219120413064957, train_loss=0.03852534294128418, time_cost=2.016937017440796
Steps:   2%|▏         | 17430/1000000 [11:17:58<2954:31:35, 10.82s/it, lr=1e-5, step_loss=0.0272]Steps:   2%|▏         | 17431/1000000 [11:18:05<2614:50:08,  9.58s/it, lr=1e-5, step_loss=0.0272][RANK-0]: Step: [17431], local_loss=0.05948055908083916, train_loss=0.030707869678735733, time_cost=2.154186248779297
Steps:   2%|▏         | 17431/1000000 [11:18:05<2614:50:08,  9.58s/it, lr=1e-5, step_loss=0.0595]Steps:   2%|▏         | 17432/1000000 [11:18:18<2887:54:34, 10.58s/it, lr=1e-5, step_loss=0.0595][RANK-0]: Step: [17432], local_loss=0.006346905138343573, train_loss=0.013196432963013649, time_cost=3.7849810123443604
Steps:   2%|▏         | 17432/1000000 [11:18:18<2887:54:34, 10.58s/it, lr=1e-5, step_loss=0.00635]Steps:   2%|▏         | 17433/1000000 [11:18:27<2750:19:32, 10.08s/it, lr=1e-5, step_loss=0.00635][RANK-0]: Step: [17433], local_loss=0.03391518443822861, train_loss=0.09633789956569672, time_cost=3.4936702251434326
Steps:   2%|▏         | 17433/1000000 [11:18:27<2750:19:32, 10.08s/it, lr=1e-5, step_loss=0.0339] Steps:   2%|▏         | 17434/1000000 [11:18:43<3245:18:26, 11.89s/it, lr=1e-5, step_loss=0.0339][RANK-0]: Step: [17434], local_loss=0.0707898736000061, train_loss=0.19031456112861633, time_cost=7.669501066207886
Steps:   2%|▏         | 17434/1000000 [11:18:43<3245:18:26, 11.89s/it, lr=1e-5, step_loss=0.0708]Steps:   2%|▏         | 17435/1000000 [11:18:48<2646:47:07,  9.70s/it, lr=1e-5, step_loss=0.0708][RANK-0]: Step: [17435], local_loss=0.004882774781435728, train_loss=0.08894021064043045, time_cost=2.292367458343506
Steps:   2%|▏         | 17435/1000000 [11:18:48<2646:47:07,  9.70s/it, lr=1e-5, step_loss=0.00488]Steps:   2%|▏         | 17436/1000000 [11:19:01<2938:01:06, 10.76s/it, lr=1e-5, step_loss=0.00488][RANK-0]: Step: [17436], local_loss=0.02603406459093094, train_loss=0.05391189083456993, time_cost=4.388152599334717
Steps:   2%|▏         | 17436/1000000 [11:19:01<2938:01:06, 10.76s/it, lr=1e-5, step_loss=0.026]  Steps:   2%|▏         | 17437/1000000 [11:19:06<2454:26:23,  8.99s/it, lr=1e-5, step_loss=0.026][RANK-0]: Step: [17437], local_loss=0.020941810682415962, train_loss=0.026649579405784607, time_cost=1.776212453842163
Steps:   2%|▏         | 17437/1000000 [11:19:06<2454:26:23,  8.99s/it, lr=1e-5, step_loss=0.0209]Steps:   2%|▏         | 17438/1000000 [11:19:10<2069:25:40,  7.58s/it, lr=1e-5, step_loss=0.0209][RANK-0]: Step: [17438], local_loss=0.016287242993712425, train_loss=0.02798212692141533, time_cost=1.269975185394287
Steps:   2%|▏         | 17438/1000000 [11:19:10<2069:25:40,  7.58s/it, lr=1e-5, step_loss=0.0163]Steps:   2%|▏         | 17439/1000000 [11:19:18<2116:36:28,  7.76s/it, lr=1e-5, step_loss=0.0163][RANK-0]: Step: [17439], local_loss=0.007106478326022625, train_loss=0.03560246154665947, time_cost=4.472571611404419
Steps:   2%|▏         | 17439/1000000 [11:19:18<2116:36:28,  7.76s/it, lr=1e-5, step_loss=0.00711]Steps:   2%|▏         | 17440/1000000 [11:19:23<1901:29:57,  6.97s/it, lr=1e-5, step_loss=0.00711][RANK-0]: Step: [17440], local_loss=0.012538658455014229, train_loss=0.07680527865886688, time_cost=2.1462559700012207
Steps:   2%|▏         | 17440/1000000 [11:19:23<1901:29:57,  6.97s/it, lr=1e-5, step_loss=0.0125] Steps:   2%|▏         | 17441/1000000 [11:19:33<2083:58:44,  7.64s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [17441], local_loss=0.022802110761404037, train_loss=0.03696670010685921, time_cost=2.9794278144836426
Steps:   2%|▏         | 17441/1000000 [11:19:33<2083:58:44,  7.64s/it, lr=1e-5, step_loss=0.0228]Steps:   2%|▏         | 17442/1000000 [11:19:44<2366:30:32,  8.67s/it, lr=1e-5, step_loss=0.0228][RANK-0]: Step: [17442], local_loss=0.005943816155195236, train_loss=0.02757040411233902, time_cost=1.5756947994232178
Steps:   2%|▏         | 17442/1000000 [11:19:44<2366:30:32,  8.67s/it, lr=1e-5, step_loss=0.00594]Steps:   2%|▏         | 17443/1000000 [11:19:54<2512:30:11,  9.21s/it, lr=1e-5, step_loss=0.00594][RANK-0]: Step: [17443], local_loss=0.008925425820052624, train_loss=0.047332875430583954, time_cost=2.1664955615997314
Steps:   2%|▏         | 17443/1000000 [11:19:54<2512:30:11,  9.21s/it, lr=1e-5, step_loss=0.00893]Steps:   2%|▏         | 17444/1000000 [11:20:06<2696:57:51,  9.88s/it, lr=1e-5, step_loss=0.00893][RANK-0]: Step: [17444], local_loss=0.012762430123984814, train_loss=0.017745288088917732, time_cost=1.221954107284546
Steps:   2%|▏         | 17444/1000000 [11:20:06<2696:57:51,  9.88s/it, lr=1e-5, step_loss=0.0128] Steps:   2%|▏         | 17445/1000000 [11:20:11<2298:23:53,  8.42s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [17445], local_loss=0.005050265230238438, train_loss=0.009156038984656334, time_cost=3.0304036140441895
Steps:   2%|▏         | 17445/1000000 [11:20:11<2298:23:53,  8.42s/it, lr=1e-5, step_loss=0.00505]Steps:   2%|▏         | 17446/1000000 [11:20:19<2263:38:37,  8.29s/it, lr=1e-5, step_loss=0.00505][RANK-0]: Step: [17446], local_loss=0.08078958094120026, train_loss=0.07077618688344955, time_cost=1.218203067779541
Steps:   2%|▏         | 17446/1000000 [11:20:19<2263:38:37,  8.29s/it, lr=1e-5, step_loss=0.0808] Steps:   2%|▏         | 17447/1000000 [11:20:24<2001:46:51,  7.33s/it, lr=1e-5, step_loss=0.0808][RANK-0]: Step: [17447], local_loss=0.022491609677672386, train_loss=0.08525457978248596, time_cost=2.225818395614624
Steps:   2%|▏         | 17447/1000000 [11:20:24<2001:46:51,  7.33s/it, lr=1e-5, step_loss=0.0225]Steps:   2%|▏         | 17448/1000000 [11:20:29<1820:07:58,  6.67s/it, lr=1e-5, step_loss=0.0225][RANK-0]: Step: [17448], local_loss=0.0505121685564518, train_loss=0.01576949842274189, time_cost=3.862586498260498
Steps:   2%|▏         | 17448/1000000 [11:20:29<1820:07:58,  6.67s/it, lr=1e-5, step_loss=0.0505]Steps:   2%|▏         | 17449/1000000 [11:20:35<1772:22:16,  6.49s/it, lr=1e-5, step_loss=0.0505][RANK-0]: Step: [17449], local_loss=0.017255162820219994, train_loss=0.05304615572094917, time_cost=1.2154710292816162
Steps:   2%|▏         | 17449/1000000 [11:20:35<1772:22:16,  6.49s/it, lr=1e-5, step_loss=0.0173]Steps:   2%|▏         | 17450/1000000 [11:20:40<1662:14:41,  6.09s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [17450], local_loss=1.0099210739135742, train_loss=0.16145837306976318, time_cost=2.204873561859131
Steps:   2%|▏         | 17450/1000000 [11:20:40<1662:14:41,  6.09s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 17451/1000000 [11:20:45<1613:40:48,  5.91s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [17451], local_loss=0.05036688596010208, train_loss=0.08384281396865845, time_cost=1.3041481971740723
Steps:   2%|▏         | 17451/1000000 [11:20:45<1613:40:48,  5.91s/it, lr=1e-5, step_loss=0.0504]Steps:   2%|▏         | 17452/1000000 [11:20:55<1930:41:20,  7.07s/it, lr=1e-5, step_loss=0.0504][RANK-0]: Step: [17452], local_loss=0.008814606815576553, train_loss=0.03236502408981323, time_cost=2.084564447402954
Steps:   2%|▏         | 17452/1000000 [11:20:55<1930:41:20,  7.07s/it, lr=1e-5, step_loss=0.00881]Steps:   2%|▏         | 17453/1000000 [11:21:11<2603:53:16,  9.54s/it, lr=1e-5, step_loss=0.00881][RANK-0]: Step: [17453], local_loss=0.017572658136487007, train_loss=0.045021429657936096, time_cost=7.34009051322937
Steps:   2%|▏         | 17453/1000000 [11:21:11<2603:53:16,  9.54s/it, lr=1e-5, step_loss=0.0176] Steps:   2%|▏         | 17454/1000000 [11:21:20<2567:23:17,  9.41s/it, lr=1e-5, step_loss=0.0176][RANK-0]: Step: [17454], local_loss=0.03089078515768051, train_loss=0.08829142153263092, time_cost=3.288623094558716
Steps:   2%|▏         | 17454/1000000 [11:21:20<2567:23:17,  9.41s/it, lr=1e-5, step_loss=0.0309]Steps:   2%|▏         | 17455/1000000 [11:21:33<2914:29:31, 10.68s/it, lr=1e-5, step_loss=0.0309][RANK-0]: Step: [17455], local_loss=0.009422718547284603, train_loss=0.24962814152240753, time_cost=4.667653799057007
Steps:   2%|▏         | 17455/1000000 [11:21:33<2914:29:31, 10.68s/it, lr=1e-5, step_loss=0.00942]Steps:   2%|▏         | 17456/1000000 [11:21:46<3066:05:08, 11.23s/it, lr=1e-5, step_loss=0.00942][RANK-0]: Step: [17456], local_loss=0.06170131638646126, train_loss=0.0833674743771553, time_cost=4.847576141357422
Steps:   2%|▏         | 17456/1000000 [11:21:46<3066:05:08, 11.23s/it, lr=1e-5, step_loss=0.0617] Steps:   2%|▏         | 17457/1000000 [11:21:51<2563:15:14,  9.39s/it, lr=1e-5, step_loss=0.0617][RANK-0]: Step: [17457], local_loss=0.014097023755311966, train_loss=0.142485573887825, time_cost=1.249730110168457
Steps:   2%|▏         | 17457/1000000 [11:21:51<2563:15:14,  9.39s/it, lr=1e-5, step_loss=0.0141]Steps:   2%|▏         | 17458/1000000 [11:21:55<2113:08:24,  7.74s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [17458], local_loss=0.026526551693677902, train_loss=0.07943439483642578, time_cost=1.6474318504333496
Steps:   2%|▏         | 17458/1000000 [11:21:55<2113:08:24,  7.74s/it, lr=1e-5, step_loss=0.0265]Steps:   2%|▏         | 17459/1000000 [11:22:08<2533:32:33,  9.28s/it, lr=1e-5, step_loss=0.0265][RANK-0]: Step: [17459], local_loss=0.04837211221456528, train_loss=0.04238125681877136, time_cost=4.135493278503418
Steps:   2%|▏         | 17459/1000000 [11:22:08<2533:32:33,  9.28s/it, lr=1e-5, step_loss=0.0484]Steps:   2%|▏         | 17460/1000000 [11:22:22<2949:38:54, 10.81s/it, lr=1e-5, step_loss=0.0484][RANK-0]: Step: [17460], local_loss=0.23786146938800812, train_loss=0.04341376945376396, time_cost=5.3167030811309814
Steps:   2%|▏         | 17460/1000000 [11:22:22<2949:38:54, 10.81s/it, lr=1e-5, step_loss=0.238] Steps:   2%|▏         | 17461/1000000 [11:22:28<2542:22:45,  9.32s/it, lr=1e-5, step_loss=0.238][RANK-0]: Step: [17461], local_loss=0.013559915125370026, train_loss=0.05551139637827873, time_cost=5.205711126327515
Steps:   2%|▏         | 17461/1000000 [11:22:28<2542:22:45,  9.32s/it, lr=1e-5, step_loss=0.0136]Steps:   2%|▏         | 17462/1000000 [11:22:39<2670:42:08,  9.79s/it, lr=1e-5, step_loss=0.0136][RANK-0]: Step: [17462], local_loss=0.027441080659627914, train_loss=0.04559285566210747, time_cost=1.255685567855835
Steps:   2%|▏         | 17462/1000000 [11:22:39<2670:42:08,  9.79s/it, lr=1e-5, step_loss=0.0274]Steps:   2%|▏         | 17463/1000000 [11:22:44<2292:13:36,  8.40s/it, lr=1e-5, step_loss=0.0274][RANK-0]: Step: [17463], local_loss=0.008052104152739048, train_loss=0.02853996492922306, time_cost=1.4825701713562012
Steps:   2%|▏         | 17463/1000000 [11:22:44<2292:13:36,  8.40s/it, lr=1e-5, step_loss=0.00805]Steps:   2%|▏         | 17464/1000000 [11:22:49<2028:50:24,  7.43s/it, lr=1e-5, step_loss=0.00805][RANK-0]: Step: [17464], local_loss=0.006490675266832113, train_loss=0.02435651794075966, time_cost=1.20713210105896
Steps:   2%|▏         | 17464/1000000 [11:22:49<2028:50:24,  7.43s/it, lr=1e-5, step_loss=0.00649]Steps:   2%|▏         | 17465/1000000 [11:22:59<2207:38:47,  8.09s/it, lr=1e-5, step_loss=0.00649][RANK-0]: Step: [17465], local_loss=0.3233426511287689, train_loss=0.21936598420143127, time_cost=3.605726718902588
Steps:   2%|▏         | 17465/1000000 [11:22:59<2207:38:47,  8.09s/it, lr=1e-5, step_loss=0.323]  Steps:   2%|▏         | 17466/1000000 [11:23:04<1958:57:10,  7.18s/it, lr=1e-5, step_loss=0.323][RANK-0]: Step: [17466], local_loss=0.06598643213510513, train_loss=0.08278092741966248, time_cost=2.153090715408325
Steps:   2%|▏         | 17466/1000000 [11:23:04<1958:57:10,  7.18s/it, lr=1e-5, step_loss=0.066]Steps:   2%|▏         | 17467/1000000 [11:23:12<2030:06:11,  7.44s/it, lr=1e-5, step_loss=0.066][RANK-0]: Step: [17467], local_loss=0.14692465960979462, train_loss=0.03145887702703476, time_cost=1.2263267040252686
Steps:   2%|▏         | 17467/1000000 [11:23:12<2030:06:11,  7.44s/it, lr=1e-5, step_loss=0.147]Steps:   2%|▏         | 17468/1000000 [11:23:17<1855:05:56,  6.80s/it, lr=1e-5, step_loss=0.147][RANK-0]: Step: [17468], local_loss=0.011428365483880043, train_loss=0.21354235708713531, time_cost=1.434445858001709
Steps:   2%|▏         | 17468/1000000 [11:23:17<1855:05:56,  6.80s/it, lr=1e-5, step_loss=0.0114]Steps:   2%|▏         | 17469/1000000 [11:23:24<1886:49:05,  6.91s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [17469], local_loss=0.00394666101783514, train_loss=0.03122653439640999, time_cost=1.8673582077026367
Steps:   2%|▏         | 17469/1000000 [11:23:24<1886:49:05,  6.91s/it, lr=1e-5, step_loss=0.00395]Steps:   2%|▏         | 17470/1000000 [11:23:32<1937:00:53,  7.10s/it, lr=1e-5, step_loss=0.00395][RANK-0]: Step: [17470], local_loss=0.043489936739206314, train_loss=0.020516006276011467, time_cost=1.4090070724487305
Steps:   2%|▏         | 17470/1000000 [11:23:32<1937:00:53,  7.10s/it, lr=1e-5, step_loss=0.0435] Steps:   2%|▏         | 17471/1000000 [11:23:48<2643:07:36,  9.68s/it, lr=1e-5, step_loss=0.0435][RANK-0]: Step: [17471], local_loss=0.041671305894851685, train_loss=0.06592804193496704, time_cost=7.849552154541016
Steps:   2%|▏         | 17471/1000000 [11:23:48<2643:07:36,  9.68s/it, lr=1e-5, step_loss=0.0417]Steps:   2%|▏         | 17472/1000000 [11:23:52<2253:25:08,  8.26s/it, lr=1e-5, step_loss=0.0417][RANK-0]: Step: [17472], local_loss=0.005317494738847017, train_loss=0.14810730516910553, time_cost=1.2082393169403076
Steps:   2%|▏         | 17472/1000000 [11:23:52<2253:25:08,  8.26s/it, lr=1e-5, step_loss=0.00532]Steps:   2%|▏         | 17473/1000000 [11:23:58<2034:15:14,  7.45s/it, lr=1e-5, step_loss=0.00532][RANK-0]: Step: [17473], local_loss=0.06766991317272186, train_loss=0.02837039902806282, time_cost=4.636416673660278
Steps:   2%|▏         | 17473/1000000 [11:23:58<2034:15:14,  7.45s/it, lr=1e-5, step_loss=0.0677] Steps:   2%|▏         | 17474/1000000 [11:24:06<2047:04:15,  7.50s/it, lr=1e-5, step_loss=0.0677][RANK-0]: Step: [17474], local_loss=0.08817742019891739, train_loss=0.0381106436252594, time_cost=1.706578254699707
Steps:   2%|▏         | 17474/1000000 [11:24:06<2047:04:15,  7.50s/it, lr=1e-5, step_loss=0.0882]Steps:   2%|▏         | 17475/1000000 [11:24:11<1879:59:02,  6.89s/it, lr=1e-5, step_loss=0.0882][RANK-0]: Step: [17475], local_loss=0.016927368938922882, train_loss=0.11074476689100266, time_cost=1.2042250633239746
Steps:   2%|▏         | 17475/1000000 [11:24:11<1879:59:02,  6.89s/it, lr=1e-5, step_loss=0.0169]Steps:   2%|▏         | 17476/1000000 [11:24:19<1942:55:48,  7.12s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [17476], local_loss=0.023418759927153587, train_loss=0.07218785583972931, time_cost=3.217707872390747
Steps:   2%|▏         | 17476/1000000 [11:24:19<1942:55:48,  7.12s/it, lr=1e-5, step_loss=0.0234]Steps:   2%|▏         | 17477/1000000 [11:24:29<2209:21:00,  8.10s/it, lr=1e-5, step_loss=0.0234][RANK-0]: Step: [17477], local_loss=0.01480415090918541, train_loss=0.053627561777830124, time_cost=2.2492711544036865
Steps:   2%|▏         | 17477/1000000 [11:24:29<2209:21:00,  8.10s/it, lr=1e-5, step_loss=0.0148]Steps:   2%|▏         | 17478/1000000 [11:24:40<2420:19:10,  8.87s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [17478], local_loss=0.008572988212108612, train_loss=0.031378015875816345, time_cost=2.0399363040924072
Steps:   2%|▏         | 17478/1000000 [11:24:40<2420:19:10,  8.87s/it, lr=1e-5, step_loss=0.00857]Steps:   2%|▏         | 17479/1000000 [11:24:51<2578:05:03,  9.45s/it, lr=1e-5, step_loss=0.00857][RANK-0]: Step: [17479], local_loss=0.01752944104373455, train_loss=0.06868861615657806, time_cost=3.0379984378814697
Steps:   2%|▏         | 17479/1000000 [11:24:51<2578:05:03,  9.45s/it, lr=1e-5, step_loss=0.0175] Steps:   2%|▏         | 17480/1000000 [11:25:04<2870:51:47, 10.52s/it, lr=1e-5, step_loss=0.0175][RANK-0]: Step: [17480], local_loss=0.012079112231731415, train_loss=0.0240156352519989, time_cost=4.316157579421997
Steps:   2%|▏         | 17480/1000000 [11:25:04<2870:51:47, 10.52s/it, lr=1e-5, step_loss=0.0121]Steps:   2%|▏         | 17481/1000000 [11:25:11<2607:05:01,  9.55s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [17481], local_loss=0.0056339348666369915, train_loss=0.017709018662571907, time_cost=2.8670291900634766
Steps:   2%|▏         | 17481/1000000 [11:25:11<2607:05:01,  9.55s/it, lr=1e-5, step_loss=0.00563]Steps:   2%|▏         | 17482/1000000 [11:25:22<2759:52:36, 10.11s/it, lr=1e-5, step_loss=0.00563][RANK-0]: Step: [17482], local_loss=0.00973596516996622, train_loss=8.776350975036621, time_cost=5.183916330337524
Steps:   2%|▏         | 17482/1000000 [11:25:22<2759:52:36, 10.11s/it, lr=1e-5, step_loss=0.00974]Steps:   2%|▏         | 17483/1000000 [11:25:27<2297:27:07,  8.42s/it, lr=1e-5, step_loss=0.00974][RANK-0]: Step: [17483], local_loss=0.005863632541149855, train_loss=0.04632483422756195, time_cost=3.363593816757202
Steps:   2%|▏         | 17483/1000000 [11:25:27<2297:27:07,  8.42s/it, lr=1e-5, step_loss=0.00586]Steps:   2%|▏         | 17484/1000000 [11:25:33<2096:12:29,  7.68s/it, lr=1e-5, step_loss=0.00586][RANK-0]: Step: [17484], local_loss=0.041327103972435, train_loss=2.9341204166412354, time_cost=2.075106620788574
Steps:   2%|▏         | 17484/1000000 [11:25:33<2096:12:29,  7.68s/it, lr=1e-5, step_loss=0.0413] Steps:   2%|▏         | 17485/1000000 [11:25:49<2773:34:17, 10.16s/it, lr=1e-5, step_loss=0.0413][RANK-0]: Step: [17485], local_loss=0.04444984719157219, train_loss=0.02455749362707138, time_cost=6.646977424621582
Steps:   2%|▏         | 17485/1000000 [11:25:49<2773:34:17, 10.16s/it, lr=1e-5, step_loss=0.0444]Steps:   2%|▏         | 17486/1000000 [11:26:01<2954:39:09, 10.83s/it, lr=1e-5, step_loss=0.0444][RANK-0]: Step: [17486], local_loss=0.0221038069576025, train_loss=0.03481246531009674, time_cost=4.057079076766968
Steps:   2%|▏         | 17486/1000000 [11:26:01<2954:39:09, 10.83s/it, lr=1e-5, step_loss=0.0221]Steps:   2%|▏         | 17487/1000000 [11:26:09<2674:58:09,  9.80s/it, lr=1e-5, step_loss=0.0221][RANK-0]: Step: [17487], local_loss=0.02652629278600216, train_loss=0.02699008584022522, time_cost=1.9505596160888672
Steps:   2%|▏         | 17487/1000000 [11:26:09<2674:58:09,  9.80s/it, lr=1e-5, step_loss=0.0265]Steps:   2%|▏         | 17488/1000000 [11:26:14<2315:25:51,  8.48s/it, lr=1e-5, step_loss=0.0265][RANK-0]: Step: [17488], local_loss=0.05702055245637894, train_loss=0.04973142221570015, time_cost=1.5252223014831543
Steps:   2%|▏         | 17488/1000000 [11:26:14<2315:25:51,  8.48s/it, lr=1e-5, step_loss=0.057] Steps:   2%|▏         | 17489/1000000 [11:26:33<3157:17:24, 11.57s/it, lr=1e-5, step_loss=0.057][RANK-0]: Step: [17489], local_loss=0.06948131322860718, train_loss=0.05788767337799072, time_cost=1.357011318206787
Steps:   2%|▏         | 17489/1000000 [11:26:33<3157:17:24, 11.57s/it, lr=1e-5, step_loss=0.0695]Steps:   2%|▏         | 17490/1000000 [11:26:38<2681:33:03,  9.83s/it, lr=1e-5, step_loss=0.0695][RANK-0]: Step: [17490], local_loss=0.03752962872385979, train_loss=0.04435569792985916, time_cost=1.925459623336792
Steps:   2%|▏         | 17490/1000000 [11:26:38<2681:33:03,  9.83s/it, lr=1e-5, step_loss=0.0375]Steps:   2%|▏         | 17491/1000000 [11:26:46<2457:58:18,  9.01s/it, lr=1e-5, step_loss=0.0375][RANK-0]: Step: [17491], local_loss=0.0410471111536026, train_loss=0.06834541261196136, time_cost=1.2973644733428955
Steps:   2%|▏         | 17491/1000000 [11:26:46<2457:58:18,  9.01s/it, lr=1e-5, step_loss=0.041] Steps:   2%|▏         | 17492/1000000 [11:26:54<2385:20:56,  8.74s/it, lr=1e-5, step_loss=0.041][RANK-0]: Step: [17492], local_loss=0.15417353808879852, train_loss=0.04772882163524628, time_cost=4.268335342407227
Steps:   2%|▏         | 17492/1000000 [11:26:54<2385:20:56,  8.74s/it, lr=1e-5, step_loss=0.154]Steps:   2%|▏         | 17493/1000000 [11:27:05<2613:33:11,  9.58s/it, lr=1e-5, step_loss=0.154][RANK-0]: Step: [17493], local_loss=0.05945098400115967, train_loss=0.19003425538539886, time_cost=3.000380516052246
Steps:   2%|▏         | 17493/1000000 [11:27:05<2613:33:11,  9.58s/it, lr=1e-5, step_loss=0.0595]Steps:   2%|▏         | 17494/1000000 [11:27:18<2893:57:52, 10.60s/it, lr=1e-5, step_loss=0.0595][RANK-0]: Step: [17494], local_loss=0.0069993482902646065, train_loss=0.028851352632045746, time_cost=4.31651496887207
Steps:   2%|▏         | 17494/1000000 [11:27:18<2893:57:52, 10.60s/it, lr=1e-5, step_loss=0.007] Steps:   2%|▏         | 17495/1000000 [11:27:23<2436:00:43,  8.93s/it, lr=1e-5, step_loss=0.007][RANK-0]: Step: [17495], local_loss=0.0052647665143013, train_loss=0.017571188509464264, time_cost=1.2058532238006592
Steps:   2%|▏         | 17495/1000000 [11:27:23<2436:00:43,  8.93s/it, lr=1e-5, step_loss=0.00526]Steps:   2%|▏         | 17496/1000000 [11:27:32<2454:02:59,  8.99s/it, lr=1e-5, step_loss=0.00526][RANK-0]: Step: [17496], local_loss=0.011449648067355156, train_loss=0.0207030288875103, time_cost=3.0795817375183105
Steps:   2%|▏         | 17496/1000000 [11:27:32<2454:02:59,  8.99s/it, lr=1e-5, step_loss=0.0114] Steps:   2%|▏         | 17497/1000000 [11:27:44<2690:21:50,  9.86s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [17497], local_loss=0.011085759848356247, train_loss=2.2414088249206543, time_cost=4.864852666854858
Steps:   2%|▏         | 17497/1000000 [11:27:44<2690:21:50,  9.86s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 17498/1000000 [11:27:51<2426:57:47,  8.89s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [17498], local_loss=0.007406052201986313, train_loss=0.028786752372980118, time_cost=1.2442278861999512
Steps:   2%|▏         | 17498/1000000 [11:27:51<2426:57:47,  8.89s/it, lr=1e-5, step_loss=0.00741]Steps:   2%|▏         | 17499/1000000 [11:27:57<2181:12:09,  7.99s/it, lr=1e-5, step_loss=0.00741][RANK-0]: Step: [17499], local_loss=0.08050672709941864, train_loss=0.034285109490156174, time_cost=1.7810626029968262
Steps:   2%|▏         | 17499/1000000 [11:27:57<2181:12:09,  7.99s/it, lr=1e-5, step_loss=0.0805] Steps:   2%|▏         | 17500/1000000 [11:28:06<2265:22:30,  8.30s/it, lr=1e-5, step_loss=0.0805][RANK-0]: Step: [17500], local_loss=0.041951101273298264, train_loss=0.037817105650901794, time_cost=3.7276153564453125
Steps:   2%|▏         | 17500/1000000 [11:28:06<2265:22:30,  8.30s/it, lr=1e-5, step_loss=0.042] Steps:   2%|▏         | 17501/1000000 [11:28:14<2253:24:40,  8.26s/it, lr=1e-5, step_loss=0.042][RANK-0]: Step: [17501], local_loss=0.005402058362960815, train_loss=0.029823632910847664, time_cost=4.061993598937988
Steps:   2%|▏         | 17501/1000000 [11:28:14<2253:24:40,  8.26s/it, lr=1e-5, step_loss=0.0054]Steps:   2%|▏         | 17502/1000000 [11:28:21<2143:36:41,  7.85s/it, lr=1e-5, step_loss=0.0054][RANK-0]: Step: [17502], local_loss=0.055594440549612045, train_loss=0.08625099062919617, time_cost=2.488365411758423
Steps:   2%|▏         | 17502/1000000 [11:28:21<2143:36:41,  7.85s/it, lr=1e-5, step_loss=0.0556]Steps:   2%|▏         | 17503/1000000 [11:28:28<2091:31:11,  7.66s/it, lr=1e-5, step_loss=0.0556][RANK-0]: Step: [17503], local_loss=0.03150367736816406, train_loss=0.14042815566062927, time_cost=3.0179848670959473
Steps:   2%|▏         | 17503/1000000 [11:28:28<2091:31:11,  7.66s/it, lr=1e-5, step_loss=0.0315]Steps:   2%|▏         | 17504/1000000 [11:28:43<2658:06:21,  9.74s/it, lr=1e-5, step_loss=0.0315][RANK-0]: Step: [17504], local_loss=0.004900800064206123, train_loss=0.051832415163517, time_cost=7.298121690750122
Steps:   2%|▏         | 17504/1000000 [11:28:43<2658:06:21,  9.74s/it, lr=1e-5, step_loss=0.0049]Steps:   2%|▏         | 17505/1000000 [11:28:48<2259:45:30,  8.28s/it, lr=1e-5, step_loss=0.0049][RANK-0]: Step: [17505], local_loss=0.4007846415042877, train_loss=0.0657634437084198, time_cost=2.03808856010437
Steps:   2%|▏         | 17505/1000000 [11:28:48<2259:45:30,  8.28s/it, lr=1e-5, step_loss=0.401] Steps:   2%|▏         | 17506/1000000 [11:28:59<2490:48:18,  9.13s/it, lr=1e-5, step_loss=0.401][RANK-0]: Step: [17506], local_loss=0.03586997091770172, train_loss=0.10041236132383347, time_cost=1.2138772010803223
Steps:   2%|▏         | 17506/1000000 [11:28:59<2490:48:18,  9.13s/it, lr=1e-5, step_loss=0.0359]Steps:   2%|▏         | 17507/1000000 [11:29:11<2716:23:19,  9.95s/it, lr=1e-5, step_loss=0.0359][RANK-0]: Step: [17507], local_loss=0.052406419068574905, train_loss=0.027299340814352036, time_cost=4.217534065246582
Steps:   2%|▏         | 17507/1000000 [11:29:11<2716:23:19,  9.95s/it, lr=1e-5, step_loss=0.0524]Steps:   2%|▏         | 17508/1000000 [11:29:18<2533:06:47,  9.28s/it, lr=1e-5, step_loss=0.0524][RANK-0]: Step: [17508], local_loss=0.006363788153976202, train_loss=0.078756183385849, time_cost=2.3957433700561523
Steps:   2%|▏         | 17508/1000000 [11:29:18<2533:06:47,  9.28s/it, lr=1e-5, step_loss=0.00636]Steps:   2%|▏         | 17509/1000000 [11:29:29<2675:37:34,  9.80s/it, lr=1e-5, step_loss=0.00636][RANK-0]: Step: [17509], local_loss=0.00604725256562233, train_loss=0.13256990909576416, time_cost=6.348886251449585
Steps:   2%|▏         | 17509/1000000 [11:29:29<2675:37:34,  9.80s/it, lr=1e-5, step_loss=0.00605]Steps:   2%|▏         | 17510/1000000 [11:29:41<2801:25:12, 10.26s/it, lr=1e-5, step_loss=0.00605][RANK-0]: Step: [17510], local_loss=0.021314892917871475, train_loss=0.03850742056965828, time_cost=2.9531848430633545
Steps:   2%|▏         | 17510/1000000 [11:29:41<2801:25:12, 10.26s/it, lr=1e-5, step_loss=0.0213] Steps:   2%|▏         | 17511/1000000 [11:29:54<3086:58:07, 11.31s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [17511], local_loss=0.011751287616789341, train_loss=0.015811359509825706, time_cost=3.9109156131744385
Steps:   2%|▏         | 17511/1000000 [11:29:54<3086:58:07, 11.31s/it, lr=1e-5, step_loss=0.0118]Steps:   2%|▏         | 17512/1000000 [11:30:02<2759:43:26, 10.11s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [17512], local_loss=0.020057832822203636, train_loss=0.019137248396873474, time_cost=2.040635824203491
Steps:   2%|▏         | 17512/1000000 [11:30:02<2759:43:26, 10.11s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 17513/1000000 [11:30:12<2769:00:53, 10.15s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [17513], local_loss=0.041855450719594955, train_loss=0.02937459573149681, time_cost=4.520754814147949
Steps:   2%|▏         | 17513/1000000 [11:30:12<2769:00:53, 10.15s/it, lr=1e-5, step_loss=0.0419]Steps:   2%|▏         | 17514/1000000 [11:30:21<2694:47:18,  9.87s/it, lr=1e-5, step_loss=0.0419][RANK-0]: Step: [17514], local_loss=0.010296555235981941, train_loss=0.030492467805743217, time_cost=1.9096169471740723
Steps:   2%|▏         | 17514/1000000 [11:30:21<2694:47:18,  9.87s/it, lr=1e-5, step_loss=0.0103]Steps:   2%|▏         | 17515/1000000 [11:30:31<2703:27:49,  9.91s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [17515], local_loss=0.006391722708940506, train_loss=0.021861907094717026, time_cost=4.587516784667969
Steps:   2%|▏         | 17515/1000000 [11:30:31<2703:27:49,  9.91s/it, lr=1e-5, step_loss=0.00639]Steps:   2%|▏         | 17516/1000000 [11:30:38<2492:41:39,  9.13s/it, lr=1e-5, step_loss=0.00639][RANK-0]: Step: [17516], local_loss=0.022152205929160118, train_loss=0.07061098515987396, time_cost=2.772583246231079
Steps:   2%|▏         | 17516/1000000 [11:30:38<2492:41:39,  9.13s/it, lr=1e-5, step_loss=0.0222] Steps:   2%|▏         | 17517/1000000 [11:30:43<2093:29:47,  7.67s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [17517], local_loss=0.009662916883826256, train_loss=0.031614355742931366, time_cost=1.5380241870880127
Steps:   2%|▏         | 17517/1000000 [11:30:43<2093:29:47,  7.67s/it, lr=1e-5, step_loss=0.00966]Steps:   2%|▏         | 17518/1000000 [11:30:54<2380:46:49,  8.72s/it, lr=1e-5, step_loss=0.00966][RANK-0]: Step: [17518], local_loss=0.03919211030006409, train_loss=0.03860488533973694, time_cost=2.478715419769287
Steps:   2%|▏         | 17518/1000000 [11:30:54<2380:46:49,  8.72s/it, lr=1e-5, step_loss=0.0392] Steps:   2%|▏         | 17519/1000000 [11:31:07<2764:03:03, 10.13s/it, lr=1e-5, step_loss=0.0392][RANK-0]: Step: [17519], local_loss=0.1270206719636917, train_loss=0.029666338115930557, time_cost=1.2038047313690186
Steps:   2%|▏         | 17519/1000000 [11:31:07<2764:03:03, 10.13s/it, lr=1e-5, step_loss=0.127] Steps:   2%|▏         | 17520/1000000 [11:31:12<2332:17:53,  8.55s/it, lr=1e-5, step_loss=0.127][RANK-0]: Step: [17520], local_loss=0.006515562534332275, train_loss=0.015451144427061081, time_cost=1.2242496013641357
Steps:   2%|▏         | 17520/1000000 [11:31:12<2332:17:53,  8.55s/it, lr=1e-5, step_loss=0.00652]Steps:   2%|▏         | 17521/1000000 [11:31:30<3101:31:58, 11.36s/it, lr=1e-5, step_loss=0.00652][RANK-0]: Step: [17521], local_loss=0.1867412030696869, train_loss=0.07495865225791931, time_cost=3.38962984085083
Steps:   2%|▏         | 17521/1000000 [11:31:30<3101:31:58, 11.36s/it, lr=1e-5, step_loss=0.187]  Steps:   2%|▏         | 17522/1000000 [11:31:41<3042:13:43, 11.15s/it, lr=1e-5, step_loss=0.187][RANK-0]: Step: [17522], local_loss=0.033477768301963806, train_loss=0.029378337785601616, time_cost=3.7208547592163086
Steps:   2%|▏         | 17522/1000000 [11:31:41<3042:13:43, 11.15s/it, lr=1e-5, step_loss=0.0335]Steps:   2%|▏         | 17523/1000000 [11:31:52<3033:31:50, 11.12s/it, lr=1e-5, step_loss=0.0335][RANK-0]: Step: [17523], local_loss=0.030467087402939796, train_loss=0.07642415165901184, time_cost=2.4974234104156494
Steps:   2%|▏         | 17523/1000000 [11:31:52<3033:31:50, 11.12s/it, lr=1e-5, step_loss=0.0305]Steps:   2%|▏         | 17524/1000000 [11:32:02<2964:22:23, 10.86s/it, lr=1e-5, step_loss=0.0305][RANK-0]: Step: [17524], local_loss=0.007648632861673832, train_loss=0.02635718509554863, time_cost=5.133236646652222
Steps:   2%|▏         | 17524/1000000 [11:32:02<2964:22:23, 10.86s/it, lr=1e-5, step_loss=0.00765]Steps:   2%|▏         | 17525/1000000 [11:32:12<2913:31:35, 10.68s/it, lr=1e-5, step_loss=0.00765][RANK-0]: Step: [17525], local_loss=0.0532364547252655, train_loss=0.08476022630929947, time_cost=2.9747090339660645
Steps:   2%|▏         | 17525/1000000 [11:32:12<2913:31:35, 10.68s/it, lr=1e-5, step_loss=0.0532] Steps:   2%|▏         | 17526/1000000 [11:32:22<2815:47:42, 10.32s/it, lr=1e-5, step_loss=0.0532][RANK-0]: Step: [17526], local_loss=0.005133416969329119, train_loss=0.011321919970214367, time_cost=1.2203590869903564
Steps:   2%|▏         | 17526/1000000 [11:32:22<2815:47:42, 10.32s/it, lr=1e-5, step_loss=0.00513]Steps:   2%|▏         | 17527/1000000 [11:32:32<2787:30:02, 10.21s/it, lr=1e-5, step_loss=0.00513][RANK-0]: Step: [17527], local_loss=0.06265465915203094, train_loss=0.053063251078128815, time_cost=7.65816855430603
Steps:   2%|▏         | 17527/1000000 [11:32:32<2787:30:02, 10.21s/it, lr=1e-5, step_loss=0.0627] Steps:   2%|▏         | 17528/1000000 [11:32:36<2320:24:11,  8.50s/it, lr=1e-5, step_loss=0.0627][RANK-0]: Step: [17528], local_loss=0.018843239173293114, train_loss=0.04250133037567139, time_cost=1.6821527481079102
Steps:   2%|▏         | 17528/1000000 [11:32:36<2320:24:11,  8.50s/it, lr=1e-5, step_loss=0.0188]Steps:   2%|▏         | 17529/1000000 [11:32:49<2628:39:24,  9.63s/it, lr=1e-5, step_loss=0.0188][RANK-0]: Step: [17529], local_loss=0.059152234345674515, train_loss=0.041493721306324005, time_cost=1.2226262092590332
Steps:   2%|▏         | 17529/1000000 [11:32:49<2628:39:24,  9.63s/it, lr=1e-5, step_loss=0.0592]Steps:   2%|▏         | 17530/1000000 [11:32:58<2594:09:27,  9.51s/it, lr=1e-5, step_loss=0.0592][RANK-0]: Step: [17530], local_loss=0.049156554043293, train_loss=0.023725520819425583, time_cost=2.6070187091827393
Steps:   2%|▏         | 17530/1000000 [11:32:58<2594:09:27,  9.51s/it, lr=1e-5, step_loss=0.0492]Steps:   2%|▏         | 17531/1000000 [11:33:05<2390:20:22,  8.76s/it, lr=1e-5, step_loss=0.0492][RANK-0]: Step: [17531], local_loss=0.016671862453222275, train_loss=0.03850241005420685, time_cost=2.764570713043213
Steps:   2%|▏         | 17531/1000000 [11:33:05<2390:20:22,  8.76s/it, lr=1e-5, step_loss=0.0167]Steps:   2%|▏         | 17532/1000000 [11:33:16<2616:05:14,  9.59s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [17532], local_loss=0.06591441482305527, train_loss=0.03743652254343033, time_cost=4.007416725158691
Steps:   2%|▏         | 17532/1000000 [11:33:16<2616:05:14,  9.59s/it, lr=1e-5, step_loss=0.0659]Steps:   2%|▏         | 17533/1000000 [11:33:23<2413:47:40,  8.84s/it, lr=1e-5, step_loss=0.0659][RANK-0]: Step: [17533], local_loss=0.011082280427217484, train_loss=0.022387277334928513, time_cost=3.0627193450927734
Steps:   2%|▏         | 17533/1000000 [11:33:23<2413:47:40,  8.84s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 17534/1000000 [11:33:29<2112:00:42,  7.74s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [17534], local_loss=0.028046762570738792, train_loss=0.03836752474308014, time_cost=2.0628738403320312
Steps:   2%|▏         | 17534/1000000 [11:33:29<2112:00:42,  7.74s/it, lr=1e-5, step_loss=0.028] Steps:   2%|▏         | 17535/1000000 [11:33:41<2519:51:21,  9.23s/it, lr=1e-5, step_loss=0.028][RANK-0]: Step: [17535], local_loss=0.2538214921951294, train_loss=0.04807448759675026, time_cost=10.147994041442871
Steps:   2%|▏         | 17535/1000000 [11:33:41<2519:51:21,  9.23s/it, lr=1e-5, step_loss=0.254]Steps:   2%|▏         | 17536/1000000 [11:33:55<2889:30:41, 10.59s/it, lr=1e-5, step_loss=0.254][RANK-0]: Step: [17536], local_loss=0.01061610784381628, train_loss=0.020140303298830986, time_cost=4.408918380737305
Steps:   2%|▏         | 17536/1000000 [11:33:55<2889:30:41, 10.59s/it, lr=1e-5, step_loss=0.0106]Steps:   2%|▏         | 17537/1000000 [11:34:03<2654:51:51,  9.73s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [17537], local_loss=0.006300552748143673, train_loss=0.022151639685034752, time_cost=3.6807894706726074
Steps:   2%|▏         | 17537/1000000 [11:34:03<2654:51:51,  9.73s/it, lr=1e-5, step_loss=0.0063]Steps:   2%|▏         | 17538/1000000 [11:34:08<2292:30:48,  8.40s/it, lr=1e-5, step_loss=0.0063][RANK-0]: Step: [17538], local_loss=0.008232745341956615, train_loss=0.05126094073057175, time_cost=2.9768238067626953
Steps:   2%|▏         | 17538/1000000 [11:34:08<2292:30:48,  8.40s/it, lr=1e-5, step_loss=0.00823]Steps:   2%|▏         | 17539/1000000 [11:34:15<2168:16:09,  7.95s/it, lr=1e-5, step_loss=0.00823][RANK-0]: Step: [17539], local_loss=0.04957987368106842, train_loss=0.03592582419514656, time_cost=2.283876657485962
Steps:   2%|▏         | 17539/1000000 [11:34:15<2168:16:09,  7.95s/it, lr=1e-5, step_loss=0.0496] Steps:   2%|▏         | 17540/1000000 [11:34:26<2417:58:09,  8.86s/it, lr=1e-5, step_loss=0.0496][RANK-0]: Step: [17540], local_loss=0.010742136277258396, train_loss=8.011106491088867, time_cost=1.2555155754089355
Steps:   2%|▏         | 17540/1000000 [11:34:26<2417:58:09,  8.86s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 17541/1000000 [11:34:34<2366:35:21,  8.67s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [17541], local_loss=0.027105286717414856, train_loss=0.03332223370671272, time_cost=3.3607776165008545
Steps:   2%|▏         | 17541/1000000 [11:34:34<2366:35:21,  8.67s/it, lr=1e-5, step_loss=0.0271]Steps:   2%|▏         | 17542/1000000 [11:34:40<2133:39:04,  7.82s/it, lr=1e-5, step_loss=0.0271][RANK-0]: Step: [17542], local_loss=0.006628560833632946, train_loss=0.07640312612056732, time_cost=1.5031816959381104
Steps:   2%|▏         | 17542/1000000 [11:34:40<2133:39:04,  7.82s/it, lr=1e-5, step_loss=0.00663]Steps:   2%|▏         | 17543/1000000 [11:34:54<2657:17:56,  9.74s/it, lr=1e-5, step_loss=0.00663][RANK-0]: Step: [17543], local_loss=0.009458855725824833, train_loss=0.030308939516544342, time_cost=8.279845237731934
Steps:   2%|▏         | 17543/1000000 [11:34:54<2657:17:56,  9.74s/it, lr=1e-5, step_loss=0.00946]Steps:   2%|▏         | 17544/1000000 [11:34:59<2288:00:01,  8.38s/it, lr=1e-5, step_loss=0.00946][RANK-0]: Step: [17544], local_loss=0.02961391769349575, train_loss=0.030499085783958435, time_cost=2.6703011989593506
Steps:   2%|▏         | 17544/1000000 [11:34:59<2288:00:01,  8.38s/it, lr=1e-5, step_loss=0.0296] Steps:   2%|▏         | 17545/1000000 [11:35:11<2511:34:56,  9.20s/it, lr=1e-5, step_loss=0.0296][RANK-0]: Step: [17545], local_loss=0.08601635694503784, train_loss=0.057463139295578, time_cost=1.2495973110198975
Steps:   2%|▏         | 17545/1000000 [11:35:11<2511:34:56,  9.20s/it, lr=1e-5, step_loss=0.086] Steps:   2%|▏         | 17546/1000000 [11:35:16<2198:42:37,  8.06s/it, lr=1e-5, step_loss=0.086][RANK-0]: Step: [17546], local_loss=0.014137106016278267, train_loss=0.03758400306105614, time_cost=2.4795398712158203
Steps:   2%|▏         | 17546/1000000 [11:35:16<2198:42:37,  8.06s/it, lr=1e-5, step_loss=0.0141]Steps:   2%|▏         | 17547/1000000 [11:35:24<2166:39:33,  7.94s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [17547], local_loss=0.007973129861056805, train_loss=0.03264617547392845, time_cost=5.7307679653167725
Steps:   2%|▏         | 17547/1000000 [11:35:24<2166:39:33,  7.94s/it, lr=1e-5, step_loss=0.00797]Steps:   2%|▏         | 17548/1000000 [11:35:28<1857:20:35,  6.81s/it, lr=1e-5, step_loss=0.00797][RANK-0]: Step: [17548], local_loss=0.07650060951709747, train_loss=0.05929681286215782, time_cost=1.3060715198516846
Steps:   2%|▏         | 17548/1000000 [11:35:28<1857:20:35,  6.81s/it, lr=1e-5, step_loss=0.0765] Steps:   2%|▏         | 17549/1000000 [11:35:32<1687:37:31,  6.18s/it, lr=1e-5, step_loss=0.0765][RANK-0]: Step: [17549], local_loss=0.04391108453273773, train_loss=0.062000345438718796, time_cost=1.3225963115692139
Steps:   2%|▏         | 17549/1000000 [11:35:32<1687:37:31,  6.18s/it, lr=1e-5, step_loss=0.0439]Steps:   2%|▏         | 17550/1000000 [11:35:37<1584:24:47,  5.81s/it, lr=1e-5, step_loss=0.0439][RANK-0]: Step: [17550], local_loss=0.8586890697479248, train_loss=0.22456307709217072, time_cost=2.4743239879608154
Steps:   2%|▏         | 17550/1000000 [11:35:37<1584:24:47,  5.81s/it, lr=1e-5, step_loss=0.859] Steps:   2%|▏         | 17551/1000000 [11:35:43<1547:35:27,  5.67s/it, lr=1e-5, step_loss=0.859][RANK-0]: Step: [17551], local_loss=0.02930043265223503, train_loss=0.016897927969694138, time_cost=2.4881112575531006
Steps:   2%|▏         | 17551/1000000 [11:35:43<1547:35:27,  5.67s/it, lr=1e-5, step_loss=0.0293]Steps:   2%|▏         | 17552/1000000 [11:35:56<2144:19:37,  7.86s/it, lr=1e-5, step_loss=0.0293][RANK-0]: Step: [17552], local_loss=0.03471720591187477, train_loss=0.034390173852443695, time_cost=3.371145248413086
Steps:   2%|▏         | 17552/1000000 [11:35:56<2144:19:37,  7.86s/it, lr=1e-5, step_loss=0.0347]Steps:   2%|▏         | 17553/1000000 [11:36:04<2190:16:52,  8.03s/it, lr=1e-5, step_loss=0.0347][RANK-0]: Step: [17553], local_loss=0.0065948739647865295, train_loss=0.025108076632022858, time_cost=6.41310977935791
Steps:   2%|▏         | 17553/1000000 [11:36:04<2190:16:52,  8.03s/it, lr=1e-5, step_loss=0.00659]Steps:   2%|▏         | 17554/1000000 [11:36:08<1887:30:12,  6.92s/it, lr=1e-5, step_loss=0.00659][RANK-0]: Step: [17554], local_loss=0.01433076336979866, train_loss=0.07060720026493073, time_cost=1.4201035499572754
Steps:   2%|▏         | 17554/1000000 [11:36:08<1887:30:12,  6.92s/it, lr=1e-5, step_loss=0.0143] Steps:   2%|▏         | 17555/1000000 [11:36:24<2593:37:12,  9.50s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [17555], local_loss=0.010690329596400261, train_loss=0.02117467299103737, time_cost=1.3664047718048096
Steps:   2%|▏         | 17555/1000000 [11:36:24<2593:37:12,  9.50s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 17556/1000000 [11:36:28<2182:22:19,  8.00s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [17556], local_loss=0.014863280579447746, train_loss=0.019945841282606125, time_cost=1.5875489711761475
Steps:   2%|▏         | 17556/1000000 [11:36:28<2182:22:19,  8.00s/it, lr=1e-5, step_loss=0.0149]Steps:   2%|▏         | 17557/1000000 [11:36:38<2281:19:09,  8.36s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [17557], local_loss=0.013996915891766548, train_loss=0.05005782097578049, time_cost=3.0458405017852783
Steps:   2%|▏         | 17557/1000000 [11:36:38<2281:19:09,  8.36s/it, lr=1e-5, step_loss=0.014] Steps:   2%|▏         | 17558/1000000 [11:36:51<2707:26:22,  9.92s/it, lr=1e-5, step_loss=0.014][RANK-0]: Step: [17558], local_loss=0.08535093069076538, train_loss=0.07200188934803009, time_cost=6.076107501983643
Steps:   2%|▏         | 17558/1000000 [11:36:51<2707:26:22,  9.92s/it, lr=1e-5, step_loss=0.0854]Steps:   2%|▏         | 17559/1000000 [11:36:57<2338:50:04,  8.57s/it, lr=1e-5, step_loss=0.0854][RANK-0]: Step: [17559], local_loss=0.06526742875576019, train_loss=0.04470214247703552, time_cost=2.2419073581695557
Steps:   2%|▏         | 17559/1000000 [11:36:57<2338:50:04,  8.57s/it, lr=1e-5, step_loss=0.0653]Steps:   2%|▏         | 17560/1000000 [11:37:12<2893:42:26, 10.60s/it, lr=1e-5, step_loss=0.0653][RANK-0]: Step: [17560], local_loss=0.031777895987033844, train_loss=0.1473180055618286, time_cost=7.350013256072998
Steps:   2%|▏         | 17560/1000000 [11:37:12<2893:42:26, 10.60s/it, lr=1e-5, step_loss=0.0318]Steps:   2%|▏         | 17561/1000000 [11:37:23<2903:03:48, 10.64s/it, lr=1e-5, step_loss=0.0318][RANK-0]: Step: [17561], local_loss=0.28126150369644165, train_loss=0.0618869811296463, time_cost=3.35809063911438
Steps:   2%|▏         | 17561/1000000 [11:37:23<2903:03:48, 10.64s/it, lr=1e-5, step_loss=0.281] Steps:   2%|▏         | 17562/1000000 [11:37:28<2477:39:02,  9.08s/it, lr=1e-5, step_loss=0.281][RANK-0]: Step: [17562], local_loss=0.012858268804848194, train_loss=0.04054573178291321, time_cost=2.8036203384399414
Steps:   2%|▏         | 17562/1000000 [11:37:28<2477:39:02,  9.08s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 17563/1000000 [11:37:33<2154:08:39,  7.89s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [17563], local_loss=0.02507009357213974, train_loss=0.03408597409725189, time_cost=1.7310729026794434
Steps:   2%|▏         | 17563/1000000 [11:37:33<2154:08:39,  7.89s/it, lr=1e-5, step_loss=0.0251]Steps:   2%|▏         | 17564/1000000 [11:37:39<1938:50:11,  7.10s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [17564], local_loss=0.19198156893253326, train_loss=0.038066547363996506, time_cost=2.4829392433166504
Steps:   2%|▏         | 17564/1000000 [11:37:39<1938:50:11,  7.10s/it, lr=1e-5, step_loss=0.192] Steps:   2%|▏         | 17565/1000000 [11:37:52<2497:08:02,  9.15s/it, lr=1e-5, step_loss=0.192][RANK-0]: Step: [17565], local_loss=0.20664449036121368, train_loss=0.041620709002017975, time_cost=4.340120553970337
Steps:   2%|▏         | 17565/1000000 [11:37:52<2497:08:02,  9.15s/it, lr=1e-5, step_loss=0.207]Steps:   2%|▏         | 17566/1000000 [11:38:03<2593:44:07,  9.50s/it, lr=1e-5, step_loss=0.207][RANK-0]: Step: [17566], local_loss=0.028521761298179626, train_loss=0.02740708738565445, time_cost=2.3658909797668457
Steps:   2%|▏         | 17566/1000000 [11:38:03<2593:44:07,  9.50s/it, lr=1e-5, step_loss=0.0285]Steps:   2%|▏         | 17567/1000000 [11:38:14<2756:24:48, 10.10s/it, lr=1e-5, step_loss=0.0285][RANK-0]: Step: [17567], local_loss=0.07415799796581268, train_loss=0.05070469155907631, time_cost=2.9429755210876465
Steps:   2%|▏         | 17567/1000000 [11:38:14<2756:24:48, 10.10s/it, lr=1e-5, step_loss=0.0742]Steps:   2%|▏         | 17568/1000000 [11:38:21<2510:35:52,  9.20s/it, lr=1e-5, step_loss=0.0742][RANK-0]: Step: [17568], local_loss=0.004705680068582296, train_loss=0.06515729427337646, time_cost=1.3140978813171387
Steps:   2%|▏         | 17568/1000000 [11:38:21<2510:35:52,  9.20s/it, lr=1e-5, step_loss=0.00471]Steps:   2%|▏         | 17569/1000000 [11:38:27<2182:29:55,  8.00s/it, lr=1e-5, step_loss=0.00471][RANK-0]: Step: [17569], local_loss=0.005299837328493595, train_loss=0.015344787389039993, time_cost=2.859159469604492
Steps:   2%|▏         | 17569/1000000 [11:38:27<2182:29:55,  8.00s/it, lr=1e-5, step_loss=0.0053] Steps:   2%|▏         | 17570/1000000 [11:38:32<1958:47:39,  7.18s/it, lr=1e-5, step_loss=0.0053][RANK-0]: Step: [17570], local_loss=0.16606412827968597, train_loss=0.08322206884622574, time_cost=1.2051212787628174
Steps:   2%|▏         | 17570/1000000 [11:38:32<1958:47:39,  7.18s/it, lr=1e-5, step_loss=0.166] Steps:   2%|▏         | 17571/1000000 [11:38:39<1934:06:10,  7.09s/it, lr=1e-5, step_loss=0.166][RANK-0]: Step: [17571], local_loss=0.008469592779874802, train_loss=0.06162348389625549, time_cost=1.7080345153808594
Steps:   2%|▏         | 17571/1000000 [11:38:39<1934:06:10,  7.09s/it, lr=1e-5, step_loss=0.00847]Steps:   2%|▏         | 17572/1000000 [11:38:53<2512:32:30,  9.21s/it, lr=1e-5, step_loss=0.00847][RANK-0]: Step: [17572], local_loss=0.008673730306327343, train_loss=0.08366483449935913, time_cost=4.072227716445923
Steps:   2%|▏         | 17572/1000000 [11:38:53<2512:32:30,  9.21s/it, lr=1e-5, step_loss=0.00867]Steps:   2%|▏         | 17573/1000000 [11:39:03<2546:05:23,  9.33s/it, lr=1e-5, step_loss=0.00867][RANK-0]: Step: [17573], local_loss=0.00923381932079792, train_loss=0.02046993374824524, time_cost=7.35325813293457
Steps:   2%|▏         | 17573/1000000 [11:39:03<2546:05:23,  9.33s/it, lr=1e-5, step_loss=0.00923]Steps:   2%|▏         | 17574/1000000 [11:39:08<2261:51:11,  8.29s/it, lr=1e-5, step_loss=0.00923][RANK-0]: Step: [17574], local_loss=0.05702874809503555, train_loss=0.025091152638196945, time_cost=1.8729360103607178
Steps:   2%|▏         | 17574/1000000 [11:39:08<2261:51:11,  8.29s/it, lr=1e-5, step_loss=0.057]  Steps:   2%|▏         | 17575/1000000 [11:39:20<2512:03:04,  9.21s/it, lr=1e-5, step_loss=0.057][RANK-0]: Step: [17575], local_loss=0.00918591395020485, train_loss=0.027285989373922348, time_cost=4.599945068359375
Steps:   2%|▏         | 17575/1000000 [11:39:20<2512:03:04,  9.21s/it, lr=1e-5, step_loss=0.00919]Steps:   2%|▏         | 17576/1000000 [11:39:25<2211:08:10,  8.10s/it, lr=1e-5, step_loss=0.00919][RANK-0]: Step: [17576], local_loss=0.03240296617150307, train_loss=0.03686036169528961, time_cost=2.748178720474243
Steps:   2%|▏         | 17576/1000000 [11:39:25<2211:08:10,  8.10s/it, lr=1e-5, step_loss=0.0324] Steps:   2%|▏         | 17577/1000000 [11:39:33<2217:37:22,  8.13s/it, lr=1e-5, step_loss=0.0324][RANK-0]: Step: [17577], local_loss=0.05889889597892761, train_loss=0.027102641761302948, time_cost=7.296590805053711
Steps:   2%|▏         | 17577/1000000 [11:39:33<2217:37:22,  8.13s/it, lr=1e-5, step_loss=0.0589]Steps:   2%|▏         | 17578/1000000 [11:39:38<1912:47:28,  7.01s/it, lr=1e-5, step_loss=0.0589][RANK-0]: Step: [17578], local_loss=0.05577016621828079, train_loss=0.03964034467935562, time_cost=1.5963971614837646
Steps:   2%|▏         | 17578/1000000 [11:39:38<1912:47:28,  7.01s/it, lr=1e-5, step_loss=0.0558]Steps:   2%|▏         | 17579/1000000 [11:39:42<1675:48:27,  6.14s/it, lr=1e-5, step_loss=0.0558][RANK-0]: Step: [17579], local_loss=0.03226976841688156, train_loss=0.03686360642313957, time_cost=1.3966619968414307
Steps:   2%|▏         | 17579/1000000 [11:39:42<1675:48:27,  6.14s/it, lr=1e-5, step_loss=0.0323]Steps:   2%|▏         | 17580/1000000 [11:39:51<1915:47:19,  7.02s/it, lr=1e-5, step_loss=0.0323][RANK-0]: Step: [17580], local_loss=0.02817588299512863, train_loss=0.0361124686896801, time_cost=3.674030065536499
Steps:   2%|▏         | 17580/1000000 [11:39:51<1915:47:19,  7.02s/it, lr=1e-5, step_loss=0.0282]Steps:   2%|▏         | 17581/1000000 [11:40:05<2510:53:11,  9.20s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [17581], local_loss=0.08076830953359604, train_loss=0.0490703247487545, time_cost=1.2631943225860596
Steps:   2%|▏         | 17581/1000000 [11:40:05<2510:53:11,  9.20s/it, lr=1e-5, step_loss=0.0808]Steps:   2%|▏         | 17582/1000000 [11:40:10<2178:28:05,  7.98s/it, lr=1e-5, step_loss=0.0808][RANK-0]: Step: [17582], local_loss=0.012809212319552898, train_loss=0.009719133377075195, time_cost=2.7096505165100098
Steps:   2%|▏         | 17582/1000000 [11:40:10<2178:28:05,  7.98s/it, lr=1e-5, step_loss=0.0128]Steps:   2%|▏         | 17583/1000000 [11:40:16<2015:07:52,  7.38s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [17583], local_loss=0.004928638227283955, train_loss=0.02824212610721588, time_cost=2.0019371509552
Steps:   2%|▏         | 17583/1000000 [11:40:16<2015:07:52,  7.38s/it, lr=1e-5, step_loss=0.00493]Steps:   2%|▏         | 17584/1000000 [11:40:30<2496:58:13,  9.15s/it, lr=1e-5, step_loss=0.00493][RANK-0]: Step: [17584], local_loss=0.02781275101006031, train_loss=0.04675506800413132, time_cost=5.225332260131836
Steps:   2%|▏         | 17584/1000000 [11:40:30<2496:58:13,  9.15s/it, lr=1e-5, step_loss=0.0278] Steps:   2%|▏         | 17585/1000000 [11:40:40<2597:55:31,  9.52s/it, lr=1e-5, step_loss=0.0278][RANK-0]: Step: [17585], local_loss=0.003972809761762619, train_loss=0.026862865313887596, time_cost=1.260995626449585
Steps:   2%|▏         | 17585/1000000 [11:40:40<2597:55:31,  9.52s/it, lr=1e-5, step_loss=0.00397]Steps:   2%|▏         | 17586/1000000 [11:40:55<3051:05:58, 11.18s/it, lr=1e-5, step_loss=0.00397][RANK-0]: Step: [17586], local_loss=0.062401123344898224, train_loss=0.06060974672436714, time_cost=11.234640836715698
Steps:   2%|▏         | 17586/1000000 [11:40:55<3051:05:58, 11.18s/it, lr=1e-5, step_loss=0.0624] Steps:   2%|▏         | 17587/1000000 [11:41:02<2719:39:45,  9.97s/it, lr=1e-5, step_loss=0.0624][RANK-0]: Step: [17587], local_loss=0.035257287323474884, train_loss=0.09410914778709412, time_cost=2.3688554763793945
Steps:   2%|▏         | 17587/1000000 [11:41:02<2719:39:45,  9.97s/it, lr=1e-5, step_loss=0.0353]Steps:   2%|▏         | 17588/1000000 [11:41:08<2375:04:20,  8.70s/it, lr=1e-5, step_loss=0.0353][RANK-0]: Step: [17588], local_loss=0.01657111570239067, train_loss=0.08089601248502731, time_cost=4.347376585006714
Steps:   2%|▏         | 17588/1000000 [11:41:08<2375:04:20,  8.70s/it, lr=1e-5, step_loss=0.0166]Steps:   2%|▏         | 17589/1000000 [11:41:15<2252:53:14,  8.26s/it, lr=1e-5, step_loss=0.0166][RANK-0]: Step: [17589], local_loss=0.030086055397987366, train_loss=0.05181368440389633, time_cost=3.664828062057495
Steps:   2%|▏         | 17589/1000000 [11:41:15<2252:53:14,  8.26s/it, lr=1e-5, step_loss=0.0301]Steps:   2%|▏         | 17590/1000000 [11:41:23<2198:47:37,  8.06s/it, lr=1e-5, step_loss=0.0301][RANK-0]: Step: [17590], local_loss=0.061427075415849686, train_loss=0.0445309579372406, time_cost=3.0028154850006104
Steps:   2%|▏         | 17590/1000000 [11:41:23<2198:47:37,  8.06s/it, lr=1e-5, step_loss=0.0614]Steps:   2%|▏         | 17591/1000000 [11:41:28<1948:29:28,  7.14s/it, lr=1e-5, step_loss=0.0614][RANK-0]: Step: [17591], local_loss=0.008486494421958923, train_loss=0.0489535890519619, time_cost=1.2184422016143799
Steps:   2%|▏         | 17591/1000000 [11:41:28<1948:29:28,  7.14s/it, lr=1e-5, step_loss=0.00849]Steps:   2%|▏         | 17592/1000000 [11:41:35<1927:54:56,  7.06s/it, lr=1e-5, step_loss=0.00849][RANK-0]: Step: [17592], local_loss=0.028961265459656715, train_loss=0.03138731047511101, time_cost=2.3424453735351562
Steps:   2%|▏         | 17592/1000000 [11:41:35<1927:54:56,  7.06s/it, lr=1e-5, step_loss=0.029]  Steps:   2%|▏         | 17593/1000000 [11:41:49<2485:54:59,  9.11s/it, lr=1e-5, step_loss=0.029][RANK-0]: Step: [17593], local_loss=0.479531466960907, train_loss=0.08348669856786728, time_cost=1.2165179252624512
Steps:   2%|▏         | 17593/1000000 [11:41:49<2485:54:59,  9.11s/it, lr=1e-5, step_loss=0.48] Steps:   2%|▏         | 17594/1000000 [11:42:04<3003:04:31, 11.00s/it, lr=1e-5, step_loss=0.48][RANK-0]: Step: [17594], local_loss=0.0036449371837079525, train_loss=0.031628575176000595, time_cost=7.3027637004852295
Steps:   2%|▏         | 17594/1000000 [11:42:04<3003:04:31, 11.00s/it, lr=1e-5, step_loss=0.00364]Steps:   2%|▏         | 17595/1000000 [11:42:16<3042:43:29, 11.15s/it, lr=1e-5, step_loss=0.00364][RANK-0]: Step: [17595], local_loss=0.0041805836372077465, train_loss=0.010063967667520046, time_cost=3.852609157562256
Steps:   2%|▏         | 17595/1000000 [11:42:16<3042:43:29, 11.15s/it, lr=1e-5, step_loss=0.00418]Steps:   2%|▏         | 17596/1000000 [11:42:21<2564:59:44,  9.40s/it, lr=1e-5, step_loss=0.00418][RANK-0]: Step: [17596], local_loss=0.028004221618175507, train_loss=0.028995487838983536, time_cost=3.1489675045013428
Steps:   2%|▏         | 17596/1000000 [11:42:21<2564:59:44,  9.40s/it, lr=1e-5, step_loss=0.028]  Steps:   2%|▏         | 17597/1000000 [11:42:28<2352:12:05,  8.62s/it, lr=1e-5, step_loss=0.028][RANK-0]: Step: [17597], local_loss=0.1157810389995575, train_loss=15.703365325927734, time_cost=1.5537261962890625
Steps:   2%|▏         | 17597/1000000 [11:42:28<2352:12:05,  8.62s/it, lr=1e-5, step_loss=0.116]Steps:   2%|▏         | 17598/1000000 [11:42:35<2220:15:38,  8.14s/it, lr=1e-5, step_loss=0.116][RANK-0]: Step: [17598], local_loss=0.014252758584916592, train_loss=0.027359554544091225, time_cost=2.740478277206421
Steps:   2%|▏         | 17598/1000000 [11:42:35<2220:15:38,  8.14s/it, lr=1e-5, step_loss=0.0143]Steps:   2%|▏         | 17599/1000000 [11:42:45<2387:33:37,  8.75s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [17599], local_loss=0.0054619573056697845, train_loss=0.08361250162124634, time_cost=1.2274587154388428
Steps:   2%|▏         | 17599/1000000 [11:42:45<2387:33:37,  8.75s/it, lr=1e-5, step_loss=0.00546]Steps:   2%|▏         | 17600/1000000 [11:42:52<2228:04:32,  8.16s/it, lr=1e-5, step_loss=0.00546][RANK-0]: Step: [17600], local_loss=0.037697117775678635, train_loss=0.08869848400354385, time_cost=4.972179174423218
Steps:   2%|▏         | 17600/1000000 [11:42:52<2228:04:32,  8.16s/it, lr=1e-5, step_loss=0.0377] Steps:   2%|▏         | 17601/1000000 [11:43:00<2206:13:39,  8.08s/it, lr=1e-5, step_loss=0.0377][RANK-0]: Step: [17601], local_loss=0.11195006966590881, train_loss=0.0758010596036911, time_cost=1.2589573860168457
Steps:   2%|▏         | 17601/1000000 [11:43:00<2206:13:39,  8.08s/it, lr=1e-5, step_loss=0.112] Steps:   2%|▏         | 17602/1000000 [11:43:07<2165:47:15,  7.94s/it, lr=1e-5, step_loss=0.112][RANK-0]: Step: [17602], local_loss=0.047089461237192154, train_loss=0.0544678270816803, time_cost=3.2541983127593994
Steps:   2%|▏         | 17602/1000000 [11:43:07<2165:47:15,  7.94s/it, lr=1e-5, step_loss=0.0471]Steps:   2%|▏         | 17603/1000000 [11:43:13<2010:19:25,  7.37s/it, lr=1e-5, step_loss=0.0471][RANK-0]: Step: [17603], local_loss=0.2753141522407532, train_loss=0.09860779345035553, time_cost=1.9214301109313965
Steps:   2%|▏         | 17603/1000000 [11:43:13<2010:19:25,  7.37s/it, lr=1e-5, step_loss=0.275] Steps:   2%|▏         | 17604/1000000 [11:43:20<1955:51:11,  7.17s/it, lr=1e-5, step_loss=0.275][RANK-0]: Step: [17604], local_loss=0.07254345715045929, train_loss=0.06722462922334671, time_cost=2.116913318634033
Steps:   2%|▏         | 17604/1000000 [11:43:20<1955:51:11,  7.17s/it, lr=1e-5, step_loss=0.0725]Steps:   2%|▏         | 17605/1000000 [11:43:26<1908:59:53,  7.00s/it, lr=1e-5, step_loss=0.0725][RANK-0]: Step: [17605], local_loss=0.021281255409121513, train_loss=0.028105182573199272, time_cost=2.170562267303467
Steps:   2%|▏         | 17605/1000000 [11:43:26<1908:59:53,  7.00s/it, lr=1e-5, step_loss=0.0213]Steps:   2%|▏         | 17606/1000000 [11:43:37<2226:39:22,  8.16s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [17606], local_loss=0.021965287625789642, train_loss=0.024799682199954987, time_cost=2.740180015563965
Steps:   2%|▏         | 17606/1000000 [11:43:37<2226:39:22,  8.16s/it, lr=1e-5, step_loss=0.022] Steps:   2%|▏         | 17607/1000000 [11:43:48<2425:48:51,  8.89s/it, lr=1e-5, step_loss=0.022][RANK-0]: Step: [17607], local_loss=0.013493387028574944, train_loss=0.0218525193631649, time_cost=3.325484037399292
Steps:   2%|▏         | 17607/1000000 [11:43:48<2425:48:51,  8.89s/it, lr=1e-5, step_loss=0.0135]Steps:   2%|▏         | 17608/1000000 [11:43:57<2445:04:21,  8.96s/it, lr=1e-5, step_loss=0.0135][RANK-0]: Step: [17608], local_loss=0.11571130156517029, train_loss=0.05325409770011902, time_cost=3.9079928398132324
Steps:   2%|▏         | 17608/1000000 [11:43:57<2445:04:21,  8.96s/it, lr=1e-5, step_loss=0.116] Steps:   2%|▏         | 17609/1000000 [11:44:05<2353:33:57,  8.62s/it, lr=1e-5, step_loss=0.116][RANK-0]: Step: [17609], local_loss=0.007458068430423737, train_loss=0.03682290017604828, time_cost=3.6278693675994873
Steps:   2%|▏         | 17609/1000000 [11:44:05<2353:33:57,  8.62s/it, lr=1e-5, step_loss=0.00746]Steps:   2%|▏         | 17610/1000000 [11:44:19<2823:07:36, 10.35s/it, lr=1e-5, step_loss=0.00746][RANK-0]: Step: [17610], local_loss=0.004052935168147087, train_loss=0.05201982706785202, time_cost=6.505173206329346
Steps:   2%|▏         | 17610/1000000 [11:44:19<2823:07:36, 10.35s/it, lr=1e-5, step_loss=0.00405]Steps:   2%|▏         | 17611/1000000 [11:44:24<2387:08:41,  8.75s/it, lr=1e-5, step_loss=0.00405][RANK-0]: Step: [17611], local_loss=0.0046716355718672276, train_loss=0.011911840178072453, time_cost=1.2292630672454834
Steps:   2%|▏         | 17611/1000000 [11:44:24<2387:08:41,  8.75s/it, lr=1e-5, step_loss=0.00467]Steps:   2%|▏         | 17612/1000000 [11:44:35<2551:48:51,  9.35s/it, lr=1e-5, step_loss=0.00467][RANK-0]: Step: [17612], local_loss=0.1421205997467041, train_loss=0.05722929909825325, time_cost=2.816365957260132
Steps:   2%|▏         | 17612/1000000 [11:44:35<2551:48:51,  9.35s/it, lr=1e-5, step_loss=0.142]  Steps:   2%|▏         | 17613/1000000 [11:44:41<2316:56:58,  8.49s/it, lr=1e-5, step_loss=0.142][RANK-0]: Step: [17613], local_loss=0.025106104090809822, train_loss=0.02275446057319641, time_cost=1.2905161380767822
Steps:   2%|▏         | 17613/1000000 [11:44:41<2316:56:58,  8.49s/it, lr=1e-5, step_loss=0.0251]Steps:   2%|▏         | 17614/1000000 [11:44:54<2623:49:13,  9.62s/it, lr=1e-5, step_loss=0.0251][RANK-0]: Step: [17614], local_loss=0.4149783253669739, train_loss=0.07756109535694122, time_cost=3.663994073867798
Steps:   2%|▏         | 17614/1000000 [11:44:54<2623:49:13,  9.62s/it, lr=1e-5, step_loss=0.415] Steps:   2%|▏         | 17615/1000000 [11:45:02<2490:17:39,  9.13s/it, lr=1e-5, step_loss=0.415][RANK-0]: Step: [17615], local_loss=0.0069209858775138855, train_loss=0.03441686928272247, time_cost=4.051947355270386
Steps:   2%|▏         | 17615/1000000 [11:45:02<2490:17:39,  9.13s/it, lr=1e-5, step_loss=0.00692]Steps:   2%|▏         | 17616/1000000 [11:45:11<2481:17:55,  9.09s/it, lr=1e-5, step_loss=0.00692][RANK-0]: Step: [17616], local_loss=0.36127233505249023, train_loss=0.2497556507587433, time_cost=2.985069513320923
Steps:   2%|▏         | 17616/1000000 [11:45:11<2481:17:55,  9.09s/it, lr=1e-5, step_loss=0.361]  Steps:   2%|▏         | 17617/1000000 [11:45:22<2641:40:41,  9.68s/it, lr=1e-5, step_loss=0.361][RANK-0]: Step: [17617], local_loss=0.03409472852945328, train_loss=0.04545501992106438, time_cost=2.673236608505249
Steps:   2%|▏         | 17617/1000000 [11:45:22<2641:40:41,  9.68s/it, lr=1e-5, step_loss=0.0341]Steps:   2%|▏         | 17618/1000000 [11:45:27<2283:14:05,  8.37s/it, lr=1e-5, step_loss=0.0341][RANK-0]: Step: [17618], local_loss=0.9813100099563599, train_loss=0.15856176614761353, time_cost=2.877349615097046
Steps:   2%|▏         | 17618/1000000 [11:45:27<2283:14:05,  8.37s/it, lr=1e-5, step_loss=0.981] Steps:   2%|▏         | 17619/1000000 [11:45:32<1976:02:19,  7.24s/it, lr=1e-5, step_loss=0.981][RANK-0]: Step: [17619], local_loss=0.04078429564833641, train_loss=0.04939386993646622, time_cost=1.8458151817321777
Steps:   2%|▏         | 17619/1000000 [11:45:32<1976:02:19,  7.24s/it, lr=1e-5, step_loss=0.0408]Steps:   2%|▏         | 17620/1000000 [11:45:39<1972:38:03,  7.23s/it, lr=1e-5, step_loss=0.0408][RANK-0]: Step: [17620], local_loss=0.3929237425327301, train_loss=0.12300795316696167, time_cost=2.8706417083740234
Steps:   2%|▏         | 17620/1000000 [11:45:39<1972:38:03,  7.23s/it, lr=1e-5, step_loss=0.393] Steps:   2%|▏         | 17621/1000000 [11:45:49<2191:21:37,  8.03s/it, lr=1e-5, step_loss=0.393][RANK-0]: Step: [17621], local_loss=0.39997589588165283, train_loss=0.10343718528747559, time_cost=1.4220900535583496
Steps:   2%|▏         | 17621/1000000 [11:45:49<2191:21:37,  8.03s/it, lr=1e-5, step_loss=0.4]  Steps:   2%|▏         | 17622/1000000 [11:45:56<2130:10:41,  7.81s/it, lr=1e-5, step_loss=0.4][RANK-0]: Step: [17622], local_loss=0.08334819972515106, train_loss=0.15269438922405243, time_cost=3.152832508087158
Steps:   2%|▏         | 17622/1000000 [11:45:56<2130:10:41,  7.81s/it, lr=1e-5, step_loss=0.0833]Steps:   2%|▏         | 17623/1000000 [11:46:09<2566:35:34,  9.41s/it, lr=1e-5, step_loss=0.0833][RANK-0]: Step: [17623], local_loss=0.01731240004301071, train_loss=0.032777950167655945, time_cost=3.8492512702941895
Steps:   2%|▏         | 17623/1000000 [11:46:09<2566:35:34,  9.41s/it, lr=1e-5, step_loss=0.0173]Steps:   2%|▏         | 17624/1000000 [11:46:16<2366:42:01,  8.67s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [17624], local_loss=0.008181774988770485, train_loss=0.02747783623635769, time_cost=2.6452996730804443
Steps:   2%|▏         | 17624/1000000 [11:46:16<2366:42:01,  8.67s/it, lr=1e-5, step_loss=0.00818]Steps:   2%|▏         | 17625/1000000 [11:46:25<2374:26:54,  8.70s/it, lr=1e-5, step_loss=0.00818][RANK-0]: Step: [17625], local_loss=0.10177557915449142, train_loss=0.050748907029628754, time_cost=2.046494722366333
Steps:   2%|▏         | 17625/1000000 [11:46:25<2374:26:54,  8.70s/it, lr=1e-5, step_loss=0.102]  Steps:   2%|▏         | 17626/1000000 [11:46:34<2381:24:15,  8.73s/it, lr=1e-5, step_loss=0.102][RANK-0]: Step: [17626], local_loss=0.005835750140249729, train_loss=0.03893975168466568, time_cost=2.5046751499176025
Steps:   2%|▏         | 17626/1000000 [11:46:34<2381:24:15,  8.73s/it, lr=1e-5, step_loss=0.00584]Steps:   2%|▏         | 17627/1000000 [11:46:45<2565:56:32,  9.40s/it, lr=1e-5, step_loss=0.00584][RANK-0]: Step: [17627], local_loss=0.044752538204193115, train_loss=0.03373724967241287, time_cost=1.6476020812988281
Steps:   2%|▏         | 17627/1000000 [11:46:45<2565:56:32,  9.40s/it, lr=1e-5, step_loss=0.0448] Steps:   2%|▏         | 17628/1000000 [11:46:54<2567:46:55,  9.41s/it, lr=1e-5, step_loss=0.0448][RANK-0]: Step: [17628], local_loss=0.33402591943740845, train_loss=0.09190618991851807, time_cost=2.5975427627563477
Steps:   2%|▏         | 17628/1000000 [11:46:54<2567:46:55,  9.41s/it, lr=1e-5, step_loss=0.334] Steps:   2%|▏         | 17629/1000000 [11:46:58<2141:02:33,  7.85s/it, lr=1e-5, step_loss=0.334][RANK-0]: Step: [17629], local_loss=0.051534656435251236, train_loss=0.033844515681266785, time_cost=1.2748827934265137
Steps:   2%|▏         | 17629/1000000 [11:46:58<2141:02:33,  7.85s/it, lr=1e-5, step_loss=0.0515]Steps:   2%|▏         | 17630/1000000 [11:47:09<2333:24:29,  8.55s/it, lr=1e-5, step_loss=0.0515][RANK-0]: Step: [17630], local_loss=0.005754814483225346, train_loss=0.14326976239681244, time_cost=2.123086929321289
Steps:   2%|▏         | 17630/1000000 [11:47:09<2333:24:29,  8.55s/it, lr=1e-5, step_loss=0.00575]Steps:   2%|▏         | 17631/1000000 [11:47:14<2063:06:29,  7.56s/it, lr=1e-5, step_loss=0.00575][RANK-0]: Step: [17631], local_loss=0.011485069058835506, train_loss=0.014979984611272812, time_cost=2.237546920776367
Steps:   2%|▏         | 17631/1000000 [11:47:14<2063:06:29,  7.56s/it, lr=1e-5, step_loss=0.0115] Steps:   2%|▏         | 17632/1000000 [11:47:25<2329:08:13,  8.54s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [17632], local_loss=0.00666718278080225, train_loss=0.10505080968141556, time_cost=3.7049713134765625
Steps:   2%|▏         | 17632/1000000 [11:47:25<2329:08:13,  8.54s/it, lr=1e-5, step_loss=0.00667]Steps:   2%|▏         | 17633/1000000 [11:47:34<2365:56:11,  8.67s/it, lr=1e-5, step_loss=0.00667][RANK-0]: Step: [17633], local_loss=0.004300395026803017, train_loss=0.026900626718997955, time_cost=2.3276965618133545
Steps:   2%|▏         | 17633/1000000 [11:47:34<2365:56:11,  8.67s/it, lr=1e-5, step_loss=0.0043] Steps:   2%|▏         | 17634/1000000 [11:47:38<2013:47:27,  7.38s/it, lr=1e-5, step_loss=0.0043][RANK-0]: Step: [17634], local_loss=0.03264310210943222, train_loss=0.06845545023679733, time_cost=3.354966163635254
Steps:   2%|▏         | 17634/1000000 [11:47:38<2013:47:27,  7.38s/it, lr=1e-5, step_loss=0.0326]Steps:   2%|▏         | 17635/1000000 [11:47:49<2290:10:42,  8.39s/it, lr=1e-5, step_loss=0.0326][RANK-0]: Step: [17635], local_loss=0.058414071798324585, train_loss=0.037206850945949554, time_cost=1.2305057048797607
Steps:   2%|▏         | 17635/1000000 [11:47:49<2290:10:42,  8.39s/it, lr=1e-5, step_loss=0.0584]Steps:   2%|▏         | 17636/1000000 [11:47:59<2480:56:19,  9.09s/it, lr=1e-5, step_loss=0.0584][RANK-0]: Step: [17636], local_loss=0.008264990523457527, train_loss=0.018087487667798996, time_cost=1.5706305503845215
Steps:   2%|▏         | 17636/1000000 [11:47:59<2480:56:19,  9.09s/it, lr=1e-5, step_loss=0.00826]Steps:   2%|▏         | 17637/1000000 [11:48:13<2809:04:28, 10.29s/it, lr=1e-5, step_loss=0.00826][RANK-0]: Step: [17637], local_loss=0.029996858909726143, train_loss=0.028187453746795654, time_cost=5.293345212936401
Steps:   2%|▏         | 17637/1000000 [11:48:13<2809:04:28, 10.29s/it, lr=1e-5, step_loss=0.03]   Steps:   2%|▏         | 17638/1000000 [11:48:17<2357:13:25,  8.64s/it, lr=1e-5, step_loss=0.03][RANK-0]: Step: [17638], local_loss=0.012796199880540371, train_loss=0.13897494971752167, time_cost=1.5773913860321045
Steps:   2%|▏         | 17638/1000000 [11:48:17<2357:13:25,  8.64s/it, lr=1e-5, step_loss=0.0128]Steps:   2%|▏         | 17639/1000000 [11:48:29<2584:26:44,  9.47s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [17639], local_loss=0.00997457280755043, train_loss=0.0351182296872139, time_cost=3.5342838764190674
Steps:   2%|▏         | 17639/1000000 [11:48:29<2584:26:44,  9.47s/it, lr=1e-5, step_loss=0.00997]Steps:   2%|▏         | 17640/1000000 [11:48:34<2217:29:46,  8.13s/it, lr=1e-5, step_loss=0.00997][RANK-0]: Step: [17640], local_loss=0.11181685328483582, train_loss=0.06316907703876495, time_cost=1.7905001640319824
Steps:   2%|▏         | 17640/1000000 [11:48:34<2217:29:46,  8.13s/it, lr=1e-5, step_loss=0.112]  Steps:   2%|▏         | 17641/1000000 [11:48:41<2151:33:10,  7.88s/it, lr=1e-5, step_loss=0.112][RANK-0]: Step: [17641], local_loss=0.014154789038002491, train_loss=0.0838557705283165, time_cost=5.541888475418091
Steps:   2%|▏         | 17641/1000000 [11:48:41<2151:33:10,  7.88s/it, lr=1e-5, step_loss=0.0142]Steps:   2%|▏         | 17642/1000000 [11:48:49<2143:13:22,  7.85s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [17642], local_loss=0.03454110398888588, train_loss=20.84788703918457, time_cost=1.2233047485351562
Steps:   2%|▏         | 17642/1000000 [11:48:49<2143:13:22,  7.85s/it, lr=1e-5, step_loss=0.0345]Steps:   2%|▏         | 17643/1000000 [11:48:54<1930:12:48,  7.07s/it, lr=1e-5, step_loss=0.0345][RANK-0]: Step: [17643], local_loss=0.014826003462076187, train_loss=0.023256564512848854, time_cost=2.5387375354766846
Steps:   2%|▏         | 17643/1000000 [11:48:54<1930:12:48,  7.07s/it, lr=1e-5, step_loss=0.0148]Steps:   2%|▏         | 17644/1000000 [11:49:00<1833:59:21,  6.72s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [17644], local_loss=0.006641093175858259, train_loss=0.03353509679436684, time_cost=3.1044938564300537
Steps:   2%|▏         | 17644/1000000 [11:49:00<1833:59:21,  6.72s/it, lr=1e-5, step_loss=0.00664]Steps:   2%|▏         | 17645/1000000 [11:49:11<2161:48:43,  7.92s/it, lr=1e-5, step_loss=0.00664][RANK-0]: Step: [17645], local_loss=0.005861206911504269, train_loss=0.0422014519572258, time_cost=1.7418928146362305
Steps:   2%|▏         | 17645/1000000 [11:49:11<2161:48:43,  7.92s/it, lr=1e-5, step_loss=0.00586]Steps:   2%|▏         | 17646/1000000 [11:49:19<2233:06:26,  8.18s/it, lr=1e-5, step_loss=0.00586][RANK-0]: Step: [17646], local_loss=0.0077135288156569, train_loss=0.020287219434976578, time_cost=2.6120617389678955
Steps:   2%|▏         | 17646/1000000 [11:49:19<2233:06:26,  8.18s/it, lr=1e-5, step_loss=0.00771]Steps:   2%|▏         | 17647/1000000 [11:49:26<2123:26:11,  7.78s/it, lr=1e-5, step_loss=0.00771][RANK-0]: Step: [17647], local_loss=0.04680459201335907, train_loss=0.03794592618942261, time_cost=2.978499174118042
Steps:   2%|▏         | 17647/1000000 [11:49:26<2123:26:11,  7.78s/it, lr=1e-5, step_loss=0.0468] Steps:   2%|▏         | 17648/1000000 [11:49:42<2760:09:12, 10.12s/it, lr=1e-5, step_loss=0.0468][RANK-0]: Step: [17648], local_loss=0.07855358719825745, train_loss=0.042131826281547546, time_cost=7.41077184677124
Steps:   2%|▏         | 17648/1000000 [11:49:42<2760:09:12, 10.12s/it, lr=1e-5, step_loss=0.0786]Steps:   2%|▏         | 17649/1000000 [11:49:46<2293:00:27,  8.40s/it, lr=1e-5, step_loss=0.0786][RANK-0]: Step: [17649], local_loss=0.40935391187667847, train_loss=0.074004165828228, time_cost=1.6720640659332275
Steps:   2%|▏         | 17649/1000000 [11:49:46<2293:00:27,  8.40s/it, lr=1e-5, step_loss=0.409] Steps:   2%|▏         | 17650/1000000 [11:49:55<2350:44:06,  8.61s/it, lr=1e-5, step_loss=0.409][RANK-0]: Step: [17650], local_loss=0.03675292059779167, train_loss=0.045412857085466385, time_cost=3.1495585441589355
Steps:   2%|▏         | 17650/1000000 [11:49:55<2350:44:06,  8.61s/it, lr=1e-5, step_loss=0.0368]Steps:   2%|▏         | 17651/1000000 [11:50:00<2002:34:18,  7.34s/it, lr=1e-5, step_loss=0.0368][RANK-0]: Step: [17651], local_loss=0.008006183430552483, train_loss=0.019544266164302826, time_cost=3.3912293910980225
Steps:   2%|▏         | 17651/1000000 [11:50:00<2002:34:18,  7.34s/it, lr=1e-5, step_loss=0.00801]Steps:   2%|▏         | 17652/1000000 [11:50:07<1974:16:46,  7.24s/it, lr=1e-5, step_loss=0.00801][RANK-0]: Step: [17652], local_loss=0.04963359236717224, train_loss=0.024160366505384445, time_cost=2.23541259765625
Steps:   2%|▏         | 17652/1000000 [11:50:07<1974:16:46,  7.24s/it, lr=1e-5, step_loss=0.0496] Steps:   2%|▏         | 17653/1000000 [11:50:12<1795:34:32,  6.58s/it, lr=1e-5, step_loss=0.0496][RANK-0]: Step: [17653], local_loss=0.050303857773542404, train_loss=0.14841173589229584, time_cost=2.142512798309326
Steps:   2%|▏         | 17653/1000000 [11:50:12<1795:34:32,  6.58s/it, lr=1e-5, step_loss=0.0503]Steps:   2%|▏         | 17654/1000000 [11:50:18<1761:39:05,  6.46s/it, lr=1e-5, step_loss=0.0503][RANK-0]: Step: [17654], local_loss=0.02463276870548725, train_loss=0.03985849767923355, time_cost=1.2348103523254395
Steps:   2%|▏         | 17654/1000000 [11:50:18<1761:39:05,  6.46s/it, lr=1e-5, step_loss=0.0246]Steps:   2%|▏         | 17655/1000000 [11:50:23<1645:06:31,  6.03s/it, lr=1e-5, step_loss=0.0246][RANK-0]: Step: [17655], local_loss=0.027177799493074417, train_loss=0.03209111467003822, time_cost=2.01839017868042
Steps:   2%|▏         | 17655/1000000 [11:50:23<1645:06:31,  6.03s/it, lr=1e-5, step_loss=0.0272]Steps:   2%|▏         | 17656/1000000 [11:50:31<1777:58:11,  6.52s/it, lr=1e-5, step_loss=0.0272][RANK-0]: Step: [17656], local_loss=0.008749288506805897, train_loss=0.0704393982887268, time_cost=1.4910047054290771
Steps:   2%|▏         | 17656/1000000 [11:50:31<1777:58:11,  6.52s/it, lr=1e-5, step_loss=0.00875]Steps:   2%|▏         | 17657/1000000 [11:50:35<1583:18:59,  5.80s/it, lr=1e-5, step_loss=0.00875][RANK-0]: Step: [17657], local_loss=0.007835040800273418, train_loss=0.04786711931228638, time_cost=3.25528883934021
Steps:   2%|▏         | 17657/1000000 [11:50:35<1583:18:59,  5.80s/it, lr=1e-5, step_loss=0.00784]Steps:   2%|▏         | 17658/1000000 [11:50:42<1696:02:36,  6.22s/it, lr=1e-5, step_loss=0.00784][RANK-0]: Step: [17658], local_loss=0.04601714015007019, train_loss=0.04192575067281723, time_cost=3.5414557456970215
Steps:   2%|▏         | 17658/1000000 [11:50:42<1696:02:36,  6.22s/it, lr=1e-5, step_loss=0.046]  Steps:   2%|▏         | 17659/1000000 [11:50:49<1775:56:01,  6.51s/it, lr=1e-5, step_loss=0.046][RANK-0]: Step: [17659], local_loss=0.036477766931056976, train_loss=0.08129564672708511, time_cost=1.2193689346313477
Steps:   2%|▏         | 17659/1000000 [11:50:49<1775:56:01,  6.51s/it, lr=1e-5, step_loss=0.0365]Steps:   2%|▏         | 17660/1000000 [11:51:06<2628:36:45,  9.63s/it, lr=1e-5, step_loss=0.0365][RANK-0]: Step: [17660], local_loss=0.4219992458820343, train_loss=9.263084411621094, time_cost=4.01312255859375
Steps:   2%|▏         | 17660/1000000 [11:51:06<2628:36:45,  9.63s/it, lr=1e-5, step_loss=0.422] Steps:   2%|▏         | 17661/1000000 [11:51:14<2492:16:11,  9.13s/it, lr=1e-5, step_loss=0.422][RANK-0]: Step: [17661], local_loss=0.006890075281262398, train_loss=0.036590080708265305, time_cost=2.3312175273895264
Steps:   2%|▏         | 17661/1000000 [11:51:14<2492:16:11,  9.13s/it, lr=1e-5, step_loss=0.00689]Steps:   2%|▏         | 17662/1000000 [11:51:21<2284:55:22,  8.37s/it, lr=1e-5, step_loss=0.00689][RANK-0]: Step: [17662], local_loss=0.03429946303367615, train_loss=0.036683715879917145, time_cost=1.212890386581421
Steps:   2%|▏         | 17662/1000000 [11:51:21<2284:55:22,  8.37s/it, lr=1e-5, step_loss=0.0343] Steps:   2%|▏         | 17663/1000000 [11:51:26<2038:37:00,  7.47s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [17663], local_loss=0.014228243380784988, train_loss=43.07734298706055, time_cost=2.57883620262146
Steps:   2%|▏         | 17663/1000000 [11:51:26<2038:37:00,  7.47s/it, lr=1e-5, step_loss=0.0142]Steps:   2%|▏         | 17664/1000000 [11:51:34<2040:27:59,  7.48s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [17664], local_loss=0.008384078741073608, train_loss=0.05173030123114586, time_cost=3.9027788639068604
Steps:   2%|▏         | 17664/1000000 [11:51:34<2040:27:59,  7.48s/it, lr=1e-5, step_loss=0.00838]Steps:   2%|▏         | 17665/1000000 [11:51:47<2553:41:56,  9.36s/it, lr=1e-5, step_loss=0.00838][RANK-0]: Step: [17665], local_loss=0.0058594634756445885, train_loss=0.06053469702601433, time_cost=5.044658184051514
Steps:   2%|▏         | 17665/1000000 [11:51:47<2553:41:56,  9.36s/it, lr=1e-5, step_loss=0.00586]Steps:   2%|▏         | 17666/1000000 [11:51:57<2572:46:21,  9.43s/it, lr=1e-5, step_loss=0.00586][RANK-0]: Step: [17666], local_loss=0.009484237059950829, train_loss=0.018468573689460754, time_cost=8.159874677658081
Steps:   2%|▏         | 17666/1000000 [11:51:57<2572:46:21,  9.43s/it, lr=1e-5, step_loss=0.00948]Steps:   2%|▏         | 17667/1000000 [11:52:01<2164:21:49,  7.93s/it, lr=1e-5, step_loss=0.00948][RANK-0]: Step: [17667], local_loss=0.033238332718610764, train_loss=0.02498941496014595, time_cost=1.8709986209869385
Steps:   2%|▏         | 17667/1000000 [11:52:01<2164:21:49,  7.93s/it, lr=1e-5, step_loss=0.0332] Steps:   2%|▏         | 17668/1000000 [11:52:09<2139:59:16,  7.84s/it, lr=1e-5, step_loss=0.0332][RANK-0]: Step: [17668], local_loss=0.0077016595751047134, train_loss=0.03664674609899521, time_cost=1.3546538352966309
Steps:   2%|▏         | 17668/1000000 [11:52:09<2139:59:16,  7.84s/it, lr=1e-5, step_loss=0.0077]Steps:   2%|▏         | 17669/1000000 [11:52:13<1851:16:19,  6.78s/it, lr=1e-5, step_loss=0.0077][RANK-0]: Step: [17669], local_loss=0.0451190322637558, train_loss=0.04898466169834137, time_cost=1.2807955741882324
Steps:   2%|▏         | 17669/1000000 [11:52:13<1851:16:19,  6.78s/it, lr=1e-5, step_loss=0.0451]Steps:   2%|▏         | 17670/1000000 [11:52:23<2055:12:00,  7.53s/it, lr=1e-5, step_loss=0.0451][RANK-0]: Step: [17670], local_loss=0.03581749275326729, train_loss=0.057500433176755905, time_cost=3.8973264694213867
Steps:   2%|▏         | 17670/1000000 [11:52:23<2055:12:00,  7.53s/it, lr=1e-5, step_loss=0.0358]Steps:   2%|▏         | 17671/1000000 [11:52:35<2498:29:34,  9.16s/it, lr=1e-5, step_loss=0.0358][RANK-0]: Step: [17671], local_loss=0.02061440981924534, train_loss=0.021200835704803467, time_cost=3.969089984893799
Steps:   2%|▏         | 17671/1000000 [11:52:35<2498:29:34,  9.16s/it, lr=1e-5, step_loss=0.0206]Steps:   2%|▏         | 17672/1000000 [11:52:40<2107:12:51,  7.72s/it, lr=1e-5, step_loss=0.0206][RANK-0]: Step: [17672], local_loss=0.015090133994817734, train_loss=0.010120715945959091, time_cost=1.4147849082946777
Steps:   2%|▏         | 17672/1000000 [11:52:40<2107:12:51,  7.72s/it, lr=1e-5, step_loss=0.0151]Steps:   2%|▏         | 17673/1000000 [11:52:47<2065:51:37,  7.57s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [17673], local_loss=0.021900709718465805, train_loss=0.05983203276991844, time_cost=3.451559543609619
Steps:   2%|▏         | 17673/1000000 [11:52:47<2065:51:37,  7.57s/it, lr=1e-5, step_loss=0.0219]Steps:   2%|▏         | 17674/1000000 [11:52:53<1900:57:36,  6.97s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [17674], local_loss=0.01217242144048214, train_loss=0.0773685872554779, time_cost=1.3314781188964844
Steps:   2%|▏         | 17674/1000000 [11:52:53<1900:57:36,  6.97s/it, lr=1e-5, step_loss=0.0122]Steps:   2%|▏         | 17675/1000000 [11:53:00<1950:45:04,  7.15s/it, lr=1e-5, step_loss=0.0122][RANK-0]: Step: [17675], local_loss=0.015399966388940811, train_loss=0.07528802752494812, time_cost=1.8398189544677734
Steps:   2%|▏         | 17675/1000000 [11:53:00<1950:45:04,  7.15s/it, lr=1e-5, step_loss=0.0154]Steps:   2%|▏         | 17676/1000000 [11:53:06<1843:04:00,  6.75s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [17676], local_loss=0.009384366683661938, train_loss=0.019572094082832336, time_cost=3.0343527793884277
Steps:   2%|▏         | 17676/1000000 [11:53:06<1843:04:00,  6.75s/it, lr=1e-5, step_loss=0.00938]Steps:   2%|▏         | 17677/1000000 [11:53:10<1643:58:22,  6.02s/it, lr=1e-5, step_loss=0.00938][RANK-0]: Step: [17677], local_loss=0.028804641216993332, train_loss=0.07622770965099335, time_cost=1.8258538246154785
Steps:   2%|▏         | 17677/1000000 [11:53:10<1643:58:22,  6.02s/it, lr=1e-5, step_loss=0.0288] Steps:   2%|▏         | 17678/1000000 [11:53:17<1654:06:41,  6.06s/it, lr=1e-5, step_loss=0.0288][RANK-0]: Step: [17678], local_loss=0.015367559157311916, train_loss=0.15846289694309235, time_cost=2.3667235374450684
Steps:   2%|▏         | 17678/1000000 [11:53:17<1654:06:41,  6.06s/it, lr=1e-5, step_loss=0.0154]Steps:   2%|▏         | 17679/1000000 [11:53:23<1724:16:18,  6.32s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [17679], local_loss=0.0108566265553236, train_loss=0.0406104139983654, time_cost=1.5386250019073486
Steps:   2%|▏         | 17679/1000000 [11:53:23<1724:16:18,  6.32s/it, lr=1e-5, step_loss=0.0109]Steps:   2%|▏         | 17680/1000000 [11:53:28<1565:40:21,  5.74s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [17680], local_loss=0.04772958159446716, train_loss=0.081368088722229, time_cost=1.453169822692871
Steps:   2%|▏         | 17680/1000000 [11:53:28<1565:40:21,  5.74s/it, lr=1e-5, step_loss=0.0477]Steps:   2%|▏         | 17681/1000000 [11:53:38<1932:54:01,  7.08s/it, lr=1e-5, step_loss=0.0477][RANK-0]: Step: [17681], local_loss=0.007013197988271713, train_loss=0.034568458795547485, time_cost=1.549264669418335
Steps:   2%|▏         | 17681/1000000 [11:53:38<1932:54:01,  7.08s/it, lr=1e-5, step_loss=0.00701]Steps:   2%|▏         | 17682/1000000 [11:53:49<2251:53:28,  8.25s/it, lr=1e-5, step_loss=0.00701][RANK-0]: Step: [17682], local_loss=0.01096811518073082, train_loss=0.03504158556461334, time_cost=8.060128450393677
Steps:   2%|▏         | 17682/1000000 [11:53:49<2251:53:28,  8.25s/it, lr=1e-5, step_loss=0.011]  Steps:   2%|▏         | 17683/1000000 [11:54:00<2484:51:24,  9.11s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [17683], local_loss=0.04098778963088989, train_loss=0.020360741764307022, time_cost=2.087660789489746
Steps:   2%|▏         | 17683/1000000 [11:54:00<2484:51:24,  9.11s/it, lr=1e-5, step_loss=0.041]Steps:   2%|▏         | 17684/1000000 [11:54:10<2571:46:29,  9.43s/it, lr=1e-5, step_loss=0.041][RANK-0]: Step: [17684], local_loss=0.01834435947239399, train_loss=0.17205482721328735, time_cost=1.6034634113311768
Steps:   2%|▏         | 17684/1000000 [11:54:10<2571:46:29,  9.43s/it, lr=1e-5, step_loss=0.0183]Steps:   2%|▏         | 17685/1000000 [11:54:25<3040:52:58, 11.14s/it, lr=1e-5, step_loss=0.0183][RANK-0]: Step: [17685], local_loss=0.033609721809625626, train_loss=2.445080518722534, time_cost=6.8388450145721436
Steps:   2%|▏         | 17685/1000000 [11:54:25<3040:52:58, 11.14s/it, lr=1e-5, step_loss=0.0336]Steps:   2%|▏         | 17686/1000000 [11:54:35<2930:24:42, 10.74s/it, lr=1e-5, step_loss=0.0336][RANK-0]: Step: [17686], local_loss=0.015395292080938816, train_loss=0.13930416107177734, time_cost=3.552907943725586
Steps:   2%|▏         | 17686/1000000 [11:54:35<2930:24:42, 10.74s/it, lr=1e-5, step_loss=0.0154]Steps:   2%|▏         | 17687/1000000 [11:54:40<2424:19:47,  8.88s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [17687], local_loss=0.006417117081582546, train_loss=0.0728507936000824, time_cost=1.250697374343872
Steps:   2%|▏         | 17687/1000000 [11:54:40<2424:19:47,  8.88s/it, lr=1e-5, step_loss=0.00642]Steps:   2%|▏         | 17688/1000000 [11:54:45<2145:58:11,  7.86s/it, lr=1e-5, step_loss=0.00642][RANK-0]: Step: [17688], local_loss=0.027536161243915558, train_loss=0.2937487065792084, time_cost=1.3219549655914307
Steps:   2%|▏         | 17688/1000000 [11:54:45<2145:58:11,  7.86s/it, lr=1e-5, step_loss=0.0275] Steps:   2%|▏         | 17689/1000000 [11:54:59<2605:39:05,  9.55s/it, lr=1e-5, step_loss=0.0275][RANK-0]: Step: [17689], local_loss=0.03500840440392494, train_loss=0.025783143937587738, time_cost=1.2231135368347168
Steps:   2%|▏         | 17689/1000000 [11:54:59<2605:39:05,  9.55s/it, lr=1e-5, step_loss=0.035] Steps:   2%|▏         | 17690/1000000 [11:55:12<2930:10:26, 10.74s/it, lr=1e-5, step_loss=0.035][RANK-0]: Step: [17690], local_loss=0.007030417677015066, train_loss=0.01592463254928589, time_cost=11.905352354049683
Steps:   2%|▏         | 17690/1000000 [11:55:12<2930:10:26, 10.74s/it, lr=1e-5, step_loss=0.00703]Steps:   2%|▏         | 17691/1000000 [11:55:19<2617:02:04,  9.59s/it, lr=1e-5, step_loss=0.00703][RANK-0]: Step: [17691], local_loss=0.028199970722198486, train_loss=0.0185902900993824, time_cost=2.7129099369049072
Steps:   2%|▏         | 17691/1000000 [11:55:19<2617:02:04,  9.59s/it, lr=1e-5, step_loss=0.0282] Steps:   2%|▏         | 17692/1000000 [11:55:31<2826:25:51, 10.36s/it, lr=1e-5, step_loss=0.0282][RANK-0]: Step: [17692], local_loss=0.0052030798979103565, train_loss=0.03378978371620178, time_cost=4.228590250015259
Steps:   2%|▏         | 17692/1000000 [11:55:31<2826:25:51, 10.36s/it, lr=1e-5, step_loss=0.0052]Steps:   2%|▏         | 17693/1000000 [11:55:37<2457:21:30,  9.01s/it, lr=1e-5, step_loss=0.0052][RANK-0]: Step: [17693], local_loss=0.01181360986083746, train_loss=0.023349134251475334, time_cost=1.500061273574829
Steps:   2%|▏         | 17693/1000000 [11:55:37<2457:21:30,  9.01s/it, lr=1e-5, step_loss=0.0118]Steps:   2%|▏         | 17694/1000000 [11:55:45<2369:49:26,  8.69s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [17694], local_loss=0.04189023748040199, train_loss=0.15187571942806244, time_cost=4.1047563552856445
Steps:   2%|▏         | 17694/1000000 [11:55:45<2369:49:26,  8.69s/it, lr=1e-5, step_loss=0.0419]Steps:   2%|▏         | 17695/1000000 [11:55:55<2428:14:45,  8.90s/it, lr=1e-5, step_loss=0.0419][RANK-0]: Step: [17695], local_loss=0.005981334485113621, train_loss=0.031182579696178436, time_cost=1.501746654510498
Steps:   2%|▏         | 17695/1000000 [11:55:55<2428:14:45,  8.90s/it, lr=1e-5, step_loss=0.00598]Steps:   2%|▏         | 17696/1000000 [11:56:05<2526:19:44,  9.26s/it, lr=1e-5, step_loss=0.00598][RANK-0]: Step: [17696], local_loss=0.01369038037955761, train_loss=0.02842174470424652, time_cost=5.248068809509277
Steps:   2%|▏         | 17696/1000000 [11:56:05<2526:19:44,  9.26s/it, lr=1e-5, step_loss=0.0137] Steps:   2%|▏         | 17697/1000000 [11:56:15<2588:52:35,  9.49s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [17697], local_loss=0.0114646190777421, train_loss=0.05027797445654869, time_cost=2.857898235321045
Steps:   2%|▏         | 17697/1000000 [11:56:15<2588:52:35,  9.49s/it, lr=1e-5, step_loss=0.0115]Steps:   2%|▏         | 17698/1000000 [11:56:29<3015:18:04, 11.05s/it, lr=1e-5, step_loss=0.0115][RANK-0]: Step: [17698], local_loss=0.004299746360629797, train_loss=0.0220018457621336, time_cost=6.70008397102356
Steps:   2%|▏         | 17698/1000000 [11:56:29<3015:18:04, 11.05s/it, lr=1e-5, step_loss=0.0043]Steps:   2%|▏         | 17699/1000000 [11:56:40<3016:12:38, 11.05s/it, lr=1e-5, step_loss=0.0043][RANK-0]: Step: [17699], local_loss=0.005518469028174877, train_loss=0.015442714095115662, time_cost=4.60768723487854
Steps:   2%|▏         | 17699/1000000 [11:56:40<3016:12:38, 11.05s/it, lr=1e-5, step_loss=0.00552]Steps:   2%|▏         | 17700/1000000 [11:56:47<2671:19:46,  9.79s/it, lr=1e-5, step_loss=0.00552][RANK-0]: Step: [17700], local_loss=0.005146200302988291, train_loss=0.024482835084199905, time_cost=1.2266218662261963
Steps:   2%|▏         | 17700/1000000 [11:56:47<2671:19:46,  9.79s/it, lr=1e-5, step_loss=0.00515]Steps:   2%|▏         | 17701/1000000 [11:56:56<2577:58:02,  9.45s/it, lr=1e-5, step_loss=0.00515][RANK-0]: Step: [17701], local_loss=0.08174053579568863, train_loss=0.09293343126773834, time_cost=2.7431857585906982
Steps:   2%|▏         | 17701/1000000 [11:56:56<2577:58:02,  9.45s/it, lr=1e-5, step_loss=0.0817] Steps:   2%|▏         | 17702/1000000 [11:57:04<2431:28:26,  8.91s/it, lr=1e-5, step_loss=0.0817][RANK-0]: Step: [17702], local_loss=0.005411218851804733, train_loss=0.02609330415725708, time_cost=1.6907663345336914
Steps:   2%|▏         | 17702/1000000 [11:57:04<2431:28:26,  8.91s/it, lr=1e-5, step_loss=0.00541]Steps:   2%|▏         | 17703/1000000 [11:57:15<2629:19:15,  9.64s/it, lr=1e-5, step_loss=0.00541][RANK-0]: Step: [17703], local_loss=0.014413348399102688, train_loss=0.05282226949930191, time_cost=4.12563419342041
Steps:   2%|▏         | 17703/1000000 [11:57:15<2629:19:15,  9.64s/it, lr=1e-5, step_loss=0.0144] Steps:   2%|▏         | 17704/1000000 [11:57:20<2246:21:46,  8.23s/it, lr=1e-5, step_loss=0.0144][RANK-0]: Step: [17704], local_loss=0.005362721160054207, train_loss=0.011042393743991852, time_cost=3.768181800842285
Steps:   2%|▏         | 17704/1000000 [11:57:20<2246:21:46,  8.23s/it, lr=1e-5, step_loss=0.00536]Steps:   2%|▏         | 17705/1000000 [11:57:29<2297:56:08,  8.42s/it, lr=1e-5, step_loss=0.00536][RANK-0]: Step: [17705], local_loss=0.06757905334234238, train_loss=0.17134158313274384, time_cost=3.0266692638397217
Steps:   2%|▏         | 17705/1000000 [11:57:29<2297:56:08,  8.42s/it, lr=1e-5, step_loss=0.0676] Steps:   2%|▏         | 17706/1000000 [11:57:34<2049:19:32,  7.51s/it, lr=1e-5, step_loss=0.0676][RANK-0]: Step: [17706], local_loss=0.08680830895900726, train_loss=6.9716796875, time_cost=2.9584105014801025
Steps:   2%|▏         | 17706/1000000 [11:57:34<2049:19:32,  7.51s/it, lr=1e-5, step_loss=0.0868]Steps:   2%|▏         | 17707/1000000 [11:57:45<2296:24:08,  8.42s/it, lr=1e-5, step_loss=0.0868][RANK-0]: Step: [17707], local_loss=0.023152941837906837, train_loss=0.03532082214951515, time_cost=3.5927748680114746
Steps:   2%|▏         | 17707/1000000 [11:57:45<2296:24:08,  8.42s/it, lr=1e-5, step_loss=0.0232]Steps:   2%|▏         | 17708/1000000 [11:57:54<2359:38:19,  8.65s/it, lr=1e-5, step_loss=0.0232][RANK-0]: Step: [17708], local_loss=0.014014730229973793, train_loss=0.022591374814510345, time_cost=3.201836109161377
Steps:   2%|▏         | 17708/1000000 [11:57:54<2359:38:19,  8.65s/it, lr=1e-5, step_loss=0.014] Steps:   2%|▏         | 17709/1000000 [11:58:08<2807:43:07, 10.29s/it, lr=1e-5, step_loss=0.014][RANK-0]: Step: [17709], local_loss=0.006647544447332621, train_loss=0.03813164681196213, time_cost=6.2792439460754395
Steps:   2%|▏         | 17709/1000000 [11:58:08<2807:43:07, 10.29s/it, lr=1e-5, step_loss=0.00665]Steps:   2%|▏         | 17710/1000000 [11:58:15<2570:36:06,  9.42s/it, lr=1e-5, step_loss=0.00665][RANK-0]: Step: [17710], local_loss=0.03625185415148735, train_loss=0.015157158486545086, time_cost=2.8190407752990723
Steps:   2%|▏         | 17710/1000000 [11:58:15<2570:36:06,  9.42s/it, lr=1e-5, step_loss=0.0363] Steps:   2%|▏         | 17711/1000000 [11:58:24<2512:16:47,  9.21s/it, lr=1e-5, step_loss=0.0363][RANK-0]: Step: [17711], local_loss=0.06996338069438934, train_loss=0.027253111824393272, time_cost=1.9671742916107178
Steps:   2%|▏         | 17711/1000000 [11:58:24<2512:16:47,  9.21s/it, lr=1e-5, step_loss=0.07]  Steps:   2%|▏         | 17712/1000000 [11:58:38<2872:50:42, 10.53s/it, lr=1e-5, step_loss=0.07][RANK-0]: Step: [17712], local_loss=0.022171182557940483, train_loss=0.04484385997056961, time_cost=3.1264705657958984
Steps:   2%|▏         | 17712/1000000 [11:58:38<2872:50:42, 10.53s/it, lr=1e-5, step_loss=0.0222]Steps:   2%|▏         | 17713/1000000 [11:58:43<2436:29:08,  8.93s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [17713], local_loss=0.19846662878990173, train_loss=0.07171572744846344, time_cost=3.051872968673706
Steps:   2%|▏         | 17713/1000000 [11:58:43<2436:29:08,  8.93s/it, lr=1e-5, step_loss=0.198] Steps:   2%|▏         | 17714/1000000 [11:58:50<2302:16:45,  8.44s/it, lr=1e-5, step_loss=0.198][RANK-0]: Step: [17714], local_loss=0.06342677026987076, train_loss=0.03097669780254364, time_cost=2.660947561264038
Steps:   2%|▏         | 17714/1000000 [11:58:50<2302:16:45,  8.44s/it, lr=1e-5, step_loss=0.0634]Steps:   2%|▏         | 17715/1000000 [11:58:58<2242:23:31,  8.22s/it, lr=1e-5, step_loss=0.0634][RANK-0]: Step: [17715], local_loss=0.02012000046670437, train_loss=0.013214408420026302, time_cost=1.9129230976104736
Steps:   2%|▏         | 17715/1000000 [11:58:58<2242:23:31,  8.22s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 17716/1000000 [11:59:03<1977:40:22,  7.25s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [17716], local_loss=0.024851273745298386, train_loss=0.05184168741106987, time_cost=2.361339807510376
Steps:   2%|▏         | 17716/1000000 [11:59:03<1977:40:22,  7.25s/it, lr=1e-5, step_loss=0.0249]Steps:   2%|▏         | 17717/1000000 [11:59:13<2243:45:49,  8.22s/it, lr=1e-5, step_loss=0.0249][RANK-0]: Step: [17717], local_loss=0.004961606580764055, train_loss=6.201533794403076, time_cost=2.4381611347198486
Steps:   2%|▏         | 17717/1000000 [11:59:13<2243:45:49,  8.22s/it, lr=1e-5, step_loss=0.00496]Steps:   2%|▏         | 17718/1000000 [11:59:25<2553:02:35,  9.36s/it, lr=1e-5, step_loss=0.00496][RANK-0]: Step: [17718], local_loss=0.006155962124466896, train_loss=0.08442185074090958, time_cost=3.904872417449951
Steps:   2%|▏         | 17718/1000000 [11:59:25<2553:02:35,  9.36s/it, lr=1e-5, step_loss=0.00616]Steps:   2%|▏         | 17719/1000000 [11:59:33<2386:19:55,  8.75s/it, lr=1e-5, step_loss=0.00616][RANK-0]: Step: [17719], local_loss=0.048658423125743866, train_loss=0.023826418444514275, time_cost=2.8914597034454346
Steps:   2%|▏         | 17719/1000000 [11:59:33<2386:19:55,  8.75s/it, lr=1e-5, step_loss=0.0487] Steps:   2%|▏         | 17720/1000000 [11:59:40<2248:12:22,  8.24s/it, lr=1e-5, step_loss=0.0487][RANK-0]: Step: [17720], local_loss=0.029198748990893364, train_loss=0.01878269761800766, time_cost=2.9819529056549072
Steps:   2%|▏         | 17720/1000000 [11:59:40<2248:12:22,  8.24s/it, lr=1e-5, step_loss=0.0292]Steps:   2%|▏         | 17721/1000000 [11:59:56<2908:35:44, 10.66s/it, lr=1e-5, step_loss=0.0292][RANK-0]: Step: [17721], local_loss=0.0049859946593642235, train_loss=0.0095209376886487, time_cost=7.210896015167236
Steps:   2%|▏         | 17721/1000000 [11:59:56<2908:35:44, 10.66s/it, lr=1e-5, step_loss=0.00499]Steps:   2%|▏         | 17722/1000000 [12:00:09<3139:53:41, 11.51s/it, lr=1e-5, step_loss=0.00499][RANK-0]: Step: [17722], local_loss=0.015167418867349625, train_loss=0.017722953110933304, time_cost=7.256860256195068
Steps:   2%|▏         | 17722/1000000 [12:00:09<3139:53:41, 11.51s/it, lr=1e-5, step_loss=0.0152] Steps:   2%|▏         | 17723/1000000 [12:00:14<2566:07:36,  9.40s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [17723], local_loss=0.030318772420287132, train_loss=0.015326999127864838, time_cost=1.5673775672912598
Steps:   2%|▏         | 17723/1000000 [12:00:14<2566:07:36,  9.40s/it, lr=1e-5, step_loss=0.0303]Steps:   2%|▏         | 17724/1000000 [12:00:23<2531:30:53,  9.28s/it, lr=1e-5, step_loss=0.0303][RANK-0]: Step: [17724], local_loss=0.01671936921775341, train_loss=0.05695807933807373, time_cost=1.2003889083862305
Steps:   2%|▏         | 17724/1000000 [12:00:23<2531:30:53,  9.28s/it, lr=1e-5, step_loss=0.0167]Steps:   2%|▏         | 17725/1000000 [12:00:28<2172:35:01,  7.96s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [17725], local_loss=0.003620794275775552, train_loss=0.034623753279447556, time_cost=1.7700679302215576
Steps:   2%|▏         | 17725/1000000 [12:00:28<2172:35:01,  7.96s/it, lr=1e-5, step_loss=0.00362]Steps:   2%|▏         | 17726/1000000 [12:00:34<2002:30:59,  7.34s/it, lr=1e-5, step_loss=0.00362][RANK-0]: Step: [17726], local_loss=207.06552124023438, train_loss=25.915576934814453, time_cost=1.685260534286499
Steps:   2%|▏         | 17726/1000000 [12:00:34<2002:30:59,  7.34s/it, lr=1e-5, step_loss=207]    Steps:   2%|▏         | 17727/1000000 [12:00:43<2167:30:19,  7.94s/it, lr=1e-5, step_loss=207][RANK-0]: Step: [17727], local_loss=0.009845023043453693, train_loss=0.04647514969110489, time_cost=3.1143977642059326
Steps:   2%|▏         | 17727/1000000 [12:00:43<2167:30:19,  7.94s/it, lr=1e-5, step_loss=0.00985]Steps:   2%|▏         | 17728/1000000 [12:00:55<2452:57:57,  8.99s/it, lr=1e-5, step_loss=0.00985][RANK-0]: Step: [17728], local_loss=0.007397978100925684, train_loss=0.031064406037330627, time_cost=3.918733835220337
Steps:   2%|▏         | 17728/1000000 [12:00:55<2452:57:57,  8.99s/it, lr=1e-5, step_loss=0.0074] Steps:   2%|▏         | 17729/1000000 [12:01:08<2816:13:19, 10.32s/it, lr=1e-5, step_loss=0.0074][RANK-0]: Step: [17729], local_loss=0.03331111744046211, train_loss=0.03820124268531799, time_cost=3.5652031898498535
Steps:   2%|▏         | 17729/1000000 [12:01:08<2816:13:19, 10.32s/it, lr=1e-5, step_loss=0.0333]Steps:   2%|▏         | 17730/1000000 [12:01:15<2561:01:28,  9.39s/it, lr=1e-5, step_loss=0.0333][RANK-0]: Step: [17730], local_loss=0.005144759081304073, train_loss=0.020113952457904816, time_cost=5.343270778656006
Steps:   2%|▏         | 17730/1000000 [12:01:15<2561:01:28,  9.39s/it, lr=1e-5, step_loss=0.00514]Steps:   2%|▏         | 17731/1000000 [12:01:24<2498:39:50,  9.16s/it, lr=1e-5, step_loss=0.00514][RANK-0]: Step: [17731], local_loss=0.06792166829109192, train_loss=6.022210597991943, time_cost=2.7943499088287354
Steps:   2%|▏         | 17731/1000000 [12:01:24<2498:39:50,  9.16s/it, lr=1e-5, step_loss=0.0679] Steps:   2%|▏         | 17732/1000000 [12:01:38<2919:55:59, 10.70s/it, lr=1e-5, step_loss=0.0679][RANK-0]: Step: [17732], local_loss=0.019374752417206764, train_loss=0.05629095435142517, time_cost=11.462693214416504
Steps:   2%|▏         | 17732/1000000 [12:01:38<2919:55:59, 10.70s/it, lr=1e-5, step_loss=0.0194]Steps:   2%|▏         | 17733/1000000 [12:01:52<3149:02:34, 11.54s/it, lr=1e-5, step_loss=0.0194][RANK-0]: Step: [17733], local_loss=0.12219443917274475, train_loss=0.0504431426525116, time_cost=4.414273977279663
Steps:   2%|▏         | 17733/1000000 [12:01:52<3149:02:34, 11.54s/it, lr=1e-5, step_loss=0.122] Steps:   2%|▏         | 17734/1000000 [12:02:00<2927:58:11, 10.73s/it, lr=1e-5, step_loss=0.122][RANK-0]: Step: [17734], local_loss=0.008449320681393147, train_loss=0.014597135595977306, time_cost=6.60691499710083
Steps:   2%|▏         | 17734/1000000 [12:02:00<2927:58:11, 10.73s/it, lr=1e-5, step_loss=0.00845]Steps:   2%|▏         | 17735/1000000 [12:02:08<2633:20:35,  9.65s/it, lr=1e-5, step_loss=0.00845][RANK-0]: Step: [17735], local_loss=0.04983080178499222, train_loss=0.014443510212004185, time_cost=2.8145267963409424
Steps:   2%|▏         | 17735/1000000 [12:02:08<2633:20:35,  9.65s/it, lr=1e-5, step_loss=0.0498] Steps:   2%|▏         | 17736/1000000 [12:02:13<2251:12:47,  8.25s/it, lr=1e-5, step_loss=0.0498][RANK-0]: Step: [17736], local_loss=0.011322062462568283, train_loss=0.018249616026878357, time_cost=2.080042600631714
Steps:   2%|▏         | 17736/1000000 [12:02:13<2251:12:47,  8.25s/it, lr=1e-5, step_loss=0.0113]Steps:   2%|▏         | 17737/1000000 [12:02:23<2447:40:17,  8.97s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [17737], local_loss=0.0076489816419780254, train_loss=0.020916709676384926, time_cost=1.391021966934204
Steps:   2%|▏         | 17737/1000000 [12:02:23<2447:40:17,  8.97s/it, lr=1e-5, step_loss=0.00765]Steps:   2%|▏         | 17738/1000000 [12:02:37<2864:49:16, 10.50s/it, lr=1e-5, step_loss=0.00765][RANK-0]: Step: [17738], local_loss=0.008365020155906677, train_loss=0.03096969798207283, time_cost=1.2910010814666748
Steps:   2%|▏         | 17738/1000000 [12:02:37<2864:49:16, 10.50s/it, lr=1e-5, step_loss=0.00837]Steps:   2%|▏         | 17739/1000000 [12:02:46<2753:38:03, 10.09s/it, lr=1e-5, step_loss=0.00837][RANK-0]: Step: [17739], local_loss=0.01740962453186512, train_loss=0.022703709080815315, time_cost=3.3686273097991943
Steps:   2%|▏         | 17739/1000000 [12:02:46<2753:38:03, 10.09s/it, lr=1e-5, step_loss=0.0174] Steps:   2%|▏         | 17740/1000000 [12:02:53<2494:52:34,  9.14s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [17740], local_loss=0.04554948955774307, train_loss=0.02493904158473015, time_cost=2.5385658740997314
Steps:   2%|▏         | 17740/1000000 [12:02:53<2494:52:34,  9.14s/it, lr=1e-5, step_loss=0.0455]Steps:   2%|▏         | 17741/1000000 [12:03:01<2357:18:25,  8.64s/it, lr=1e-5, step_loss=0.0455][RANK-0]: Step: [17741], local_loss=13.561931610107422, train_loss=1.7324719429016113, time_cost=3.2218503952026367
Steps:   2%|▏         | 17741/1000000 [12:03:01<2357:18:25,  8.64s/it, lr=1e-5, step_loss=13.6]  Steps:   2%|▏         | 17742/1000000 [12:03:12<2541:19:54,  9.31s/it, lr=1e-5, step_loss=13.6][RANK-0]: Step: [17742], local_loss=0.007235904689878225, train_loss=0.06913922727108002, time_cost=3.087820053100586
Steps:   2%|▏         | 17742/1000000 [12:03:12<2541:19:54,  9.31s/it, lr=1e-5, step_loss=0.00724]Steps:   2%|▏         | 17743/1000000 [12:03:18<2285:52:39,  8.38s/it, lr=1e-5, step_loss=0.00724][RANK-0]: Step: [17743], local_loss=0.025568634271621704, train_loss=0.014056723564863205, time_cost=5.065240383148193
Steps:   2%|▏         | 17743/1000000 [12:03:18<2285:52:39,  8.38s/it, lr=1e-5, step_loss=0.0256] Steps:   2%|▏         | 17744/1000000 [12:03:24<2099:06:26,  7.69s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [17744], local_loss=0.07691048830747604, train_loss=0.11994906514883041, time_cost=1.6705482006072998
Steps:   2%|▏         | 17744/1000000 [12:03:24<2099:06:26,  7.69s/it, lr=1e-5, step_loss=0.0769]Steps:   2%|▏         | 17745/1000000 [12:03:28<1824:34:20,  6.69s/it, lr=1e-5, step_loss=0.0769][RANK-0]: Step: [17745], local_loss=0.0052384561859071255, train_loss=0.03073767013847828, time_cost=1.2963473796844482
Steps:   2%|▏         | 17745/1000000 [12:03:28<1824:34:20,  6.69s/it, lr=1e-5, step_loss=0.00524]Steps:   2%|▏         | 17746/1000000 [12:03:40<2223:55:02,  8.15s/it, lr=1e-5, step_loss=0.00524][RANK-0]: Step: [17746], local_loss=0.011383934877812862, train_loss=0.08517733216285706, time_cost=3.6240503787994385
Steps:   2%|▏         | 17746/1000000 [12:03:40<2223:55:02,  8.15s/it, lr=1e-5, step_loss=0.0114] Steps:   2%|▏         | 17747/1000000 [12:03:51<2474:28:23,  9.07s/it, lr=1e-5, step_loss=0.0114][RANK-0]: Step: [17747], local_loss=0.46812155842781067, train_loss=0.12932240962982178, time_cost=2.8029541969299316
Steps:   2%|▏         | 17747/1000000 [12:03:51<2474:28:23,  9.07s/it, lr=1e-5, step_loss=0.468] Steps:   2%|▏         | 17748/1000000 [12:04:05<2911:30:12, 10.67s/it, lr=1e-5, step_loss=0.468][RANK-0]: Step: [17748], local_loss=0.00546248210594058, train_loss=0.059262461960315704, time_cost=7.0900256633758545
Steps:   2%|▏         | 17748/1000000 [12:04:05<2911:30:12, 10.67s/it, lr=1e-5, step_loss=0.00546]Steps:   2%|▏         | 17749/1000000 [12:04:14<2752:29:17, 10.09s/it, lr=1e-5, step_loss=0.00546][RANK-0]: Step: [17749], local_loss=0.005353486631065607, train_loss=0.045693546533584595, time_cost=1.2300360202789307
Steps:   2%|▏         | 17749/1000000 [12:04:14<2752:29:17, 10.09s/it, lr=1e-5, step_loss=0.00535]Steps:   2%|▏         | 17750/1000000 [12:04:30<3204:52:43, 11.75s/it, lr=1e-5, step_loss=0.00535][RANK-0]: Step: [17750], local_loss=0.03602418303489685, train_loss=0.07289446145296097, time_cost=7.2852091789245605
Steps:   2%|▏         | 17750/1000000 [12:04:30<3204:52:43, 11.75s/it, lr=1e-5, step_loss=0.036]  Steps:   2%|▏         | 17751/1000000 [12:04:37<2809:55:23, 10.30s/it, lr=1e-5, step_loss=0.036][RANK-0]: Step: [17751], local_loss=0.12031406164169312, train_loss=0.04046378657221794, time_cost=1.3022997379302979
Steps:   2%|▏         | 17751/1000000 [12:04:37<2809:55:23, 10.30s/it, lr=1e-5, step_loss=0.12] Steps:   2%|▏         | 17752/1000000 [12:04:52<3229:35:20, 11.84s/it, lr=1e-5, step_loss=0.12][RANK-0]: Step: [17752], local_loss=0.023625317960977554, train_loss=0.058881424367427826, time_cost=3.144958019256592
Steps:   2%|▏         | 17752/1000000 [12:04:52<3229:35:20, 11.84s/it, lr=1e-5, step_loss=0.0236]Steps:   2%|▏         | 17753/1000000 [12:04:57<2624:33:04,  9.62s/it, lr=1e-5, step_loss=0.0236][RANK-0]: Step: [17753], local_loss=0.012324163690209389, train_loss=0.013594104908406734, time_cost=3.6650848388671875
Steps:   2%|▏         | 17753/1000000 [12:04:57<2624:33:04,  9.62s/it, lr=1e-5, step_loss=0.0123]Steps:   2%|▏         | 17754/1000000 [12:05:05<2509:52:55,  9.20s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [17754], local_loss=0.025158744305372238, train_loss=0.032791461795568466, time_cost=1.7681808471679688
Steps:   2%|▏         | 17754/1000000 [12:05:05<2509:52:55,  9.20s/it, lr=1e-5, step_loss=0.0252]Steps:   2%|▏         | 17755/1000000 [12:05:12<2348:01:19,  8.61s/it, lr=1e-5, step_loss=0.0252][RANK-0]: Step: [17755], local_loss=0.017654435709118843, train_loss=0.03601083159446716, time_cost=2.729275941848755
Steps:   2%|▏         | 17755/1000000 [12:05:12<2348:01:19,  8.61s/it, lr=1e-5, step_loss=0.0177]Steps:   2%|▏         | 17756/1000000 [12:05:17<2064:39:18,  7.57s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [17756], local_loss=0.007541388273239136, train_loss=0.0772705078125, time_cost=2.4471898078918457
Steps:   2%|▏         | 17756/1000000 [12:05:17<2064:39:18,  7.57s/it, lr=1e-5, step_loss=0.00754]Steps:   2%|▏         | 17757/1000000 [12:05:25<2051:36:20,  7.52s/it, lr=1e-5, step_loss=0.00754][RANK-0]: Step: [17757], local_loss=0.0055092256516218185, train_loss=0.06377927213907242, time_cost=3.2131574153900146
Steps:   2%|▏         | 17757/1000000 [12:05:25<2051:36:20,  7.52s/it, lr=1e-5, step_loss=0.00551]Steps:   2%|▏         | 17758/1000000 [12:05:30<1859:12:37,  6.81s/it, lr=1e-5, step_loss=0.00551][RANK-0]: Step: [17758], local_loss=0.009015679359436035, train_loss=0.09123881906270981, time_cost=2.121546983718872
Steps:   2%|▏         | 17758/1000000 [12:05:30<1859:12:37,  6.81s/it, lr=1e-5, step_loss=0.00902]Steps:   2%|▏         | 17759/1000000 [12:05:44<2466:59:49,  9.04s/it, lr=1e-5, step_loss=0.00902][RANK-0]: Step: [17759], local_loss=0.010478357784450054, train_loss=0.04577464982867241, time_cost=2.784874677658081
Steps:   2%|▏         | 17759/1000000 [12:05:44<2466:59:49,  9.04s/it, lr=1e-5, step_loss=0.0105] Steps:   2%|▏         | 17760/1000000 [12:05:50<2242:29:13,  8.22s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [17760], local_loss=0.005652768537402153, train_loss=0.015098332427442074, time_cost=2.3975677490234375
Steps:   2%|▏         | 17760/1000000 [12:05:50<2242:29:13,  8.22s/it, lr=1e-5, step_loss=0.00565]Steps:   2%|▏         | 17761/1000000 [12:05:58<2173:58:44,  7.97s/it, lr=1e-5, step_loss=0.00565][RANK-0]: Step: [17761], local_loss=0.010193660855293274, train_loss=0.034884512424468994, time_cost=3.0931766033172607
Steps:   2%|▏         | 17761/1000000 [12:05:58<2173:58:44,  7.97s/it, lr=1e-5, step_loss=0.0102] Steps:   2%|▏         | 17762/1000000 [12:06:04<2015:12:31,  7.39s/it, lr=1e-5, step_loss=0.0102][RANK-0]: Step: [17762], local_loss=0.02956797555088997, train_loss=38.72224807739258, time_cost=1.6316921710968018
Steps:   2%|▏         | 17762/1000000 [12:06:04<2015:12:31,  7.39s/it, lr=1e-5, step_loss=0.0296]Steps:   2%|▏         | 17763/1000000 [12:06:13<2160:13:12,  7.92s/it, lr=1e-5, step_loss=0.0296][RANK-0]: Step: [17763], local_loss=0.12914703786373138, train_loss=0.053539399057626724, time_cost=3.3401761054992676
Steps:   2%|▏         | 17763/1000000 [12:06:13<2160:13:12,  7.92s/it, lr=1e-5, step_loss=0.129] Steps:   2%|▏         | 17764/1000000 [12:06:18<1903:13:56,  6.98s/it, lr=1e-5, step_loss=0.129][RANK-0]: Step: [17764], local_loss=0.03429046645760536, train_loss=0.056562311947345734, time_cost=1.8812637329101562
Steps:   2%|▏         | 17764/1000000 [12:06:18<1903:13:56,  6.98s/it, lr=1e-5, step_loss=0.0343]Steps:   2%|▏         | 17765/1000000 [12:06:27<2077:38:45,  7.61s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [17765], local_loss=0.2883220314979553, train_loss=0.07576635479927063, time_cost=3.847858190536499
Steps:   2%|▏         | 17765/1000000 [12:06:27<2077:38:45,  7.61s/it, lr=1e-5, step_loss=0.288] Steps:   2%|▏         | 17766/1000000 [12:06:31<1815:00:46,  6.65s/it, lr=1e-5, step_loss=0.288][RANK-0]: Step: [17766], local_loss=0.029515286907553673, train_loss=0.022706199437379837, time_cost=3.1690444946289062
Steps:   2%|▏         | 17766/1000000 [12:06:31<1815:00:46,  6.65s/it, lr=1e-5, step_loss=0.0295]Steps:   2%|▏         | 17767/1000000 [12:06:37<1706:35:37,  6.25s/it, lr=1e-5, step_loss=0.0295][RANK-0]: Step: [17767], local_loss=0.06753496080636978, train_loss=0.037429288029670715, time_cost=1.7388639450073242
Steps:   2%|▏         | 17767/1000000 [12:06:37<1706:35:37,  6.25s/it, lr=1e-5, step_loss=0.0675]Steps:   2%|▏         | 17768/1000000 [12:06:41<1557:25:10,  5.71s/it, lr=1e-5, step_loss=0.0675][RANK-0]: Step: [17768], local_loss=0.12254777550697327, train_loss=0.03988080471754074, time_cost=1.4760973453521729
Steps:   2%|▏         | 17768/1000000 [12:06:41<1557:25:10,  5.71s/it, lr=1e-5, step_loss=0.123] Steps:   2%|▏         | 17769/1000000 [12:06:47<1554:45:04,  5.70s/it, lr=1e-5, step_loss=0.123][RANK-0]: Step: [17769], local_loss=0.03423798829317093, train_loss=0.061873823404312134, time_cost=2.958162307739258
Steps:   2%|▏         | 17769/1000000 [12:06:47<1554:45:04,  5.70s/it, lr=1e-5, step_loss=0.0342]Steps:   2%|▏         | 17770/1000000 [12:07:00<2144:48:12,  7.86s/it, lr=1e-5, step_loss=0.0342][RANK-0]: Step: [17770], local_loss=0.008241797797381878, train_loss=0.08515619486570358, time_cost=7.039396524429321
Steps:   2%|▏         | 17770/1000000 [12:07:00<2144:48:12,  7.86s/it, lr=1e-5, step_loss=0.00824]Steps:   2%|▏         | 17771/1000000 [12:07:09<2316:04:22,  8.49s/it, lr=1e-5, step_loss=0.00824][RANK-0]: Step: [17771], local_loss=0.09827540069818497, train_loss=0.03423459082841873, time_cost=2.7948222160339355
Steps:   2%|▏         | 17771/1000000 [12:07:09<2316:04:22,  8.49s/it, lr=1e-5, step_loss=0.0983] Steps:   2%|▏         | 17772/1000000 [12:07:21<2534:02:45,  9.29s/it, lr=1e-5, step_loss=0.0983][RANK-0]: Step: [17772], local_loss=0.05916237086057663, train_loss=0.0697539746761322, time_cost=4.6491334438323975
Steps:   2%|▏         | 17772/1000000 [12:07:21<2534:02:45,  9.29s/it, lr=1e-5, step_loss=0.0592]Steps:   2%|▏         | 17773/1000000 [12:07:27<2268:28:39,  8.31s/it, lr=1e-5, step_loss=0.0592][RANK-0]: Step: [17773], local_loss=0.02384071983397007, train_loss=0.058536604046821594, time_cost=1.7725510597229004
Steps:   2%|▏         | 17773/1000000 [12:07:27<2268:28:39,  8.31s/it, lr=1e-5, step_loss=0.0238]Steps:   2%|▏         | 17774/1000000 [12:07:32<2046:06:47,  7.50s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [17774], local_loss=0.01860092207789421, train_loss=0.02757115662097931, time_cost=1.2298941612243652
Steps:   2%|▏         | 17774/1000000 [12:07:32<2046:06:47,  7.50s/it, lr=1e-5, step_loss=0.0186]Steps:   2%|▏         | 17775/1000000 [12:07:41<2155:47:36,  7.90s/it, lr=1e-5, step_loss=0.0186][RANK-0]: Step: [17775], local_loss=0.06627220660448074, train_loss=0.053724728524684906, time_cost=1.8155174255371094
Steps:   2%|▏         | 17775/1000000 [12:07:41<2155:47:36,  7.90s/it, lr=1e-5, step_loss=0.0663]Steps:   2%|▏         | 17776/1000000 [12:07:48<2096:26:56,  7.68s/it, lr=1e-5, step_loss=0.0663][RANK-0]: Step: [17776], local_loss=0.010048606432974339, train_loss=0.021251395344734192, time_cost=1.2471363544464111
Steps:   2%|▏         | 17776/1000000 [12:07:48<2096:26:56,  7.68s/it, lr=1e-5, step_loss=0.01]  Steps:   2%|▏         | 17777/1000000 [12:07:53<1821:06:35,  6.67s/it, lr=1e-5, step_loss=0.01][RANK-0]: Step: [17777], local_loss=0.01129878405481577, train_loss=0.032179392874240875, time_cost=1.4122908115386963
Steps:   2%|▏         | 17777/1000000 [12:07:53<1821:06:35,  6.67s/it, lr=1e-5, step_loss=0.0113]Steps:   2%|▏         | 17778/1000000 [12:07:58<1709:03:18,  6.26s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [17778], local_loss=0.011037365533411503, train_loss=0.06097412109375, time_cost=1.4414141178131104
Steps:   2%|▏         | 17778/1000000 [12:07:58<1709:03:18,  6.26s/it, lr=1e-5, step_loss=0.011] Steps:   2%|▏         | 17779/1000000 [12:08:04<1682:24:57,  6.17s/it, lr=1e-5, step_loss=0.011][RANK-0]: Step: [17779], local_loss=0.01532154344022274, train_loss=0.035333868116140366, time_cost=1.349355936050415
Steps:   2%|▏         | 17779/1000000 [12:08:04<1682:24:57,  6.17s/it, lr=1e-5, step_loss=0.0153]Steps:   2%|▏         | 17780/1000000 [12:08:15<2070:04:23,  7.59s/it, lr=1e-5, step_loss=0.0153][RANK-0]: Step: [17780], local_loss=0.27773866057395935, train_loss=0.05878084525465965, time_cost=8.876327991485596
Steps:   2%|▏         | 17780/1000000 [12:08:15<2070:04:23,  7.59s/it, lr=1e-5, step_loss=0.278] Steps:   2%|▏         | 17781/1000000 [12:08:27<2429:29:35,  8.90s/it, lr=1e-5, step_loss=0.278][RANK-0]: Step: [17781], local_loss=0.08592092245817184, train_loss=0.03830338269472122, time_cost=3.013108730316162
Steps:   2%|▏         | 17781/1000000 [12:08:27<2429:29:35,  8.90s/it, lr=1e-5, step_loss=0.0859]Steps:   2%|▏         | 17782/1000000 [12:08:33<2249:19:27,  8.24s/it, lr=1e-5, step_loss=0.0859][RANK-0]: Step: [17782], local_loss=0.07495620846748352, train_loss=0.033680982887744904, time_cost=3.050671339035034
Steps:   2%|▏         | 17782/1000000 [12:08:33<2249:19:27,  8.24s/it, lr=1e-5, step_loss=0.075] Steps:   2%|▏         | 17783/1000000 [12:08:41<2231:54:59,  8.18s/it, lr=1e-5, step_loss=0.075][RANK-0]: Step: [17783], local_loss=0.013039572164416313, train_loss=0.027317997068166733, time_cost=2.8936920166015625
Steps:   2%|▏         | 17783/1000000 [12:08:41<2231:54:59,  8.18s/it, lr=1e-5, step_loss=0.013]Steps:   2%|▏         | 17784/1000000 [12:08:48<2121:32:47,  7.78s/it, lr=1e-5, step_loss=0.013][RANK-0]: Step: [17784], local_loss=0.019086750224232674, train_loss=0.02065894566476345, time_cost=1.460425853729248
Steps:   2%|▏         | 17784/1000000 [12:08:48<2121:32:47,  7.78s/it, lr=1e-5, step_loss=0.0191]Steps:   2%|▏         | 17785/1000000 [12:08:54<1961:22:20,  7.19s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [17785], local_loss=0.028321564197540283, train_loss=0.07121852785348892, time_cost=1.8746929168701172
Steps:   2%|▏         | 17785/1000000 [12:08:54<1961:22:20,  7.19s/it, lr=1e-5, step_loss=0.0283]Steps:   2%|▏         | 17786/1000000 [12:09:03<2095:31:31,  7.68s/it, lr=1e-5, step_loss=0.0283][RANK-0]: Step: [17786], local_loss=0.004482329357415438, train_loss=0.04037110507488251, time_cost=4.032687187194824
Steps:   2%|▏         | 17786/1000000 [12:09:03<2095:31:31,  7.68s/it, lr=1e-5, step_loss=0.00448]Steps:   2%|▏         | 17787/1000000 [12:09:08<1873:05:43,  6.87s/it, lr=1e-5, step_loss=0.00448][RANK-0]: Step: [17787], local_loss=0.057157646864652634, train_loss=0.025601543486118317, time_cost=1.2262918949127197
Steps:   2%|▏         | 17787/1000000 [12:09:08<1873:05:43,  6.87s/it, lr=1e-5, step_loss=0.0572] Steps:   2%|▏         | 17788/1000000 [12:09:14<1836:58:51,  6.73s/it, lr=1e-5, step_loss=0.0572][RANK-0]: Step: [17788], local_loss=0.06794317811727524, train_loss=0.04469263553619385, time_cost=1.9679598808288574
Steps:   2%|▏         | 17788/1000000 [12:09:14<1836:58:51,  6.73s/it, lr=1e-5, step_loss=0.0679]Steps:   2%|▏         | 17789/1000000 [12:09:28<2428:23:25,  8.90s/it, lr=1e-5, step_loss=0.0679][RANK-0]: Step: [17789], local_loss=0.004351608920842409, train_loss=0.0827290266752243, time_cost=5.4169347286224365
Steps:   2%|▏         | 17789/1000000 [12:09:28<2428:23:25,  8.90s/it, lr=1e-5, step_loss=0.00435]Steps:   2%|▏         | 17790/1000000 [12:09:38<2456:53:05,  9.00s/it, lr=1e-5, step_loss=0.00435][RANK-0]: Step: [17790], local_loss=0.022494828328490257, train_loss=0.01862930878996849, time_cost=3.2436704635620117
Steps:   2%|▏         | 17790/1000000 [12:09:38<2456:53:05,  9.00s/it, lr=1e-5, step_loss=0.0225] Steps:   2%|▏         | 17791/1000000 [12:09:48<2600:15:00,  9.53s/it, lr=1e-5, step_loss=0.0225][RANK-0]: Step: [17791], local_loss=0.01872924156486988, train_loss=26.709671020507812, time_cost=1.7417409420013428
Steps:   2%|▏         | 17791/1000000 [12:09:48<2600:15:00,  9.53s/it, lr=1e-5, step_loss=0.0187]Steps:   2%|▏         | 17792/1000000 [12:09:54<2288:44:46,  8.39s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [17792], local_loss=0.05966584011912346, train_loss=0.022970564663410187, time_cost=3.0428884029388428
Steps:   2%|▏         | 17792/1000000 [12:09:54<2288:44:46,  8.39s/it, lr=1e-5, step_loss=0.0597]Steps:   2%|▏         | 17793/1000000 [12:10:08<2744:49:38, 10.06s/it, lr=1e-5, step_loss=0.0597][RANK-0]: Step: [17793], local_loss=0.046586085110902786, train_loss=0.06898795068264008, time_cost=5.870790481567383
Steps:   2%|▏         | 17793/1000000 [12:10:08<2744:49:38, 10.06s/it, lr=1e-5, step_loss=0.0466]Steps:   2%|▏         | 17794/1000000 [12:10:14<2404:21:14,  8.81s/it, lr=1e-5, step_loss=0.0466][RANK-0]: Step: [17794], local_loss=0.024584505707025528, train_loss=0.0621311217546463, time_cost=1.6172146797180176
Steps:   2%|▏         | 17794/1000000 [12:10:14<2404:21:14,  8.81s/it, lr=1e-5, step_loss=0.0246]Steps:   2%|▏         | 17795/1000000 [12:10:22<2321:12:46,  8.51s/it, lr=1e-5, step_loss=0.0246][RANK-0]: Step: [17795], local_loss=0.035835716873407364, train_loss=0.03920796513557434, time_cost=3.4277496337890625
Steps:   2%|▏         | 17795/1000000 [12:10:22<2321:12:46,  8.51s/it, lr=1e-5, step_loss=0.0358]Steps:   2%|▏         | 17796/1000000 [12:10:29<2250:30:41,  8.25s/it, lr=1e-5, step_loss=0.0358][RANK-0]: Step: [17796], local_loss=0.007357222959399223, train_loss=0.031001776456832886, time_cost=2.0762734413146973
Steps:   2%|▏         | 17796/1000000 [12:10:29<2250:30:41,  8.25s/it, lr=1e-5, step_loss=0.00736]Steps:   2%|▏         | 17797/1000000 [12:10:35<2052:34:08,  7.52s/it, lr=1e-5, step_loss=0.00736][RANK-0]: Step: [17797], local_loss=0.008866171352565289, train_loss=0.03726955130696297, time_cost=1.3261864185333252
Steps:   2%|▏         | 17797/1000000 [12:10:35<2052:34:08,  7.52s/it, lr=1e-5, step_loss=0.00887]Steps:   2%|▏         | 17798/1000000 [12:10:51<2736:53:56, 10.03s/it, lr=1e-5, step_loss=0.00887][RANK-0]: Step: [17798], local_loss=0.04187912866473198, train_loss=0.04300326853990555, time_cost=8.032742500305176
Steps:   2%|▏         | 17798/1000000 [12:10:51<2736:53:56, 10.03s/it, lr=1e-5, step_loss=0.0419] Steps:   2%|▏         | 17799/1000000 [12:10:56<2358:04:00,  8.64s/it, lr=1e-5, step_loss=0.0419][RANK-0]: Step: [17799], local_loss=0.007815445773303509, train_loss=0.04341348260641098, time_cost=1.5701358318328857
Steps:   2%|▏         | 17799/1000000 [12:10:56<2358:04:00,  8.64s/it, lr=1e-5, step_loss=0.00782]Steps:   2%|▏         | 17800/1000000 [12:11:01<2022:12:03,  7.41s/it, lr=1e-5, step_loss=0.00782][RANK-0]: Step: [17800], local_loss=0.00916201900690794, train_loss=0.02039751037955284, time_cost=1.2264835834503174
Steps:   2%|▏         | 17800/1000000 [12:11:01<2022:12:03,  7.41s/it, lr=1e-5, step_loss=0.00916]Steps:   2%|▏         | 17801/1000000 [12:11:11<2273:35:42,  8.33s/it, lr=1e-5, step_loss=0.00916][RANK-0]: Step: [17801], local_loss=0.02156904526054859, train_loss=0.115391805768013, time_cost=1.205371379852295
Steps:   2%|▏         | 17801/1000000 [12:11:11<2273:35:42,  8.33s/it, lr=1e-5, step_loss=0.0216] Steps:   2%|▏         | 17802/1000000 [12:11:18<2164:27:02,  7.93s/it, lr=1e-5, step_loss=0.0216][RANK-0]: Step: [17802], local_loss=0.004594660364091396, train_loss=0.021291812881827354, time_cost=2.5934770107269287
Steps:   2%|▏         | 17802/1000000 [12:11:18<2164:27:02,  7.93s/it, lr=1e-5, step_loss=0.00459]Steps:   2%|▏         | 17803/1000000 [12:11:25<2012:23:10,  7.38s/it, lr=1e-5, step_loss=0.00459][RANK-0]: Step: [17803], local_loss=0.03594376519322395, train_loss=0.038773808628320694, time_cost=1.6675641536712646
Steps:   2%|▏         | 17803/1000000 [12:11:25<2012:23:10,  7.38s/it, lr=1e-5, step_loss=0.0359] Steps:   2%|▏         | 17804/1000000 [12:11:30<1845:51:37,  6.77s/it, lr=1e-5, step_loss=0.0359][RANK-0]: Step: [17804], local_loss=0.006019848398864269, train_loss=0.034950654953718185, time_cost=4.120055913925171
Steps:   2%|▏         | 17804/1000000 [12:11:30<1845:51:37,  6.77s/it, lr=1e-5, step_loss=0.00602]Steps:   2%|▏         | 17805/1000000 [12:11:35<1715:58:38,  6.29s/it, lr=1e-5, step_loss=0.00602][RANK-0]: Step: [17805], local_loss=0.23904366791248322, train_loss=0.06796103715896606, time_cost=2.2500829696655273
Steps:   2%|▏         | 17805/1000000 [12:11:35<1715:58:38,  6.29s/it, lr=1e-5, step_loss=0.239]  Steps:   2%|▏         | 17806/1000000 [12:11:45<1990:29:15,  7.30s/it, lr=1e-5, step_loss=0.239][RANK-0]: Step: [17806], local_loss=0.01092881616204977, train_loss=0.027949947863817215, time_cost=3.6962668895721436
Steps:   2%|▏         | 17806/1000000 [12:11:45<1990:29:15,  7.30s/it, lr=1e-5, step_loss=0.0109]Steps:   2%|▏         | 17807/1000000 [12:12:00<2650:59:56,  9.72s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [17807], local_loss=0.045539140701293945, train_loss=0.024273261427879333, time_cost=7.471825122833252
Steps:   2%|▏         | 17807/1000000 [12:12:00<2650:59:56,  9.72s/it, lr=1e-5, step_loss=0.0455]Steps:   2%|▏         | 17808/1000000 [12:12:09<2583:25:02,  9.47s/it, lr=1e-5, step_loss=0.0455][RANK-0]: Step: [17808], local_loss=0.019188852980732918, train_loss=0.016989856958389282, time_cost=3.291396141052246
Steps:   2%|▏         | 17808/1000000 [12:12:09<2583:25:02,  9.47s/it, lr=1e-5, step_loss=0.0192]Steps:   2%|▏         | 17809/1000000 [12:12:20<2721:28:02,  9.97s/it, lr=1e-5, step_loss=0.0192][RANK-0]: Step: [17809], local_loss=0.00798437837511301, train_loss=0.025113970041275024, time_cost=3.6806302070617676
Steps:   2%|▏         | 17809/1000000 [12:12:20<2721:28:02,  9.97s/it, lr=1e-5, step_loss=0.00798]Steps:   2%|▏         | 17810/1000000 [12:12:29<2657:54:19,  9.74s/it, lr=1e-5, step_loss=0.00798][RANK-0]: Step: [17810], local_loss=0.037119895219802856, train_loss=0.07624085992574692, time_cost=3.2360925674438477
Steps:   2%|▏         | 17810/1000000 [12:12:29<2657:54:19,  9.74s/it, lr=1e-5, step_loss=0.0371] Steps:   2%|▏         | 17811/1000000 [12:12:44<3067:46:11, 11.24s/it, lr=1e-5, step_loss=0.0371][RANK-0]: Step: [17811], local_loss=0.04690815135836601, train_loss=0.04374924302101135, time_cost=5.312042951583862
Steps:   2%|▏         | 17811/1000000 [12:12:44<3067:46:11, 11.24s/it, lr=1e-5, step_loss=0.0469]Steps:   2%|▏         | 17812/1000000 [12:12:59<3333:09:06, 12.22s/it, lr=1e-5, step_loss=0.0469][RANK-0]: Step: [17812], local_loss=0.11408664286136627, train_loss=0.027209322899580002, time_cost=3.230175256729126
Steps:   2%|▏         | 17812/1000000 [12:12:59<3333:09:06, 12.22s/it, lr=1e-5, step_loss=0.114] Steps:   2%|▏         | 17813/1000000 [12:13:04<2751:32:10, 10.09s/it, lr=1e-5, step_loss=0.114][RANK-0]: Step: [17813], local_loss=0.02011777088046074, train_loss=0.1498890221118927, time_cost=3.900874614715576
Steps:   2%|▏         | 17813/1000000 [12:13:04<2751:32:10, 10.09s/it, lr=1e-5, step_loss=0.0201]Steps:   2%|▏         | 17814/1000000 [12:13:08<2306:17:11,  8.45s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [17814], local_loss=0.1422896534204483, train_loss=0.049924205988645554, time_cost=2.2997548580169678
Steps:   2%|▏         | 17814/1000000 [12:13:08<2306:17:11,  8.45s/it, lr=1e-5, step_loss=0.142] Steps:   2%|▏         | 17815/1000000 [12:13:22<2749:03:13, 10.08s/it, lr=1e-5, step_loss=0.142][RANK-0]: Step: [17815], local_loss=0.008919292129576206, train_loss=0.03117399476468563, time_cost=5.8292601108551025
Steps:   2%|▏         | 17815/1000000 [12:13:22<2749:03:13, 10.08s/it, lr=1e-5, step_loss=0.00892]Steps:   2%|▏         | 17816/1000000 [12:13:30<2553:15:21,  9.36s/it, lr=1e-5, step_loss=0.00892][RANK-0]: Step: [17816], local_loss=0.01774296909570694, train_loss=0.02154868096113205, time_cost=1.8579258918762207
Steps:   2%|▏         | 17816/1000000 [12:13:30<2553:15:21,  9.36s/it, lr=1e-5, step_loss=0.0177] Steps:   2%|▏         | 17817/1000000 [12:13:41<2705:48:15,  9.92s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [17817], local_loss=0.008145862258970737, train_loss=0.04164840281009674, time_cost=2.8245656490325928
Steps:   2%|▏         | 17817/1000000 [12:13:41<2705:48:15,  9.92s/it, lr=1e-5, step_loss=0.00815]Steps:   2%|▏         | 17818/1000000 [12:13:47<2379:43:41,  8.72s/it, lr=1e-5, step_loss=0.00815][RANK-0]: Step: [17818], local_loss=0.017050612717866898, train_loss=0.03883139789104462, time_cost=1.4164454936981201
Steps:   2%|▏         | 17818/1000000 [12:13:47<2379:43:41,  8.72s/it, lr=1e-5, step_loss=0.0171] Steps:   2%|▏         | 17819/1000000 [12:13:54<2233:39:22,  8.19s/it, lr=1e-5, step_loss=0.0171][RANK-0]: Step: [17819], local_loss=0.02946210466325283, train_loss=0.0420946329832077, time_cost=3.263292074203491
Steps:   2%|▏         | 17819/1000000 [12:13:54<2233:39:22,  8.19s/it, lr=1e-5, step_loss=0.0295]Steps:   2%|▏         | 17820/1000000 [12:14:03<2275:19:47,  8.34s/it, lr=1e-5, step_loss=0.0295][RANK-0]: Step: [17820], local_loss=0.03641355782747269, train_loss=0.028365295380353928, time_cost=3.003934860229492
Steps:   2%|▏         | 17820/1000000 [12:14:03<2275:19:47,  8.34s/it, lr=1e-5, step_loss=0.0364]Steps:   2%|▏         | 17821/1000000 [12:14:10<2199:45:13,  8.06s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [17821], local_loss=0.011207466945052147, train_loss=0.056807730346918106, time_cost=2.369304656982422
Steps:   2%|▏         | 17821/1000000 [12:14:10<2199:45:13,  8.06s/it, lr=1e-5, step_loss=0.0112]Steps:   2%|▏         | 17822/1000000 [12:14:24<2655:30:10,  9.73s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [17822], local_loss=0.005769128445535898, train_loss=0.0476553700864315, time_cost=1.226562738418579
Steps:   2%|▏         | 17822/1000000 [12:14:24<2655:30:10,  9.73s/it, lr=1e-5, step_loss=0.00577]Steps:   2%|▏         | 17823/1000000 [12:14:34<2738:22:48, 10.04s/it, lr=1e-5, step_loss=0.00577][RANK-0]: Step: [17823], local_loss=0.017215020954608917, train_loss=0.05759128928184509, time_cost=2.003155469894409
Steps:   2%|▏         | 17823/1000000 [12:14:34<2738:22:48, 10.04s/it, lr=1e-5, step_loss=0.0172] Steps:   2%|▏         | 17824/1000000 [12:14:43<2643:27:04,  9.69s/it, lr=1e-5, step_loss=0.0172][RANK-0]: Step: [17824], local_loss=0.035993725061416626, train_loss=0.044799380004405975, time_cost=2.002019166946411
Steps:   2%|▏         | 17824/1000000 [12:14:43<2643:27:04,  9.69s/it, lr=1e-5, step_loss=0.036] Steps:   2%|▏         | 17825/1000000 [12:14:52<2589:17:59,  9.49s/it, lr=1e-5, step_loss=0.036][RANK-0]: Step: [17825], local_loss=0.012405955232679844, train_loss=0.030873063951730728, time_cost=1.2163324356079102
Steps:   2%|▏         | 17825/1000000 [12:14:52<2589:17:59,  9.49s/it, lr=1e-5, step_loss=0.0124]Steps:   2%|▏         | 17826/1000000 [12:15:06<2929:19:19, 10.74s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [17826], local_loss=0.01662786677479744, train_loss=0.025964688509702682, time_cost=4.997202634811401
Steps:   2%|▏         | 17826/1000000 [12:15:06<2929:19:19, 10.74s/it, lr=1e-5, step_loss=0.0166]Steps:   2%|▏         | 17827/1000000 [12:15:12<2541:18:32,  9.31s/it, lr=1e-5, step_loss=0.0166][RANK-0]: Step: [17827], local_loss=0.01071759033948183, train_loss=0.02850520983338356, time_cost=1.2504470348358154
Steps:   2%|▏         | 17827/1000000 [12:15:12<2541:18:32,  9.31s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 17828/1000000 [12:15:23<2717:02:41,  9.96s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [17828], local_loss=0.011962009593844414, train_loss=0.02664082683622837, time_cost=3.4340686798095703
Steps:   2%|▏         | 17828/1000000 [12:15:23<2717:02:41,  9.96s/it, lr=1e-5, step_loss=0.012] Steps:   2%|▏         | 17829/1000000 [12:15:34<2797:37:53, 10.25s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [17829], local_loss=0.007897292263805866, train_loss=0.03192761540412903, time_cost=3.3221161365509033
Steps:   2%|▏         | 17829/1000000 [12:15:34<2797:37:53, 10.25s/it, lr=1e-5, step_loss=0.0079]Steps:   2%|▏         | 17830/1000000 [12:15:39<2335:02:17,  8.56s/it, lr=1e-5, step_loss=0.0079][RANK-0]: Step: [17830], local_loss=0.4989696443080902, train_loss=0.08380034565925598, time_cost=1.6222631931304932
Steps:   2%|▏         | 17830/1000000 [12:15:39<2335:02:17,  8.56s/it, lr=1e-5, step_loss=0.499] Steps:   2%|▏         | 17831/1000000 [12:15:53<2767:10:00, 10.14s/it, lr=1e-5, step_loss=0.499][RANK-0]: Step: [17831], local_loss=0.006417750846594572, train_loss=13.313426971435547, time_cost=2.853362798690796
Steps:   2%|▏         | 17831/1000000 [12:15:53<2767:10:00, 10.14s/it, lr=1e-5, step_loss=0.00642]Steps:   2%|▏         | 17832/1000000 [12:16:07<3065:26:32, 11.24s/it, lr=1e-5, step_loss=0.00642][RANK-0]: Step: [17832], local_loss=0.02190590836107731, train_loss=0.16979077458381653, time_cost=4.3511786460876465
Steps:   2%|▏         | 17832/1000000 [12:16:07<3065:26:32, 11.24s/it, lr=1e-5, step_loss=0.0219] Steps:   2%|▏         | 17833/1000000 [12:16:14<2737:49:16, 10.04s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [17833], local_loss=0.011904430575668812, train_loss=0.02694605477154255, time_cost=1.8401212692260742
Steps:   2%|▏         | 17833/1000000 [12:16:14<2737:49:16, 10.04s/it, lr=1e-5, step_loss=0.0119]Steps:   2%|▏         | 17834/1000000 [12:16:28<3075:00:36, 11.27s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [17834], local_loss=0.007732233498245478, train_loss=0.015194731764495373, time_cost=6.087425947189331
Steps:   2%|▏         | 17834/1000000 [12:16:28<3075:00:36, 11.27s/it, lr=1e-5, step_loss=0.00773]Steps:   2%|▏         | 17835/1000000 [12:16:37<2855:52:42, 10.47s/it, lr=1e-5, step_loss=0.00773][RANK-0]: Step: [17835], local_loss=0.018718576058745384, train_loss=0.016934463754296303, time_cost=3.044926643371582
Steps:   2%|▏         | 17835/1000000 [12:16:37<2855:52:42, 10.47s/it, lr=1e-5, step_loss=0.0187] Steps:   2%|▏         | 17836/1000000 [12:16:46<2750:36:23, 10.08s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [17836], local_loss=0.016683707013726234, train_loss=0.03582841157913208, time_cost=1.9801692962646484
Steps:   2%|▏         | 17836/1000000 [12:16:46<2750:36:23, 10.08s/it, lr=1e-5, step_loss=0.0167]Steps:   2%|▏         | 17837/1000000 [12:16:56<2754:00:09, 10.09s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [17837], local_loss=0.02878662198781967, train_loss=0.14516359567642212, time_cost=1.7948834896087646
Steps:   2%|▏         | 17837/1000000 [12:16:56<2754:00:09, 10.09s/it, lr=1e-5, step_loss=0.0288]Steps:   2%|▏         | 17838/1000000 [12:17:08<2883:33:37, 10.57s/it, lr=1e-5, step_loss=0.0288][RANK-0]: Step: [17838], local_loss=0.005865264683961868, train_loss=0.024418041110038757, time_cost=4.125669956207275
Steps:   2%|▏         | 17838/1000000 [12:17:08<2883:33:37, 10.57s/it, lr=1e-5, step_loss=0.00587]Steps:   2%|▏         | 17839/1000000 [12:17:21<3121:32:38, 11.44s/it, lr=1e-5, step_loss=0.00587][RANK-0]: Step: [17839], local_loss=0.016280144453048706, train_loss=0.012504598125815392, time_cost=3.951986789703369
Steps:   2%|▏         | 17839/1000000 [12:17:21<3121:32:38, 11.44s/it, lr=1e-5, step_loss=0.0163] Steps:   2%|▏         | 17840/1000000 [12:17:28<2765:41:18, 10.14s/it, lr=1e-5, step_loss=0.0163][RANK-0]: Step: [17840], local_loss=0.04587339982390404, train_loss=0.01621701940894127, time_cost=3.094465970993042
Steps:   2%|▏         | 17840/1000000 [12:17:28<2765:41:18, 10.14s/it, lr=1e-5, step_loss=0.0459]Steps:   2%|▏         | 17841/1000000 [12:17:35<2496:57:33,  9.15s/it, lr=1e-5, step_loss=0.0459][RANK-0]: Step: [17841], local_loss=0.010879108682274818, train_loss=0.015289545059204102, time_cost=5.217860460281372
Steps:   2%|▏         | 17841/1000000 [12:17:35<2496:57:33,  9.15s/it, lr=1e-5, step_loss=0.0109]Steps:   2%|▏         | 17842/1000000 [12:17:44<2491:09:47,  9.13s/it, lr=1e-5, step_loss=0.0109][RANK-0]: Step: [17842], local_loss=0.11207841336727142, train_loss=0.04422464594244957, time_cost=3.303086757659912
Steps:   2%|▏         | 17842/1000000 [12:17:44<2491:09:47,  9.13s/it, lr=1e-5, step_loss=0.112] Steps:   2%|▏         | 17843/1000000 [12:17:49<2186:04:22,  8.01s/it, lr=1e-5, step_loss=0.112][RANK-0]: Step: [17843], local_loss=0.0054399557411670685, train_loss=0.02657412551343441, time_cost=2.3691306114196777
Steps:   2%|▏         | 17843/1000000 [12:17:49<2186:04:22,  8.01s/it, lr=1e-5, step_loss=0.00544]Steps:   2%|▏         | 17844/1000000 [12:18:00<2376:28:36,  8.71s/it, lr=1e-5, step_loss=0.00544][RANK-0]: Step: [17844], local_loss=0.14438287913799286, train_loss=0.05540184676647186, time_cost=3.1185944080352783
Steps:   2%|▏         | 17844/1000000 [12:18:00<2376:28:36,  8.71s/it, lr=1e-5, step_loss=0.144]  Steps:   2%|▏         | 17845/1000000 [12:18:07<2242:31:12,  8.22s/it, lr=1e-5, step_loss=0.144][RANK-0]: Step: [17845], local_loss=0.05359045788645744, train_loss=0.02924247272312641, time_cost=5.367563247680664
Steps:   2%|▏         | 17845/1000000 [12:18:07<2242:31:12,  8.22s/it, lr=1e-5, step_loss=0.0536]Steps:   2%|▏         | 17846/1000000 [12:18:11<1931:53:52,  7.08s/it, lr=1e-5, step_loss=0.0536][RANK-0]: Step: [17846], local_loss=0.008939738385379314, train_loss=0.22078821063041687, time_cost=1.5207014083862305
Steps:   2%|▏         | 17846/1000000 [12:18:11<1931:53:52,  7.08s/it, lr=1e-5, step_loss=0.00894]Steps:   2%|▏         | 17847/1000000 [12:18:23<2290:57:10,  8.40s/it, lr=1e-5, step_loss=0.00894][RANK-0]: Step: [17847], local_loss=0.01939893700182438, train_loss=0.06297558546066284, time_cost=1.759183645248413
Steps:   2%|▏         | 17847/1000000 [12:18:23<2290:57:10,  8.40s/it, lr=1e-5, step_loss=0.0194] Steps:   2%|▏         | 17848/1000000 [12:18:29<2072:28:16,  7.60s/it, lr=1e-5, step_loss=0.0194][RANK-0]: Step: [17848], local_loss=0.010473516769707203, train_loss=0.06334832310676575, time_cost=2.1358642578125
Steps:   2%|▏         | 17848/1000000 [12:18:29<2072:28:16,  7.60s/it, lr=1e-5, step_loss=0.0105]Steps:   2%|▏         | 17849/1000000 [12:18:38<2205:48:58,  8.09s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [17849], local_loss=0.012918401509523392, train_loss=0.0446930006146431, time_cost=4.261720657348633
Steps:   2%|▏         | 17849/1000000 [12:18:38<2205:48:58,  8.09s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 17850/1000000 [12:18:47<2287:12:23,  8.38s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [17850], local_loss=0.01312088593840599, train_loss=0.12962524592876434, time_cost=3.7498209476470947
Steps:   2%|▏         | 17850/1000000 [12:18:47<2287:12:23,  8.38s/it, lr=1e-5, step_loss=0.0131]Steps:   2%|▏         | 17851/1000000 [12:18:58<2518:36:46,  9.23s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [17851], local_loss=0.014103318564593792, train_loss=0.007538041099905968, time_cost=4.709046840667725
Steps:   2%|▏         | 17851/1000000 [12:18:58<2518:36:46,  9.23s/it, lr=1e-5, step_loss=0.0141]Steps:   2%|▏         | 17852/1000000 [12:19:03<2195:09:38,  8.05s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [17852], local_loss=0.05197691172361374, train_loss=0.1583286076784134, time_cost=1.65748929977417
Steps:   2%|▏         | 17852/1000000 [12:19:03<2195:09:38,  8.05s/it, lr=1e-5, step_loss=0.052] Steps:   2%|▏         | 17853/1000000 [12:19:15<2482:59:28,  9.10s/it, lr=1e-5, step_loss=0.052][RANK-0]: Step: [17853], local_loss=0.004755248315632343, train_loss=0.01816249080002308, time_cost=2.873189687728882
Steps:   2%|▏         | 17853/1000000 [12:19:15<2482:59:28,  9.10s/it, lr=1e-5, step_loss=0.00476]Steps:   2%|▏         | 17854/1000000 [12:19:24<2468:41:29,  9.05s/it, lr=1e-5, step_loss=0.00476][RANK-0]: Step: [17854], local_loss=0.00829050038009882, train_loss=0.13947592675685883, time_cost=5.4560863971710205
Steps:   2%|▏         | 17854/1000000 [12:19:24<2468:41:29,  9.05s/it, lr=1e-5, step_loss=0.00829]Steps:   2%|▏         | 17855/1000000 [12:19:31<2299:37:21,  8.43s/it, lr=1e-5, step_loss=0.00829][RANK-0]: Step: [17855], local_loss=0.06074674054980278, train_loss=0.29314619302749634, time_cost=5.951694965362549
Steps:   2%|▏         | 17855/1000000 [12:19:31<2299:37:21,  8.43s/it, lr=1e-5, step_loss=0.0607] Steps:   2%|▏         | 17856/1000000 [12:19:39<2241:20:10,  8.22s/it, lr=1e-5, step_loss=0.0607][RANK-0]: Step: [17856], local_loss=0.03886088356375694, train_loss=0.04751778393983841, time_cost=1.7912678718566895
Steps:   2%|▏         | 17856/1000000 [12:19:39<2241:20:10,  8.22s/it, lr=1e-5, step_loss=0.0389]Steps:   2%|▏         | 17857/1000000 [12:19:44<2036:04:47,  7.46s/it, lr=1e-5, step_loss=0.0389][RANK-0]: Step: [17857], local_loss=0.02623276226222515, train_loss=0.05565134435892105, time_cost=3.0740315914154053
Steps:   2%|▏         | 17857/1000000 [12:19:44<2036:04:47,  7.46s/it, lr=1e-5, step_loss=0.0262]Steps:   2%|▏         | 17858/1000000 [12:19:51<1987:59:57,  7.29s/it, lr=1e-5, step_loss=0.0262][RANK-0]: Step: [17858], local_loss=0.003777997102588415, train_loss=0.12711885571479797, time_cost=2.8286476135253906
Steps:   2%|▏         | 17858/1000000 [12:19:51<1987:59:57,  7.29s/it, lr=1e-5, step_loss=0.00378]Steps:   2%|▏         | 17859/1000000 [12:20:00<2159:20:32,  7.91s/it, lr=1e-5, step_loss=0.00378][RANK-0]: Step: [17859], local_loss=0.04767311364412308, train_loss=0.04140888527035713, time_cost=3.46343994140625
Steps:   2%|▏         | 17859/1000000 [12:20:00<2159:20:32,  7.91s/it, lr=1e-5, step_loss=0.0477] Steps:   2%|▏         | 17860/1000000 [12:20:10<2256:10:34,  8.27s/it, lr=1e-5, step_loss=0.0477][RANK-0]: Step: [17860], local_loss=0.07562367618083954, train_loss=0.026083506643772125, time_cost=5.403500556945801
Steps:   2%|▏         | 17860/1000000 [12:20:10<2256:10:34,  8.27s/it, lr=1e-5, step_loss=0.0756]Steps:   2%|▏         | 17861/1000000 [12:20:24<2772:30:23, 10.16s/it, lr=1e-5, step_loss=0.0756][RANK-0]: Step: [17861], local_loss=0.020908260717988014, train_loss=0.06171455979347229, time_cost=5.895974397659302
Steps:   2%|▏         | 17861/1000000 [12:20:24<2772:30:23, 10.16s/it, lr=1e-5, step_loss=0.0209]Steps:   2%|▏         | 17862/1000000 [12:20:29<2364:20:24,  8.67s/it, lr=1e-5, step_loss=0.0209][RANK-0]: Step: [17862], local_loss=0.021056603640317917, train_loss=0.014613820239901543, time_cost=2.6324350833892822
Steps:   2%|▏         | 17862/1000000 [12:20:29<2364:20:24,  8.67s/it, lr=1e-5, step_loss=0.0211]Steps:   2%|▏         | 17863/1000000 [12:20:41<2583:15:05,  9.47s/it, lr=1e-5, step_loss=0.0211][RANK-0]: Step: [17863], local_loss=0.00590814184397459, train_loss=0.05150970444083214, time_cost=4.288810968399048
Steps:   2%|▏         | 17863/1000000 [12:20:41<2583:15:05,  9.47s/it, lr=1e-5, step_loss=0.00591]Steps:   2%|▏         | 17864/1000000 [12:20:50<2584:30:14,  9.47s/it, lr=1e-5, step_loss=0.00591][RANK-0]: Step: [17864], local_loss=0.007318655028939247, train_loss=0.022216442972421646, time_cost=1.8069093227386475
Steps:   2%|▏         | 17864/1000000 [12:20:50<2584:30:14,  9.47s/it, lr=1e-5, step_loss=0.00732]Steps:   2%|▏         | 17865/1000000 [12:20:57<2345:40:36,  8.60s/it, lr=1e-5, step_loss=0.00732][RANK-0]: Step: [17865], local_loss=0.003837341209873557, train_loss=0.027687011286616325, time_cost=1.6644995212554932
Steps:   2%|▏         | 17865/1000000 [12:20:57<2345:40:36,  8.60s/it, lr=1e-5, step_loss=0.00384]Steps:   2%|▏         | 17866/1000000 [12:21:03<2121:41:32,  7.78s/it, lr=1e-5, step_loss=0.00384][RANK-0]: Step: [17866], local_loss=0.01593746617436409, train_loss=0.05970752239227295, time_cost=1.4114482402801514
Steps:   2%|▏         | 17866/1000000 [12:21:03<2121:41:32,  7.78s/it, lr=1e-5, step_loss=0.0159] Steps:   2%|▏         | 17867/1000000 [12:21:14<2388:43:20,  8.76s/it, lr=1e-5, step_loss=0.0159][RANK-0]: Step: [17867], local_loss=0.01060951966792345, train_loss=0.09205645322799683, time_cost=3.1903820037841797
Steps:   2%|▏         | 17867/1000000 [12:21:14<2388:43:20,  8.76s/it, lr=1e-5, step_loss=0.0106]Steps:   2%|▏         | 17868/1000000 [12:21:18<2056:34:48,  7.54s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [17868], local_loss=0.020777229219675064, train_loss=0.06276606023311615, time_cost=2.2014882564544678
Steps:   2%|▏         | 17868/1000000 [12:21:18<2056:34:48,  7.54s/it, lr=1e-5, step_loss=0.0208]Steps:   2%|▏         | 17869/1000000 [12:21:24<1910:15:36,  7.00s/it, lr=1e-5, step_loss=0.0208][RANK-0]: Step: [17869], local_loss=0.0055411197245121, train_loss=0.029595905914902687, time_cost=3.3938751220703125
Steps:   2%|▏         | 17869/1000000 [12:21:24<1910:15:36,  7.00s/it, lr=1e-5, step_loss=0.00554]Steps:   2%|▏         | 17870/1000000 [12:21:29<1761:08:36,  6.46s/it, lr=1e-5, step_loss=0.00554][RANK-0]: Step: [17870], local_loss=0.12855608761310577, train_loss=0.05630825087428093, time_cost=2.6120522022247314
Steps:   2%|▏         | 17870/1000000 [12:21:29<1761:08:36,  6.46s/it, lr=1e-5, step_loss=0.129]  Steps:   2%|▏         | 17871/1000000 [12:21:40<2106:44:47,  7.72s/it, lr=1e-5, step_loss=0.129][RANK-0]: Step: [17871], local_loss=0.0228666253387928, train_loss=0.06703745573759079, time_cost=1.8738555908203125
Steps:   2%|▏         | 17871/1000000 [12:21:40<2106:44:47,  7.72s/it, lr=1e-5, step_loss=0.0229]Steps:   2%|▏         | 17872/1000000 [12:21:49<2246:32:47,  8.23s/it, lr=1e-5, step_loss=0.0229][RANK-0]: Step: [17872], local_loss=0.022650670260190964, train_loss=0.029727313667535782, time_cost=7.049403667449951
Steps:   2%|▏         | 17872/1000000 [12:21:49<2246:32:47,  8.23s/it, lr=1e-5, step_loss=0.0227]Steps:   2%|▏         | 17873/1000000 [12:21:58<2282:43:12,  8.37s/it, lr=1e-5, step_loss=0.0227][RANK-0]: Step: [17873], local_loss=0.030664289370179176, train_loss=0.08934217691421509, time_cost=3.0064187049865723
Steps:   2%|▏         | 17873/1000000 [12:21:58<2282:43:12,  8.37s/it, lr=1e-5, step_loss=0.0307]Steps:   2%|▏         | 17874/1000000 [12:22:03<2022:02:48,  7.41s/it, lr=1e-5, step_loss=0.0307][RANK-0]: Step: [17874], local_loss=0.023974118754267693, train_loss=0.07236827909946442, time_cost=2.09379506111145
Steps:   2%|▏         | 17874/1000000 [12:22:03<2022:02:48,  7.41s/it, lr=1e-5, step_loss=0.024] Steps:   2%|▏         | 17875/1000000 [12:22:11<2046:12:54,  7.50s/it, lr=1e-5, step_loss=0.024][RANK-0]: Step: [17875], local_loss=0.011957320384681225, train_loss=0.12489818036556244, time_cost=4.2101850509643555
Steps:   2%|▏         | 17875/1000000 [12:22:11<2046:12:54,  7.50s/it, lr=1e-5, step_loss=0.012]Steps:   2%|▏         | 17876/1000000 [12:22:18<2027:05:35,  7.43s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [17876], local_loss=0.03491167351603508, train_loss=0.03055712953209877, time_cost=5.269491910934448
Steps:   2%|▏         | 17876/1000000 [12:22:18<2027:05:35,  7.43s/it, lr=1e-5, step_loss=0.0349]Steps:   2%|▏         | 17877/1000000 [12:22:28<2202:25:55,  8.07s/it, lr=1e-5, step_loss=0.0349][RANK-0]: Step: [17877], local_loss=0.03863590210676193, train_loss=0.03422772139310837, time_cost=2.2744693756103516
Steps:   2%|▏         | 17877/1000000 [12:22:28<2202:25:55,  8.07s/it, lr=1e-5, step_loss=0.0386]Steps:   2%|▏         | 17878/1000000 [12:22:37<2314:00:24,  8.48s/it, lr=1e-5, step_loss=0.0386][RANK-0]: Step: [17878], local_loss=1.0022252798080444, train_loss=0.1588735282421112, time_cost=2.1795976161956787
Steps:   2%|▏         | 17878/1000000 [12:22:37<2314:00:24,  8.48s/it, lr=1e-5, step_loss=1]     Steps:   2%|▏         | 17879/1000000 [12:22:50<2705:00:52,  9.92s/it, lr=1e-5, step_loss=1][RANK-0]: Step: [17879], local_loss=0.004130852874368429, train_loss=0.019953226670622826, time_cost=1.2125661373138428
Steps:   2%|▏         | 17879/1000000 [12:22:50<2705:00:52,  9.92s/it, lr=1e-5, step_loss=0.00413]Steps:   2%|▏         | 17880/1000000 [12:22:55<2261:16:47,  8.29s/it, lr=1e-5, step_loss=0.00413][RANK-0]: Step: [17880], local_loss=0.00882025994360447, train_loss=0.012981884181499481, time_cost=1.5016453266143799
Steps:   2%|▏         | 17880/1000000 [12:22:55<2261:16:47,  8.29s/it, lr=1e-5, step_loss=0.00882]Steps:   2%|▏         | 17881/1000000 [12:23:02<2178:39:30,  7.99s/it, lr=1e-5, step_loss=0.00882][RANK-0]: Step: [17881], local_loss=0.03173417970538139, train_loss=0.07219574600458145, time_cost=5.937160491943359
Steps:   2%|▏         | 17881/1000000 [12:23:02<2178:39:30,  7.99s/it, lr=1e-5, step_loss=0.0317] Steps:   2%|▏         | 17882/1000000 [12:23:07<1953:33:17,  7.16s/it, lr=1e-5, step_loss=0.0317][RANK-0]: Step: [17882], local_loss=0.025601183995604515, train_loss=0.02099474146962166, time_cost=2.4871203899383545
Steps:   2%|▏         | 17882/1000000 [12:23:07<1953:33:17,  7.16s/it, lr=1e-5, step_loss=0.0256]Steps:   2%|▏         | 17883/1000000 [12:23:13<1790:11:14,  6.56s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [17883], local_loss=0.006824118085205555, train_loss=0.06726216524839401, time_cost=2.2495150566101074
Steps:   2%|▏         | 17883/1000000 [12:23:13<1790:11:14,  6.56s/it, lr=1e-5, step_loss=0.00682]Steps:   2%|▏         | 17884/1000000 [12:23:26<2320:34:04,  8.51s/it, lr=1e-5, step_loss=0.00682][RANK-0]: Step: [17884], local_loss=0.07465184479951859, train_loss=0.06003272533416748, time_cost=4.567664384841919
Steps:   2%|▏         | 17884/1000000 [12:23:26<2320:34:04,  8.51s/it, lr=1e-5, step_loss=0.0747] Steps:   2%|▏         | 17885/1000000 [12:23:36<2498:57:52,  9.16s/it, lr=1e-5, step_loss=0.0747][RANK-0]: Step: [17885], local_loss=0.005859756842255592, train_loss=0.13349008560180664, time_cost=1.8501014709472656
Steps:   2%|▏         | 17885/1000000 [12:23:36<2498:57:52,  9.16s/it, lr=1e-5, step_loss=0.00586]Steps:   2%|▏         | 17886/1000000 [12:23:48<2738:24:17, 10.04s/it, lr=1e-5, step_loss=0.00586][RANK-0]: Step: [17886], local_loss=0.043828535825014114, train_loss=0.05318237468600273, time_cost=3.7670159339904785
Steps:   2%|▏         | 17886/1000000 [12:23:48<2738:24:17, 10.04s/it, lr=1e-5, step_loss=0.0438] Steps:   2%|▏         | 17887/1000000 [12:23:58<2723:38:11,  9.98s/it, lr=1e-5, step_loss=0.0438][RANK-0]: Step: [17887], local_loss=0.006528549827635288, train_loss=0.03353350609540939, time_cost=3.9201083183288574
Steps:   2%|▏         | 17887/1000000 [12:23:58<2723:38:11,  9.98s/it, lr=1e-5, step_loss=0.00653]Steps:   2%|▏         | 17888/1000000 [12:24:03<2325:51:59,  8.53s/it, lr=1e-5, step_loss=0.00653][RANK-0]: Step: [17888], local_loss=0.04771166294813156, train_loss=0.030082058161497116, time_cost=2.703075647354126
Steps:   2%|▏         | 17888/1000000 [12:24:03<2325:51:59,  8.53s/it, lr=1e-5, step_loss=0.0477] Steps:   2%|▏         | 17889/1000000 [12:24:14<2498:39:37,  9.16s/it, lr=1e-5, step_loss=0.0477][RANK-0]: Step: [17889], local_loss=0.008818930946290493, train_loss=0.02307925745844841, time_cost=3.410810947418213
Steps:   2%|▏         | 17889/1000000 [12:24:14<2498:39:37,  9.16s/it, lr=1e-5, step_loss=0.00882]Steps:   2%|▏         | 17890/1000000 [12:24:19<2138:56:04,  7.84s/it, lr=1e-5, step_loss=0.00882][RANK-0]: Step: [17890], local_loss=0.01283056940883398, train_loss=0.06046104431152344, time_cost=2.345508098602295
Steps:   2%|▏         | 17890/1000000 [12:24:19<2138:56:04,  7.84s/it, lr=1e-5, step_loss=0.0128] Steps:   2%|▏         | 17891/1000000 [12:24:29<2330:55:01,  8.54s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [17891], local_loss=0.025968600064516068, train_loss=0.050346896052360535, time_cost=1.7344093322753906
Steps:   2%|▏         | 17891/1000000 [12:24:29<2330:55:01,  8.54s/it, lr=1e-5, step_loss=0.026] Steps:   2%|▏         | 17892/1000000 [12:24:40<2545:45:55,  9.33s/it, lr=1e-5, step_loss=0.026][RANK-0]: Step: [17892], local_loss=0.05090264976024628, train_loss=0.050526052713394165, time_cost=5.968047380447388
Steps:   2%|▏         | 17892/1000000 [12:24:40<2545:45:55,  9.33s/it, lr=1e-5, step_loss=0.0509]Steps:   2%|▏         | 17893/1000000 [12:24:52<2724:09:40,  9.99s/it, lr=1e-5, step_loss=0.0509][RANK-0]: Step: [17893], local_loss=0.0034785110037773848, train_loss=0.0300002358853817, time_cost=4.418435096740723
Steps:   2%|▏         | 17893/1000000 [12:24:52<2724:09:40,  9.99s/it, lr=1e-5, step_loss=0.00348]Steps:   2%|▏         | 17894/1000000 [12:24:57<2347:45:20,  8.61s/it, lr=1e-5, step_loss=0.00348][RANK-0]: Step: [17894], local_loss=0.028377559036016464, train_loss=0.036992065608501434, time_cost=2.791266441345215
Steps:   2%|▏         | 17894/1000000 [12:24:57<2347:45:20,  8.61s/it, lr=1e-5, step_loss=0.0284] Steps:   2%|▏         | 17895/1000000 [12:25:03<2092:22:38,  7.67s/it, lr=1e-5, step_loss=0.0284][RANK-0]: Step: [17895], local_loss=0.0391354039311409, train_loss=0.11025217175483704, time_cost=2.784848213195801
Steps:   2%|▏         | 17895/1000000 [12:25:03<2092:22:38,  7.67s/it, lr=1e-5, step_loss=0.0391]Steps:   2%|▏         | 17896/1000000 [12:25:17<2633:45:40,  9.65s/it, lr=1e-5, step_loss=0.0391][RANK-0]: Step: [17896], local_loss=0.09222318232059479, train_loss=0.042088642716407776, time_cost=6.610763072967529
Steps:   2%|▏         | 17896/1000000 [12:25:17<2633:45:40,  9.65s/it, lr=1e-5, step_loss=0.0922]Steps:   2%|▏         | 17897/1000000 [12:25:22<2278:25:26,  8.35s/it, lr=1e-5, step_loss=0.0922][RANK-0]: Step: [17897], local_loss=0.007176059763878584, train_loss=0.0680549293756485, time_cost=2.462484359741211
Steps:   2%|▏         | 17897/1000000 [12:25:22<2278:25:26,  8.35s/it, lr=1e-5, step_loss=0.00718]Steps:   2%|▏         | 17898/1000000 [12:25:39<2970:50:56, 10.89s/it, lr=1e-5, step_loss=0.00718][RANK-0]: Step: [17898], local_loss=0.021945828571915627, train_loss=0.07979169487953186, time_cost=8.610209465026855
Steps:   2%|▏         | 17898/1000000 [12:25:39<2970:50:56, 10.89s/it, lr=1e-5, step_loss=0.0219] Steps:   2%|▏         | 17899/1000000 [12:25:53<3219:41:26, 11.80s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [17899], local_loss=0.03447208181023598, train_loss=0.048944104462862015, time_cost=4.644716501235962
Steps:   2%|▏         | 17899/1000000 [12:25:53<3219:41:26, 11.80s/it, lr=1e-5, step_loss=0.0345]Steps:   2%|▏         | 17900/1000000 [12:26:05<3240:14:21, 11.88s/it, lr=1e-5, step_loss=0.0345][RANK-0]: Step: [17900], local_loss=0.008480909280478954, train_loss=0.01204508077353239, time_cost=3.223353624343872
Steps:   2%|▏         | 17900/1000000 [12:26:05<3240:14:21, 11.88s/it, lr=1e-5, step_loss=0.00848]Steps:   2%|▏         | 17901/1000000 [12:26:10<2686:18:33,  9.85s/it, lr=1e-5, step_loss=0.00848][RANK-0]: Step: [17901], local_loss=0.005935984198004007, train_loss=0.04697285592556, time_cost=2.584575653076172
Steps:   2%|▏         | 17901/1000000 [12:26:10<2686:18:33,  9.85s/it, lr=1e-5, step_loss=0.00594]Steps:   2%|▏         | 17902/1000000 [12:26:19<2624:12:06,  9.62s/it, lr=1e-5, step_loss=0.00594][RANK-0]: Step: [17902], local_loss=0.02560959756374359, train_loss=0.04352099448442459, time_cost=4.168878793716431
Steps:   2%|▏         | 17902/1000000 [12:26:19<2624:12:06,  9.62s/it, lr=1e-5, step_loss=0.0256] Steps:   2%|▏         | 17903/1000000 [12:26:29<2618:26:24,  9.60s/it, lr=1e-5, step_loss=0.0256][RANK-0]: Step: [17903], local_loss=0.019642416387796402, train_loss=0.05176958441734314, time_cost=2.386500358581543
Steps:   2%|▏         | 17903/1000000 [12:26:29<2618:26:24,  9.60s/it, lr=1e-5, step_loss=0.0196]Steps:   2%|▏         | 17904/1000000 [12:26:35<2337:20:20,  8.57s/it, lr=1e-5, step_loss=0.0196][RANK-0]: Step: [17904], local_loss=0.005184569396078587, train_loss=0.17748874425888062, time_cost=2.429222583770752
Steps:   2%|▏         | 17904/1000000 [12:26:35<2337:20:20,  8.57s/it, lr=1e-5, step_loss=0.00518]Steps:   2%|▏         | 17905/1000000 [12:26:44<2423:01:48,  8.88s/it, lr=1e-5, step_loss=0.00518][RANK-0]: Step: [17905], local_loss=0.012790655717253685, train_loss=0.06247945874929428, time_cost=1.348893404006958
Steps:   2%|▏         | 17905/1000000 [12:26:44<2423:01:48,  8.88s/it, lr=1e-5, step_loss=0.0128] Steps:   2%|▏         | 17906/1000000 [12:26:49<2075:18:44,  7.61s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [17906], local_loss=0.017368705943226814, train_loss=0.042400091886520386, time_cost=1.8276643753051758
Steps:   2%|▏         | 17906/1000000 [12:26:49<2075:18:44,  7.61s/it, lr=1e-5, step_loss=0.0174]Steps:   2%|▏         | 17907/1000000 [12:26:54<1849:21:55,  6.78s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [17907], local_loss=0.022781919687986374, train_loss=0.17404717206954956, time_cost=2.1382813453674316
Steps:   2%|▏         | 17907/1000000 [12:26:54<1849:21:55,  6.78s/it, lr=1e-5, step_loss=0.0228]Steps:   2%|▏         | 17908/1000000 [12:26:59<1734:27:42,  6.36s/it, lr=1e-5, step_loss=0.0228][RANK-0]: Step: [17908], local_loss=0.04739522933959961, train_loss=0.04243120178580284, time_cost=1.5512638092041016
Steps:   2%|▏         | 17908/1000000 [12:26:59<1734:27:42,  6.36s/it, lr=1e-5, step_loss=0.0474]Steps:   2%|▏         | 17909/1000000 [12:27:12<2274:01:08,  8.34s/it, lr=1e-5, step_loss=0.0474][RANK-0]: Step: [17909], local_loss=0.05777614563703537, train_loss=0.07722780853509903, time_cost=1.227393627166748
Steps:   2%|▏         | 17909/1000000 [12:27:12<2274:01:08,  8.34s/it, lr=1e-5, step_loss=0.0578]Steps:   2%|▏         | 17910/1000000 [12:27:24<2536:54:50,  9.30s/it, lr=1e-5, step_loss=0.0578][RANK-0]: Step: [17910], local_loss=0.01243501901626587, train_loss=0.017424821853637695, time_cost=8.751940965652466
Steps:   2%|▏         | 17910/1000000 [12:27:24<2536:54:50,  9.30s/it, lr=1e-5, step_loss=0.0124]Steps:   2%|▏         | 17911/1000000 [12:27:31<2363:20:03,  8.66s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [17911], local_loss=0.15144678950309753, train_loss=0.18349553644657135, time_cost=1.4054083824157715
Steps:   2%|▏         | 17911/1000000 [12:27:31<2363:20:03,  8.66s/it, lr=1e-5, step_loss=0.151] Steps:   2%|▏         | 17912/1000000 [12:27:40<2428:21:57,  8.90s/it, lr=1e-5, step_loss=0.151][RANK-0]: Step: [17912], local_loss=0.007117792498320341, train_loss=0.05099755525588989, time_cost=4.05527138710022
Steps:   2%|▏         | 17912/1000000 [12:27:40<2428:21:57,  8.90s/it, lr=1e-5, step_loss=0.00712]Steps:   2%|▏         | 17913/1000000 [12:27:51<2580:05:50,  9.46s/it, lr=1e-5, step_loss=0.00712][RANK-0]: Step: [17913], local_loss=0.10814169049263, train_loss=0.032865576446056366, time_cost=1.8343944549560547
Steps:   2%|▏         | 17913/1000000 [12:27:51<2580:05:50,  9.46s/it, lr=1e-5, step_loss=0.108]  Steps:   2%|▏         | 17914/1000000 [12:27:59<2406:17:28,  8.82s/it, lr=1e-5, step_loss=0.108][RANK-0]: Step: [17914], local_loss=0.18751299381256104, train_loss=0.03760908544063568, time_cost=1.4715430736541748
Steps:   2%|▏         | 17914/1000000 [12:27:59<2406:17:28,  8.82s/it, lr=1e-5, step_loss=0.188]Steps:   2%|▏         | 17915/1000000 [12:28:03<2082:18:25,  7.63s/it, lr=1e-5, step_loss=0.188][RANK-0]: Step: [17915], local_loss=0.014786377549171448, train_loss=0.02372031658887863, time_cost=2.833540678024292
Steps:   2%|▏         | 17915/1000000 [12:28:03<2082:18:25,  7.63s/it, lr=1e-5, step_loss=0.0148]Steps:   2%|▏         | 17916/1000000 [12:28:08<1861:06:45,  6.82s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [17916], local_loss=0.05242985859513283, train_loss=0.018742622807621956, time_cost=2.4957802295684814
Steps:   2%|▏         | 17916/1000000 [12:28:08<1861:06:45,  6.82s/it, lr=1e-5, step_loss=0.0524]Steps:   2%|▏         | 17917/1000000 [12:28:18<2084:24:50,  7.64s/it, lr=1e-5, step_loss=0.0524][RANK-0]: Step: [17917], local_loss=0.013772055506706238, train_loss=0.02904890850186348, time_cost=3.2831742763519287
Steps:   2%|▏         | 17917/1000000 [12:28:18<2084:24:50,  7.64s/it, lr=1e-5, step_loss=0.0138]Steps:   2%|▏         | 17918/1000000 [12:28:27<2194:48:54,  8.05s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [17918], local_loss=0.01383072417229414, train_loss=0.04664279893040657, time_cost=1.317720651626587
Steps:   2%|▏         | 17918/1000000 [12:28:27<2194:48:54,  8.05s/it, lr=1e-5, step_loss=0.0138]Steps:   2%|▏         | 17919/1000000 [12:28:34<2095:31:11,  7.68s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [17919], local_loss=0.01841244474053383, train_loss=0.019213123247027397, time_cost=1.2140846252441406
Steps:   2%|▏         | 17919/1000000 [12:28:34<2095:31:11,  7.68s/it, lr=1e-5, step_loss=0.0184]Steps:   2%|▏         | 17920/1000000 [12:28:41<2089:18:12,  7.66s/it, lr=1e-5, step_loss=0.0184][RANK-0]: Step: [17920], local_loss=0.008642150089144707, train_loss=0.014936293475329876, time_cost=3.087603807449341
Steps:   2%|▏         | 17920/1000000 [12:28:41<2089:18:12,  7.66s/it, lr=1e-5, step_loss=0.00864]Steps:   2%|▏         | 17921/1000000 [12:28:57<2735:34:11, 10.03s/it, lr=1e-5, step_loss=0.00864][RANK-0]: Step: [17921], local_loss=0.012441521510481834, train_loss=0.04333959147334099, time_cost=8.462655305862427
Steps:   2%|▏         | 17921/1000000 [12:28:57<2735:34:11, 10.03s/it, lr=1e-5, step_loss=0.0124] Steps:   2%|▏         | 17922/1000000 [12:29:03<2388:45:30,  8.76s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [17922], local_loss=0.029297463595867157, train_loss=0.014491159468889236, time_cost=1.8562052249908447
Steps:   2%|▏         | 17922/1000000 [12:29:03<2388:45:30,  8.76s/it, lr=1e-5, step_loss=0.0293]Steps:   2%|▏         | 17923/1000000 [12:29:13<2556:59:25,  9.37s/it, lr=1e-5, step_loss=0.0293][RANK-0]: Step: [17923], local_loss=0.014943009242415428, train_loss=22.45975112915039, time_cost=2.7920644283294678
Steps:   2%|▏         | 17923/1000000 [12:29:13<2556:59:25,  9.37s/it, lr=1e-5, step_loss=0.0149]Steps:   2%|▏         | 17924/1000000 [12:29:21<2422:42:12,  8.88s/it, lr=1e-5, step_loss=0.0149][RANK-0]: Step: [17924], local_loss=0.012103462591767311, train_loss=0.01813068799674511, time_cost=1.2216875553131104
Steps:   2%|▏         | 17924/1000000 [12:29:21<2422:42:12,  8.88s/it, lr=1e-5, step_loss=0.0121]Steps:   2%|▏         | 17925/1000000 [12:29:28<2273:09:04,  8.33s/it, lr=1e-5, step_loss=0.0121][RANK-0]: Step: [17925], local_loss=0.016754791140556335, train_loss=0.08590517938137054, time_cost=2.8198904991149902
Steps:   2%|▏         | 17925/1000000 [12:29:28<2273:09:04,  8.33s/it, lr=1e-5, step_loss=0.0168]Steps:   2%|▏         | 17926/1000000 [12:29:33<2000:22:31,  7.33s/it, lr=1e-5, step_loss=0.0168][RANK-0]: Step: [17926], local_loss=0.06024467572569847, train_loss=0.04048999398946762, time_cost=4.022600412368774
Steps:   2%|▏         | 17926/1000000 [12:29:33<2000:22:31,  7.33s/it, lr=1e-5, step_loss=0.0602]Steps:   2%|▏         | 17927/1000000 [12:29:49<2724:12:04,  9.99s/it, lr=1e-5, step_loss=0.0602][RANK-0]: Step: [17927], local_loss=0.009472144767642021, train_loss=0.051415301859378815, time_cost=7.339375257492065
Steps:   2%|▏         | 17927/1000000 [12:29:49<2724:12:04,  9.99s/it, lr=1e-5, step_loss=0.00947]Steps:   2%|▏         | 17928/1000000 [12:30:00<2730:10:16, 10.01s/it, lr=1e-5, step_loss=0.00947][RANK-0]: Step: [17928], local_loss=0.01077522523701191, train_loss=0.04168543964624405, time_cost=1.686342716217041
Steps:   2%|▏         | 17928/1000000 [12:30:00<2730:10:16, 10.01s/it, lr=1e-5, step_loss=0.0108] Steps:   2%|▏         | 17929/1000000 [12:30:05<2374:14:58,  8.70s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [17929], local_loss=0.015211006626486778, train_loss=0.014641855843365192, time_cost=2.7761330604553223
Steps:   2%|▏         | 17929/1000000 [12:30:05<2374:14:58,  8.70s/it, lr=1e-5, step_loss=0.0152]Steps:   2%|▏         | 17930/1000000 [12:30:17<2650:15:14,  9.72s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [17930], local_loss=0.007263639010488987, train_loss=0.019686568528413773, time_cost=5.480459451675415
Steps:   2%|▏         | 17930/1000000 [12:30:17<2650:15:14,  9.72s/it, lr=1e-5, step_loss=0.00726]Steps:   2%|▏         | 17931/1000000 [12:30:23<2337:28:56,  8.57s/it, lr=1e-5, step_loss=0.00726][RANK-0]: Step: [17931], local_loss=0.01405867375433445, train_loss=0.03028923273086548, time_cost=1.891869306564331
Steps:   2%|▏         | 17931/1000000 [12:30:23<2337:28:56,  8.57s/it, lr=1e-5, step_loss=0.0141] Steps:   2%|▏         | 17932/1000000 [12:30:30<2164:33:06,  7.93s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [17932], local_loss=0.0075797513127326965, train_loss=0.02740292251110077, time_cost=1.2043657302856445
Steps:   2%|▏         | 17932/1000000 [12:30:30<2164:33:06,  7.93s/it, lr=1e-5, step_loss=0.00758]Steps:   2%|▏         | 17933/1000000 [12:30:40<2365:04:38,  8.67s/it, lr=1e-5, step_loss=0.00758][RANK-0]: Step: [17933], local_loss=0.04309919476509094, train_loss=0.06026512756943703, time_cost=1.4344427585601807
Steps:   2%|▏         | 17933/1000000 [12:30:40<2365:04:38,  8.67s/it, lr=1e-5, step_loss=0.0431] Steps:   2%|▏         | 17934/1000000 [12:30:47<2220:19:00,  8.14s/it, lr=1e-5, step_loss=0.0431][RANK-0]: Step: [17934], local_loss=0.09157335758209229, train_loss=0.039605144411325455, time_cost=1.2243380546569824
Steps:   2%|▏         | 17934/1000000 [12:30:47<2220:19:00,  8.14s/it, lr=1e-5, step_loss=0.0916]Steps:   2%|▏         | 17935/1000000 [12:30:58<2499:50:56,  9.16s/it, lr=1e-5, step_loss=0.0916][RANK-0]: Step: [17935], local_loss=0.023325329646468163, train_loss=0.027742866426706314, time_cost=8.383139610290527
Steps:   2%|▏         | 17935/1000000 [12:30:58<2499:50:56,  9.16s/it, lr=1e-5, step_loss=0.0233]Steps:   2%|▏         | 17936/1000000 [12:31:10<2686:33:23,  9.85s/it, lr=1e-5, step_loss=0.0233][RANK-0]: Step: [17936], local_loss=0.026648754253983498, train_loss=0.036815039813518524, time_cost=4.000796318054199
Steps:   2%|▏         | 17936/1000000 [12:31:10<2686:33:23,  9.85s/it, lr=1e-5, step_loss=0.0266]Steps:   2%|▏         | 17937/1000000 [12:31:21<2797:48:49, 10.26s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [17937], local_loss=0.021693594753742218, train_loss=0.07288724184036255, time_cost=3.849874496459961
Steps:   2%|▏         | 17937/1000000 [12:31:21<2797:48:49, 10.26s/it, lr=1e-5, step_loss=0.0217]Steps:   2%|▏         | 17938/1000000 [12:31:28<2520:48:02,  9.24s/it, lr=1e-5, step_loss=0.0217][RANK-0]: Step: [17938], local_loss=0.00429639732465148, train_loss=0.03340831398963928, time_cost=1.215174674987793
Steps:   2%|▏         | 17938/1000000 [12:31:28<2520:48:02,  9.24s/it, lr=1e-5, step_loss=0.0043]Steps:   2%|▏         | 17939/1000000 [12:31:33<2176:41:14,  7.98s/it, lr=1e-5, step_loss=0.0043][RANK-0]: Step: [17939], local_loss=0.015631577000021935, train_loss=0.0435599684715271, time_cost=1.3532435894012451
Steps:   2%|▏         | 17939/1000000 [12:31:33<2176:41:14,  7.98s/it, lr=1e-5, step_loss=0.0156]Steps:   2%|▏         | 17940/1000000 [12:31:44<2390:02:28,  8.76s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [17940], local_loss=0.006345214322209358, train_loss=0.033584922552108765, time_cost=1.501267433166504
Steps:   2%|▏         | 17940/1000000 [12:31:44<2390:02:28,  8.76s/it, lr=1e-5, step_loss=0.00635]Steps:   2%|▏         | 17941/1000000 [12:31:57<2761:30:39, 10.12s/it, lr=1e-5, step_loss=0.00635][RANK-0]: Step: [17941], local_loss=0.012277060188353062, train_loss=0.01135043054819107, time_cost=5.7328267097473145
Steps:   2%|▏         | 17941/1000000 [12:31:57<2761:30:39, 10.12s/it, lr=1e-5, step_loss=0.0123] Steps:   2%|▏         | 17942/1000000 [12:32:09<2926:04:46, 10.73s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [17942], local_loss=0.029441671445965767, train_loss=0.038579151034355164, time_cost=4.146987676620483
Steps:   2%|▏         | 17942/1000000 [12:32:09<2926:04:46, 10.73s/it, lr=1e-5, step_loss=0.0294]Steps:   2%|▏         | 17943/1000000 [12:32:16<2611:54:48,  9.57s/it, lr=1e-5, step_loss=0.0294][RANK-0]: Step: [17943], local_loss=0.021053068339824677, train_loss=0.02284419909119606, time_cost=2.4512617588043213
Steps:   2%|▏         | 17943/1000000 [12:32:16<2611:54:48,  9.57s/it, lr=1e-5, step_loss=0.0211]Steps:   2%|▏         | 17944/1000000 [12:32:29<2926:41:48, 10.73s/it, lr=1e-5, step_loss=0.0211][RANK-0]: Step: [17944], local_loss=0.038085903972387314, train_loss=0.04865441471338272, time_cost=1.2185392379760742
Steps:   2%|▏         | 17944/1000000 [12:32:29<2926:41:48, 10.73s/it, lr=1e-5, step_loss=0.0381]Steps:   2%|▏         | 17945/1000000 [12:32:41<2991:55:13, 10.97s/it, lr=1e-5, step_loss=0.0381][RANK-0]: Step: [17945], local_loss=0.008865561336278915, train_loss=0.1437455713748932, time_cost=4.934053897857666
Steps:   2%|▏         | 17945/1000000 [12:32:41<2991:55:13, 10.97s/it, lr=1e-5, step_loss=0.00887]Steps:   2%|▏         | 17946/1000000 [12:32:49<2799:34:44, 10.26s/it, lr=1e-5, step_loss=0.00887][RANK-0]: Step: [17946], local_loss=0.004733753390610218, train_loss=0.03656509518623352, time_cost=1.4645042419433594
Steps:   2%|▏         | 17946/1000000 [12:32:49<2799:34:44, 10.26s/it, lr=1e-5, step_loss=0.00473]Steps:   2%|▏         | 17947/1000000 [12:32:57<2546:54:41,  9.34s/it, lr=1e-5, step_loss=0.00473][RANK-0]: Step: [17947], local_loss=0.040400296449661255, train_loss=0.05452495068311691, time_cost=1.802011489868164
Steps:   2%|▏         | 17947/1000000 [12:32:57<2546:54:41,  9.34s/it, lr=1e-5, step_loss=0.0404] Steps:   2%|▏         | 17948/1000000 [12:33:04<2384:23:19,  8.74s/it, lr=1e-5, step_loss=0.0404][RANK-0]: Step: [17948], local_loss=1.0171080827713013, train_loss=0.13976351916790009, time_cost=2.887436628341675
Steps:   2%|▏         | 17948/1000000 [12:33:04<2384:23:19,  8.74s/it, lr=1e-5, step_loss=1.02]  Steps:   2%|▏         | 17949/1000000 [12:33:13<2402:29:23,  8.81s/it, lr=1e-5, step_loss=1.02][RANK-0]: Step: [17949], local_loss=0.028859445825219154, train_loss=0.08353665471076965, time_cost=1.6158668994903564
Steps:   2%|▏         | 17949/1000000 [12:33:13<2402:29:23,  8.81s/it, lr=1e-5, step_loss=0.0289]Steps:   2%|▏         | 17950/1000000 [12:33:23<2471:28:34,  9.06s/it, lr=1e-5, step_loss=0.0289][RANK-0]: Step: [17950], local_loss=0.016451247036457062, train_loss=0.022916045039892197, time_cost=2.2794606685638428
Steps:   2%|▏         | 17950/1000000 [12:33:23<2471:28:34,  9.06s/it, lr=1e-5, step_loss=0.0165]Steps:   2%|▏         | 17951/1000000 [12:33:28<2207:05:04,  8.09s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [17951], local_loss=0.007247315254062414, train_loss=0.012682616710662842, time_cost=4.268211603164673
Steps:   2%|▏         | 17951/1000000 [12:33:28<2207:05:04,  8.09s/it, lr=1e-5, step_loss=0.00725]Steps:   2%|▏         | 17952/1000000 [12:33:34<1982:55:03,  7.27s/it, lr=1e-5, step_loss=0.00725][RANK-0]: Step: [17952], local_loss=0.09631579369306564, train_loss=0.0803908035159111, time_cost=1.2229373455047607
Steps:   2%|▏         | 17952/1000000 [12:33:34<1982:55:03,  7.27s/it, lr=1e-5, step_loss=0.0963] Steps:   2%|▏         | 17953/1000000 [12:33:38<1719:24:35,  6.30s/it, lr=1e-5, step_loss=0.0963][RANK-0]: Step: [17953], local_loss=0.02192172221839428, train_loss=0.0719967857003212, time_cost=1.3293859958648682
Steps:   2%|▏         | 17953/1000000 [12:33:38<1719:24:35,  6.30s/it, lr=1e-5, step_loss=0.0219]Steps:   2%|▏         | 17954/1000000 [12:33:46<1860:25:32,  6.82s/it, lr=1e-5, step_loss=0.0219][RANK-0]: Step: [17954], local_loss=0.008801371790468693, train_loss=0.08051949739456177, time_cost=1.8531830310821533
Steps:   2%|▏         | 17954/1000000 [12:33:46<1860:25:32,  6.82s/it, lr=1e-5, step_loss=0.0088]Steps:   2%|▏         | 17955/1000000 [12:33:50<1667:21:21,  6.11s/it, lr=1e-5, step_loss=0.0088][RANK-0]: Step: [17955], local_loss=0.037718042731285095, train_loss=0.13065841794013977, time_cost=3.741471290588379
Steps:   2%|▏         | 17955/1000000 [12:33:50<1667:21:21,  6.11s/it, lr=1e-5, step_loss=0.0377]Steps:   2%|▏         | 17956/1000000 [12:34:04<2278:08:13,  8.35s/it, lr=1e-5, step_loss=0.0377][RANK-0]: Step: [17956], local_loss=0.03429877385497093, train_loss=0.03147604316473007, time_cost=4.605804443359375
Steps:   2%|▏         | 17956/1000000 [12:34:04<2278:08:13,  8.35s/it, lr=1e-5, step_loss=0.0343]Steps:   2%|▏         | 17957/1000000 [12:34:09<2042:53:50,  7.49s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [17957], local_loss=0.0066771795973181725, train_loss=0.015476387925446033, time_cost=1.220848560333252
Steps:   2%|▏         | 17957/1000000 [12:34:09<2042:53:50,  7.49s/it, lr=1e-5, step_loss=0.00668]Steps:   2%|▏         | 17958/1000000 [12:34:18<2177:29:59,  7.98s/it, lr=1e-5, step_loss=0.00668][RANK-0]: Step: [17958], local_loss=0.05146445333957672, train_loss=0.0342976413667202, time_cost=1.2788550853729248
Steps:   2%|▏         | 17958/1000000 [12:34:19<2177:29:59,  7.98s/it, lr=1e-5, step_loss=0.0515] Steps:   2%|▏         | 17959/1000000 [12:34:23<1866:13:32,  6.84s/it, lr=1e-5, step_loss=0.0515][RANK-0]: Step: [17959], local_loss=0.05207955464720726, train_loss=0.041908249258995056, time_cost=1.4269659519195557
Steps:   2%|▏         | 17959/1000000 [12:34:23<1866:13:32,  6.84s/it, lr=1e-5, step_loss=0.0521]Steps:   2%|▏         | 17960/1000000 [12:34:37<2441:09:25,  8.95s/it, lr=1e-5, step_loss=0.0521][RANK-0]: Step: [17960], local_loss=0.005922788754105568, train_loss=0.049518439918756485, time_cost=6.341046094894409
Steps:   2%|▏         | 17960/1000000 [12:34:37<2441:09:25,  8.95s/it, lr=1e-5, step_loss=0.00592]Steps:   2%|▏         | 17961/1000000 [12:34:44<2326:12:08,  8.53s/it, lr=1e-5, step_loss=0.00592][RANK-0]: Step: [17961], local_loss=0.00457411166280508, train_loss=0.01385405845940113, time_cost=1.5301694869995117
Steps:   2%|▏         | 17961/1000000 [12:34:44<2326:12:08,  8.53s/it, lr=1e-5, step_loss=0.00457]Steps:   2%|▏         | 17962/1000000 [12:34:50<2096:30:02,  7.69s/it, lr=1e-5, step_loss=0.00457][RANK-0]: Step: [17962], local_loss=0.02101333625614643, train_loss=0.04077344015240669, time_cost=3.323462724685669
Steps:   2%|▏         | 17962/1000000 [12:34:50<2096:30:02,  7.69s/it, lr=1e-5, step_loss=0.021]  Steps:   2%|▏         | 17963/1000000 [12:35:01<2368:37:40,  8.68s/it, lr=1e-5, step_loss=0.021][RANK-0]: Step: [17963], local_loss=0.013766143471002579, train_loss=0.023141654208302498, time_cost=3.847090005874634
Steps:   2%|▏         | 17963/1000000 [12:35:01<2368:37:40,  8.68s/it, lr=1e-5, step_loss=0.0138]Steps:   2%|▏         | 17964/1000000 [12:35:06<2079:40:29,  7.62s/it, lr=1e-5, step_loss=0.0138][RANK-0]: Step: [17964], local_loss=0.0094796447083354, train_loss=0.14928178489208221, time_cost=2.1270105838775635
Steps:   2%|▏         | 17964/1000000 [12:35:06<2079:40:29,  7.62s/it, lr=1e-5, step_loss=0.00948]Steps:   2%|▏         | 17965/1000000 [12:35:11<1885:45:26,  6.91s/it, lr=1e-5, step_loss=0.00948][RANK-0]: Step: [17965], local_loss=0.0064234137535095215, train_loss=0.013072457164525986, time_cost=2.2984020709991455
Steps:   2%|▏         | 17965/1000000 [12:35:11<1885:45:26,  6.91s/it, lr=1e-5, step_loss=0.00642]Steps:   2%|▏         | 17966/1000000 [12:35:23<2282:57:18,  8.37s/it, lr=1e-5, step_loss=0.00642][RANK-0]: Step: [17966], local_loss=0.04270780086517334, train_loss=0.09983804821968079, time_cost=4.492175102233887
Steps:   2%|▏         | 17966/1000000 [12:35:23<2282:57:18,  8.37s/it, lr=1e-5, step_loss=0.0427] Steps:   2%|▏         | 17967/1000000 [12:35:37<2761:40:17, 10.12s/it, lr=1e-5, step_loss=0.0427][RANK-0]: Step: [17967], local_loss=0.05481475964188576, train_loss=0.07178756594657898, time_cost=4.461632490158081
Steps:   2%|▏         | 17967/1000000 [12:35:37<2761:40:17, 10.12s/it, lr=1e-5, step_loss=0.0548]Steps:   2%|▏         | 17968/1000000 [12:35:51<3089:00:53, 11.32s/it, lr=1e-5, step_loss=0.0548][RANK-0]: Step: [17968], local_loss=0.007082045543938875, train_loss=0.016585323959589005, time_cost=1.5952460765838623
Steps:   2%|▏         | 17968/1000000 [12:35:51<3089:00:53, 11.32s/it, lr=1e-5, step_loss=0.00708]Steps:   2%|▏         | 17969/1000000 [12:36:04<3218:08:22, 11.80s/it, lr=1e-5, step_loss=0.00708][RANK-0]: Step: [17969], local_loss=0.008708292618393898, train_loss=0.055003780871629715, time_cost=4.288941144943237
Steps:   2%|▏         | 17969/1000000 [12:36:04<3218:08:22, 11.80s/it, lr=1e-5, step_loss=0.00871]Steps:   2%|▏         | 17970/1000000 [12:36:15<3099:07:31, 11.36s/it, lr=1e-5, step_loss=0.00871][RANK-0]: Step: [17970], local_loss=0.004217030014842749, train_loss=0.022366641089320183, time_cost=7.681714773178101
Steps:   2%|▏         | 17970/1000000 [12:36:15<3099:07:31, 11.36s/it, lr=1e-5, step_loss=0.00422]Steps:   2%|▏         | 17971/1000000 [12:36:26<3097:47:54, 11.36s/it, lr=1e-5, step_loss=0.00422][RANK-0]: Step: [17971], local_loss=0.01771760918200016, train_loss=0.0142293032258749, time_cost=3.3026583194732666
Steps:   2%|▏         | 17971/1000000 [12:36:26<3097:47:54, 11.36s/it, lr=1e-5, step_loss=0.0177] Steps:   2%|▏         | 17972/1000000 [12:36:41<3436:26:19, 12.60s/it, lr=1e-5, step_loss=0.0177][RANK-0]: Step: [17972], local_loss=0.014183048158884048, train_loss=0.019602350890636444, time_cost=4.307652950286865
Steps:   2%|▏         | 17972/1000000 [12:36:41<3436:26:19, 12.60s/it, lr=1e-5, step_loss=0.0142]Steps:   2%|▏         | 17973/1000000 [12:36:47<2838:33:06, 10.41s/it, lr=1e-5, step_loss=0.0142][RANK-0]: Step: [17973], local_loss=0.003819131525233388, train_loss=0.039446648210287094, time_cost=3.8531367778778076
Steps:   2%|▏         | 17973/1000000 [12:36:47<2838:33:06, 10.41s/it, lr=1e-5, step_loss=0.00382]Steps:   2%|▏         | 17974/1000000 [12:37:03<3290:28:14, 12.06s/it, lr=1e-5, step_loss=0.00382][RANK-0]: Step: [17974], local_loss=0.011651475913822651, train_loss=0.052980512380599976, time_cost=4.928093194961548
Steps:   2%|▏         | 17974/1000000 [12:37:03<3290:28:14, 12.06s/it, lr=1e-5, step_loss=0.0117] Steps:   2%|▏         | 17975/1000000 [12:37:10<2871:18:47, 10.53s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [17975], local_loss=0.008258476853370667, train_loss=0.007672571577131748, time_cost=3.029482364654541
Steps:   2%|▏         | 17975/1000000 [12:37:10<2871:18:47, 10.53s/it, lr=1e-5, step_loss=0.00826]Steps:   2%|▏         | 17976/1000000 [12:37:21<2904:01:23, 10.65s/it, lr=1e-5, step_loss=0.00826][RANK-0]: Step: [17976], local_loss=0.018153749406337738, train_loss=0.027894869446754456, time_cost=2.2596423625946045
Steps:   2%|▏         | 17976/1000000 [12:37:21<2904:01:23, 10.65s/it, lr=1e-5, step_loss=0.0182] Steps:   2%|▏         | 17977/1000000 [12:37:31<2927:25:07, 10.73s/it, lr=1e-5, step_loss=0.0182][RANK-0]: Step: [17977], local_loss=0.050324372947216034, train_loss=0.01748715341091156, time_cost=1.2490286827087402
Steps:   2%|▏         | 17977/1000000 [12:37:31<2927:25:07, 10.73s/it, lr=1e-5, step_loss=0.0503]Steps:   2%|▏         | 17978/1000000 [12:37:42<2952:00:57, 10.82s/it, lr=1e-5, step_loss=0.0503][RANK-0]: Step: [17978], local_loss=0.006116174161434174, train_loss=0.024471573531627655, time_cost=2.7277214527130127
Steps:   2%|▏         | 17978/1000000 [12:37:42<2952:00:57, 10.82s/it, lr=1e-5, step_loss=0.00612]Steps:   2%|▏         | 17979/1000000 [12:37:48<2551:47:48,  9.35s/it, lr=1e-5, step_loss=0.00612][RANK-0]: Step: [17979], local_loss=0.004756017588078976, train_loss=0.01617986522614956, time_cost=1.2766571044921875
Steps:   2%|▏         | 17979/1000000 [12:37:48<2551:47:48,  9.35s/it, lr=1e-5, step_loss=0.00476]Steps:   2%|▏         | 17980/1000000 [12:37:54<2219:09:16,  8.14s/it, lr=1e-5, step_loss=0.00476][RANK-0]: Step: [17980], local_loss=0.10286211222410202, train_loss=0.08286666870117188, time_cost=2.379770040512085
Steps:   2%|▏         | 17980/1000000 [12:37:54<2219:09:16,  8.14s/it, lr=1e-5, step_loss=0.103]  Steps:   2%|▏         | 17981/1000000 [12:37:58<1911:41:49,  7.01s/it, lr=1e-5, step_loss=0.103][RANK-0]: Step: [17981], local_loss=0.0110731590539217, train_loss=0.017705265432596207, time_cost=1.695892333984375
Steps:   2%|▏         | 17981/1000000 [12:37:58<1911:41:49,  7.01s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 17982/1000000 [12:38:07<2083:57:20,  7.64s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [17982], local_loss=0.009260691702365875, train_loss=0.0228253360837698, time_cost=4.295865535736084
Steps:   2%|▏         | 17982/1000000 [12:38:07<2083:57:20,  7.64s/it, lr=1e-5, step_loss=0.00926]Steps:   2%|▏         | 17983/1000000 [12:38:20<2540:24:19,  9.31s/it, lr=1e-5, step_loss=0.00926][RANK-0]: Step: [17983], local_loss=0.011753981001675129, train_loss=0.01949445903301239, time_cost=3.8822720050811768
Steps:   2%|▏         | 17983/1000000 [12:38:20<2540:24:19,  9.31s/it, lr=1e-5, step_loss=0.0118] Steps:   2%|▏         | 17984/1000000 [12:38:34<2861:40:39, 10.49s/it, lr=1e-5, step_loss=0.0118][RANK-0]: Step: [17984], local_loss=0.009224876761436462, train_loss=0.17133952677249908, time_cost=4.702662467956543
Steps:   2%|▏         | 17984/1000000 [12:38:34<2861:40:39, 10.49s/it, lr=1e-5, step_loss=0.00922]Steps:   2%|▏         | 17985/1000000 [12:38:41<2599:33:30,  9.53s/it, lr=1e-5, step_loss=0.00922][RANK-0]: Step: [17985], local_loss=0.02224106714129448, train_loss=0.02013210952281952, time_cost=1.2563698291778564
Steps:   2%|▏         | 17985/1000000 [12:38:41<2599:33:30,  9.53s/it, lr=1e-5, step_loss=0.0222] Steps:   2%|▏         | 17986/1000000 [12:38:47<2314:05:33,  8.48s/it, lr=1e-5, step_loss=0.0222][RANK-0]: Step: [17986], local_loss=0.03864350542426109, train_loss=0.02331826277077198, time_cost=1.9713153839111328
Steps:   2%|▏         | 17986/1000000 [12:38:47<2314:05:33,  8.48s/it, lr=1e-5, step_loss=0.0386]Steps:   2%|▏         | 17987/1000000 [12:38:54<2221:32:11,  8.14s/it, lr=1e-5, step_loss=0.0386][RANK-0]: Step: [17987], local_loss=0.05610689893364906, train_loss=0.07449714094400406, time_cost=5.371147155761719
Steps:   2%|▏         | 17987/1000000 [12:38:54<2221:32:11,  8.14s/it, lr=1e-5, step_loss=0.0561]Steps:   2%|▏         | 17988/1000000 [12:39:06<2473:26:59,  9.07s/it, lr=1e-5, step_loss=0.0561][RANK-0]: Step: [17988], local_loss=0.05686890333890915, train_loss=0.08883734047412872, time_cost=9.711448907852173
Steps:   2%|▏         | 17988/1000000 [12:39:06<2473:26:59,  9.07s/it, lr=1e-5, step_loss=0.0569]Steps:   2%|▏         | 17989/1000000 [12:39:22<3041:42:32, 11.15s/it, lr=1e-5, step_loss=0.0569][RANK-0]: Step: [17989], local_loss=0.021121511235833168, train_loss=0.03208468481898308, time_cost=7.564169645309448
Steps:   2%|▏         | 17989/1000000 [12:39:22<3041:42:32, 11.15s/it, lr=1e-5, step_loss=0.0211]Steps:   2%|▏         | 17990/1000000 [12:39:31<2885:12:22, 10.58s/it, lr=1e-5, step_loss=0.0211][RANK-0]: Step: [17990], local_loss=0.04703294113278389, train_loss=0.054719336330890656, time_cost=3.2673139572143555
Steps:   2%|▏         | 17990/1000000 [12:39:31<2885:12:22, 10.58s/it, lr=1e-5, step_loss=0.047] Steps:   2%|▏         | 17991/1000000 [12:39:38<2580:02:36,  9.46s/it, lr=1e-5, step_loss=0.047][RANK-0]: Step: [17991], local_loss=0.061889201402664185, train_loss=0.03489116579294205, time_cost=5.868875026702881
Steps:   2%|▏         | 17991/1000000 [12:39:38<2580:02:36,  9.46s/it, lr=1e-5, step_loss=0.0619]Steps:   2%|▏         | 17992/1000000 [12:39:51<2937:52:30, 10.77s/it, lr=1e-5, step_loss=0.0619][RANK-0]: Step: [17992], local_loss=1.0105072259902954, train_loss=0.17526227235794067, time_cost=4.514612197875977
Steps:   2%|▏         | 17992/1000000 [12:39:51<2937:52:30, 10.77s/it, lr=1e-5, step_loss=1.01]  Steps:   2%|▏         | 17993/1000000 [12:40:03<2966:40:44, 10.88s/it, lr=1e-5, step_loss=1.01][RANK-0]: Step: [17993], local_loss=0.006966591812670231, train_loss=0.1347023993730545, time_cost=3.7019124031066895
Steps:   2%|▏         | 17993/1000000 [12:40:03<2966:40:44, 10.88s/it, lr=1e-5, step_loss=0.00697]Steps:   2%|▏         | 17994/1000000 [12:40:13<2933:43:50, 10.75s/it, lr=1e-5, step_loss=0.00697][RANK-0]: Step: [17994], local_loss=0.013402510434389114, train_loss=0.0500679537653923, time_cost=3.4124481678009033
Steps:   2%|▏         | 17994/1000000 [12:40:13<2933:43:50, 10.75s/it, lr=1e-5, step_loss=0.0134] Steps:   2%|▏         | 17995/1000000 [12:40:25<3032:06:58, 11.12s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [17995], local_loss=0.005933205597102642, train_loss=0.02822365239262581, time_cost=1.2242000102996826
Steps:   2%|▏         | 17995/1000000 [12:40:25<3032:06:58, 11.12s/it, lr=1e-5, step_loss=0.00593]Steps:   2%|▏         | 17996/1000000 [12:40:29<2488:47:30,  9.12s/it, lr=1e-5, step_loss=0.00593][RANK-0]: Step: [17996], local_loss=0.013096500188112259, train_loss=0.011964349076151848, time_cost=1.6527254581451416
Steps:   2%|▏         | 17996/1000000 [12:40:30<2488:47:30,  9.12s/it, lr=1e-5, step_loss=0.0131] Steps:   2%|▏         | 17997/1000000 [12:40:34<2142:00:25,  7.85s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [17997], local_loss=0.14183536171913147, train_loss=0.037725239992141724, time_cost=2.3537073135375977
Steps:   2%|▏         | 17997/1000000 [12:40:34<2142:00:25,  7.85s/it, lr=1e-5, step_loss=0.142] Steps:   2%|▏         | 17998/1000000 [12:40:40<1920:54:59,  7.04s/it, lr=1e-5, step_loss=0.142][RANK-0]: Step: [17998], local_loss=0.07739560306072235, train_loss=0.050404928624629974, time_cost=2.726788282394409
Steps:   2%|▏         | 17998/1000000 [12:40:40<1920:54:59,  7.04s/it, lr=1e-5, step_loss=0.0774]Steps:   2%|▏         | 17999/1000000 [12:40:49<2156:12:36,  7.90s/it, lr=1e-5, step_loss=0.0774][RANK-0]: Step: [17999], local_loss=0.9856921434402466, train_loss=0.15713249146938324, time_cost=1.211484670639038
Steps:   2%|▏         | 17999/1000000 [12:40:49<2156:12:36,  7.90s/it, lr=1e-5, step_loss=0.986] Steps:   2%|▏         | 18000/1000000 [12:40:59<2250:49:33,  8.25s/it, lr=1e-5, step_loss=0.986][RANK-0]: Step: [18000], local_loss=0.2826196551322937, train_loss=0.09152820706367493, time_cost=1.7744417190551758
09/18/2024 22:05:01 - INFO - accelerate.accelerator - Saving current state to /home/save_dir/runs/allinpaint_stage1/checkpoint-18000
09/18/2024 22:05:01 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-18 22:05:01,894] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-09-18 22:05:01,924] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/mp_rank_00_model_states.pt
[2024-09-18 22:05:01,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-18 22:05:19,936] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-18 22:05:19,951] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt...
[2024-09-18 22:05:19,951] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2024-09-18 22:05:19,951] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
[2024-09-18 22:05:19,951] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt...
[2024-09-18 22:05:19,951] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2024-09-18 22:05:19,951] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt...
[2024-09-18 22:05:19,951] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-09-18 22:05:19,954] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-18 22:05:53,876] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt.
[2024-09-18 22:05:53,876] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt
[2024-09-18 22:05:53,876] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 22:05:55,824] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt.
[2024-09-18 22:05:55,825] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt
[2024-09-18 22:05:55,825] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 22:05:55,915] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
[2024-09-18 22:05:55,916] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
[2024-09-18 22:05:55,916] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 22:05:55,965] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2024-09-18 22:05:55,965] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[2024-09-18 22:05:55,965] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 22:05:55,994] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt.
[2024-09-18 22:05:55,994] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt
[2024-09-18 22:05:55,994] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 22:05:55,996] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2024-09-18 22:05:55,996] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[2024-09-18 22:05:55,996] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 22:05:56,108] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-18 22:05:56,165] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-18 22:05:56,165] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-09-18 22:05:56,193] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-09-18 22:05:56,193] [INFO] [engine.py:3443:_save_zero_checkpoint] zero checkpoint saved /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-09-18 22:05:56,193] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/18/2024 22:05:56 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/pytorch_model
{'norm_num_groups', 'dropout', 'use_additional_conditions'} was not found in config. Values will be initialized to default values.
Configuration saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/model_ema/config.json
Model weights saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/model_ema/diffusion_pytorch_model.safetensors
Configuration saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/model/config.json
Model weights saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/model/diffusion_pytorch_model.safetensors
09/18/2024 22:06:59 - INFO - accelerate.checkpointing - Scheduler state saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/scheduler.bin
09/18/2024 22:06:59 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/sampler.bin
09/18/2024 22:06:59 - INFO - accelerate.checkpointing - Random states saved in /home/save_dir/runs/allinpaint_stage1/checkpoint-18000/random_states_0.pkl
09/18/2024 22:06:59 - INFO - __main__ - Saved state to /home/save_dir/runs/allinpaint_stage1/checkpoint-18000
Steps:   2%|▏         | 18000/1000000 [12:42:56<2250:49:33,  8.25s/it, lr=1e-5, step_loss=0.283]Steps:   2%|▏         | 18001/1000000 [12:43:00<11537:47:47, 42.30s/it, lr=1e-5, step_loss=0.283][RANK-0]: Step: [18001], local_loss=0.058915164321660995, train_loss=0.042529698461294174, time_cost=1.3276517391204834
Steps:   2%|▏         | 18001/1000000 [12:43:00<11537:47:47, 42.30s/it, lr=1e-5, step_loss=0.0589]Steps:   2%|▏         | 18002/1000000 [12:43:12<9061:56:23, 33.22s/it, lr=1e-5, step_loss=0.0589] [RANK-0]: Step: [18002], local_loss=0.008859915658831596, train_loss=0.019945882260799408, time_cost=5.942732572555542
Steps:   2%|▏         | 18002/1000000 [12:43:12<9061:56:23, 33.22s/it, lr=1e-5, step_loss=0.00886]Steps:   2%|▏         | 18003/1000000 [12:43:21<7085:20:01, 25.97s/it, lr=1e-5, step_loss=0.00886][RANK-0]: Step: [18003], local_loss=0.07131955772638321, train_loss=0.03823030740022659, time_cost=1.6855108737945557
Steps:   2%|▏         | 18003/1000000 [12:43:21<7085:20:01, 25.97s/it, lr=1e-5, step_loss=0.0713] Steps:   2%|▏         | 18004/1000000 [12:43:26<5368:39:12, 19.68s/it, lr=1e-5, step_loss=0.0713][RANK-0]: Step: [18004], local_loss=0.03430434316396713, train_loss=0.04339243099093437, time_cost=1.3135874271392822
Steps:   2%|▏         | 18004/1000000 [12:43:26<5368:39:12, 19.68s/it, lr=1e-5, step_loss=0.0343]Steps:   2%|▏         | 18005/1000000 [12:43:31<4128:41:51, 15.14s/it, lr=1e-5, step_loss=0.0343][RANK-0]: Step: [18005], local_loss=0.011130310595035553, train_loss=0.03223086893558502, time_cost=1.7480583190917969
Steps:   2%|▏         | 18005/1000000 [12:43:31<4128:41:51, 15.14s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 18006/1000000 [12:43:44<3930:49:48, 14.41s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [18006], local_loss=0.003618052462115884, train_loss=0.03826231509447098, time_cost=3.950289249420166
Steps:   2%|▏         | 18006/1000000 [12:43:44<3930:49:48, 14.41s/it, lr=1e-5, step_loss=0.00362]Steps:   2%|▏         | 18007/1000000 [12:43:51<3372:32:20, 12.36s/it, lr=1e-5, step_loss=0.00362][RANK-0]: Step: [18007], local_loss=0.040771834552288055, train_loss=0.04030274599790573, time_cost=3.7671728134155273
Steps:   2%|▏         | 18007/1000000 [12:43:51<3372:32:20, 12.36s/it, lr=1e-5, step_loss=0.0408] Steps:   2%|▏         | 18008/1000000 [12:43:56<2786:09:09, 10.21s/it, lr=1e-5, step_loss=0.0408][RANK-0]: Step: [18008], local_loss=0.050718165934085846, train_loss=0.028998032212257385, time_cost=2.237872838973999
Steps:   2%|▏         | 18008/1000000 [12:43:56<2786:09:09, 10.21s/it, lr=1e-5, step_loss=0.0507]Steps:   2%|▏         | 18009/1000000 [12:44:10<3097:57:33, 11.36s/it, lr=1e-5, step_loss=0.0507][RANK-0]: Step: [18009], local_loss=0.015151206403970718, train_loss=0.0701194629073143, time_cost=5.744014739990234
Steps:   2%|▏         | 18009/1000000 [12:44:10<3097:57:33, 11.36s/it, lr=1e-5, step_loss=0.0152]Steps:   2%|▏         | 18010/1000000 [12:44:27<3521:56:10, 12.91s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [18010], local_loss=0.01030721515417099, train_loss=0.022150501608848572, time_cost=8.196459293365479
Steps:   2%|▏         | 18010/1000000 [12:44:27<3521:56:10, 12.91s/it, lr=1e-5, step_loss=0.0103]Steps:   2%|▏         | 18011/1000000 [12:44:41<3642:57:09, 13.36s/it, lr=1e-5, step_loss=0.0103][RANK-0]: Step: [18011], local_loss=0.006005221977829933, train_loss=0.01165944617241621, time_cost=6.789825439453125
Steps:   2%|▏         | 18011/1000000 [12:44:41<3642:57:09, 13.36s/it, lr=1e-5, step_loss=0.00601]Steps:   2%|▏         | 18012/1000000 [12:44:57<3861:17:58, 14.16s/it, lr=1e-5, step_loss=0.00601][RANK-0]: Step: [18012], local_loss=0.02279116027057171, train_loss=0.032908692955970764, time_cost=6.75730562210083
Steps:   2%|▏         | 18012/1000000 [12:44:57<3861:17:58, 14.16s/it, lr=1e-5, step_loss=0.0228] Steps:   2%|▏         | 18013/1000000 [12:45:04<3263:05:12, 11.96s/it, lr=1e-5, step_loss=0.0228][RANK-0]: Step: [18013], local_loss=0.005707903299480677, train_loss=0.012488391250371933, time_cost=2.32489275932312
Steps:   2%|▏         | 18013/1000000 [12:45:04<3263:05:12, 11.96s/it, lr=1e-5, step_loss=0.00571]Steps:   2%|▏         | 18014/1000000 [12:45:15<3177:05:49, 11.65s/it, lr=1e-5, step_loss=0.00571][RANK-0]: Step: [18014], local_loss=0.025022296234965324, train_loss=0.02358689159154892, time_cost=1.813185214996338
Steps:   2%|▏         | 18014/1000000 [12:45:15<3177:05:49, 11.65s/it, lr=1e-5, step_loss=0.025]  Steps:   2%|▏         | 18015/1000000 [12:45:22<2814:04:25, 10.32s/it, lr=1e-5, step_loss=0.025][RANK-0]: Step: [18015], local_loss=0.04358759522438049, train_loss=0.04642503336071968, time_cost=6.021589279174805
Steps:   2%|▏         | 18015/1000000 [12:45:22<2814:04:25, 10.32s/it, lr=1e-5, step_loss=0.0436]Steps:   2%|▏         | 18016/1000000 [12:45:32<2722:47:33,  9.98s/it, lr=1e-5, step_loss=0.0436][RANK-0]: Step: [18016], local_loss=0.017075112089514732, train_loss=0.03646958991885185, time_cost=2.1862940788269043
Steps:   2%|▏         | 18016/1000000 [12:45:32<2722:47:33,  9.98s/it, lr=1e-5, step_loss=0.0171]Steps:   2%|▏         | 18017/1000000 [12:45:38<2464:50:47,  9.04s/it, lr=1e-5, step_loss=0.0171][RANK-0]: Step: [18017], local_loss=0.030798476189374924, train_loss=0.04960236698389053, time_cost=1.3446087837219238
Steps:   2%|▏         | 18017/1000000 [12:45:38<2464:50:47,  9.04s/it, lr=1e-5, step_loss=0.0308]Steps:   2%|▏         | 18018/1000000 [12:45:46<2310:56:22,  8.47s/it, lr=1e-5, step_loss=0.0308][RANK-0]: Step: [18018], local_loss=0.004002555273473263, train_loss=0.06308402866125107, time_cost=2.7150473594665527
Steps:   2%|▏         | 18018/1000000 [12:45:46<2310:56:22,  8.47s/it, lr=1e-5, step_loss=0.004] Steps:   2%|▏         | 18019/1000000 [12:45:56<2501:54:47,  9.17s/it, lr=1e-5, step_loss=0.004][RANK-0]: Step: [18019], local_loss=0.04872378334403038, train_loss=0.04423556476831436, time_cost=3.8600544929504395
Steps:   2%|▏         | 18019/1000000 [12:45:56<2501:54:47,  9.17s/it, lr=1e-5, step_loss=0.0487]Steps:   2%|▏         | 18020/1000000 [12:46:01<2096:50:06,  7.69s/it, lr=1e-5, step_loss=0.0487][RANK-0]: Step: [18020], local_loss=0.014505078084766865, train_loss=0.016161687672138214, time_cost=1.398451328277588
Steps:   2%|▏         | 18020/1000000 [12:46:01<2096:50:06,  7.69s/it, lr=1e-5, step_loss=0.0145]Steps:   2%|▏         | 18021/1000000 [12:46:11<2361:02:55,  8.66s/it, lr=1e-5, step_loss=0.0145][RANK-0]: Step: [18021], local_loss=0.0055577801540493965, train_loss=0.07832854986190796, time_cost=4.583942174911499
Steps:   2%|▏         | 18021/1000000 [12:46:11<2361:02:55,  8.66s/it, lr=1e-5, step_loss=0.00556]Steps:   2%|▏         | 18022/1000000 [12:46:18<2200:23:05,  8.07s/it, lr=1e-5, step_loss=0.00556][RANK-0]: Step: [18022], local_loss=0.07415978610515594, train_loss=0.0416533499956131, time_cost=1.5053975582122803
Steps:   2%|▏         | 18022/1000000 [12:46:18<2200:23:05,  8.07s/it, lr=1e-5, step_loss=0.0742] Steps:   2%|▏         | 18023/1000000 [12:46:25<2134:34:49,  7.83s/it, lr=1e-5, step_loss=0.0742][RANK-0]: Step: [18023], local_loss=0.012862570583820343, train_loss=0.028047718107700348, time_cost=1.2392005920410156
Steps:   2%|▏         | 18023/1000000 [12:46:25<2134:34:49,  7.83s/it, lr=1e-5, step_loss=0.0129]Steps:   2%|▏         | 18024/1000000 [12:46:32<2008:16:07,  7.36s/it, lr=1e-5, step_loss=0.0129][RANK-0]: Step: [18024], local_loss=0.05123762786388397, train_loss=0.03347780182957649, time_cost=1.208810806274414
Steps:   2%|▏         | 18024/1000000 [12:46:32<2008:16:07,  7.36s/it, lr=1e-5, step_loss=0.0512]Steps:   2%|▏         | 18025/1000000 [12:46:37<1872:41:40,  6.87s/it, lr=1e-5, step_loss=0.0512][RANK-0]: Step: [18025], local_loss=0.009605539962649345, train_loss=0.03378564119338989, time_cost=3.1401782035827637
Steps:   2%|▏         | 18025/1000000 [12:46:37<1872:41:40,  6.87s/it, lr=1e-5, step_loss=0.00961]Steps:   2%|▏         | 18026/1000000 [12:46:42<1675:18:11,  6.14s/it, lr=1e-5, step_loss=0.00961][RANK-0]: Step: [18026], local_loss=0.008328273892402649, train_loss=0.03691964969038963, time_cost=1.7119956016540527
Steps:   2%|▏         | 18026/1000000 [12:46:42<1675:18:11,  6.14s/it, lr=1e-5, step_loss=0.00833]Steps:   2%|▏         | 18027/1000000 [12:46:46<1509:58:30,  5.54s/it, lr=1e-5, step_loss=0.00833][RANK-0]: Step: [18027], local_loss=0.02014363370835781, train_loss=0.03287212550640106, time_cost=1.2471060752868652
Steps:   2%|▏         | 18027/1000000 [12:46:46<1509:58:30,  5.54s/it, lr=1e-5, step_loss=0.0201] Steps:   2%|▏         | 18028/1000000 [12:46:53<1610:52:51,  5.91s/it, lr=1e-5, step_loss=0.0201][RANK-0]: Step: [18028], local_loss=0.008984294719994068, train_loss=0.01831599697470665, time_cost=2.420081853866577
Steps:   2%|▏         | 18028/1000000 [12:46:53<1610:52:51,  5.91s/it, lr=1e-5, step_loss=0.00898]Steps:   2%|▏         | 18029/1000000 [12:46:57<1501:37:01,  5.51s/it, lr=1e-5, step_loss=0.00898][RANK-0]: Step: [18029], local_loss=0.06319669634103775, train_loss=0.022128982469439507, time_cost=1.8749423027038574
Steps:   2%|▏         | 18029/1000000 [12:46:57<1501:37:01,  5.51s/it, lr=1e-5, step_loss=0.0632] Steps:   2%|▏         | 18030/1000000 [12:47:08<1901:22:22,  6.97s/it, lr=1e-5, step_loss=0.0632][RANK-0]: Step: [18030], local_loss=0.05718492344021797, train_loss=0.02071573957800865, time_cost=5.089327335357666
Steps:   2%|▏         | 18030/1000000 [12:47:08<1901:22:22,  6.97s/it, lr=1e-5, step_loss=0.0572]Steps:   2%|▏         | 18031/1000000 [12:47:14<1817:54:02,  6.66s/it, lr=1e-5, step_loss=0.0572][RANK-0]: Step: [18031], local_loss=0.06323881447315216, train_loss=0.021843431517481804, time_cost=4.817842245101929
Steps:   2%|▏         | 18031/1000000 [12:47:14<1817:54:02,  6.66s/it, lr=1e-5, step_loss=0.0632]Steps:   2%|▏         | 18032/1000000 [12:47:29<2513:17:02,  9.21s/it, lr=1e-5, step_loss=0.0632][RANK-0]: Step: [18032], local_loss=0.039892349392175674, train_loss=0.03044910542666912, time_cost=5.664201736450195
Steps:   2%|▏         | 18032/1000000 [12:47:29<2513:17:02,  9.21s/it, lr=1e-5, step_loss=0.0399]Steps:   2%|▏         | 18033/1000000 [12:47:33<2115:08:57,  7.75s/it, lr=1e-5, step_loss=0.0399][RANK-0]: Step: [18033], local_loss=0.02000107429921627, train_loss=0.06298111379146576, time_cost=1.6555836200714111
Steps:   2%|▏         | 18033/1000000 [12:47:33<2115:08:57,  7.75s/it, lr=1e-5, step_loss=0.02]  Steps:   2%|▏         | 18034/1000000 [12:47:45<2441:10:59,  8.95s/it, lr=1e-5, step_loss=0.02][RANK-0]: Step: [18034], local_loss=0.05426398664712906, train_loss=0.03662284463644028, time_cost=2.2220921516418457
Steps:   2%|▏         | 18034/1000000 [12:47:45<2441:10:59,  8.95s/it, lr=1e-5, step_loss=0.0543]Steps:   2%|▏         | 18035/1000000 [12:47:58<2752:45:17, 10.09s/it, lr=1e-5, step_loss=0.0543][RANK-0]: Step: [18035], local_loss=0.011855942197144032, train_loss=0.01787715218961239, time_cost=3.6288907527923584
Steps:   2%|▏         | 18035/1000000 [12:47:58<2752:45:17, 10.09s/it, lr=1e-5, step_loss=0.0119]Steps:   2%|▏         | 18036/1000000 [12:48:07<2670:49:53,  9.79s/it, lr=1e-5, step_loss=0.0119][RANK-0]: Step: [18036], local_loss=0.008690639398992062, train_loss=0.009881878271698952, time_cost=1.3139398097991943
Steps:   2%|▏         | 18036/1000000 [12:48:07<2670:49:53,  9.79s/it, lr=1e-5, step_loss=0.00869]Steps:   2%|▏         | 18037/1000000 [12:48:16<2610:35:55,  9.57s/it, lr=1e-5, step_loss=0.00869][RANK-0]: Step: [18037], local_loss=0.007312421221286058, train_loss=0.04582776501774788, time_cost=1.5782678127288818
Steps:   2%|▏         | 18037/1000000 [12:48:16<2610:35:55,  9.57s/it, lr=1e-5, step_loss=0.00731]Steps:   2%|▏         | 18038/1000000 [12:48:20<2178:27:58,  7.99s/it, lr=1e-5, step_loss=0.00731][RANK-0]: Step: [18038], local_loss=0.08081024885177612, train_loss=0.027186671271920204, time_cost=1.4293100833892822
Steps:   2%|▏         | 18038/1000000 [12:48:20<2178:27:58,  7.99s/it, lr=1e-5, step_loss=0.0808] Steps:   2%|▏         | 18039/1000000 [12:48:32<2472:37:05,  9.06s/it, lr=1e-5, step_loss=0.0808][RANK-0]: Step: [18039], local_loss=0.011053778231143951, train_loss=0.029493030160665512, time_cost=2.951946973800659
Steps:   2%|▏         | 18039/1000000 [12:48:32<2472:37:05,  9.06s/it, lr=1e-5, step_loss=0.0111]Steps:   2%|▏         | 18040/1000000 [12:48:43<2642:29:26,  9.69s/it, lr=1e-5, step_loss=0.0111][RANK-0]: Step: [18040], local_loss=0.0059082466177642345, train_loss=0.019201867282390594, time_cost=3.223776340484619
Steps:   2%|▏         | 18040/1000000 [12:48:43<2642:29:26,  9.69s/it, lr=1e-5, step_loss=0.00591]Steps:   2%|▏         | 18041/1000000 [12:48:55<2831:46:23, 10.38s/it, lr=1e-5, step_loss=0.00591][RANK-0]: Step: [18041], local_loss=0.015649812296032906, train_loss=0.021258899942040443, time_cost=5.0774149894714355
Steps:   2%|▏         | 18041/1000000 [12:48:55<2831:46:23, 10.38s/it, lr=1e-5, step_loss=0.0156] Steps:   2%|▏         | 18042/1000000 [12:49:01<2470:04:50,  9.06s/it, lr=1e-5, step_loss=0.0156][RANK-0]: Step: [18042], local_loss=0.01978405937552452, train_loss=0.024731913581490517, time_cost=1.2925238609313965
Steps:   2%|▏         | 18042/1000000 [12:49:01<2470:04:50,  9.06s/it, lr=1e-5, step_loss=0.0198]Steps:   2%|▏         | 18043/1000000 [12:49:06<2128:22:35,  7.80s/it, lr=1e-5, step_loss=0.0198][RANK-0]: Step: [18043], local_loss=0.08231678605079651, train_loss=0.06900531053543091, time_cost=1.6266415119171143
Steps:   2%|▏         | 18043/1000000 [12:49:06<2128:22:35,  7.80s/it, lr=1e-5, step_loss=0.0823]Steps:   2%|▏         | 18044/1000000 [12:49:12<1992:54:44,  7.31s/it, lr=1e-5, step_loss=0.0823][RANK-0]: Step: [18044], local_loss=0.03690468147397041, train_loss=0.04606448486447334, time_cost=2.1729373931884766
Steps:   2%|▏         | 18044/1000000 [12:49:12<1992:54:44,  7.31s/it, lr=1e-5, step_loss=0.0369]Steps:   2%|▏         | 18045/1000000 [12:49:16<1770:26:12,  6.49s/it, lr=1e-5, step_loss=0.0369][RANK-0]: Step: [18045], local_loss=0.013864520937204361, train_loss=0.03245900571346283, time_cost=1.4529023170471191
Steps:   2%|▏         | 18045/1000000 [12:49:16<1770:26:12,  6.49s/it, lr=1e-5, step_loss=0.0139]Steps:   2%|▏         | 18046/1000000 [12:49:23<1812:33:57,  6.65s/it, lr=1e-5, step_loss=0.0139][RANK-0]: Step: [18046], local_loss=0.005847637075930834, train_loss=0.0473075732588768, time_cost=2.939220905303955
Steps:   2%|▏         | 18046/1000000 [12:49:23<1812:33:57,  6.65s/it, lr=1e-5, step_loss=0.00585]Steps:   2%|▏         | 18047/1000000 [12:49:29<1749:15:32,  6.41s/it, lr=1e-5, step_loss=0.00585][RANK-0]: Step: [18047], local_loss=0.00810939259827137, train_loss=0.01878335326910019, time_cost=1.5848615169525146
Steps:   2%|▏         | 18047/1000000 [12:49:29<1749:15:32,  6.41s/it, lr=1e-5, step_loss=0.00811]Steps:   2%|▏         | 18048/1000000 [12:49:35<1660:34:19,  6.09s/it, lr=1e-5, step_loss=0.00811][RANK-0]: Step: [18048], local_loss=0.022642342373728752, train_loss=0.048088423907756805, time_cost=1.6891670227050781
Steps:   2%|▏         | 18048/1000000 [12:49:35<1660:34:19,  6.09s/it, lr=1e-5, step_loss=0.0226] Steps:   2%|▏         | 18049/1000000 [12:49:41<1669:04:09,  6.12s/it, lr=1e-5, step_loss=0.0226][RANK-0]: Step: [18049], local_loss=0.014340002089738846, train_loss=0.03456432744860649, time_cost=1.8598599433898926
Steps:   2%|▏         | 18049/1000000 [12:49:41<1669:04:09,  6.12s/it, lr=1e-5, step_loss=0.0143]Steps:   2%|▏         | 18050/1000000 [12:49:53<2194:28:43,  8.05s/it, lr=1e-5, step_loss=0.0143][RANK-0]: Step: [18050], local_loss=0.028113946318626404, train_loss=0.02064250223338604, time_cost=3.048551082611084
Steps:   2%|▏         | 18050/1000000 [12:49:53<2194:28:43,  8.05s/it, lr=1e-5, step_loss=0.0281]Steps:   2%|▏         | 18051/1000000 [12:49:59<2013:06:51,  7.38s/it, lr=1e-5, step_loss=0.0281][RANK-0]: Step: [18051], local_loss=0.007679094094783068, train_loss=0.021281711757183075, time_cost=3.516563892364502
Steps:   2%|▏         | 18051/1000000 [12:49:59<2013:06:51,  7.38s/it, lr=1e-5, step_loss=0.00768]Steps:   2%|▏         | 18052/1000000 [12:50:05<1860:15:23,  6.82s/it, lr=1e-5, step_loss=0.00768][RANK-0]: Step: [18052], local_loss=0.008103631436824799, train_loss=0.03568551316857338, time_cost=3.217022180557251
Steps:   2%|▏         | 18052/1000000 [12:50:05<1860:15:23,  6.82s/it, lr=1e-5, step_loss=0.0081] Steps:   2%|▏         | 18053/1000000 [12:50:16<2245:26:31,  8.23s/it, lr=1e-5, step_loss=0.0081][RANK-0]: Step: [18053], local_loss=0.013117148540914059, train_loss=0.06232758238911629, time_cost=2.9898200035095215
Steps:   2%|▏         | 18053/1000000 [12:50:16<2245:26:31,  8.23s/it, lr=1e-5, step_loss=0.0131]Steps:   2%|▏         | 18054/1000000 [12:50:27<2420:53:22,  8.88s/it, lr=1e-5, step_loss=0.0131][RANK-0]: Step: [18054], local_loss=0.008157162927091122, train_loss=0.0271468423306942, time_cost=2.4291481971740723
Steps:   2%|▏         | 18054/1000000 [12:50:27<2420:53:22,  8.88s/it, lr=1e-5, step_loss=0.00816]Steps:   2%|▏         | 18055/1000000 [12:50:35<2393:43:45,  8.78s/it, lr=1e-5, step_loss=0.00816][RANK-0]: Step: [18055], local_loss=0.004510104190558195, train_loss=0.008307878859341145, time_cost=2.0679776668548584
Steps:   2%|▏         | 18055/1000000 [12:50:35<2393:43:45,  8.78s/it, lr=1e-5, step_loss=0.00451]Steps:   2%|▏         | 18056/1000000 [12:50:46<2576:34:10,  9.45s/it, lr=1e-5, step_loss=0.00451][RANK-0]: Step: [18056], local_loss=0.1389724612236023, train_loss=0.07871157675981522, time_cost=1.5398030281066895
Steps:   2%|▏         | 18056/1000000 [12:50:46<2576:34:10,  9.45s/it, lr=1e-5, step_loss=0.139]  Steps:   2%|▏         | 18057/1000000 [12:50:53<2333:15:55,  8.55s/it, lr=1e-5, step_loss=0.139][RANK-0]: Step: [18057], local_loss=0.011244789697229862, train_loss=0.010897466912865639, time_cost=2.9065704345703125
Steps:   2%|▏         | 18057/1000000 [12:50:53<2333:15:55,  8.55s/it, lr=1e-5, step_loss=0.0112]Steps:   2%|▏         | 18058/1000000 [12:51:00<2215:24:57,  8.12s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [18058], local_loss=0.1350603699684143, train_loss=0.038509923964738846, time_cost=1.3408496379852295
Steps:   2%|▏         | 18058/1000000 [12:51:00<2215:24:57,  8.12s/it, lr=1e-5, step_loss=0.135] Steps:   2%|▏         | 18059/1000000 [12:51:11<2446:26:15,  8.97s/it, lr=1e-5, step_loss=0.135][RANK-0]: Step: [18059], local_loss=0.03273353353142738, train_loss=0.09849155694246292, time_cost=1.3144841194152832
Steps:   2%|▏         | 18059/1000000 [12:51:11<2446:26:15,  8.97s/it, lr=1e-5, step_loss=0.0327]Steps:   2%|▏         | 18060/1000000 [12:51:16<2152:30:12,  7.89s/it, lr=1e-5, step_loss=0.0327][RANK-0]: Step: [18060], local_loss=0.07006534188985825, train_loss=0.08584171533584595, time_cost=4.085931062698364
Steps:   2%|▏         | 18060/1000000 [12:51:16<2152:30:12,  7.89s/it, lr=1e-5, step_loss=0.0701]Steps:   2%|▏         | 18061/1000000 [12:51:25<2229:51:52,  8.18s/it, lr=1e-5, step_loss=0.0701][RANK-0]: Step: [18061], local_loss=0.11050921678543091, train_loss=0.057441871613264084, time_cost=3.4128003120422363
Steps:   2%|▏         | 18061/1000000 [12:51:25<2229:51:52,  8.18s/it, lr=1e-5, step_loss=0.111] Steps:   2%|▏         | 18062/1000000 [12:51:36<2451:24:18,  8.99s/it, lr=1e-5, step_loss=0.111][RANK-0]: Step: [18062], local_loss=0.02128230407834053, train_loss=0.03291739523410797, time_cost=1.3292906284332275
Steps:   2%|▏         | 18062/1000000 [12:51:36<2451:24:18,  8.99s/it, lr=1e-5, step_loss=0.0213]Steps:   2%|▏         | 18063/1000000 [12:51:43<2347:11:55,  8.61s/it, lr=1e-5, step_loss=0.0213][RANK-0]: Step: [18063], local_loss=0.004702581092715263, train_loss=6.118527412414551, time_cost=2.4414925575256348
Steps:   2%|▏         | 18063/1000000 [12:51:43<2347:11:55,  8.61s/it, lr=1e-5, step_loss=0.0047]Steps:   2%|▏         | 18064/1000000 [12:51:55<2548:55:02,  9.34s/it, lr=1e-5, step_loss=0.0047][RANK-0]: Step: [18064], local_loss=0.012954901903867722, train_loss=0.032160840928554535, time_cost=1.8635337352752686
Steps:   2%|▏         | 18064/1000000 [12:51:55<2548:55:02,  9.34s/it, lr=1e-5, step_loss=0.013] Steps:   2%|▏         | 18065/1000000 [12:52:02<2394:27:15,  8.78s/it, lr=1e-5, step_loss=0.013][RANK-0]: Step: [18065], local_loss=0.005671302322298288, train_loss=0.016682881861925125, time_cost=4.424083948135376
Steps:   2%|▏         | 18065/1000000 [12:52:02<2394:27:15,  8.78s/it, lr=1e-5, step_loss=0.00567]Steps:   2%|▏         | 18066/1000000 [12:52:13<2593:17:54,  9.51s/it, lr=1e-5, step_loss=0.00567][RANK-0]: Step: [18066], local_loss=0.01613592728972435, train_loss=0.03856220841407776, time_cost=2.9793684482574463
Steps:   2%|▏         | 18066/1000000 [12:52:13<2593:17:54,  9.51s/it, lr=1e-5, step_loss=0.0161] Steps:   2%|▏         | 18067/1000000 [12:52:25<2742:42:47, 10.06s/it, lr=1e-5, step_loss=0.0161][RANK-0]: Step: [18067], local_loss=0.007977423258125782, train_loss=0.027895428240299225, time_cost=8.746424913406372
Steps:   2%|▏         | 18067/1000000 [12:52:25<2742:42:47, 10.06s/it, lr=1e-5, step_loss=0.00798]Steps:   2%|▏         | 18068/1000000 [12:52:33<2579:55:56,  9.46s/it, lr=1e-5, step_loss=0.00798][RANK-0]: Step: [18068], local_loss=0.02070832997560501, train_loss=0.10454795509576797, time_cost=3.765437364578247
Steps:   2%|▏         | 18068/1000000 [12:52:33<2579:55:56,  9.46s/it, lr=1e-5, step_loss=0.0207] Steps:   2%|▏         | 18069/1000000 [12:52:44<2738:07:03, 10.04s/it, lr=1e-5, step_loss=0.0207][RANK-0]: Step: [18069], local_loss=0.04837774485349655, train_loss=0.02308417484164238, time_cost=3.586916923522949
Steps:   2%|▏         | 18069/1000000 [12:52:44<2738:07:03, 10.04s/it, lr=1e-5, step_loss=0.0484]Steps:   2%|▏         | 18070/1000000 [12:52:52<2580:01:55,  9.46s/it, lr=1e-5, step_loss=0.0484][RANK-0]: Step: [18070], local_loss=0.12702205777168274, train_loss=0.06016043573617935, time_cost=2.513953447341919
Steps:   2%|▏         | 18070/1000000 [12:52:52<2580:01:55,  9.46s/it, lr=1e-5, step_loss=0.127] Steps:   2%|▏         | 18071/1000000 [12:53:00<2442:18:49,  8.95s/it, lr=1e-5, step_loss=0.127][RANK-0]: Step: [18071], local_loss=0.011998928152024746, train_loss=0.06057393178343773, time_cost=3.443883180618286
Steps:   2%|▏         | 18071/1000000 [12:53:00<2442:18:49,  8.95s/it, lr=1e-5, step_loss=0.012]Steps:   2%|▏         | 18072/1000000 [12:53:10<2576:34:43,  9.45s/it, lr=1e-5, step_loss=0.012][RANK-0]: Step: [18072], local_loss=0.0080493725836277, train_loss=0.023468714207410812, time_cost=9.056174278259277
Steps:   2%|▏         | 18072/1000000 [12:53:10<2576:34:43,  9.45s/it, lr=1e-5, step_loss=0.00805]Steps:   2%|▏         | 18073/1000000 [12:53:20<2545:31:11,  9.33s/it, lr=1e-5, step_loss=0.00805][RANK-0]: Step: [18073], local_loss=0.011561542749404907, train_loss=0.033727727830410004, time_cost=4.338506698608398
Steps:   2%|▏         | 18073/1000000 [12:53:20<2545:31:11,  9.33s/it, lr=1e-5, step_loss=0.0116] Steps:   2%|▏         | 18074/1000000 [12:53:27<2399:19:44,  8.80s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [18074], local_loss=0.004505546297878027, train_loss=0.023764971643686295, time_cost=5.67158055305481
Steps:   2%|▏         | 18074/1000000 [12:53:27<2399:19:44,  8.80s/it, lr=1e-5, step_loss=0.00451]Steps:   2%|▏         | 18075/1000000 [12:53:32<2092:04:55,  7.67s/it, lr=1e-5, step_loss=0.00451][RANK-0]: Step: [18075], local_loss=0.13713215291500092, train_loss=0.041880715638399124, time_cost=2.0575613975524902
Steps:   2%|▏         | 18075/1000000 [12:53:32<2092:04:55,  7.67s/it, lr=1e-5, step_loss=0.137]  Steps:   2%|▏         | 18076/1000000 [12:53:39<2033:41:48,  7.46s/it, lr=1e-5, step_loss=0.137][RANK-0]: Step: [18076], local_loss=0.006750529166311026, train_loss=0.020271383225917816, time_cost=1.4334735870361328
Steps:   2%|▏         | 18076/1000000 [12:53:39<2033:41:48,  7.46s/it, lr=1e-5, step_loss=0.00675]Steps:   2%|▏         | 18077/1000000 [12:53:49<2266:46:34,  8.31s/it, lr=1e-5, step_loss=0.00675][RANK-0]: Step: [18077], local_loss=0.008608730509877205, train_loss=0.02970338985323906, time_cost=2.2103800773620605
Steps:   2%|▏         | 18077/1000000 [12:53:49<2266:46:34,  8.31s/it, lr=1e-5, step_loss=0.00861]Steps:   2%|▏         | 18078/1000000 [12:54:04<2788:24:28, 10.22s/it, lr=1e-5, step_loss=0.00861][RANK-0]: Step: [18078], local_loss=0.013165979646146297, train_loss=0.017266925424337387, time_cost=7.306210517883301
Steps:   2%|▏         | 18078/1000000 [12:54:04<2788:24:28, 10.22s/it, lr=1e-5, step_loss=0.0132] Steps:   2%|▏         | 18079/1000000 [12:54:09<2321:53:02,  8.51s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [18079], local_loss=0.012486591935157776, train_loss=0.029106423258781433, time_cost=1.5863041877746582
Steps:   2%|▏         | 18079/1000000 [12:54:09<2321:53:02,  8.51s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 18080/1000000 [12:54:20<2536:16:39,  9.30s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [18080], local_loss=0.05472494289278984, train_loss=0.1598605513572693, time_cost=3.641716241836548
Steps:   2%|▏         | 18080/1000000 [12:54:20<2536:16:39,  9.30s/it, lr=1e-5, step_loss=0.0547]Steps:   2%|▏         | 18081/1000000 [12:54:31<2668:39:53,  9.78s/it, lr=1e-5, step_loss=0.0547][RANK-0]: Step: [18081], local_loss=0.018712446093559265, train_loss=0.030976075679063797, time_cost=2.825160503387451
Steps:   2%|▏         | 18081/1000000 [12:54:31<2668:39:53,  9.78s/it, lr=1e-5, step_loss=0.0187]Steps:   2%|▏         | 18082/1000000 [12:54:45<3004:07:49, 11.01s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [18082], local_loss=0.005244141444563866, train_loss=0.00979945994913578, time_cost=4.516545057296753
Steps:   2%|▏         | 18082/1000000 [12:54:45<3004:07:49, 11.01s/it, lr=1e-5, step_loss=0.00524]Steps:   2%|▏         | 18083/1000000 [12:54:57<3160:53:08, 11.59s/it, lr=1e-5, step_loss=0.00524][RANK-0]: Step: [18083], local_loss=0.014053348451852798, train_loss=0.021938689053058624, time_cost=4.248012542724609
Steps:   2%|▏         | 18083/1000000 [12:54:57<3160:53:08, 11.59s/it, lr=1e-5, step_loss=0.0141] Steps:   2%|▏         | 18084/1000000 [12:55:08<3101:08:08, 11.37s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [18084], local_loss=0.012626049108803272, train_loss=0.04019972309470177, time_cost=2.641096591949463
Steps:   2%|▏         | 18084/1000000 [12:55:08<3101:08:08, 11.37s/it, lr=1e-5, step_loss=0.0126]Steps:   2%|▏         | 18085/1000000 [12:55:19<3068:48:24, 11.25s/it, lr=1e-5, step_loss=0.0126][RANK-0]: Step: [18085], local_loss=0.0037528870161622763, train_loss=0.13105471432209015, time_cost=2.3294174671173096
Steps:   2%|▏         | 18085/1000000 [12:55:19<3068:48:24, 11.25s/it, lr=1e-5, step_loss=0.00375]Steps:   2%|▏         | 18086/1000000 [12:55:24<2500:55:05,  9.17s/it, lr=1e-5, step_loss=0.00375][RANK-0]: Step: [18086], local_loss=0.009931922890245914, train_loss=0.023378703743219376, time_cost=1.57790207862854
Steps:   2%|▏         | 18086/1000000 [12:55:24<2500:55:05,  9.17s/it, lr=1e-5, step_loss=0.00993]Steps:   2%|▏         | 18087/1000000 [12:55:38<2942:55:30, 10.79s/it, lr=1e-5, step_loss=0.00993][RANK-0]: Step: [18087], local_loss=0.01733812689781189, train_loss=0.031426120549440384, time_cost=3.4114065170288086
Steps:   2%|▏         | 18087/1000000 [12:55:38<2942:55:30, 10.79s/it, lr=1e-5, step_loss=0.0173] Steps:   2%|▏         | 18088/1000000 [12:55:53<3251:59:41, 11.92s/it, lr=1e-5, step_loss=0.0173][RANK-0]: Step: [18088], local_loss=0.006303813774138689, train_loss=0.012570841237902641, time_cost=5.923975706100464
Steps:   2%|▏         | 18088/1000000 [12:55:53<3251:59:41, 11.92s/it, lr=1e-5, step_loss=0.0063]Steps:   2%|▏         | 18089/1000000 [12:56:04<3219:08:18, 11.80s/it, lr=1e-5, step_loss=0.0063][RANK-0]: Step: [18089], local_loss=0.009493826888501644, train_loss=0.023204542696475983, time_cost=1.2909328937530518
Steps:   2%|▏         | 18089/1000000 [12:56:04<3219:08:18, 11.80s/it, lr=1e-5, step_loss=0.00949]Steps:   2%|▏         | 18090/1000000 [12:56:09<2641:06:49,  9.68s/it, lr=1e-5, step_loss=0.00949][RANK-0]: Step: [18090], local_loss=0.006055073346942663, train_loss=0.1442720890045166, time_cost=1.8485324382781982
Steps:   2%|▏         | 18090/1000000 [12:56:09<2641:06:49,  9.68s/it, lr=1e-5, step_loss=0.00606]Steps:   2%|▏         | 18091/1000000 [12:56:17<2524:57:08,  9.26s/it, lr=1e-5, step_loss=0.00606][RANK-0]: Step: [18091], local_loss=0.1385454535484314, train_loss=0.04516419768333435, time_cost=3.790627956390381
Steps:   2%|▏         | 18091/1000000 [12:56:17<2524:57:08,  9.26s/it, lr=1e-5, step_loss=0.139]  Steps:   2%|▏         | 18092/1000000 [12:56:28<2668:15:18,  9.78s/it, lr=1e-5, step_loss=0.139][RANK-0]: Step: [18092], local_loss=0.006187988445162773, train_loss=0.031226642429828644, time_cost=3.12539005279541
Steps:   2%|▏         | 18092/1000000 [12:56:28<2668:15:18,  9.78s/it, lr=1e-5, step_loss=0.00619]Steps:   2%|▏         | 18093/1000000 [12:56:39<2762:17:34, 10.13s/it, lr=1e-5, step_loss=0.00619][RANK-0]: Step: [18093], local_loss=0.01813315413892269, train_loss=0.05359969288110733, time_cost=9.65090537071228
Steps:   2%|▏         | 18093/1000000 [12:56:39<2762:17:34, 10.13s/it, lr=1e-5, step_loss=0.0181] Steps:   2%|▏         | 18094/1000000 [12:56:46<2511:19:42,  9.21s/it, lr=1e-5, step_loss=0.0181][RANK-0]: Step: [18094], local_loss=0.08192083984613419, train_loss=0.028456242755055428, time_cost=2.520284652709961
Steps:   2%|▏         | 18094/1000000 [12:56:46<2511:19:42,  9.21s/it, lr=1e-5, step_loss=0.0819]Steps:   2%|▏         | 18095/1000000 [12:56:53<2335:17:33,  8.56s/it, lr=1e-5, step_loss=0.0819][RANK-0]: Step: [18095], local_loss=0.04669946804642677, train_loss=0.02765137515962124, time_cost=1.4435348510742188
Steps:   2%|▏         | 18095/1000000 [12:56:53<2335:17:33,  8.56s/it, lr=1e-5, step_loss=0.0467]Steps:   2%|▏         | 18096/1000000 [12:57:00<2168:04:25,  7.95s/it, lr=1e-5, step_loss=0.0467][RANK-0]: Step: [18096], local_loss=0.09362559020519257, train_loss=0.05006860941648483, time_cost=2.556389808654785
Steps:   2%|▏         | 18096/1000000 [12:57:00<2168:04:25,  7.95s/it, lr=1e-5, step_loss=0.0936]Steps:   2%|▏         | 18097/1000000 [12:57:11<2425:42:03,  8.89s/it, lr=1e-5, step_loss=0.0936][RANK-0]: Step: [18097], local_loss=0.028820641338825226, train_loss=0.02165031060576439, time_cost=1.3316683769226074
Steps:   2%|▏         | 18097/1000000 [12:57:11<2425:42:03,  8.89s/it, lr=1e-5, step_loss=0.0288]Steps:   2%|▏         | 18098/1000000 [12:57:16<2113:21:06,  7.75s/it, lr=1e-5, step_loss=0.0288][RANK-0]: Step: [18098], local_loss=5.116754055023193, train_loss=0.6592747569084167, time_cost=1.4675488471984863
Steps:   2%|▏         | 18098/1000000 [12:57:16<2113:21:06,  7.75s/it, lr=1e-5, step_loss=5.12]  Steps:   2%|▏         | 18099/1000000 [12:57:27<2412:49:31,  8.85s/it, lr=1e-5, step_loss=5.12][RANK-0]: Step: [18099], local_loss=0.017234014347195625, train_loss=0.02431296370923519, time_cost=3.704984188079834
Steps:   2%|▏         | 18099/1000000 [12:57:27<2412:49:31,  8.85s/it, lr=1e-5, step_loss=0.0172]Steps:   2%|▏         | 18100/1000000 [12:57:39<2647:29:55,  9.71s/it, lr=1e-5, step_loss=0.0172][RANK-0]: Step: [18100], local_loss=0.06013127788901329, train_loss=0.02027992531657219, time_cost=4.263632774353027
Steps:   2%|▏         | 18100/1000000 [12:57:39<2647:29:55,  9.71s/it, lr=1e-5, step_loss=0.0601]Steps:   2%|▏         | 18101/1000000 [12:57:44<2256:05:25,  8.27s/it, lr=1e-5, step_loss=0.0601][RANK-0]: Step: [18101], local_loss=0.005654092878103256, train_loss=0.14840145409107208, time_cost=1.8219823837280273
Steps:   2%|▏         | 18101/1000000 [12:57:44<2256:05:25,  8.27s/it, lr=1e-5, step_loss=0.00565]Steps:   2%|▏         | 18102/1000000 [12:57:57<2598:15:49,  9.53s/it, lr=1e-5, step_loss=0.00565][RANK-0]: Step: [18102], local_loss=0.08728161454200745, train_loss=0.05548582598567009, time_cost=4.237905979156494
Steps:   2%|▏         | 18102/1000000 [12:57:57<2598:15:49,  9.53s/it, lr=1e-5, step_loss=0.0873] Steps:   2%|▏         | 18103/1000000 [12:58:09<2805:44:29, 10.29s/it, lr=1e-5, step_loss=0.0873][RANK-0]: Step: [18103], local_loss=0.019588900730013847, train_loss=0.03173253312706947, time_cost=1.2105481624603271
Steps:   2%|▏         | 18103/1000000 [12:58:09<2805:44:29, 10.29s/it, lr=1e-5, step_loss=0.0196]Steps:   2%|▏         | 18104/1000000 [12:58:20<2878:51:13, 10.55s/it, lr=1e-5, step_loss=0.0196][RANK-0]: Step: [18104], local_loss=0.03758152201771736, train_loss=0.07525958865880966, time_cost=5.090531826019287
Steps:   2%|▏         | 18104/1000000 [12:58:20<2878:51:13, 10.55s/it, lr=1e-5, step_loss=0.0376]Steps:   2%|▏         | 18105/1000000 [12:58:26<2501:46:39,  9.17s/it, lr=1e-5, step_loss=0.0376][RANK-0]: Step: [18105], local_loss=0.008113610558211803, train_loss=0.0185561403632164, time_cost=4.240069389343262
Steps:   2%|▏         | 18105/1000000 [12:58:26<2501:46:39,  9.17s/it, lr=1e-5, step_loss=0.00811]Steps:   2%|▏         | 18106/1000000 [12:58:34<2464:26:40,  9.04s/it, lr=1e-5, step_loss=0.00811][RANK-0]: Step: [18106], local_loss=0.023303022608160973, train_loss=0.02256731688976288, time_cost=1.965635061264038
Steps:   2%|▏         | 18106/1000000 [12:58:34<2464:26:40,  9.04s/it, lr=1e-5, step_loss=0.0233] Steps:   2%|▏         | 18107/1000000 [12:58:40<2194:50:50,  8.05s/it, lr=1e-5, step_loss=0.0233][RANK-0]: Step: [18107], local_loss=0.006572871468961239, train_loss=0.05097946524620056, time_cost=3.116777181625366
Steps:   2%|▏         | 18107/1000000 [12:58:40<2194:50:50,  8.05s/it, lr=1e-5, step_loss=0.00657]Steps:   2%|▏         | 18108/1000000 [12:58:51<2395:54:25,  8.78s/it, lr=1e-5, step_loss=0.00657][RANK-0]: Step: [18108], local_loss=0.04689225181937218, train_loss=0.04017878323793411, time_cost=2.518204927444458
Steps:   2%|▏         | 18108/1000000 [12:58:51<2395:54:25,  8.78s/it, lr=1e-5, step_loss=0.0469] Steps:   2%|▏         | 18109/1000000 [12:58:55<2066:20:38,  7.58s/it, lr=1e-5, step_loss=0.0469][RANK-0]: Step: [18109], local_loss=0.005057353992015123, train_loss=0.02059006877243519, time_cost=2.0139076709747314
Steps:   2%|▏         | 18109/1000000 [12:58:55<2066:20:38,  7.58s/it, lr=1e-5, step_loss=0.00506]Steps:   2%|▏         | 18110/1000000 [12:59:09<2546:00:57,  9.33s/it, lr=1e-5, step_loss=0.00506][RANK-0]: Step: [18110], local_loss=0.011577485129237175, train_loss=0.01979893445968628, time_cost=4.348998785018921
Steps:   2%|▏         | 18110/1000000 [12:59:09<2546:00:57,  9.33s/it, lr=1e-5, step_loss=0.0116] Steps:   2%|▏         | 18111/1000000 [12:59:20<2697:47:47,  9.89s/it, lr=1e-5, step_loss=0.0116][RANK-0]: Step: [18111], local_loss=0.01122137252241373, train_loss=0.026101941242814064, time_cost=1.4391281604766846
Steps:   2%|▏         | 18111/1000000 [12:59:20<2697:47:47,  9.89s/it, lr=1e-5, step_loss=0.0112]Steps:   2%|▏         | 18112/1000000 [12:59:27<2450:11:15,  8.98s/it, lr=1e-5, step_loss=0.0112][RANK-0]: Step: [18112], local_loss=0.03253685310482979, train_loss=0.03140717372298241, time_cost=1.2107892036437988
Steps:   2%|▏         | 18112/1000000 [12:59:27<2450:11:15,  8.98s/it, lr=1e-5, step_loss=0.0325]Steps:   2%|▏         | 18113/1000000 [12:59:37<2555:59:10,  9.37s/it, lr=1e-5, step_loss=0.0325][RANK-0]: Step: [18113], local_loss=0.006966624408960342, train_loss=0.014903002418577671, time_cost=7.411816120147705
Steps:   2%|▏         | 18113/1000000 [12:59:37<2555:59:10,  9.37s/it, lr=1e-5, step_loss=0.00697]Steps:   2%|▏         | 18114/1000000 [12:59:50<2840:40:00, 10.42s/it, lr=1e-5, step_loss=0.00697][RANK-0]: Step: [18114], local_loss=0.039089396595954895, train_loss=0.02101624384522438, time_cost=6.802067995071411
Steps:   2%|▏         | 18114/1000000 [12:59:50<2840:40:00, 10.42s/it, lr=1e-5, step_loss=0.0391] Steps:   2%|▏         | 18115/1000000 [12:59:56<2499:14:08,  9.16s/it, lr=1e-5, step_loss=0.0391][RANK-0]: Step: [18115], local_loss=0.040558140724897385, train_loss=0.028374025598168373, time_cost=1.3416094779968262
Steps:   2%|▏         | 18115/1000000 [12:59:56<2499:14:08,  9.16s/it, lr=1e-5, step_loss=0.0406]Steps:   2%|▏         | 18116/1000000 [13:00:07<2603:01:10,  9.54s/it, lr=1e-5, step_loss=0.0406][RANK-0]: Step: [18116], local_loss=0.0100690433755517, train_loss=0.05261124297976494, time_cost=2.0302774906158447
Steps:   2%|▏         | 18116/1000000 [13:00:07<2603:01:10,  9.54s/it, lr=1e-5, step_loss=0.0101]Steps:   2%|▏         | 18117/1000000 [13:00:14<2452:53:23,  8.99s/it, lr=1e-5, step_loss=0.0101][RANK-0]: Step: [18117], local_loss=0.015362400561571121, train_loss=0.012979596853256226, time_cost=1.5476126670837402
Steps:   2%|▏         | 18117/1000000 [13:00:14<2452:53:23,  8.99s/it, lr=1e-5, step_loss=0.0154]Steps:   2%|▏         | 18118/1000000 [13:00:26<2655:10:14,  9.73s/it, lr=1e-5, step_loss=0.0154][RANK-0]: Step: [18118], local_loss=0.010634391568601131, train_loss=0.03782660514116287, time_cost=3.4412295818328857
Steps:   2%|▏         | 18118/1000000 [13:00:26<2655:10:14,  9.73s/it, lr=1e-5, step_loss=0.0106]Steps:   2%|▏         | 18119/1000000 [13:00:37<2743:11:51, 10.06s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [18119], local_loss=0.2946016192436218, train_loss=0.096869558095932, time_cost=2.7435145378112793
Steps:   2%|▏         | 18119/1000000 [13:00:37<2743:11:51, 10.06s/it, lr=1e-5, step_loss=0.295] Steps:   2%|▏         | 18120/1000000 [13:00:50<2976:17:20, 10.91s/it, lr=1e-5, step_loss=0.295][RANK-0]: Step: [18120], local_loss=0.022085925564169884, train_loss=0.014567682519555092, time_cost=3.2198166847229004
Steps:   2%|▏         | 18120/1000000 [13:00:50<2976:17:20, 10.91s/it, lr=1e-5, step_loss=0.0221]Steps:   2%|▏         | 18121/1000000 [13:00:54<2472:44:18,  9.07s/it, lr=1e-5, step_loss=0.0221][RANK-0]: Step: [18121], local_loss=0.00841212272644043, train_loss=0.02210244908928871, time_cost=2.3365187644958496
Steps:   2%|▏         | 18121/1000000 [13:00:54<2472:44:18,  9.07s/it, lr=1e-5, step_loss=0.00841]Steps:   2%|▏         | 18122/1000000 [13:01:10<2976:07:07, 10.91s/it, lr=1e-5, step_loss=0.00841][RANK-0]: Step: [18122], local_loss=0.31085315346717834, train_loss=0.08381512016057968, time_cost=7.384209394454956
Steps:   2%|▏         | 18122/1000000 [13:01:10<2976:07:07, 10.91s/it, lr=1e-5, step_loss=0.311]  Steps:   2%|▏         | 18123/1000000 [13:01:15<2522:10:10,  9.25s/it, lr=1e-5, step_loss=0.311][RANK-0]: Step: [18123], local_loss=0.18132628500461578, train_loss=0.038041647523641586, time_cost=2.512467622756958
Steps:   2%|▏         | 18123/1000000 [13:01:15<2522:10:10,  9.25s/it, lr=1e-5, step_loss=0.181]Steps:   2%|▏         | 18124/1000000 [13:01:25<2602:38:52,  9.54s/it, lr=1e-5, step_loss=0.181][RANK-0]: Step: [18124], local_loss=0.016477428376674652, train_loss=0.0633167028427124, time_cost=1.328817367553711
Steps:   2%|▏         | 18124/1000000 [13:01:25<2602:38:52,  9.54s/it, lr=1e-5, step_loss=0.0165]Steps:   2%|▏         | 18125/1000000 [13:01:31<2255:39:17,  8.27s/it, lr=1e-5, step_loss=0.0165][RANK-0]: Step: [18125], local_loss=0.026868585497140884, train_loss=0.018144376575946808, time_cost=2.189964532852173
Steps:   2%|▏         | 18125/1000000 [13:01:31<2255:39:17,  8.27s/it, lr=1e-5, step_loss=0.0269]Steps:   2%|▏         | 18126/1000000 [13:01:41<2441:11:57,  8.95s/it, lr=1e-5, step_loss=0.0269][RANK-0]: Step: [18126], local_loss=0.04916054755449295, train_loss=0.03223206102848053, time_cost=1.5038433074951172
Steps:   2%|▏         | 18126/1000000 [13:01:41<2441:11:57,  8.95s/it, lr=1e-5, step_loss=0.0492]Steps:   2%|▏         | 18127/1000000 [13:01:46<2114:01:06,  7.75s/it, lr=1e-5, step_loss=0.0492][RANK-0]: Step: [18127], local_loss=0.004387033171951771, train_loss=0.019444987177848816, time_cost=2.4339489936828613
Steps:   2%|▏         | 18127/1000000 [13:01:46<2114:01:06,  7.75s/it, lr=1e-5, step_loss=0.00439]Steps:   2%|▏         | 18128/1000000 [13:01:52<1974:46:33,  7.24s/it, lr=1e-5, step_loss=0.00439][RANK-0]: Step: [18128], local_loss=0.030601274222135544, train_loss=0.09673301130533218, time_cost=1.7435100078582764
Steps:   2%|▏         | 18128/1000000 [13:01:52<1974:46:33,  7.24s/it, lr=1e-5, step_loss=0.0306] Steps:   2%|▏         | 18129/1000000 [13:02:01<2108:08:00,  7.73s/it, lr=1e-5, step_loss=0.0306][RANK-0]: Step: [18129], local_loss=0.008038010448217392, train_loss=0.025588776916265488, time_cost=2.8953425884246826
Steps:   2%|▏         | 18129/1000000 [13:02:01<2108:08:00,  7.73s/it, lr=1e-5, step_loss=0.00804]Steps:   2%|▏         | 18130/1000000 [13:02:06<1878:36:44,  6.89s/it, lr=1e-5, step_loss=0.00804][RANK-0]: Step: [18130], local_loss=0.04071275517344475, train_loss=0.06746409088373184, time_cost=2.2673428058624268
Steps:   2%|▏         | 18130/1000000 [13:02:06<1878:36:44,  6.89s/it, lr=1e-5, step_loss=0.0407] Steps:   2%|▏         | 18131/1000000 [13:02:14<2011:12:57,  7.37s/it, lr=1e-5, step_loss=0.0407][RANK-0]: Step: [18131], local_loss=0.003097651759162545, train_loss=0.0700126513838768, time_cost=1.2383787631988525
Steps:   2%|▏         | 18131/1000000 [13:02:14<2011:12:57,  7.37s/it, lr=1e-5, step_loss=0.0031]Steps:   2%|▏         | 18132/1000000 [13:02:20<1841:56:06,  6.75s/it, lr=1e-5, step_loss=0.0031][RANK-0]: Step: [18132], local_loss=0.012511065229773521, train_loss=5.529755592346191, time_cost=1.6789278984069824
Steps:   2%|▏         | 18132/1000000 [13:02:20<1841:56:06,  6.75s/it, lr=1e-5, step_loss=0.0125]Steps:   2%|▏         | 18133/1000000 [13:02:31<2234:55:23,  8.19s/it, lr=1e-5, step_loss=0.0125][RANK-0]: Step: [18133], local_loss=0.00695835379883647, train_loss=0.034370001405477524, time_cost=3.5460410118103027
Steps:   2%|▏         | 18133/1000000 [13:02:31<2234:55:23,  8.19s/it, lr=1e-5, step_loss=0.00696]Steps:   2%|▏         | 18134/1000000 [13:02:42<2473:52:02,  9.07s/it, lr=1e-5, step_loss=0.00696][RANK-0]: Step: [18134], local_loss=0.02664591744542122, train_loss=0.04019903764128685, time_cost=4.00756311416626
Steps:   2%|▏         | 18134/1000000 [13:02:42<2473:52:02,  9.07s/it, lr=1e-5, step_loss=0.0266] Steps:   2%|▏         | 18135/1000000 [13:02:53<2633:48:35,  9.66s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [18135], local_loss=0.011651216074824333, train_loss=0.01017991453409195, time_cost=1.685283899307251
Steps:   2%|▏         | 18135/1000000 [13:02:53<2633:48:35,  9.66s/it, lr=1e-5, step_loss=0.0117]Steps:   2%|▏         | 18136/1000000 [13:03:11<3261:02:45, 11.96s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [18136], local_loss=0.030316269025206566, train_loss=0.05436406657099724, time_cost=3.635044574737549
Steps:   2%|▏         | 18136/1000000 [13:03:11<3261:02:45, 11.96s/it, lr=1e-5, step_loss=0.0303]Steps:   2%|▏         | 18137/1000000 [13:03:21<3159:22:22, 11.58s/it, lr=1e-5, step_loss=0.0303][RANK-0]: Step: [18137], local_loss=0.022861165925860405, train_loss=0.020899761468172073, time_cost=7.882483243942261
Steps:   2%|▏         | 18137/1000000 [13:03:21<3159:22:22, 11.58s/it, lr=1e-5, step_loss=0.0229]Steps:   2%|▏         | 18138/1000000 [13:03:29<2860:55:13, 10.49s/it, lr=1e-5, step_loss=0.0229][RANK-0]: Step: [18138], local_loss=0.023832494392991066, train_loss=0.029829148203134537, time_cost=2.5140459537506104
Steps:   2%|▏         | 18138/1000000 [13:03:29<2860:55:13, 10.49s/it, lr=1e-5, step_loss=0.0238]Steps:   2%|▏         | 18139/1000000 [13:03:33<2342:07:17,  8.59s/it, lr=1e-5, step_loss=0.0238][RANK-0]: Step: [18139], local_loss=0.016431184485554695, train_loss=0.03907529637217522, time_cost=3.2516467571258545
Steps:   2%|▏         | 18139/1000000 [13:03:33<2342:07:17,  8.59s/it, lr=1e-5, step_loss=0.0164]Steps:   2%|▏         | 18140/1000000 [13:03:46<2648:51:04,  9.71s/it, lr=1e-5, step_loss=0.0164][RANK-0]: Step: [18140], local_loss=0.050601355731487274, train_loss=0.06363190710544586, time_cost=5.629173994064331
Steps:   2%|▏         | 18140/1000000 [13:03:46<2648:51:04,  9.71s/it, lr=1e-5, step_loss=0.0506]Steps:   2%|▏         | 18141/1000000 [13:03:54<2552:09:19,  9.36s/it, lr=1e-5, step_loss=0.0506][RANK-0]: Step: [18141], local_loss=0.010712921619415283, train_loss=0.013011796399950981, time_cost=2.2770400047302246
Steps:   2%|▏         | 18141/1000000 [13:03:54<2552:09:19,  9.36s/it, lr=1e-5, step_loss=0.0107]Steps:   2%|▏         | 18142/1000000 [13:04:00<2223:59:29,  8.15s/it, lr=1e-5, step_loss=0.0107][RANK-0]: Step: [18142], local_loss=0.019409289583563805, train_loss=19.986385345458984, time_cost=2.9271881580352783
Steps:   2%|▏         | 18142/1000000 [13:04:00<2223:59:29,  8.15s/it, lr=1e-5, step_loss=0.0194]Steps:   2%|▏         | 18143/1000000 [13:04:08<2216:18:58,  8.13s/it, lr=1e-5, step_loss=0.0194][RANK-0]: Step: [18143], local_loss=0.007337430492043495, train_loss=0.1527988612651825, time_cost=3.7527430057525635
Steps:   2%|▏         | 18143/1000000 [13:04:08<2216:18:58,  8.13s/it, lr=1e-5, step_loss=0.00734]Steps:   2%|▏         | 18144/1000000 [13:04:21<2612:17:53,  9.58s/it, lr=1e-5, step_loss=0.00734][RANK-0]: Step: [18144], local_loss=0.017760861665010452, train_loss=0.020179037004709244, time_cost=1.2023816108703613
Steps:   2%|▏         | 18144/1000000 [13:04:21<2612:17:53,  9.58s/it, lr=1e-5, step_loss=0.0178] Steps:   2%|▏         | 18145/1000000 [13:04:35<2959:33:56, 10.85s/it, lr=1e-5, step_loss=0.0178][RANK-0]: Step: [18145], local_loss=0.05009603872895241, train_loss=0.05596742406487465, time_cost=5.850573778152466
Steps:   2%|▏         | 18145/1000000 [13:04:35<2959:33:56, 10.85s/it, lr=1e-5, step_loss=0.0501]Steps:   2%|▏         | 18146/1000000 [13:04:44<2828:00:29, 10.37s/it, lr=1e-5, step_loss=0.0501][RANK-0]: Step: [18146], local_loss=0.008749647065997124, train_loss=0.016400396823883057, time_cost=2.0875699520111084
Steps:   2%|▏         | 18146/1000000 [13:04:44<2828:00:29, 10.37s/it, lr=1e-5, step_loss=0.00875]Steps:   2%|▏         | 18147/1000000 [13:04:52<2624:48:01,  9.62s/it, lr=1e-5, step_loss=0.00875][RANK-0]: Step: [18147], local_loss=0.008040503598749638, train_loss=0.02492631785571575, time_cost=6.555104970932007
Steps:   2%|▏         | 18147/1000000 [13:04:52<2624:48:01,  9.62s/it, lr=1e-5, step_loss=0.00804]Steps:   2%|▏         | 18148/1000000 [13:04:57<2271:37:20,  8.33s/it, lr=1e-5, step_loss=0.00804][RANK-0]: Step: [18148], local_loss=0.07900635898113251, train_loss=0.1481042206287384, time_cost=2.5586469173431396
Steps:   2%|▏         | 18148/1000000 [13:04:57<2271:37:20,  8.33s/it, lr=1e-5, step_loss=0.079]  Steps:   2%|▏         | 18149/1000000 [13:05:03<2068:19:05,  7.58s/it, lr=1e-5, step_loss=0.079][RANK-0]: Step: [18149], local_loss=0.008280497044324875, train_loss=0.018200956284999847, time_cost=1.8511793613433838
Steps:   2%|▏         | 18149/1000000 [13:05:03<2068:19:05,  7.58s/it, lr=1e-5, step_loss=0.00828]Steps:   2%|▏         | 18150/1000000 [13:05:08<1857:42:12,  6.81s/it, lr=1e-5, step_loss=0.00828][RANK-0]: Step: [18150], local_loss=0.10861857235431671, train_loss=0.039792753756046295, time_cost=1.4187510013580322
Steps:   2%|▏         | 18150/1000000 [13:05:08<1857:42:12,  6.81s/it, lr=1e-5, step_loss=0.109]  Steps:   2%|▏         | 18151/1000000 [13:05:22<2493:36:34,  9.14s/it, lr=1e-5, step_loss=0.109][RANK-0]: Step: [18151], local_loss=0.04451649636030197, train_loss=0.0493919663131237, time_cost=8.097970724105835
Steps:   2%|▏         | 18151/1000000 [13:05:22<2493:36:34,  9.14s/it, lr=1e-5, step_loss=0.0445]Steps:   2%|▏         | 18152/1000000 [13:05:27<2105:42:09,  7.72s/it, lr=1e-5, step_loss=0.0445][RANK-0]: Step: [18152], local_loss=0.0329488180577755, train_loss=0.03343535214662552, time_cost=1.6983904838562012
Steps:   2%|▏         | 18152/1000000 [13:05:27<2105:42:09,  7.72s/it, lr=1e-5, step_loss=0.0329]Steps:   2%|▏         | 18153/1000000 [13:05:34<2065:54:00,  7.57s/it, lr=1e-5, step_loss=0.0329][RANK-0]: Step: [18153], local_loss=0.01509257685393095, train_loss=0.016451383009552956, time_cost=2.4217824935913086
Steps:   2%|▏         | 18153/1000000 [13:05:34<2065:54:00,  7.57s/it, lr=1e-5, step_loss=0.0151]Steps:   2%|▏         | 18154/1000000 [13:05:46<2430:22:04,  8.91s/it, lr=1e-5, step_loss=0.0151][RANK-0]: Step: [18154], local_loss=0.007734485901892185, train_loss=0.03585539013147354, time_cost=5.319468975067139
Steps:   2%|▏         | 18154/1000000 [13:05:46<2430:22:04,  8.91s/it, lr=1e-5, step_loss=0.00773]Steps:   2%|▏         | 18155/1000000 [13:05:57<2598:33:34,  9.53s/it, lr=1e-5, step_loss=0.00773][RANK-0]: Step: [18155], local_loss=0.011285942047834396, train_loss=0.05386850982904434, time_cost=8.719141721725464
Steps:   2%|▏         | 18155/1000000 [13:05:57<2598:33:34,  9.53s/it, lr=1e-5, step_loss=0.0113] Steps:   2%|▏         | 18156/1000000 [13:06:11<2981:21:32, 10.93s/it, lr=1e-5, step_loss=0.0113][RANK-0]: Step: [18156], local_loss=0.014827125705778599, train_loss=0.019555915147066116, time_cost=6.2821269035339355
Steps:   2%|▏         | 18156/1000000 [13:06:11<2981:21:32, 10.93s/it, lr=1e-5, step_loss=0.0148]Steps:   2%|▏         | 18157/1000000 [13:06:20<2810:09:28, 10.30s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [18157], local_loss=0.00808802992105484, train_loss=0.020391400903463364, time_cost=4.256243944168091
Steps:   2%|▏         | 18157/1000000 [13:06:20<2810:09:28, 10.30s/it, lr=1e-5, step_loss=0.00809]Steps:   2%|▏         | 18158/1000000 [13:06:24<2298:24:17,  8.43s/it, lr=1e-5, step_loss=0.00809][RANK-0]: Step: [18158], local_loss=0.010833580046892166, train_loss=0.020672574639320374, time_cost=1.7245559692382812
Steps:   2%|▏         | 18158/1000000 [13:06:24<2298:24:17,  8.43s/it, lr=1e-5, step_loss=0.0108] Steps:   2%|▏         | 18159/1000000 [13:06:30<2067:33:21,  7.58s/it, lr=1e-5, step_loss=0.0108][RANK-0]: Step: [18159], local_loss=0.012967286631464958, train_loss=0.03151210397481918, time_cost=3.2395846843719482
Steps:   2%|▏         | 18159/1000000 [13:06:30<2067:33:21,  7.58s/it, lr=1e-5, step_loss=0.013] Steps:   2%|▏         | 18160/1000000 [13:06:41<2385:50:21,  8.75s/it, lr=1e-5, step_loss=0.013][RANK-0]: Step: [18160], local_loss=0.08293623477220535, train_loss=0.03551097214221954, time_cost=3.2004027366638184
Steps:   2%|▏         | 18160/1000000 [13:06:41<2385:50:21,  8.75s/it, lr=1e-5, step_loss=0.0829]Steps:   2%|▏         | 18161/1000000 [13:06:57<2999:20:28, 11.00s/it, lr=1e-5, step_loss=0.0829][RANK-0]: Step: [18161], local_loss=0.009556920267641544, train_loss=0.01586160436272621, time_cost=3.529108762741089
Steps:   2%|▏         | 18161/1000000 [13:06:57<2999:20:28, 11.00s/it, lr=1e-5, step_loss=0.00956]Steps:   2%|▏         | 18162/1000000 [13:07:05<2705:35:20,  9.92s/it, lr=1e-5, step_loss=0.00956][RANK-0]: Step: [18162], local_loss=0.008630966767668724, train_loss=0.016263868659734726, time_cost=1.9477179050445557
Steps:   2%|▏         | 18162/1000000 [13:07:05<2705:35:20,  9.92s/it, lr=1e-5, step_loss=0.00863]Steps:   2%|▏         | 18163/1000000 [13:07:16<2831:33:54, 10.38s/it, lr=1e-5, step_loss=0.00863][RANK-0]: Step: [18163], local_loss=0.047604724764823914, train_loss=0.03327178582549095, time_cost=3.90305757522583
Steps:   2%|▏         | 18163/1000000 [13:07:16<2831:33:54, 10.38s/it, lr=1e-5, step_loss=0.0476] Steps:   2%|▏         | 18164/1000000 [13:07:22<2473:53:02,  9.07s/it, lr=1e-5, step_loss=0.0476][RANK-0]: Step: [18164], local_loss=0.009201042354106903, train_loss=0.020530477166175842, time_cost=1.5002079010009766
Steps:   2%|▏         | 18164/1000000 [13:07:22<2473:53:02,  9.07s/it, lr=1e-5, step_loss=0.0092]Steps:   2%|▏         | 18165/1000000 [13:07:35<2770:15:23, 10.16s/it, lr=1e-5, step_loss=0.0092][RANK-0]: Step: [18165], local_loss=0.03302065283060074, train_loss=0.05170507729053497, time_cost=3.798096179962158
Steps:   2%|▏         | 18165/1000000 [13:07:35<2770:15:23, 10.16s/it, lr=1e-5, step_loss=0.033] Steps:   2%|▏         | 18166/1000000 [13:07:44<2694:18:27,  9.88s/it, lr=1e-5, step_loss=0.033][RANK-0]: Step: [18166], local_loss=0.016665758565068245, train_loss=0.030653491616249084, time_cost=2.9473774433135986
Steps:   2%|▏         | 18166/1000000 [13:07:44<2694:18:27,  9.88s/it, lr=1e-5, step_loss=0.0167]Steps:   2%|▏         | 18167/1000000 [13:07:50<2362:58:43,  8.66s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [18167], local_loss=0.013220681808888912, train_loss=0.024440567940473557, time_cost=1.4648547172546387
Steps:   2%|▏         | 18167/1000000 [13:07:50<2362:58:43,  8.66s/it, lr=1e-5, step_loss=0.0132]Steps:   2%|▏         | 18168/1000000 [13:07:55<2075:00:39,  7.61s/it, lr=1e-5, step_loss=0.0132][RANK-0]: Step: [18168], local_loss=0.03251759707927704, train_loss=0.1598416268825531, time_cost=2.3800737857818604
Steps:   2%|▏         | 18168/1000000 [13:07:55<2075:00:39,  7.61s/it, lr=1e-5, step_loss=0.0325]Steps:   2%|▏         | 18169/1000000 [13:08:07<2425:20:28,  8.89s/it, lr=1e-5, step_loss=0.0325][RANK-0]: Step: [18169], local_loss=0.026191161945462227, train_loss=0.036153070628643036, time_cost=3.1055140495300293
Steps:   2%|▏         | 18169/1000000 [13:08:07<2425:20:28,  8.89s/it, lr=1e-5, step_loss=0.0262]Steps:   2%|▏         | 18170/1000000 [13:08:19<2655:11:08,  9.74s/it, lr=1e-5, step_loss=0.0262][RANK-0]: Step: [18170], local_loss=0.008363633416593075, train_loss=0.04002979397773743, time_cost=9.583123207092285
Steps:   2%|▏         | 18170/1000000 [13:08:19<2655:11:08,  9.74s/it, lr=1e-5, step_loss=0.00836]Steps:   2%|▏         | 18171/1000000 [13:08:26<2440:18:33,  8.95s/it, lr=1e-5, step_loss=0.00836][RANK-0]: Step: [18171], local_loss=0.01913624070584774, train_loss=0.07338858395814896, time_cost=2.9874727725982666
Steps:   2%|▏         | 18171/1000000 [13:08:26<2440:18:33,  8.95s/it, lr=1e-5, step_loss=0.0191] Steps:   2%|▏         | 18172/1000000 [13:08:36<2541:22:30,  9.32s/it, lr=1e-5, step_loss=0.0191][RANK-0]: Step: [18172], local_loss=0.00531058618798852, train_loss=0.0214066281914711, time_cost=3.078632354736328
Steps:   2%|▏         | 18172/1000000 [13:08:36<2541:22:30,  9.32s/it, lr=1e-5, step_loss=0.00531]Steps:   2%|▏         | 18173/1000000 [13:08:44<2396:16:21,  8.79s/it, lr=1e-5, step_loss=0.00531][RANK-0]: Step: [18173], local_loss=0.005499673541635275, train_loss=0.01842917501926422, time_cost=1.6964454650878906
Steps:   2%|▏         | 18173/1000000 [13:08:44<2396:16:21,  8.79s/it, lr=1e-5, step_loss=0.0055] Steps:   2%|▏         | 18174/1000000 [13:08:53<2431:16:57,  8.91s/it, lr=1e-5, step_loss=0.0055][RANK-0]: Step: [18174], local_loss=0.006793018896132708, train_loss=0.03867608681321144, time_cost=1.616814136505127
Steps:   2%|▏         | 18174/1000000 [13:08:53<2431:16:57,  8.91s/it, lr=1e-5, step_loss=0.00679]Steps:   2%|▏         | 18175/1000000 [13:08:58<2143:13:14,  7.86s/it, lr=1e-5, step_loss=0.00679][RANK-0]: Step: [18175], local_loss=0.18611939251422882, train_loss=0.05271674692630768, time_cost=2.6147642135620117
Steps:   2%|▏         | 18175/1000000 [13:08:58<2143:13:14,  7.86s/it, lr=1e-5, step_loss=0.186]  Steps:   2%|▏         | 18176/1000000 [13:09:08<2312:05:08,  8.48s/it, lr=1e-5, step_loss=0.186][RANK-0]: Step: [18176], local_loss=0.014075011014938354, train_loss=0.05439840629696846, time_cost=2.9146838188171387
Steps:   2%|▏         | 18176/1000000 [13:09:08<2312:05:08,  8.48s/it, lr=1e-5, step_loss=0.0141]Steps:   2%|▏         | 18177/1000000 [13:09:18<2392:42:48,  8.77s/it, lr=1e-5, step_loss=0.0141][RANK-0]: Step: [18177], local_loss=0.04706624150276184, train_loss=0.0233624167740345, time_cost=4.641847610473633
Steps:   2%|▏         | 18177/1000000 [13:09:18<2392:42:48,  8.77s/it, lr=1e-5, step_loss=0.0471]Steps:   2%|▏         | 18178/1000000 [13:09:32<2841:01:09, 10.42s/it, lr=1e-5, step_loss=0.0471][RANK-0]: Step: [18178], local_loss=0.007294048089534044, train_loss=0.031600482761859894, time_cost=5.240105628967285
Steps:   2%|▏         | 18178/1000000 [13:09:32<2841:01:09, 10.42s/it, lr=1e-5, step_loss=0.00729]Steps:   2%|▏         | 18179/1000000 [13:09:45<3024:35:42, 11.09s/it, lr=1e-5, step_loss=0.00729][RANK-0]: Step: [18179], local_loss=0.0026243345346301794, train_loss=0.020435690879821777, time_cost=5.47660231590271
Steps:   2%|▏         | 18179/1000000 [13:09:45<3024:35:42, 11.09s/it, lr=1e-5, step_loss=0.00262]Steps:   2%|▏         | 18180/1000000 [13:09:49<2477:35:42,  9.08s/it, lr=1e-5, step_loss=0.00262][RANK-0]: Step: [18180], local_loss=0.018984168767929077, train_loss=0.06349588930606842, time_cost=1.7351298332214355
Steps:   2%|▏         | 18180/1000000 [13:09:49<2477:35:42,  9.08s/it, lr=1e-5, step_loss=0.019]  Steps:   2%|▏         | 18181/1000000 [13:09:58<2478:03:53,  9.09s/it, lr=1e-5, step_loss=0.019][RANK-0]: Step: [18181], local_loss=0.034598346799612045, train_loss=0.0497102290391922, time_cost=1.960754156112671
Steps:   2%|▏         | 18181/1000000 [13:09:58<2478:03:53,  9.09s/it, lr=1e-5, step_loss=0.0346]Steps:   2%|▏         | 18182/1000000 [13:10:07<2498:35:05,  9.16s/it, lr=1e-5, step_loss=0.0346][RANK-0]: Step: [18182], local_loss=0.07421636581420898, train_loss=0.03189878165721893, time_cost=3.5339815616607666
Steps:   2%|▏         | 18182/1000000 [13:10:07<2498:35:05,  9.16s/it, lr=1e-5, step_loss=0.0742]Steps:   2%|▏         | 18183/1000000 [13:10:16<2491:32:31,  9.14s/it, lr=1e-5, step_loss=0.0742][RANK-0]: Step: [18183], local_loss=0.2589266002178192, train_loss=0.07392262667417526, time_cost=6.871935844421387
Steps:   2%|▏         | 18183/1000000 [13:10:16<2491:32:31,  9.14s/it, lr=1e-5, step_loss=0.259] Steps:   2%|▏         | 18184/1000000 [13:10:28<2667:05:07,  9.78s/it, lr=1e-5, step_loss=0.259][RANK-0]: Step: [18184], local_loss=0.05131683871150017, train_loss=0.032035671174526215, time_cost=3.6549501419067383
Steps:   2%|▏         | 18184/1000000 [13:10:28<2667:05:07,  9.78s/it, lr=1e-5, step_loss=0.0513]Steps:   2%|▏         | 18185/1000000 [13:10:45<3293:44:52, 12.08s/it, lr=1e-5, step_loss=0.0513][RANK-0]: Step: [18185], local_loss=0.009033126756548882, train_loss=0.017819300293922424, time_cost=14.519775629043579
Steps:   2%|▏         | 18185/1000000 [13:10:45<3293:44:52, 12.08s/it, lr=1e-5, step_loss=0.00903]Steps:   2%|▏         | 18186/1000000 [13:10:50<2682:48:19,  9.84s/it, lr=1e-5, step_loss=0.00903][RANK-0]: Step: [18186], local_loss=0.006330321542918682, train_loss=0.19271469116210938, time_cost=1.7913281917572021
Steps:   2%|▏         | 18186/1000000 [13:10:50<2682:48:19,  9.84s/it, lr=1e-5, step_loss=0.00633]Steps:   2%|▏         | 18187/1000000 [13:11:00<2672:40:01,  9.80s/it, lr=1e-5, step_loss=0.00633][RANK-0]: Step: [18187], local_loss=0.00491942698135972, train_loss=0.023490479215979576, time_cost=3.695791721343994
Steps:   2%|▏         | 18187/1000000 [13:11:00<2672:40:01,  9.80s/it, lr=1e-5, step_loss=0.00492]Steps:   2%|▏         | 18188/1000000 [13:11:04<2277:05:48,  8.35s/it, lr=1e-5, step_loss=0.00492][RANK-0]: Step: [18188], local_loss=0.031018828973174095, train_loss=0.0334644541144371, time_cost=2.386580228805542
Steps:   2%|▏         | 18188/1000000 [13:11:04<2277:05:48,  8.35s/it, lr=1e-5, step_loss=0.031]  Steps:   2%|▏         | 18189/1000000 [13:11:18<2710:24:43,  9.94s/it, lr=1e-5, step_loss=0.031][RANK-0]: Step: [18189], local_loss=0.012328856624662876, train_loss=0.06767033040523529, time_cost=6.101442337036133
Steps:   2%|▏         | 18189/1000000 [13:11:18<2710:24:43,  9.94s/it, lr=1e-5, step_loss=0.0123]Steps:   2%|▏         | 18190/1000000 [13:11:23<2322:35:37,  8.52s/it, lr=1e-5, step_loss=0.0123][RANK-0]: Step: [18190], local_loss=0.01329047605395317, train_loss=0.013187378644943237, time_cost=2.2424449920654297
Steps:   2%|▏         | 18190/1000000 [13:11:23<2322:35:37,  8.52s/it, lr=1e-5, step_loss=0.0133]Steps:   2%|▏         | 18191/1000000 [13:11:37<2747:04:39, 10.07s/it, lr=1e-5, step_loss=0.0133][RANK-0]: Step: [18191], local_loss=0.007932107895612717, train_loss=0.015539792366325855, time_cost=5.8860554695129395
Steps:   2%|▏         | 18191/1000000 [13:11:37<2747:04:39, 10.07s/it, lr=1e-5, step_loss=0.00793]Steps:   2%|▏         | 18192/1000000 [13:11:48<2829:19:37, 10.37s/it, lr=1e-5, step_loss=0.00793][RANK-0]: Step: [18192], local_loss=0.006774603389203548, train_loss=0.01868734508752823, time_cost=1.5871937274932861
Steps:   2%|▏         | 18192/1000000 [13:11:48<2829:19:37, 10.37s/it, lr=1e-5, step_loss=0.00677]Steps:   2%|▏         | 18193/1000000 [13:11:53<2387:28:53,  8.75s/it, lr=1e-5, step_loss=0.00677][RANK-0]: Step: [18193], local_loss=0.019737444818019867, train_loss=0.01734045520424843, time_cost=1.9344372749328613
Steps:   2%|▏         | 18193/1000000 [13:11:53<2387:28:53,  8.75s/it, lr=1e-5, step_loss=0.0197] Steps:   2%|▏         | 18194/1000000 [13:12:05<2647:46:56,  9.71s/it, lr=1e-5, step_loss=0.0197][RANK-0]: Step: [18194], local_loss=0.07256454974412918, train_loss=0.057274267077445984, time_cost=1.2111947536468506
Steps:   2%|▏         | 18194/1000000 [13:12:05<2647:46:56,  9.71s/it, lr=1e-5, step_loss=0.0726]Steps:   2%|▏         | 18195/1000000 [13:12:15<2689:54:36,  9.86s/it, lr=1e-5, step_loss=0.0726][RANK-0]: Step: [18195], local_loss=0.04856255277991295, train_loss=0.027812041342258453, time_cost=2.9715116024017334
Steps:   2%|▏         | 18195/1000000 [13:12:15<2689:54:36,  9.86s/it, lr=1e-5, step_loss=0.0486]Steps:   2%|▏         | 18196/1000000 [13:12:30<3088:23:52, 11.32s/it, lr=1e-5, step_loss=0.0486][RANK-0]: Step: [18196], local_loss=0.02726825699210167, train_loss=0.022549565881490707, time_cost=3.230879783630371
Steps:   2%|▏         | 18196/1000000 [13:12:30<3088:23:52, 11.32s/it, lr=1e-5, step_loss=0.0273]Steps:   2%|▏         | 18197/1000000 [13:12:39<2917:26:11, 10.70s/it, lr=1e-5, step_loss=0.0273][RANK-0]: Step: [18197], local_loss=0.02641266956925392, train_loss=0.023282000795006752, time_cost=2.3216824531555176
Steps:   2%|▏         | 18197/1000000 [13:12:39<2917:26:11, 10.70s/it, lr=1e-5, step_loss=0.0264]Steps:   2%|▏         | 18198/1000000 [13:12:48<2798:11:45, 10.26s/it, lr=1e-5, step_loss=0.0264][RANK-0]: Step: [18198], local_loss=0.018710564821958542, train_loss=0.07191748917102814, time_cost=7.252506971359253
Steps:   2%|▏         | 18198/1000000 [13:12:48<2798:11:45, 10.26s/it, lr=1e-5, step_loss=0.0187]Steps:   2%|▏         | 18199/1000000 [13:12:54<2406:32:08,  8.82s/it, lr=1e-5, step_loss=0.0187][RANK-0]: Step: [18199], local_loss=0.05575239658355713, train_loss=0.036965616047382355, time_cost=1.6456592082977295
Steps:   2%|▏         | 18199/1000000 [13:12:54<2406:32:08,  8.82s/it, lr=1e-5, step_loss=0.0558]Steps:   2%|▏         | 18200/1000000 [13:13:04<2542:45:23,  9.32s/it, lr=1e-5, step_loss=0.0558][RANK-0]: Step: [18200], local_loss=0.04244329407811165, train_loss=0.06397491693496704, time_cost=1.576612949371338
Steps:   2%|▏         | 18200/1000000 [13:13:04<2542:45:23,  9.32s/it, lr=1e-5, step_loss=0.0424]Steps:   2%|▏         | 18201/1000000 [13:13:12<2391:12:09,  8.77s/it, lr=1e-5, step_loss=0.0424][RANK-0]: Step: [18201], local_loss=0.016882797703146935, train_loss=0.057430461049079895, time_cost=2.5326220989227295
Steps:   2%|▏         | 18201/1000000 [13:13:12<2391:12:09,  8.77s/it, lr=1e-5, step_loss=0.0169]Steps:   2%|▏         | 18202/1000000 [13:13:27<2878:16:18, 10.55s/it, lr=1e-5, step_loss=0.0169][RANK-0]: Step: [18202], local_loss=0.07865499705076218, train_loss=0.04606262594461441, time_cost=7.521785736083984
Steps:   2%|▏         | 18202/1000000 [13:13:27<2878:16:18, 10.55s/it, lr=1e-5, step_loss=0.0787]Steps:   2%|▏         | 18203/1000000 [13:13:35<2674:38:32,  9.81s/it, lr=1e-5, step_loss=0.0787][RANK-0]: Step: [18203], local_loss=0.03113398514688015, train_loss=0.02686055563390255, time_cost=4.0263307094573975
Steps:   2%|▏         | 18203/1000000 [13:13:35<2674:38:32,  9.81s/it, lr=1e-5, step_loss=0.0311]Steps:   2%|▏         | 18204/1000000 [13:13:39<2221:11:27,  8.14s/it, lr=1e-5, step_loss=0.0311][RANK-0]: Step: [18204], local_loss=0.04953749105334282, train_loss=0.02475406602025032, time_cost=1.8042175769805908
Steps:   2%|▏         | 18204/1000000 [13:13:39<2221:11:27,  8.14s/it, lr=1e-5, step_loss=0.0495]Steps:   2%|▏         | 18205/1000000 [13:13:54<2816:47:32, 10.33s/it, lr=1e-5, step_loss=0.0495][RANK-0]: Step: [18205], local_loss=0.04174800217151642, train_loss=0.03916594386100769, time_cost=9.760315418243408
Steps:   2%|▏         | 18205/1000000 [13:13:54<2816:47:32, 10.33s/it, lr=1e-5, step_loss=0.0417]Steps:   2%|▏         | 18206/1000000 [13:14:00<2456:10:02,  9.01s/it, lr=1e-5, step_loss=0.0417][RANK-0]: Step: [18206], local_loss=0.07433898746967316, train_loss=0.029432352632284164, time_cost=1.4665484428405762
Steps:   2%|▏         | 18206/1000000 [13:14:00<2456:10:02,  9.01s/it, lr=1e-5, step_loss=0.0743]Steps:   2%|▏         | 18207/1000000 [13:14:05<2096:26:57,  7.69s/it, lr=1e-5, step_loss=0.0743][RANK-0]: Step: [18207], local_loss=0.8713523149490356, train_loss=0.12840136885643005, time_cost=1.874584674835205
Steps:   2%|▏         | 18207/1000000 [13:14:05<2096:26:57,  7.69s/it, lr=1e-5, step_loss=0.871] Steps:   2%|▏         | 18208/1000000 [13:14:10<1878:22:09,  6.89s/it, lr=1e-5, step_loss=0.871][RANK-0]: Step: [18208], local_loss=0.05851798504590988, train_loss=0.2115682065486908, time_cost=1.53047513961792
Steps:   2%|▏         | 18208/1000000 [13:14:10<1878:22:09,  6.89s/it, lr=1e-5, step_loss=0.0585]Steps:   2%|▏         | 18209/1000000 [13:14:17<1891:59:53,  6.94s/it, lr=1e-5, step_loss=0.0585][RANK-0]: Step: [18209], local_loss=0.006879366934299469, train_loss=0.027879569679498672, time_cost=1.3255009651184082
Steps:   2%|▏         | 18209/1000000 [13:14:17<1891:59:53,  6.94s/it, lr=1e-5, step_loss=0.00688]Steps:   2%|▏         | 18210/1000000 [13:14:30<2427:13:51,  8.90s/it, lr=1e-5, step_loss=0.00688][RANK-0]: Step: [18210], local_loss=0.0038590149488300085, train_loss=0.036261819303035736, time_cost=4.821540832519531
Steps:   2%|▏         | 18210/1000000 [13:14:30<2427:13:51,  8.90s/it, lr=1e-5, step_loss=0.00386]Steps:   2%|▏         | 18211/1000000 [13:14:39<2392:38:38,  8.77s/it, lr=1e-5, step_loss=0.00386][RANK-0]: Step: [18211], local_loss=0.08980710804462433, train_loss=0.03088475950062275, time_cost=2.6469881534576416
Steps:   2%|▏         | 18211/1000000 [13:14:39<2392:38:38,  8.77s/it, lr=1e-5, step_loss=0.0898] Steps:   2%|▏         | 18212/1000000 [13:14:46<2236:11:58,  8.20s/it, lr=1e-5, step_loss=0.0898][RANK-0]: Step: [18212], local_loss=0.007541914936155081, train_loss=0.06273919343948364, time_cost=3.1898868083953857
Steps:   2%|▏         | 18212/1000000 [13:14:46<2236:11:58,  8.20s/it, lr=1e-5, step_loss=0.00754]Steps:   2%|▏         | 18213/1000000 [13:14:59<2671:50:47,  9.80s/it, lr=1e-5, step_loss=0.00754][RANK-0]: Step: [18213], local_loss=0.010594048537313938, train_loss=0.020503828302025795, time_cost=3.837414026260376
Steps:   2%|▏         | 18213/1000000 [13:14:59<2671:50:47,  9.80s/it, lr=1e-5, step_loss=0.0106] Steps:   2%|▏         | 18214/1000000 [13:15:04<2228:28:57,  8.17s/it, lr=1e-5, step_loss=0.0106][RANK-0]: Step: [18214], local_loss=0.045643482357263565, train_loss=0.023809440433979034, time_cost=2.0329649448394775
Steps:   2%|▏         | 18214/1000000 [13:15:04<2228:28:57,  8.17s/it, lr=1e-5, step_loss=0.0456]Steps:   2%|▏         | 18215/1000000 [13:15:17<2662:59:26,  9.76s/it, lr=1e-5, step_loss=0.0456][RANK-0]: Step: [18215], local_loss=0.1040508970618248, train_loss=0.027703436091542244, time_cost=4.285916328430176
Steps:   2%|▏         | 18215/1000000 [13:15:17<2662:59:26,  9.76s/it, lr=1e-5, step_loss=0.104] Steps:   2%|▏         | 18216/1000000 [13:15:30<2885:09:12, 10.58s/it, lr=1e-5, step_loss=0.104][RANK-0]: Step: [18216], local_loss=0.017433296889066696, train_loss=0.030642617493867874, time_cost=4.686971187591553
Steps:   2%|▏         | 18216/1000000 [13:15:30<2885:09:12, 10.58s/it, lr=1e-5, step_loss=0.0174]Steps:   2%|▏         | 18217/1000000 [13:15:40<2880:52:51, 10.56s/it, lr=1e-5, step_loss=0.0174][RANK-0]: Step: [18217], local_loss=0.02385997213423252, train_loss=0.0533732995390892, time_cost=4.335027694702148
Steps:   2%|▏         | 18217/1000000 [13:15:40<2880:52:51, 10.56s/it, lr=1e-5, step_loss=0.0239]Steps:   2%|▏         | 18218/1000000 [13:15:45<2439:49:06,  8.95s/it, lr=1e-5, step_loss=0.0239][RANK-0]: Step: [18218], local_loss=0.3154400587081909, train_loss=0.05492938682436943, time_cost=2.4623863697052
Steps:   2%|▏         | 18218/1000000 [13:15:45<2439:49:06,  8.95s/it, lr=1e-5, step_loss=0.315] Steps:   2%|▏         | 18219/1000000 [13:15:51<2179:00:37,  7.99s/it, lr=1e-5, step_loss=0.315][RANK-0]: Step: [18219], local_loss=0.032036855816841125, train_loss=0.08009522408246994, time_cost=1.5059797763824463
Steps:   2%|▏         | 18219/1000000 [13:15:51<2179:00:37,  7.99s/it, lr=1e-5, step_loss=0.032]Steps:   2%|▏         | 18220/1000000 [13:15:57<2017:41:09,  7.40s/it, lr=1e-5, step_loss=0.032][RANK-0]: Step: [18220], local_loss=0.013036358170211315, train_loss=0.1084657832980156, time_cost=1.818274974822998
Steps:   2%|▏         | 18220/1000000 [13:15:57<2017:41:09,  7.40s/it, lr=1e-5, step_loss=0.013]Steps:   2%|▏         | 18221/1000000 [13:16:08<2303:48:07,  8.45s/it, lr=1e-5, step_loss=0.013][RANK-0]: Step: [18221], local_loss=0.04620731994509697, train_loss=0.08392614126205444, time_cost=2.898996591567993
Steps:   2%|▏         | 18221/1000000 [13:16:08<2303:48:07,  8.45s/it, lr=1e-5, step_loss=0.0462]Steps:   2%|▏         | 18222/1000000 [13:16:19<2473:39:34,  9.07s/it, lr=1e-5, step_loss=0.0462][RANK-0]: Step: [18222], local_loss=0.05044595152139664, train_loss=0.02520740032196045, time_cost=1.2276723384857178
Steps:   2%|▏         | 18222/1000000 [13:16:19<2473:39:34,  9.07s/it, lr=1e-5, step_loss=0.0504]Steps:   2%|▏         | 18223/1000000 [13:16:24<2149:03:32,  7.88s/it, lr=1e-5, step_loss=0.0504][RANK-0]: Step: [18223], local_loss=0.008232327178120613, train_loss=0.014657719060778618, time_cost=2.326227903366089
Steps:   2%|▏         | 18223/1000000 [13:16:24<2149:03:32,  7.88s/it, lr=1e-5, step_loss=0.00823]Steps:   2%|▏         | 18224/1000000 [13:16:28<1852:22:23,  6.79s/it, lr=1e-5, step_loss=0.00823][RANK-0]: Step: [18224], local_loss=0.06790313124656677, train_loss=0.042823560535907745, time_cost=1.4946677684783936
Steps:   2%|▏         | 18224/1000000 [13:16:28<1852:22:23,  6.79s/it, lr=1e-5, step_loss=0.0679] Steps:   2%|▏         | 18225/1000000 [13:16:38<2151:55:42,  7.89s/it, lr=1e-5, step_loss=0.0679][RANK-0]: Step: [18225], local_loss=0.04235704988241196, train_loss=0.1596534550189972, time_cost=2.8861896991729736
Steps:   2%|▏         | 18225/1000000 [13:16:38<2151:55:42,  7.89s/it, lr=1e-5, step_loss=0.0424]Steps:   2%|▏         | 18226/1000000 [13:16:51<2567:40:20,  9.42s/it, lr=1e-5, step_loss=0.0424][RANK-0]: Step: [18226], local_loss=0.027558963745832443, train_loss=0.04286317154765129, time_cost=5.0060272216796875
Steps:   2%|▏         | 18226/1000000 [13:16:51<2567:40:20,  9.42s/it, lr=1e-5, step_loss=0.0276]Steps:   2%|▏         | 18227/1000000 [13:16:59<2384:37:11,  8.74s/it, lr=1e-5, step_loss=0.0276][RANK-0]: Step: [18227], local_loss=0.016670845448970795, train_loss=0.05371379852294922, time_cost=2.902592897415161
Steps:   2%|▏         | 18227/1000000 [13:16:59<2384:37:11,  8.74s/it, lr=1e-5, step_loss=0.0167]Steps:   2%|▏         | 18228/1000000 [13:17:09<2504:56:57,  9.19s/it, lr=1e-5, step_loss=0.0167][RANK-0]: Step: [18228], local_loss=0.03507485240697861, train_loss=0.025228215381503105, time_cost=1.7840416431427002
Steps:   2%|▏         | 18228/1000000 [13:17:09<2504:56:57,  9.19s/it, lr=1e-5, step_loss=0.0351]Steps:   2%|▏         | 18229/1000000 [13:17:13<2101:55:22,  7.71s/it, lr=1e-5, step_loss=0.0351][RANK-0]: Step: [18229], local_loss=0.02072945423424244, train_loss=0.022406432777643204, time_cost=1.223726511001587
Steps:   2%|▏         | 18229/1000000 [13:17:13<2101:55:22,  7.71s/it, lr=1e-5, step_loss=0.0207]Steps:   2%|▏         | 18230/1000000 [13:17:21<2106:22:21,  7.72s/it, lr=1e-5, step_loss=0.0207][RANK-0]: Step: [18230], local_loss=0.005896301940083504, train_loss=0.04408491775393486, time_cost=3.780560255050659
Steps:   2%|▏         | 18230/1000000 [13:17:21<2106:22:21,  7.72s/it, lr=1e-5, step_loss=0.0059]Steps:   2%|▏         | 18231/1000000 [13:17:26<1890:45:31,  6.93s/it, lr=1e-5, step_loss=0.0059][RANK-0]: Step: [18231], local_loss=0.03564104437828064, train_loss=0.02055257558822632, time_cost=1.499140977859497
Steps:   2%|▏         | 18231/1000000 [13:17:26<1890:45:31,  6.93s/it, lr=1e-5, step_loss=0.0356]Steps:   2%|▏         | 18232/1000000 [13:17:35<2086:06:24,  7.65s/it, lr=1e-5, step_loss=0.0356][RANK-0]: Step: [18232], local_loss=0.04132828861474991, train_loss=0.02408253401517868, time_cost=7.822662591934204
Steps:   2%|▏         | 18232/1000000 [13:17:35<2086:06:24,  7.65s/it, lr=1e-5, step_loss=0.0413]Steps:   2%|▏         | 18233/1000000 [13:17:49<2572:14:52,  9.43s/it, lr=1e-5, step_loss=0.0413][RANK-0]: Step: [18233], local_loss=0.00906942319124937, train_loss=0.01854204759001732, time_cost=1.2135941982269287
Steps:   2%|▏         | 18233/1000000 [13:17:49<2572:14:52,  9.43s/it, lr=1e-5, step_loss=0.00907]Steps:   2%|▏         | 18234/1000000 [13:18:05<3100:42:19, 11.37s/it, lr=1e-5, step_loss=0.00907][RANK-0]: Step: [18234], local_loss=0.007118017412722111, train_loss=0.008029108867049217, time_cost=7.142882347106934
Steps:   2%|▏         | 18234/1000000 [13:18:05<3100:42:19, 11.37s/it, lr=1e-5, step_loss=0.00712]Steps:   2%|▏         | 18235/1000000 [13:18:15<2988:23:17, 10.96s/it, lr=1e-5, step_loss=0.00712][RANK-0]: Step: [18235], local_loss=0.014825109392404556, train_loss=0.019622020423412323, time_cost=5.422454595565796
Steps:   2%|▏         | 18235/1000000 [13:18:15<2988:23:17, 10.96s/it, lr=1e-5, step_loss=0.0148] Steps:   2%|▏         | 18236/1000000 [13:18:20<2551:15:26,  9.36s/it, lr=1e-5, step_loss=0.0148][RANK-0]: Step: [18236], local_loss=0.05262140929698944, train_loss=0.02242320217192173, time_cost=2.4438021183013916
Steps:   2%|▏         | 18236/1000000 [13:18:20<2551:15:26,  9.36s/it, lr=1e-5, step_loss=0.0526]Steps:   2%|▏         | 18237/1000000 [13:18:30<2565:20:33,  9.41s/it, lr=1e-5, step_loss=0.0526][RANK-0]: Step: [18237], local_loss=0.029404599219560623, train_loss=0.0785069689154625, time_cost=1.6473801136016846
Steps:   2%|▏         | 18237/1000000 [13:18:30<2565:20:33,  9.41s/it, lr=1e-5, step_loss=0.0294]Steps:   2%|▏         | 18238/1000000 [13:18:42<2776:00:32, 10.18s/it, lr=1e-5, step_loss=0.0294][RANK-0]: Step: [18238], local_loss=0.026647958904504776, train_loss=0.026873895898461342, time_cost=3.985995054244995
Steps:   2%|▏         | 18238/1000000 [13:18:42<2776:00:32, 10.18s/it, lr=1e-5, step_loss=0.0266]Steps:   2%|▏         | 18239/1000000 [13:18:46<2285:34:41,  8.38s/it, lr=1e-5, step_loss=0.0266][RANK-0]: Step: [18239], local_loss=0.009586872532963753, train_loss=0.05673127993941307, time_cost=1.221010684967041
Steps:   2%|▏         | 18239/1000000 [13:18:46<2285:34:41,  8.38s/it, lr=1e-5, step_loss=0.00959]Steps:   2%|▏         | 18240/1000000 [13:19:00<2727:05:07, 10.00s/it, lr=1e-5, step_loss=0.00959][RANK-0]: Step: [18240], local_loss=0.8028590679168701, train_loss=0.1623721718788147, time_cost=5.932931423187256
Steps:   2%|▏         | 18240/1000000 [13:19:00<2727:05:07, 10.00s/it, lr=1e-5, step_loss=0.803]  Steps:   2%|▏         | 18241/1000000 [13:19:05<2343:22:17,  8.59s/it, lr=1e-5, step_loss=0.803][RANK-0]: Step: [18241], local_loss=0.008068175055086613, train_loss=0.027436677366495132, time_cost=2.422665596008301
Steps:   2%|▏         | 18241/1000000 [13:19:05<2343:22:17,  8.59s/it, lr=1e-5, step_loss=0.00807]Steps:   2%|▏         | 18242/1000000 [13:19:13<2272:15:30,  8.33s/it, lr=1e-5, step_loss=0.00807][RANK-0]: Step: [18242], local_loss=0.0035130148753523827, train_loss=0.18553197383880615, time_cost=3.976341724395752
Steps:   2%|▏         | 18242/1000000 [13:19:13<2272:15:30,  8.33s/it, lr=1e-5, step_loss=0.00351]Steps:   2%|▏         | 18243/1000000 [13:19:25<2582:38:32,  9.47s/it, lr=1e-5, step_loss=0.00351][RANK-0]: Step: [18243], local_loss=0.08343058824539185, train_loss=0.10802359879016876, time_cost=3.0108273029327393
Steps:   2%|▏         | 18243/1000000 [13:19:25<2582:38:32,  9.47s/it, lr=1e-5, step_loss=0.0834] Steps:   2%|▏         | 18244/1000000 [13:19:32<2368:56:38,  8.69s/it, lr=1e-5, step_loss=0.0834][RANK-0]: Step: [18244], local_loss=0.029221605509519577, train_loss=0.022740164771676064, time_cost=2.2538342475891113
Steps:   2%|▏         | 18244/1000000 [13:19:32<2368:56:38,  8.69s/it, lr=1e-5, step_loss=0.0292]Steps:   2%|▏         | 18245/1000000 [13:19:41<2389:09:00,  8.76s/it, lr=1e-5, step_loss=0.0292][RANK-0]: Step: [18245], local_loss=0.009345479309558868, train_loss=0.048889052122831345, time_cost=2.963603973388672
Steps:   2%|▏         | 18245/1000000 [13:19:41<2389:09:00,  8.76s/it, lr=1e-5, step_loss=0.00935]Steps:   2%|▏         | 18246/1000000 [13:19:49<2321:08:37,  8.51s/it, lr=1e-5, step_loss=0.00935][RANK-0]: Step: [18246], local_loss=0.006636491045355797, train_loss=0.03144994378089905, time_cost=4.267294406890869
Steps:   2%|▏         | 18246/1000000 [13:19:49<2321:08:37,  8.51s/it, lr=1e-5, step_loss=0.00664]Steps:   2%|▏         | 18247/1000000 [13:19:58<2404:34:41,  8.82s/it, lr=1e-5, step_loss=0.00664][RANK-0]: Step: [18247], local_loss=0.03638343885540962, train_loss=0.09416626393795013, time_cost=3.5908186435699463
Steps:   2%|▏         | 18247/1000000 [13:19:58<2404:34:41,  8.82s/it, lr=1e-5, step_loss=0.0364] Steps:   2%|▏         | 18248/1000000 [13:20:13<2879:08:18, 10.56s/it, lr=1e-5, step_loss=0.0364][RANK-0]: Step: [18248], local_loss=0.23244942724704742, train_loss=0.057009607553482056, time_cost=5.537808179855347
Steps:   2%|▏         | 18248/1000000 [13:20:13<2879:08:18, 10.56s/it, lr=1e-5, step_loss=0.232] Steps:   2%|▏         | 18249/1000000 [13:20:18<2456:25:07,  9.01s/it, lr=1e-5, step_loss=0.232][RANK-0]: Step: [18249], local_loss=0.007701480761170387, train_loss=0.014532959088683128, time_cost=2.719228982925415
Steps:   2%|▏         | 18249/1000000 [13:20:18<2456:25:07,  9.01s/it, lr=1e-5, step_loss=0.0077]Steps:   2%|▏         | 18250/1000000 [13:20:28<2498:17:30,  9.16s/it, lr=1e-5, step_loss=0.0077][RANK-0]: Step: [18250], local_loss=0.00693521648645401, train_loss=0.02530178613960743, time_cost=4.0996246337890625
Steps:   2%|▏         | 18250/1000000 [13:20:28<2498:17:30,  9.16s/it, lr=1e-5, step_loss=0.00694]Steps:   2%|▏         | 18251/1000000 [13:20:33<2147:17:19,  7.87s/it, lr=1e-5, step_loss=0.00694][RANK-0]: Step: [18251], local_loss=0.011745452880859375, train_loss=0.10033602267503738, time_cost=1.9636869430541992
Steps:   2%|▏         | 18251/1000000 [13:20:33<2147:17:19,  7.87s/it, lr=1e-5, step_loss=0.0117] Steps:   2%|▏         | 18252/1000000 [13:20:44<2425:36:48,  8.89s/it, lr=1e-5, step_loss=0.0117][RANK-0]: Step: [18252], local_loss=0.004249457735568285, train_loss=0.02418951876461506, time_cost=2.327040672302246
Steps:   2%|▏         | 18252/1000000 [13:20:44<2425:36:48,  8.89s/it, lr=1e-5, step_loss=0.00425]Steps:   2%|▏         | 18253/1000000 [13:20:53<2461:18:59,  9.03s/it, lr=1e-5, step_loss=0.00425][RANK-0]: Step: [18253], local_loss=0.1413460522890091, train_loss=0.03325413912534714, time_cost=2.0960938930511475
Steps:   2%|▏         | 18253/1000000 [13:20:53<2461:18:59,  9.03s/it, lr=1e-5, step_loss=0.141]  Steps:   2%|▏         | 18254/1000000 [13:21:05<2726:30:17, 10.00s/it, lr=1e-5, step_loss=0.141][RANK-0]: Step: [18254], local_loss=0.0634334608912468, train_loss=0.03238895907998085, time_cost=1.2297554016113281
Steps:   2%|▏         | 18254/1000000 [13:21:05<2726:30:17, 10.00s/it, lr=1e-5, step_loss=0.0634]Steps:   2%|▏         | 18255/1000000 [13:21:22<3251:27:14, 11.92s/it, lr=1e-5, step_loss=0.0634][RANK-0]: Step: [18255], local_loss=0.005382951349020004, train_loss=0.10066655278205872, time_cost=8.318339824676514
Steps:   2%|▏         | 18255/1000000 [13:21:22<3251:27:14, 11.92s/it, lr=1e-5, step_loss=0.00538]Steps:   2%|▏         | 18256/1000000 [13:21:28<2751:55:04, 10.09s/it, lr=1e-5, step_loss=0.00538][RANK-0]: Step: [18256], local_loss=0.025225810706615448, train_loss=0.025507498532533646, time_cost=1.3672480583190918
Steps:   2%|▏         | 18256/1000000 [13:21:28<2751:55:04, 10.09s/it, lr=1e-5, step_loss=0.0252] Steps:   2%|▏         | 18257/1000000 [13:21:38<2781:56:42, 10.20s/it, lr=1e-5, step_loss=0.0252][RANK-0]: Step: [18257], local_loss=0.007917089387774467, train_loss=0.04967004805803299, time_cost=7.76461124420166
Steps:   2%|▏         | 18257/1000000 [13:21:38<2781:56:42, 10.20s/it, lr=1e-5, step_loss=0.00792]Steps:   2%|▏         | 18258/1000000 [13:21:49<2875:48:23, 10.55s/it, lr=1e-5, step_loss=0.00792][RANK-0]: Step: [18258], local_loss=0.05155472457408905, train_loss=0.026927240192890167, time_cost=4.060027122497559
Steps:   2%|▏         | 18258/1000000 [13:21:49<2875:48:23, 10.55s/it, lr=1e-5, step_loss=0.0516] Steps:   2%|▏         | 18259/1000000 [13:21:55<2476:23:14,  9.08s/it, lr=1e-5, step_loss=0.0516][RANK-0]: Step: [18259], local_loss=0.012835858389735222, train_loss=0.06815233826637268, time_cost=1.74680757522583
Steps:   2%|▏         | 18259/1000000 [13:21:55<2476:23:14,  9.08s/it, lr=1e-5, step_loss=0.0128]Steps:   2%|▏         | 18260/1000000 [13:22:08<2800:19:07, 10.27s/it, lr=1e-5, step_loss=0.0128][RANK-0]: Step: [18260], local_loss=0.00496422965079546, train_loss=39.082698822021484, time_cost=1.5522103309631348
Steps:   2%|▏         | 18260/1000000 [13:22:08<2800:19:07, 10.27s/it, lr=1e-5, step_loss=0.00496]Steps:   2%|▏         | 18261/1000000 [13:22:22<3070:56:46, 11.26s/it, lr=1e-5, step_loss=0.00496][RANK-0]: Step: [18261], local_loss=0.007654671091586351, train_loss=0.05808160826563835, time_cost=2.538212537765503
Steps:   2%|▏         | 18261/1000000 [13:22:22<3070:56:46, 11.26s/it, lr=1e-5, step_loss=0.00765]Steps:   2%|▏         | 18262/1000000 [13:22:31<2946:37:24, 10.81s/it, lr=1e-5, step_loss=0.00765][RANK-0]: Step: [18262], local_loss=0.0044708093628287315, train_loss=0.011139003559947014, time_cost=6.960188627243042
Steps:   2%|▏         | 18262/1000000 [13:22:31<2946:37:24, 10.81s/it, lr=1e-5, step_loss=0.00447]Steps:   2%|▏         | 18263/1000000 [13:22:42<2930:46:43, 10.75s/it, lr=1e-5, step_loss=0.00447][RANK-0]: Step: [18263], local_loss=0.04210379347205162, train_loss=0.02380547486245632, time_cost=1.7851231098175049
Steps:   2%|▏         | 18263/1000000 [13:22:42<2930:46:43, 10.75s/it, lr=1e-5, step_loss=0.0421] Steps:   2%|▏         | 18264/1000000 [13:22:51<2774:54:47, 10.18s/it, lr=1e-5, step_loss=0.0421][RANK-0]: Step: [18264], local_loss=0.02808733843266964, train_loss=0.05903425067663193, time_cost=2.3139851093292236
Steps:   2%|▏         | 18264/1000000 [13:22:51<2774:54:47, 10.18s/it, lr=1e-5, step_loss=0.0281]Steps:   2%|▏         | 18265/1000000 [13:22:56<2389:49:39,  8.76s/it, lr=1e-5, step_loss=0.0281][RANK-0]: Step: [18265], local_loss=0.013399798423051834, train_loss=0.03928293660283089, time_cost=3.1227941513061523
Steps:   2%|▏         | 18265/1000000 [13:22:56<2389:49:39,  8.76s/it, lr=1e-5, step_loss=0.0134]Steps:   2%|▏         | 18266/1000000 [13:23:11<2897:48:29, 10.63s/it, lr=1e-5, step_loss=0.0134][RANK-0]: Step: [18266], local_loss=0.02159915864467621, train_loss=0.04786066710948944, time_cost=1.5667078495025635
Steps:   2%|▏         | 18266/1000000 [13:23:11<2897:48:29, 10.63s/it, lr=1e-5, step_loss=0.0216]Steps:   2%|▏         | 18267/1000000 [13:23:16<2448:53:42,  8.98s/it, lr=1e-5, step_loss=0.0216][RANK-0]: Step: [18267], local_loss=0.00762158865109086, train_loss=0.05867950990796089, time_cost=1.3873193264007568
Steps:   2%|▏         | 18267/1000000 [13:23:16<2448:53:42,  8.98s/it, lr=1e-5, step_loss=0.00762]Steps:   2%|▏         | 18268/1000000 [13:23:30<2845:21:01, 10.43s/it, lr=1e-5, step_loss=0.00762][RANK-0]: Step: [18268], local_loss=0.039832498878240585, train_loss=0.03032878413796425, time_cost=5.817519664764404
Steps:   2%|▏         | 18268/1000000 [13:23:30<2845:21:01, 10.43s/it, lr=1e-5, step_loss=0.0398] Steps:   2%|▏         | 18269/1000000 [13:23:41<2880:04:15, 10.56s/it, lr=1e-5, step_loss=0.0398][RANK-0]: Step: [18269], local_loss=0.008403963409364223, train_loss=0.04050463065505028, time_cost=4.113060474395752
Steps:   2%|▏         | 18269/1000000 [13:23:41<2880:04:15, 10.56s/it, lr=1e-5, step_loss=0.0084]Steps:   2%|▏         | 18270/1000000 [13:23:46<2374:38:06,  8.71s/it, lr=1e-5, step_loss=0.0084][RANK-0]: Step: [18270], local_loss=0.008667237125337124, train_loss=0.02405361831188202, time_cost=1.5617890357971191
Steps:   2%|▏         | 18270/1000000 [13:23:46<2374:38:06,  8.71s/it, lr=1e-5, step_loss=0.00867]Steps:   2%|▏         | 18271/1000000 [13:23:51<2107:37:26,  7.73s/it, lr=1e-5, step_loss=0.00867][RANK-0]: Step: [18271], local_loss=0.0074485717341303825, train_loss=0.06037013232707977, time_cost=2.3457791805267334
Steps:   2%|▏         | 18271/1000000 [13:23:51<2107:37:26,  7.73s/it, lr=1e-5, step_loss=0.00745]Steps:   2%|▏         | 18272/1000000 [13:23:57<1925:55:56,  7.06s/it, lr=1e-5, step_loss=0.00745][RANK-0]: Step: [18272], local_loss=0.010516317561268806, train_loss=0.08617115765810013, time_cost=2.217813014984131
Steps:   2%|▏         | 18272/1000000 [13:23:57<1925:55:56,  7.06s/it, lr=1e-5, step_loss=0.0105] Steps:   2%|▏         | 18273/1000000 [13:24:02<1761:16:06,  6.46s/it, lr=1e-5, step_loss=0.0105][RANK-0]: Step: [18273], local_loss=0.06393295526504517, train_loss=0.04154984652996063, time_cost=3.8496599197387695
Steps:   2%|▏         | 18273/1000000 [13:24:02<1761:16:06,  6.46s/it, lr=1e-5, step_loss=0.0639]Steps:   2%|▏         | 18274/1000000 [13:24:07<1701:36:46,  6.24s/it, lr=1e-5, step_loss=0.0639][RANK-0]: Step: [18274], local_loss=0.008249446749687195, train_loss=0.032304756343364716, time_cost=3.1206881999969482
Steps:   2%|▏         | 18274/1000000 [13:24:07<1701:36:46,  6.24s/it, lr=1e-5, step_loss=0.00825]Steps:   2%|▏         | 18275/1000000 [13:24:16<1921:44:46,  7.05s/it, lr=1e-5, step_loss=0.00825][RANK-0]: Step: [18275], local_loss=0.012710154056549072, train_loss=0.021678339689970016, time_cost=1.71012282371521
Steps:   2%|▏         | 18275/1000000 [13:24:16<1921:44:46,  7.05s/it, lr=1e-5, step_loss=0.0127] Steps:   2%|▏         | 18276/1000000 [13:24:22<1847:42:30,  6.78s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [18276], local_loss=0.07891883701086044, train_loss=0.027955494821071625, time_cost=4.372750282287598
Steps:   2%|▏         | 18276/1000000 [13:24:22<1847:42:30,  6.78s/it, lr=1e-5, step_loss=0.0789]Steps:   2%|▏         | 18277/1000000 [13:24:27<1704:00:37,  6.25s/it, lr=1e-5, step_loss=0.0789][RANK-0]: Step: [18277], local_loss=0.013735580258071423, train_loss=0.06428004801273346, time_cost=2.56070613861084
Steps:   2%|▏         | 18277/1000000 [13:24:27<1704:00:37,  6.25s/it, lr=1e-5, step_loss=0.0137]Steps:   2%|▏         | 18278/1000000 [13:24:40<2217:41:15,  8.13s/it, lr=1e-5, step_loss=0.0137][RANK-0]: Step: [18278], local_loss=0.0453418605029583, train_loss=0.0344887301325798, time_cost=3.6930623054504395
Steps:   2%|▏         | 18278/1000000 [13:24:40<2217:41:15,  8.13s/it, lr=1e-5, step_loss=0.0453]Steps:   2%|▏         | 18279/1000000 [13:24:52<2561:32:15,  9.39s/it, lr=1e-5, step_loss=0.0453][RANK-0]: Step: [18279], local_loss=0.010373787954449654, train_loss=0.016307570040225983, time_cost=5.100217580795288
Steps:   2%|▏         | 18279/1000000 [13:24:52<2561:32:15,  9.39s/it, lr=1e-5, step_loss=0.0104]Steps:   2%|▏         | 18280/1000000 [13:24:58<2278:50:20,  8.36s/it, lr=1e-5, step_loss=0.0104][RANK-0]: Step: [18280], local_loss=0.030536573380231857, train_loss=0.021642977371811867, time_cost=1.2786865234375
Steps:   2%|▏         | 18280/1000000 [13:24:58<2278:50:20,  8.36s/it, lr=1e-5, step_loss=0.0305]Steps:   2%|▏         | 18281/1000000 [13:25:09<2511:26:06,  9.21s/it, lr=1e-5, step_loss=0.0305][RANK-0]: Step: [18281], local_loss=0.026507047936320305, train_loss=0.01955418661236763, time_cost=2.776423454284668
Steps:   2%|▏         | 18281/1000000 [13:25:09<2511:26:06,  9.21s/it, lr=1e-5, step_loss=0.0265]Steps:   2%|▏         | 18282/1000000 [13:25:23<2873:36:48, 10.54s/it, lr=1e-5, step_loss=0.0265][RANK-0]: Step: [18282], local_loss=0.038423940539360046, train_loss=0.026679566130042076, time_cost=5.9999566078186035
Steps:   2%|▏         | 18282/1000000 [13:25:23<2873:36:48, 10.54s/it, lr=1e-5, step_loss=0.0384]Steps:   2%|▏         | 18283/1000000 [13:25:34<2944:54:11, 10.80s/it, lr=1e-5, step_loss=0.0384][RANK-0]: Step: [18283], local_loss=0.012417146936058998, train_loss=0.01093099731951952, time_cost=4.033362150192261
Steps:   2%|▏         | 18283/1000000 [13:25:34<2944:54:11, 10.80s/it, lr=1e-5, step_loss=0.0124]Steps:   2%|▏         | 18284/1000000 [13:25:40<2501:35:02,  9.17s/it, lr=1e-5, step_loss=0.0124][RANK-0]: Step: [18284], local_loss=0.01272924616932869, train_loss=0.012890750542283058, time_cost=2.385314702987671
Steps:   2%|▏         | 18284/1000000 [13:25:40<2501:35:02,  9.17s/it, lr=1e-5, step_loss=0.0127]Steps:   2%|▏         | 18285/1000000 [13:25:45<2163:02:33,  7.93s/it, lr=1e-5, step_loss=0.0127][RANK-0]: Step: [18285], local_loss=0.015168114565312862, train_loss=0.05702533200383186, time_cost=2.1877994537353516
Steps:   2%|▏         | 18285/1000000 [13:25:45<2163:02:33,  7.93s/it, lr=1e-5, step_loss=0.0152]Steps:   2%|▏         | 18286/1000000 [13:25:50<1914:03:19,  7.02s/it, lr=1e-5, step_loss=0.0152][RANK-0]: Step: [18286], local_loss=0.031209032982587814, train_loss=0.05101520195603371, time_cost=2.0473885536193848
Steps:   2%|▏         | 18286/1000000 [13:25:50<1914:03:19,  7.02s/it, lr=1e-5, step_loss=0.0312]Steps:   2%|▏         | 18287/1000000 [13:25:57<1917:25:36,  7.03s/it, lr=1e-5, step_loss=0.0312][RANK-0]: Step: [18287], local_loss=0.19110465049743652, train_loss=0.08075180649757385, time_cost=2.1307907104492188
Steps:   2%|▏         | 18287/1000000 [13:25:57<1917:25:36,  7.03s/it, lr=1e-5, step_loss=0.191] Steps:   2%|▏         | 18288/1000000 [13:26:02<1755:15:56,  6.44s/it, lr=1e-5, step_loss=0.191][RANK-0]: Step: [18288], local_loss=0.3357612192630768, train_loss=0.09112051129341125, time_cost=2.574532985687256
Steps:   2%|▏         | 18288/1000000 [13:26:02<1755:15:56,  6.44s/it, lr=1e-5, step_loss=0.336]Steps:   2%|▏         | 18289/1000000 [13:26:07<1646:51:54,  6.04s/it, lr=1e-5, step_loss=0.336][RANK-0]: Step: [18289], local_loss=0.03890828415751457, train_loss=0.03511017560958862, time_cost=3.139523983001709
Steps:   2%|▏         | 18289/1000000 [13:26:07<1646:51:54,  6.04s/it, lr=1e-5, step_loss=0.0389]Steps:   2%|▏         | 18290/1000000 [13:26:12<1555:46:04,  5.71s/it, lr=1e-5, step_loss=0.0389][RANK-0]: Step: [18290], local_loss=0.008316083811223507, train_loss=0.05562715604901314, time_cost=2.7619786262512207
Steps:   2%|▏         | 18290/1000000 [13:26:12<1555:46:04,  5.71s/it, lr=1e-5, step_loss=0.00832]Steps:   2%|▏         | 18291/1000000 [13:26:16<1452:18:41,  5.33s/it, lr=1e-5, step_loss=0.00832][RANK-0]: Step: [18291], local_loss=0.05923028662800789, train_loss=0.04662489518523216, time_cost=1.8636465072631836
Steps:   2%|▏         | 18291/1000000 [13:26:16<1452:18:41,  5.33s/it, lr=1e-5, step_loss=0.0592] Steps:   2%|▏         | 18292/1000000 [13:26:23<1575:04:27,  5.78s/it, lr=1e-5, step_loss=0.0592][RANK-0]: Step: [18292], local_loss=0.006395383737981319, train_loss=0.020594626665115356, time_cost=5.363509654998779
Steps:   2%|▏         | 18292/1000000 [13:26:23<1575:04:27,  5.78s/it, lr=1e-5, step_loss=0.0064]scripts/text_condition/npu/train_inpaint_sparse1d_newmodel_motion.sh: line 81:   212 Killed                  accelerate launch --config_file scripts/accelerate_configs/multi_node_example_by_deepspeed.yaml --machine_rank=${MACHINE_RANK} --main_process_ip=${MAIN_PROCESS_IP_VALUE} opensora/train/train_inpaint.py --model OpenSoraInpaint-L/122 --text_encoder_name google/mt5-xxl --cache_dir "../../cache_dir/" --dataset inpaint --data "scripts/train_data/video_data_debug.txt" --ae WFVAEModel_D8_4x8x8 --ae_path "/home/image_data/lb/Open-Sora-Plan/WFVAE_DISTILL_FORMAL" --sample_rate 1 --num_frames 93 --max_height 320 --max_width 320 --interpolation_scale_t 1.0 --interpolation_scale_h 1.0 --interpolation_scale_w 1.0 --attention_mode xformers --gradient_checkpointing --train_batch_size=1 --dataloader_num_workers 0 --gradient_accumulation_steps=1 --max_train_steps=1000000 --learning_rate=1e-5 --lr_scheduler="constant" --lr_warmup_steps=0 --mixed_precision="bf16" --report_to="wandb" --checkpointing_steps=1000 --allow_tf32 --model_max_length 512 --use_image_num 0 --use_ema --ema_start_step 0 --cfg 0.1 --noise_offset 0.0 --use_rope --skip_low_resolution --speed_factor 1.0 --ema_decay 0.9999 --drop_short_ratio 0.0 --hw_stride 32 --sparse1d --sparse_n 4 --use_motion --train_fps 16 --seed 1234 --trained_data_global_step 0 --group_data --use_decord --prediction_type "v_prediction" --rescale_betas_zero_snr --t2v_ratio 0.0 --i2v_ratio 0.0 --transition_ratio 0.0 --v2v_ratio 0.0 --Semantic_ratio 0.2 --bbox_ratio 0.2 --background_ratio 0.2 --fixed_ratio 0.1 --Semantic_expansion_ratio 0.1 --fixed_bg_ratio 0.1 --clear_video_ratio 0.0 --min_clear_ratio 0.25 --default_text_ratio 0.0 --output_dir /home/save_dir/runs/$PROJECT --pretrained_transformer_model_path "/home/image_data/captions/vpre_latest_134k/model_ema" --yolomodel_pathorname "/home/image_data/hxy/Open-Sora-Plan/opensora/dataset/yolov9c-seg.pt" --resume_from_checkpoint="/home/save_dir/runs/allinpaint_stage1/checkpoint-13000"
